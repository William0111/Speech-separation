{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import part\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "clean_mask = np.loadtxt(\"clean_mask.txt\")\n",
    "spec_train = np.loadtxt(\"spec_train.txt\")\n",
    "clean_mask_test = np.loadtxt(\"clean_mask_test.txt\")\n",
    "spec_train_test = np.loadtxt(\"spec_train_test.txt\")\n",
    "\n",
    "# data pre-processing\n",
    "X_train = spec_train\n",
    "X_test = clean_mask\n",
    "y_train = spec_train_test\n",
    "y_test = clean_mask_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(100, input_dim=2470),\n",
    "    Activation('relu'), #,sigmoid softmax\n",
    "    Dense(2470),\n",
    "    Activation('relu')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-------------------------\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "rmsprop = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(\n",
    "    optimizer= rmsprop,\n",
    "    loss = 'mean_squared_error',\n",
    "    metrics=['accuracy']#, mean_pred]\n",
    "    )\n",
    "\n",
    "print('Train-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 25 samples\n",
      "Epoch 1/1000\n",
      "75/75 [==============================] - 0s 6ms/step - loss: 0.7823 - acc: 0.0000e+00 - val_loss: 0.7580 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.7664 - acc: 0.0000e+00 - val_loss: 0.7559 - val_acc: 0.0400\n",
      "Epoch 3/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.7564 - acc: 0.0133 - val_loss: 0.7516 - val_acc: 0.0400\n",
      "Epoch 4/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.7477 - acc: 0.0133 - val_loss: 0.7503 - val_acc: 0.0400\n",
      "Epoch 5/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.7404 - acc: 0.0133 - val_loss: 0.7495 - val_acc: 0.0400\n",
      "Epoch 6/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.7340 - acc: 0.0133 - val_loss: 0.7472 - val_acc: 0.0400\n",
      "Epoch 7/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.7275 - acc: 0.0133 - val_loss: 0.7422 - val_acc: 0.0400\n",
      "Epoch 8/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.7222 - acc: 0.0133 - val_loss: 0.7405 - val_acc: 0.0400\n",
      "Epoch 9/1000\n",
      "75/75 [==============================] - 0s 236us/step - loss: 0.7162 - acc: 0.0133 - val_loss: 0.7432 - val_acc: 0.0400\n",
      "Epoch 10/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.7101 - acc: 0.0133 - val_loss: 0.7369 - val_acc: 0.0400\n",
      "Epoch 11/1000\n",
      "75/75 [==============================] - 0s 157us/step - loss: 0.7050 - acc: 0.0133 - val_loss: 0.7388 - val_acc: 0.0400\n",
      "Epoch 12/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.7003 - acc: 0.0133 - val_loss: 0.7342 - val_acc: 0.0400\n",
      "Epoch 13/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.6957 - acc: 0.0133 - val_loss: 0.7326 - val_acc: 0.0400\n",
      "Epoch 14/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.6913 - acc: 0.0133 - val_loss: 0.7326 - val_acc: 0.0400\n",
      "Epoch 15/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.6866 - acc: 0.0133 - val_loss: 0.7295 - val_acc: 0.0400\n",
      "Epoch 16/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.6815 - acc: 0.0133 - val_loss: 0.7327 - val_acc: 0.0400\n",
      "Epoch 17/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.6752 - acc: 0.0133 - val_loss: 0.7340 - val_acc: 0.0400\n",
      "Epoch 18/1000\n",
      "75/75 [==============================] - 0s 157us/step - loss: 0.6708 - acc: 0.0133 - val_loss: 0.7332 - val_acc: 0.0400\n",
      "Epoch 19/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.6647 - acc: 0.0133 - val_loss: 0.7315 - val_acc: 0.0400\n",
      "Epoch 20/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.6596 - acc: 0.0133 - val_loss: 0.7320 - val_acc: 0.0400\n",
      "Epoch 21/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.6542 - acc: 0.0133 - val_loss: 0.7299 - val_acc: 0.0400\n",
      "Epoch 22/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.6490 - acc: 0.0133 - val_loss: 0.7290 - val_acc: 0.0400\n",
      "Epoch 23/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.6456 - acc: 0.0133 - val_loss: 0.7322 - val_acc: 0.0400\n",
      "Epoch 24/1000\n",
      "75/75 [==============================] - 0s 155us/step - loss: 0.6431 - acc: 0.0133 - val_loss: 0.7362 - val_acc: 0.0400\n",
      "Epoch 25/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.6367 - acc: 0.0133 - val_loss: 0.7307 - val_acc: 0.0400\n",
      "Epoch 26/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.6354 - acc: 0.0133 - val_loss: 0.7252 - val_acc: 0.0400\n",
      "Epoch 27/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.6307 - acc: 0.0133 - val_loss: 0.7381 - val_acc: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.6270 - acc: 0.0133 - val_loss: 0.7322 - val_acc: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.6230 - acc: 0.0133 - val_loss: 0.7343 - val_acc: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.6192 - acc: 0.0133 - val_loss: 0.7303 - val_acc: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.6163 - acc: 0.0133 - val_loss: 0.7330 - val_acc: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.6133 - acc: 0.0133 - val_loss: 0.7315 - val_acc: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.6098 - acc: 0.0133 - val_loss: 0.7398 - val_acc: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.6074 - acc: 0.0133 - val_loss: 0.7329 - val_acc: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.6023 - acc: 0.0133 - val_loss: 0.7287 - val_acc: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.6003 - acc: 0.0133 - val_loss: 0.7352 - val_acc: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.5962 - acc: 0.0133 - val_loss: 0.7335 - val_acc: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.5942 - acc: 0.0133 - val_loss: 0.7309 - val_acc: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.5901 - acc: 0.0133 - val_loss: 0.7289 - val_acc: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.5870 - acc: 0.0133 - val_loss: 0.7355 - val_acc: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.5837 - acc: 0.0133 - val_loss: 0.7484 - val_acc: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.5839 - acc: 0.0133 - val_loss: 0.7280 - val_acc: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.5789 - acc: 0.0133 - val_loss: 0.7299 - val_acc: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.5764 - acc: 0.0133 - val_loss: 0.7450 - val_acc: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.5734 - acc: 0.0133 - val_loss: 0.7310 - val_acc: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.5700 - acc: 0.0133 - val_loss: 0.7344 - val_acc: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.5680 - acc: 0.0133 - val_loss: 0.7348 - val_acc: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.5651 - acc: 0.0133 - val_loss: 0.7300 - val_acc: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.5625 - acc: 0.0133 - val_loss: 0.7467 - val_acc: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.5613 - acc: 0.0267 - val_loss: 0.7323 - val_acc: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.5581 - acc: 0.0267 - val_loss: 0.7317 - val_acc: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.5547 - acc: 0.0267 - val_loss: 0.7453 - val_acc: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.5515 - acc: 0.0267 - val_loss: 0.7311 - val_acc: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.5491 - acc: 0.0267 - val_loss: 0.7368 - val_acc: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.5457 - acc: 0.0400 - val_loss: 0.7434 - val_acc: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.5434 - acc: 0.0400 - val_loss: 0.7325 - val_acc: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.5421 - acc: 0.0267 - val_loss: 0.7290 - val_acc: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.5415 - acc: 0.0400 - val_loss: 0.7511 - val_acc: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.5371 - acc: 0.0400 - val_loss: 0.7541 - val_acc: 0.0000e+00\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 155us/step - loss: 0.5344 - acc: 0.0400 - val_loss: 0.7409 - val_acc: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.5316 - acc: 0.0400 - val_loss: 0.7519 - val_acc: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.5287 - acc: 0.0400 - val_loss: 0.7421 - val_acc: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.5291 - acc: 0.0400 - val_loss: 0.7466 - val_acc: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.5240 - acc: 0.0400 - val_loss: 0.7594 - val_acc: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.5219 - acc: 0.0400 - val_loss: 0.7339 - val_acc: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.5207 - acc: 0.0400 - val_loss: 0.7438 - val_acc: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "75/75 [==============================] - 0s 157us/step - loss: 0.5174 - acc: 0.0400 - val_loss: 0.7518 - val_acc: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.5141 - acc: 0.0400 - val_loss: 0.7405 - val_acc: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.5133 - acc: 0.0400 - val_loss: 0.7421 - val_acc: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.5112 - acc: 0.0400 - val_loss: 0.7547 - val_acc: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.5084 - acc: 0.0400 - val_loss: 0.7368 - val_acc: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.5065 - acc: 0.0400 - val_loss: 0.7544 - val_acc: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.5049 - acc: 0.0400 - val_loss: 0.7503 - val_acc: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.5013 - acc: 0.0400 - val_loss: 0.7560 - val_acc: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.4991 - acc: 0.0400 - val_loss: 0.7578 - val_acc: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.4972 - acc: 0.0400 - val_loss: 0.7718 - val_acc: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.4957 - acc: 0.0400 - val_loss: 0.7772 - val_acc: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.4931 - acc: 0.0400 - val_loss: 0.7579 - val_acc: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.4898 - acc: 0.0400 - val_loss: 0.7497 - val_acc: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.4881 - acc: 0.0400 - val_loss: 0.7490 - val_acc: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.4867 - acc: 0.0400 - val_loss: 0.7424 - val_acc: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.4857 - acc: 0.0267 - val_loss: 0.7580 - val_acc: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.4819 - acc: 0.0267 - val_loss: 0.7679 - val_acc: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.4798 - acc: 0.0267 - val_loss: 0.7783 - val_acc: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.4791 - acc: 0.0400 - val_loss: 0.7579 - val_acc: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.4753 - acc: 0.0267 - val_loss: 0.7880 - val_acc: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.4758 - acc: 0.0267 - val_loss: 0.7697 - val_acc: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.4723 - acc: 0.0267 - val_loss: 0.7823 - val_acc: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.4695 - acc: 0.0267 - val_loss: 0.7765 - val_acc: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.4672 - acc: 0.0267 - val_loss: 0.7657 - val_acc: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.4655 - acc: 0.0267 - val_loss: 0.7799 - val_acc: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.4629 - acc: 0.0267 - val_loss: 0.7695 - val_acc: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.4609 - acc: 0.0267 - val_loss: 0.7652 - val_acc: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.4587 - acc: 0.0267 - val_loss: 0.7624 - val_acc: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.4565 - acc: 0.0400 - val_loss: 0.8072 - val_acc: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.4566 - acc: 0.0267 - val_loss: 0.7821 - val_acc: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.4520 - acc: 0.0267 - val_loss: 0.7693 - val_acc: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.4495 - acc: 0.0267 - val_loss: 0.7750 - val_acc: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.4486 - acc: 0.0267 - val_loss: 0.7747 - val_acc: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.4475 - acc: 0.0400 - val_loss: 0.7764 - val_acc: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.4444 - acc: 0.0267 - val_loss: 0.7722 - val_acc: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.4442 - acc: 0.0400 - val_loss: 0.7909 - val_acc: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.4410 - acc: 0.0267 - val_loss: 0.7951 - val_acc: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.4385 - acc: 0.0267 - val_loss: 0.7816 - val_acc: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.4384 - acc: 0.0133 - val_loss: 0.8030 - val_acc: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.4340 - acc: 0.0267 - val_loss: 0.7833 - val_acc: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.4314 - acc: 0.0267 - val_loss: 0.8131 - val_acc: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.4308 - acc: 0.0267 - val_loss: 0.8003 - val_acc: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.4288 - acc: 0.0133 - val_loss: 0.8038 - val_acc: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.4264 - acc: 0.0133 - val_loss: 0.7918 - val_acc: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.4267 - acc: 0.0400 - val_loss: 0.7890 - val_acc: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.4227 - acc: 0.0400 - val_loss: 0.7818 - val_acc: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.4228 - acc: 0.0267 - val_loss: 0.7996 - val_acc: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.4193 - acc: 0.0267 - val_loss: 0.7922 - val_acc: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.4178 - acc: 0.0400 - val_loss: 0.7912 - val_acc: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.4148 - acc: 0.0267 - val_loss: 0.7935 - val_acc: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.4134 - acc: 0.0400 - val_loss: 0.8173 - val_acc: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.4112 - acc: 0.0267 - val_loss: 0.7842 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.4101 - acc: 0.0267 - val_loss: 0.8102 - val_acc: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.4075 - acc: 0.0267 - val_loss: 0.8046 - val_acc: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.4063 - acc: 0.0267 - val_loss: 0.7931 - val_acc: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.4040 - acc: 0.0400 - val_loss: 0.7988 - val_acc: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "75/75 [==============================] - 0s 126us/step - loss: 0.4036 - acc: 0.0267 - val_loss: 0.7866 - val_acc: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.4006 - acc: 0.0400 - val_loss: 0.7956 - val_acc: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.3986 - acc: 0.0400 - val_loss: 0.8249 - val_acc: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.3992 - acc: 0.0267 - val_loss: 0.8141 - val_acc: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.3954 - acc: 0.0267 - val_loss: 0.8073 - val_acc: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.3936 - acc: 0.0267 - val_loss: 0.8324 - val_acc: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.3924 - acc: 0.0267 - val_loss: 0.7910 - val_acc: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.3915 - acc: 0.0400 - val_loss: 0.8029 - val_acc: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.3882 - acc: 0.0400 - val_loss: 0.8078 - val_acc: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.3865 - acc: 0.0267 - val_loss: 0.8263 - val_acc: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.3859 - acc: 0.0267 - val_loss: 0.8105 - val_acc: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.3851 - acc: 0.0267 - val_loss: 0.8105 - val_acc: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.3816 - acc: 0.0267 - val_loss: 0.8326 - val_acc: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.3815 - acc: 0.0267 - val_loss: 0.8187 - val_acc: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.3790 - acc: 0.0267 - val_loss: 0.8040 - val_acc: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.3775 - acc: 0.0267 - val_loss: 0.8357 - val_acc: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.3759 - acc: 0.0267 - val_loss: 0.8127 - val_acc: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.3750 - acc: 0.0267 - val_loss: 0.8235 - val_acc: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.3720 - acc: 0.0400 - val_loss: 0.8315 - val_acc: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.3718 - acc: 0.0267 - val_loss: 0.8113 - val_acc: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.3696 - acc: 0.0267 - val_loss: 0.8079 - val_acc: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.3682 - acc: 0.0267 - val_loss: 0.8217 - val_acc: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.3655 - acc: 0.0267 - val_loss: 0.8139 - val_acc: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.3645 - acc: 0.0267 - val_loss: 0.8140 - val_acc: 0.0000e+00\n",
      "Epoch 147/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.3630 - acc: 0.0267 - val_loss: 0.8451 - val_acc: 0.0000e+00\n",
      "Epoch 148/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.3625 - acc: 0.0267 - val_loss: 0.8381 - val_acc: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.3598 - acc: 0.0267 - val_loss: 0.8503 - val_acc: 0.0000e+00\n",
      "Epoch 150/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.3574 - acc: 0.0267 - val_loss: 0.8232 - val_acc: 0.0000e+00\n",
      "Epoch 151/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.3559 - acc: 0.0400 - val_loss: 0.8328 - val_acc: 0.0000e+00\n",
      "Epoch 152/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.3543 - acc: 0.0267 - val_loss: 0.8143 - val_acc: 0.0000e+00\n",
      "Epoch 153/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.3547 - acc: 0.0400 - val_loss: 0.8562 - val_acc: 0.0000e+00\n",
      "Epoch 154/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.3518 - acc: 0.0267 - val_loss: 0.8326 - val_acc: 0.0000e+00\n",
      "Epoch 155/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.3504 - acc: 0.0400 - val_loss: 0.8719 - val_acc: 0.0000e+00\n",
      "Epoch 156/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.3489 - acc: 0.0400 - val_loss: 0.8309 - val_acc: 0.0000e+00\n",
      "Epoch 157/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.3475 - acc: 0.0400 - val_loss: 0.8534 - val_acc: 0.0000e+00\n",
      "Epoch 158/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.3452 - acc: 0.0400 - val_loss: 0.8247 - val_acc: 0.0000e+00\n",
      "Epoch 159/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.3441 - acc: 0.0400 - val_loss: 0.8363 - val_acc: 0.0000e+00\n",
      "Epoch 160/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.3425 - acc: 0.0400 - val_loss: 0.8209 - val_acc: 0.0000e+00\n",
      "Epoch 161/1000\n",
      "75/75 [==============================] - 0s 201us/step - loss: 0.3420 - acc: 0.0533 - val_loss: 0.8574 - val_acc: 0.0000e+00\n",
      "Epoch 162/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.3401 - acc: 0.0400 - val_loss: 0.8651 - val_acc: 0.0000e+00\n",
      "Epoch 163/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.3387 - acc: 0.0400 - val_loss: 0.8630 - val_acc: 0.0000e+00\n",
      "Epoch 164/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.3370 - acc: 0.0400 - val_loss: 0.8518 - val_acc: 0.0000e+00\n",
      "Epoch 165/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.3362 - acc: 0.0400 - val_loss: 0.8699 - val_acc: 0.0000e+00\n",
      "Epoch 166/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.3339 - acc: 0.0400 - val_loss: 0.8402 - val_acc: 0.0000e+00\n",
      "Epoch 167/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.3337 - acc: 0.0667 - val_loss: 0.8722 - val_acc: 0.0000e+00\n",
      "Epoch 168/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.3312 - acc: 0.0400 - val_loss: 0.8596 - val_acc: 0.0000e+00\n",
      "Epoch 169/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.3304 - acc: 0.0533 - val_loss: 0.8513 - val_acc: 0.0000e+00\n",
      "Epoch 170/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.3282 - acc: 0.0533 - val_loss: 0.8560 - val_acc: 0.0000e+00\n",
      "Epoch 171/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.3270 - acc: 0.0533 - val_loss: 0.8409 - val_acc: 0.0000e+00\n",
      "Epoch 172/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.3255 - acc: 0.0400 - val_loss: 0.8668 - val_acc: 0.0000e+00\n",
      "Epoch 173/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.3239 - acc: 0.0533 - val_loss: 0.8434 - val_acc: 0.0000e+00\n",
      "Epoch 174/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.3241 - acc: 0.0533 - val_loss: 0.8504 - val_acc: 0.0000e+00\n",
      "Epoch 175/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.3214 - acc: 0.0400 - val_loss: 0.8629 - val_acc: 0.0000e+00\n",
      "Epoch 176/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.3209 - acc: 0.0400 - val_loss: 0.8934 - val_acc: 0.0000e+00\n",
      "Epoch 177/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 138us/step - loss: 0.3196 - acc: 0.0533 - val_loss: 0.8480 - val_acc: 0.0000e+00\n",
      "Epoch 178/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.3187 - acc: 0.0667 - val_loss: 0.8670 - val_acc: 0.0000e+00\n",
      "Epoch 179/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.3153 - acc: 0.0533 - val_loss: 0.8547 - val_acc: 0.0000e+00\n",
      "Epoch 180/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.3147 - acc: 0.0533 - val_loss: 0.8629 - val_acc: 0.0000e+00\n",
      "Epoch 181/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.3133 - acc: 0.0533 - val_loss: 0.8625 - val_acc: 0.0000e+00\n",
      "Epoch 182/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.3127 - acc: 0.0533 - val_loss: 0.8524 - val_acc: 0.0000e+00\n",
      "Epoch 183/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.3114 - acc: 0.0533 - val_loss: 0.8627 - val_acc: 0.0000e+00\n",
      "Epoch 184/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.3104 - acc: 0.0667 - val_loss: 0.8797 - val_acc: 0.0000e+00\n",
      "Epoch 185/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.3100 - acc: 0.0533 - val_loss: 0.8621 - val_acc: 0.0000e+00\n",
      "Epoch 186/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.3079 - acc: 0.0667 - val_loss: 0.9014 - val_acc: 0.0000e+00\n",
      "Epoch 187/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.3070 - acc: 0.0533 - val_loss: 0.8912 - val_acc: 0.0000e+00\n",
      "Epoch 188/1000\n",
      "75/75 [==============================] - 0s 155us/step - loss: 0.3055 - acc: 0.0533 - val_loss: 0.8737 - val_acc: 0.0000e+00\n",
      "Epoch 189/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.3040 - acc: 0.0533 - val_loss: 0.9049 - val_acc: 0.0000e+00\n",
      "Epoch 190/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.3019 - acc: 0.0533 - val_loss: 0.8561 - val_acc: 0.0000e+00\n",
      "Epoch 191/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.3019 - acc: 0.0533 - val_loss: 0.9013 - val_acc: 0.0000e+00\n",
      "Epoch 192/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.3006 - acc: 0.0533 - val_loss: 0.8827 - val_acc: 0.0000e+00\n",
      "Epoch 193/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.2981 - acc: 0.0533 - val_loss: 0.8700 - val_acc: 0.0000e+00\n",
      "Epoch 194/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.2969 - acc: 0.0667 - val_loss: 0.8936 - val_acc: 0.0000e+00\n",
      "Epoch 195/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.2967 - acc: 0.0533 - val_loss: 0.8753 - val_acc: 0.0000e+00\n",
      "Epoch 196/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.2949 - acc: 0.0533 - val_loss: 0.8693 - val_acc: 0.0000e+00\n",
      "Epoch 197/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.2944 - acc: 0.0667 - val_loss: 0.8733 - val_acc: 0.0000e+00\n",
      "Epoch 198/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.2925 - acc: 0.0533 - val_loss: 0.8955 - val_acc: 0.0000e+00\n",
      "Epoch 199/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.2915 - acc: 0.0533 - val_loss: 0.8828 - val_acc: 0.0000e+00\n",
      "Epoch 200/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.2903 - acc: 0.0533 - val_loss: 0.9108 - val_acc: 0.0000e+00\n",
      "Epoch 201/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.2902 - acc: 0.0667 - val_loss: 0.8813 - val_acc: 0.0000e+00\n",
      "Epoch 202/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.2883 - acc: 0.0667 - val_loss: 0.8739 - val_acc: 0.0000e+00\n",
      "Epoch 203/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.2868 - acc: 0.0800 - val_loss: 0.9111 - val_acc: 0.0000e+00\n",
      "Epoch 204/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.2859 - acc: 0.0667 - val_loss: 0.8751 - val_acc: 0.0000e+00\n",
      "Epoch 205/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.2854 - acc: 0.0800 - val_loss: 0.9075 - val_acc: 0.0000e+00\n",
      "Epoch 206/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.2831 - acc: 0.0667 - val_loss: 0.8740 - val_acc: 0.0000e+00\n",
      "Epoch 207/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.2817 - acc: 0.0667 - val_loss: 0.8922 - val_acc: 0.0000e+00\n",
      "Epoch 208/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.2803 - acc: 0.0667 - val_loss: 0.8869 - val_acc: 0.0000e+00\n",
      "Epoch 209/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.2796 - acc: 0.0800 - val_loss: 0.8746 - val_acc: 0.0000e+00\n",
      "Epoch 210/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.2798 - acc: 0.0800 - val_loss: 0.9137 - val_acc: 0.0000e+00\n",
      "Epoch 211/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.2771 - acc: 0.0800 - val_loss: 0.9069 - val_acc: 0.0000e+00\n",
      "Epoch 212/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.2764 - acc: 0.0800 - val_loss: 0.9111 - val_acc: 0.0000e+00\n",
      "Epoch 213/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.2755 - acc: 0.0933 - val_loss: 0.9281 - val_acc: 0.0000e+00\n",
      "Epoch 214/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.2748 - acc: 0.0800 - val_loss: 0.8899 - val_acc: 0.0000e+00\n",
      "Epoch 215/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.2720 - acc: 0.0667 - val_loss: 0.8887 - val_acc: 0.0000e+00\n",
      "Epoch 216/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.2723 - acc: 0.0933 - val_loss: 0.8991 - val_acc: 0.0000e+00\n",
      "Epoch 217/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.2697 - acc: 0.0800 - val_loss: 0.9057 - val_acc: 0.0000e+00\n",
      "Epoch 218/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.2688 - acc: 0.0800 - val_loss: 0.9150 - val_acc: 0.0000e+00\n",
      "Epoch 219/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.2684 - acc: 0.0933 - val_loss: 0.8806 - val_acc: 0.0000e+00\n",
      "Epoch 220/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.2690 - acc: 0.0800 - val_loss: 0.9086 - val_acc: 0.0000e+00\n",
      "Epoch 221/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.2659 - acc: 0.0933 - val_loss: 0.9364 - val_acc: 0.0000e+00\n",
      "Epoch 222/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.2669 - acc: 0.0933 - val_loss: 0.9048 - val_acc: 0.0000e+00\n",
      "Epoch 223/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.2636 - acc: 0.0800 - val_loss: 0.9106 - val_acc: 0.0000e+00\n",
      "Epoch 224/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.2628 - acc: 0.0933 - val_loss: 0.9203 - val_acc: 0.0000e+00\n",
      "Epoch 225/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.2615 - acc: 0.0933 - val_loss: 0.9189 - val_acc: 0.0000e+00\n",
      "Epoch 226/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.2602 - acc: 0.0800 - val_loss: 0.9047 - val_acc: 0.0000e+00\n",
      "Epoch 227/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.2589 - acc: 0.0800 - val_loss: 0.9337 - val_acc: 0.0000e+00\n",
      "Epoch 228/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.2593 - acc: 0.0933 - val_loss: 0.8885 - val_acc: 0.0000e+00\n",
      "Epoch 229/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.2593 - acc: 0.1067 - val_loss: 0.9339 - val_acc: 0.0000e+00\n",
      "Epoch 230/1000\n",
      "75/75 [==============================] - 0s 125us/step - loss: 0.2559 - acc: 0.0933 - val_loss: 0.9130 - val_acc: 0.0000e+00\n",
      "Epoch 231/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.2554 - acc: 0.0933 - val_loss: 0.9203 - val_acc: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.2548 - acc: 0.0933 - val_loss: 0.9038 - val_acc: 0.0000e+00\n",
      "Epoch 233/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.2531 - acc: 0.0933 - val_loss: 0.9060 - val_acc: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.2532 - acc: 0.0933 - val_loss: 0.9359 - val_acc: 0.0000e+00\n",
      "Epoch 235/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 134us/step - loss: 0.2521 - acc: 0.0933 - val_loss: 0.9136 - val_acc: 0.0000e+00\n",
      "Epoch 236/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.2503 - acc: 0.0933 - val_loss: 0.9190 - val_acc: 0.0000e+00\n",
      "Epoch 237/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.2490 - acc: 0.0933 - val_loss: 0.9222 - val_acc: 0.0000e+00\n",
      "Epoch 238/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.2477 - acc: 0.0933 - val_loss: 0.9162 - val_acc: 0.0000e+00\n",
      "Epoch 239/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.2469 - acc: 0.1067 - val_loss: 0.9220 - val_acc: 0.0000e+00\n",
      "Epoch 240/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.2465 - acc: 0.1067 - val_loss: 0.9467 - val_acc: 0.0000e+00\n",
      "Epoch 241/1000\n",
      "75/75 [==============================] - 0s 124us/step - loss: 0.2455 - acc: 0.0933 - val_loss: 0.9253 - val_acc: 0.0000e+00\n",
      "Epoch 242/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.2440 - acc: 0.0933 - val_loss: 0.9431 - val_acc: 0.0000e+00\n",
      "Epoch 243/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.2427 - acc: 0.0933 - val_loss: 0.9045 - val_acc: 0.0000e+00\n",
      "Epoch 244/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.2417 - acc: 0.0933 - val_loss: 0.9376 - val_acc: 0.0000e+00\n",
      "Epoch 245/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.2407 - acc: 0.0933 - val_loss: 0.9247 - val_acc: 0.0000e+00\n",
      "Epoch 246/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.2388 - acc: 0.0933 - val_loss: 0.9276 - val_acc: 0.0000e+00\n",
      "Epoch 247/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.2375 - acc: 0.0933 - val_loss: 0.9269 - val_acc: 0.0000e+00\n",
      "Epoch 248/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.2374 - acc: 0.1067 - val_loss: 0.9345 - val_acc: 0.0000e+00\n",
      "Epoch 249/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.2358 - acc: 0.0933 - val_loss: 0.9510 - val_acc: 0.0000e+00\n",
      "Epoch 250/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.2353 - acc: 0.1067 - val_loss: 0.9467 - val_acc: 0.0000e+00\n",
      "Epoch 251/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.2351 - acc: 0.1067 - val_loss: 0.9500 - val_acc: 0.0000e+00\n",
      "Epoch 252/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.2337 - acc: 0.0933 - val_loss: 0.9362 - val_acc: 0.0000e+00\n",
      "Epoch 253/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.2326 - acc: 0.1067 - val_loss: 0.9217 - val_acc: 0.0000e+00\n",
      "Epoch 254/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.2324 - acc: 0.0933 - val_loss: 0.9590 - val_acc: 0.0000e+00\n",
      "Epoch 255/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.2299 - acc: 0.1067 - val_loss: 0.9325 - val_acc: 0.0000e+00\n",
      "Epoch 256/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.2284 - acc: 0.1067 - val_loss: 0.9225 - val_acc: 0.0000e+00\n",
      "Epoch 257/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.2281 - acc: 0.0933 - val_loss: 0.9570 - val_acc: 0.0000e+00\n",
      "Epoch 258/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.2277 - acc: 0.1067 - val_loss: 0.9181 - val_acc: 0.0000e+00\n",
      "Epoch 259/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.2268 - acc: 0.1067 - val_loss: 0.9528 - val_acc: 0.0000e+00\n",
      "Epoch 260/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.2251 - acc: 0.1067 - val_loss: 0.9178 - val_acc: 0.0000e+00\n",
      "Epoch 261/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.2244 - acc: 0.1067 - val_loss: 0.9540 - val_acc: 0.0000e+00\n",
      "Epoch 262/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.2234 - acc: 0.1067 - val_loss: 0.9349 - val_acc: 0.0000e+00\n",
      "Epoch 263/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.2222 - acc: 0.1067 - val_loss: 0.9412 - val_acc: 0.0000e+00\n",
      "Epoch 264/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.2209 - acc: 0.1067 - val_loss: 0.9404 - val_acc: 0.0000e+00\n",
      "Epoch 265/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.2205 - acc: 0.1067 - val_loss: 0.9671 - val_acc: 0.0000e+00\n",
      "Epoch 266/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.2198 - acc: 0.1067 - val_loss: 0.9329 - val_acc: 0.0000e+00\n",
      "Epoch 267/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.2183 - acc: 0.1200 - val_loss: 0.9495 - val_acc: 0.0000e+00\n",
      "Epoch 268/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.2173 - acc: 0.1200 - val_loss: 0.9111 - val_acc: 0.0000e+00\n",
      "Epoch 269/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.2186 - acc: 0.1200 - val_loss: 0.9525 - val_acc: 0.0000e+00\n",
      "Epoch 270/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.2151 - acc: 0.1067 - val_loss: 0.9534 - val_acc: 0.0000e+00\n",
      "Epoch 271/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.2145 - acc: 0.1333 - val_loss: 0.9430 - val_acc: 0.0000e+00\n",
      "Epoch 272/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.2140 - acc: 0.1200 - val_loss: 0.9615 - val_acc: 0.0000e+00\n",
      "Epoch 273/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.2134 - acc: 0.1067 - val_loss: 0.9505 - val_acc: 0.0000e+00\n",
      "Epoch 274/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.2118 - acc: 0.1067 - val_loss: 0.9408 - val_acc: 0.0000e+00\n",
      "Epoch 275/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.2108 - acc: 0.1200 - val_loss: 0.9438 - val_acc: 0.0000e+00\n",
      "Epoch 276/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.2097 - acc: 0.1067 - val_loss: 0.9540 - val_acc: 0.0000e+00\n",
      "Epoch 277/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.2091 - acc: 0.1067 - val_loss: 0.9371 - val_acc: 0.0000e+00\n",
      "Epoch 278/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.2093 - acc: 0.0933 - val_loss: 0.9656 - val_acc: 0.0000e+00\n",
      "Epoch 279/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.2078 - acc: 0.1067 - val_loss: 0.9432 - val_acc: 0.0000e+00\n",
      "Epoch 280/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.2062 - acc: 0.1200 - val_loss: 0.9737 - val_acc: 0.0000e+00\n",
      "Epoch 281/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.2059 - acc: 0.1200 - val_loss: 0.9365 - val_acc: 0.0000e+00\n",
      "Epoch 282/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.2045 - acc: 0.1333 - val_loss: 0.9838 - val_acc: 0.0000e+00\n",
      "Epoch 283/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.2053 - acc: 0.1067 - val_loss: 0.9354 - val_acc: 0.0000e+00\n",
      "Epoch 284/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.2036 - acc: 0.1200 - val_loss: 0.9790 - val_acc: 0.0000e+00\n",
      "Epoch 285/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.2027 - acc: 0.1333 - val_loss: 0.9498 - val_acc: 0.0000e+00\n",
      "Epoch 286/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.2018 - acc: 0.0933 - val_loss: 0.9690 - val_acc: 0.0000e+00\n",
      "Epoch 287/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.2001 - acc: 0.1200 - val_loss: 0.9413 - val_acc: 0.0000e+00\n",
      "Epoch 288/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.1999 - acc: 0.1067 - val_loss: 0.9854 - val_acc: 0.0000e+00\n",
      "Epoch 289/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.2010 - acc: 0.1067 - val_loss: 0.9424 - val_acc: 0.0000e+00\n",
      "Epoch 290/1000\n",
      "75/75 [==============================] - 0s 157us/step - loss: 0.1981 - acc: 0.1467 - val_loss: 0.9706 - val_acc: 0.0000e+00\n",
      "Epoch 291/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.1973 - acc: 0.1200 - val_loss: 0.9760 - val_acc: 0.0000e+00\n",
      "Epoch 292/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.1961 - acc: 0.0933 - val_loss: 0.9823 - val_acc: 0.0000e+00\n",
      "Epoch 293/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 154us/step - loss: 0.1950 - acc: 0.1200 - val_loss: 0.9459 - val_acc: 0.0000e+00\n",
      "Epoch 294/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.1955 - acc: 0.0933 - val_loss: 1.0083 - val_acc: 0.0000e+00\n",
      "Epoch 295/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.1963 - acc: 0.1067 - val_loss: 0.9527 - val_acc: 0.0000e+00\n",
      "Epoch 296/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.1927 - acc: 0.1067 - val_loss: 0.9621 - val_acc: 0.0000e+00\n",
      "Epoch 297/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.1919 - acc: 0.1067 - val_loss: 0.9617 - val_acc: 0.0000e+00\n",
      "Epoch 298/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.1915 - acc: 0.0933 - val_loss: 0.9838 - val_acc: 0.0000e+00\n",
      "Epoch 299/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.1912 - acc: 0.1200 - val_loss: 0.9696 - val_acc: 0.0000e+00\n",
      "Epoch 300/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.1906 - acc: 0.0933 - val_loss: 1.0132 - val_acc: 0.0000e+00\n",
      "Epoch 301/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.1916 - acc: 0.0933 - val_loss: 0.9611 - val_acc: 0.0000e+00\n",
      "Epoch 302/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.1883 - acc: 0.0933 - val_loss: 0.9734 - val_acc: 0.0000e+00\n",
      "Epoch 303/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1877 - acc: 0.1067 - val_loss: 0.9549 - val_acc: 0.0000e+00\n",
      "Epoch 304/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.1873 - acc: 0.1067 - val_loss: 0.9923 - val_acc: 0.0000e+00\n",
      "Epoch 305/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.1870 - acc: 0.0667 - val_loss: 0.9469 - val_acc: 0.0000e+00\n",
      "Epoch 306/1000\n",
      "75/75 [==============================] - 0s 153us/step - loss: 0.1856 - acc: 0.1067 - val_loss: 0.9813 - val_acc: 0.0000e+00\n",
      "Epoch 307/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.1856 - acc: 0.1067 - val_loss: 0.9431 - val_acc: 0.0000e+00\n",
      "Epoch 308/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.1842 - acc: 0.1200 - val_loss: 0.9990 - val_acc: 0.0000e+00\n",
      "Epoch 309/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.1842 - acc: 0.0933 - val_loss: 0.9596 - val_acc: 0.0000e+00\n",
      "Epoch 310/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.1828 - acc: 0.0800 - val_loss: 0.9823 - val_acc: 0.0000e+00\n",
      "Epoch 311/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.1819 - acc: 0.0667 - val_loss: 0.9704 - val_acc: 0.0000e+00\n",
      "Epoch 312/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.1811 - acc: 0.1200 - val_loss: 0.9879 - val_acc: 0.0000e+00\n",
      "Epoch 313/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.1811 - acc: 0.0933 - val_loss: 0.9692 - val_acc: 0.0000e+00\n",
      "Epoch 314/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.1795 - acc: 0.1067 - val_loss: 0.9753 - val_acc: 0.0000e+00\n",
      "Epoch 315/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.1787 - acc: 0.0933 - val_loss: 1.0063 - val_acc: 0.0000e+00\n",
      "Epoch 316/1000\n",
      "75/75 [==============================] - 0s 126us/step - loss: 0.1794 - acc: 0.0667 - val_loss: 0.9657 - val_acc: 0.0000e+00\n",
      "Epoch 317/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.1784 - acc: 0.0933 - val_loss: 0.9925 - val_acc: 0.0000e+00\n",
      "Epoch 318/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.1777 - acc: 0.0933 - val_loss: 0.9615 - val_acc: 0.0000e+00\n",
      "Epoch 319/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.1756 - acc: 0.1067 - val_loss: 0.9692 - val_acc: 0.0000e+00\n",
      "Epoch 320/1000\n",
      "75/75 [==============================] - 0s 153us/step - loss: 0.1749 - acc: 0.0667 - val_loss: 0.9774 - val_acc: 0.0000e+00\n",
      "Epoch 321/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1741 - acc: 0.0933 - val_loss: 0.9790 - val_acc: 0.0000e+00\n",
      "Epoch 322/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.1746 - acc: 0.0933 - val_loss: 0.9964 - val_acc: 0.0000e+00\n",
      "Epoch 323/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1742 - acc: 0.1200 - val_loss: 0.9830 - val_acc: 0.0000e+00\n",
      "Epoch 324/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.1724 - acc: 0.0933 - val_loss: 0.9807 - val_acc: 0.0000e+00\n",
      "Epoch 325/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.1714 - acc: 0.0933 - val_loss: 0.9686 - val_acc: 0.0000e+00\n",
      "Epoch 326/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.1714 - acc: 0.1200 - val_loss: 1.0064 - val_acc: 0.0000e+00\n",
      "Epoch 327/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.1719 - acc: 0.1333 - val_loss: 0.9721 - val_acc: 0.0000e+00\n",
      "Epoch 328/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.1709 - acc: 0.1067 - val_loss: 1.0047 - val_acc: 0.0000e+00\n",
      "Epoch 329/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.1690 - acc: 0.0933 - val_loss: 0.9826 - val_acc: 0.0000e+00\n",
      "Epoch 330/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.1680 - acc: 0.1067 - val_loss: 1.0165 - val_acc: 0.0000e+00\n",
      "Epoch 331/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.1689 - acc: 0.1200 - val_loss: 0.9662 - val_acc: 0.0000e+00\n",
      "Epoch 332/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.1688 - acc: 0.1067 - val_loss: 1.0097 - val_acc: 0.0000e+00\n",
      "Epoch 333/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.1679 - acc: 0.0933 - val_loss: 0.9732 - val_acc: 0.0000e+00\n",
      "Epoch 334/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.1654 - acc: 0.1067 - val_loss: 0.9947 - val_acc: 0.0000e+00\n",
      "Epoch 335/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.1646 - acc: 0.0933 - val_loss: 0.9908 - val_acc: 0.0000e+00\n",
      "Epoch 336/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.1639 - acc: 0.0933 - val_loss: 1.0015 - val_acc: 0.0000e+00\n",
      "Epoch 337/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.1639 - acc: 0.1067 - val_loss: 0.9600 - val_acc: 0.0000e+00\n",
      "Epoch 338/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1658 - acc: 0.0933 - val_loss: 1.0234 - val_acc: 0.0000e+00\n",
      "Epoch 339/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.1641 - acc: 0.0933 - val_loss: 0.9760 - val_acc: 0.0000e+00\n",
      "Epoch 340/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.1618 - acc: 0.1200 - val_loss: 0.9895 - val_acc: 0.0000e+00\n",
      "Epoch 341/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.1607 - acc: 0.1200 - val_loss: 0.9887 - val_acc: 0.0000e+00\n",
      "Epoch 342/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.1605 - acc: 0.1067 - val_loss: 0.9772 - val_acc: 0.0000e+00\n",
      "Epoch 343/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.1614 - acc: 0.1067 - val_loss: 1.0091 - val_acc: 0.0000e+00\n",
      "Epoch 344/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1601 - acc: 0.1333 - val_loss: 0.9665 - val_acc: 0.0000e+00\n",
      "Epoch 345/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.1601 - acc: 0.1333 - val_loss: 1.0070 - val_acc: 0.0000e+00\n",
      "Epoch 346/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.1586 - acc: 0.1333 - val_loss: 0.9686 - val_acc: 0.0000e+00\n",
      "Epoch 347/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.1585 - acc: 0.1333 - val_loss: 0.9799 - val_acc: 0.0000e+00\n",
      "Epoch 348/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.1569 - acc: 0.1333 - val_loss: 0.9958 - val_acc: 0.0000e+00\n",
      "Epoch 349/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.1566 - acc: 0.1467 - val_loss: 0.9669 - val_acc: 0.0000e+00\n",
      "Epoch 350/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.1567 - acc: 0.1333 - val_loss: 1.0168 - val_acc: 0.0000e+00\n",
      "Epoch 351/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 140us/step - loss: 0.1562 - acc: 0.1333 - val_loss: 0.9728 - val_acc: 0.0000e+00\n",
      "Epoch 352/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.1559 - acc: 0.1467 - val_loss: 1.0010 - val_acc: 0.0000e+00\n",
      "Epoch 353/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.1557 - acc: 0.1333 - val_loss: 0.9903 - val_acc: 0.0000e+00\n",
      "Epoch 354/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.1537 - acc: 0.1333 - val_loss: 1.0090 - val_acc: 0.0000e+00\n",
      "Epoch 355/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.1531 - acc: 0.1333 - val_loss: 0.9972 - val_acc: 0.0000e+00\n",
      "Epoch 356/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.1531 - acc: 0.1200 - val_loss: 1.0115 - val_acc: 0.0000e+00\n",
      "Epoch 357/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.1535 - acc: 0.1733 - val_loss: 0.9568 - val_acc: 0.0000e+00\n",
      "Epoch 358/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.1532 - acc: 0.1467 - val_loss: 1.0089 - val_acc: 0.0000e+00\n",
      "Epoch 359/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.1511 - acc: 0.1600 - val_loss: 0.9894 - val_acc: 0.0000e+00\n",
      "Epoch 360/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.1501 - acc: 0.1467 - val_loss: 0.9990 - val_acc: 0.0000e+00\n",
      "Epoch 361/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.1500 - acc: 0.1467 - val_loss: 0.9757 - val_acc: 0.0000e+00\n",
      "Epoch 362/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.1498 - acc: 0.1200 - val_loss: 1.0110 - val_acc: 0.0000e+00\n",
      "Epoch 363/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.1493 - acc: 0.1467 - val_loss: 0.9723 - val_acc: 0.0000e+00\n",
      "Epoch 364/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1491 - acc: 0.1200 - val_loss: 1.0321 - val_acc: 0.0000e+00\n",
      "Epoch 365/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.1489 - acc: 0.1333 - val_loss: 0.9873 - val_acc: 0.0000e+00\n",
      "Epoch 366/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.1483 - acc: 0.1600 - val_loss: 1.0203 - val_acc: 0.0000e+00\n",
      "Epoch 367/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.1469 - acc: 0.1200 - val_loss: 0.9914 - val_acc: 0.0000e+00\n",
      "Epoch 368/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.1454 - acc: 0.1733 - val_loss: 0.9938 - val_acc: 0.0000e+00\n",
      "Epoch 369/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.1451 - acc: 0.1333 - val_loss: 1.0190 - val_acc: 0.0000e+00\n",
      "Epoch 370/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.1455 - acc: 0.1467 - val_loss: 0.9703 - val_acc: 0.0000e+00\n",
      "Epoch 371/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.1482 - acc: 0.1333 - val_loss: 1.0097 - val_acc: 0.0000e+00\n",
      "Epoch 372/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.1435 - acc: 0.1333 - val_loss: 0.9964 - val_acc: 0.0000e+00\n",
      "Epoch 373/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.1429 - acc: 0.1333 - val_loss: 0.9836 - val_acc: 0.0000e+00\n",
      "Epoch 374/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.1436 - acc: 0.1467 - val_loss: 1.0174 - val_acc: 0.0000e+00\n",
      "Epoch 375/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.1433 - acc: 0.1333 - val_loss: 0.9858 - val_acc: 0.0000e+00\n",
      "Epoch 376/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.1421 - acc: 0.1333 - val_loss: 1.0117 - val_acc: 0.0000e+00\n",
      "Epoch 377/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.1426 - acc: 0.1200 - val_loss: 0.9807 - val_acc: 0.0000e+00\n",
      "Epoch 378/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.1408 - acc: 0.1467 - val_loss: 1.0111 - val_acc: 0.0000e+00\n",
      "Epoch 379/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.1407 - acc: 0.1333 - val_loss: 0.9748 - val_acc: 0.0000e+00\n",
      "Epoch 380/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.1407 - acc: 0.1333 - val_loss: 1.0164 - val_acc: 0.0000e+00\n",
      "Epoch 381/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.1402 - acc: 0.1600 - val_loss: 0.9935 - val_acc: 0.0000e+00\n",
      "Epoch 382/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.1387 - acc: 0.1600 - val_loss: 1.0159 - val_acc: 0.0000e+00\n",
      "Epoch 383/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.1378 - acc: 0.1333 - val_loss: 0.9952 - val_acc: 0.0000e+00\n",
      "Epoch 384/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.1375 - acc: 0.1600 - val_loss: 1.0150 - val_acc: 0.0000e+00\n",
      "Epoch 385/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.1373 - acc: 0.1200 - val_loss: 1.0212 - val_acc: 0.0000e+00\n",
      "Epoch 386/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.1382 - acc: 0.1467 - val_loss: 0.9715 - val_acc: 0.0000e+00\n",
      "Epoch 387/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.1379 - acc: 0.1200 - val_loss: 1.0236 - val_acc: 0.0000e+00\n",
      "Epoch 388/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.1359 - acc: 0.1333 - val_loss: 0.9766 - val_acc: 0.0000e+00\n",
      "Epoch 389/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.1366 - acc: 0.1600 - val_loss: 1.0164 - val_acc: 0.0000e+00\n",
      "Epoch 390/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.1350 - acc: 0.1333 - val_loss: 0.9866 - val_acc: 0.0000e+00\n",
      "Epoch 391/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.1353 - acc: 0.1600 - val_loss: 1.0169 - val_acc: 0.0000e+00\n",
      "Epoch 392/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.1340 - acc: 0.1333 - val_loss: 0.9854 - val_acc: 0.0000e+00\n",
      "Epoch 393/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.1345 - acc: 0.1467 - val_loss: 1.0268 - val_acc: 0.0000e+00\n",
      "Epoch 394/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.1338 - acc: 0.1600 - val_loss: 0.9903 - val_acc: 0.0000e+00\n",
      "Epoch 395/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.1330 - acc: 0.1333 - val_loss: 1.0215 - val_acc: 0.0000e+00\n",
      "Epoch 396/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.1328 - acc: 0.1333 - val_loss: 0.9821 - val_acc: 0.0000e+00\n",
      "Epoch 397/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1325 - acc: 0.1600 - val_loss: 1.0129 - val_acc: 0.0000e+00\n",
      "Epoch 398/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.1316 - acc: 0.1467 - val_loss: 0.9943 - val_acc: 0.0000e+00\n",
      "Epoch 399/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.1326 - acc: 0.1467 - val_loss: 1.0463 - val_acc: 0.0000e+00\n",
      "Epoch 400/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.1324 - acc: 0.1733 - val_loss: 0.9907 - val_acc: 0.0000e+00\n",
      "Epoch 401/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.1297 - acc: 0.1467 - val_loss: 1.0150 - val_acc: 0.0000e+00\n",
      "Epoch 402/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.1290 - acc: 0.1333 - val_loss: 1.0145 - val_acc: 0.0000e+00\n",
      "Epoch 403/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.1288 - acc: 0.1600 - val_loss: 1.0010 - val_acc: 0.0000e+00\n",
      "Epoch 404/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.1289 - acc: 0.1467 - val_loss: 1.0335 - val_acc: 0.0000e+00\n",
      "Epoch 405/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.1292 - acc: 0.1600 - val_loss: 0.9820 - val_acc: 0.0000e+00\n",
      "Epoch 406/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.1291 - acc: 0.1467 - val_loss: 1.0559 - val_acc: 0.0000e+00\n",
      "Epoch 407/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.1304 - acc: 0.1867 - val_loss: 1.0033 - val_acc: 0.0000e+00\n",
      "Epoch 408/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.1264 - acc: 0.1600 - val_loss: 1.0039 - val_acc: 0.0000e+00\n",
      "Epoch 409/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 143us/step - loss: 0.1259 - acc: 0.1733 - val_loss: 1.0006 - val_acc: 0.0000e+00\n",
      "Epoch 410/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.1260 - acc: 0.1733 - val_loss: 1.0295 - val_acc: 0.0000e+00\n",
      "Epoch 411/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.1271 - acc: 0.1600 - val_loss: 0.9907 - val_acc: 0.0000e+00\n",
      "Epoch 412/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.1267 - acc: 0.1467 - val_loss: 1.0315 - val_acc: 0.0000e+00\n",
      "Epoch 413/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.1250 - acc: 0.1733 - val_loss: 0.9958 - val_acc: 0.0000e+00\n",
      "Epoch 414/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.1247 - acc: 0.1600 - val_loss: 1.0273 - val_acc: 0.0000e+00\n",
      "Epoch 415/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.1251 - acc: 0.1467 - val_loss: 0.9954 - val_acc: 0.0000e+00\n",
      "Epoch 416/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1241 - acc: 0.1467 - val_loss: 1.0183 - val_acc: 0.0000e+00\n",
      "Epoch 417/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.1231 - acc: 0.1733 - val_loss: 0.9862 - val_acc: 0.0000e+00\n",
      "Epoch 418/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.1232 - acc: 0.1733 - val_loss: 1.0379 - val_acc: 0.0000e+00\n",
      "Epoch 419/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.1234 - acc: 0.1600 - val_loss: 0.9893 - val_acc: 0.0000e+00\n",
      "Epoch 420/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1228 - acc: 0.1600 - val_loss: 1.0419 - val_acc: 0.0000e+00\n",
      "Epoch 421/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.1226 - acc: 0.1733 - val_loss: 0.9948 - val_acc: 0.0000e+00\n",
      "Epoch 422/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.1212 - acc: 0.1467 - val_loss: 1.0244 - val_acc: 0.0000e+00\n",
      "Epoch 423/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1206 - acc: 0.1867 - val_loss: 0.9944 - val_acc: 0.0000e+00\n",
      "Epoch 424/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.1209 - acc: 0.1600 - val_loss: 1.0329 - val_acc: 0.0000e+00\n",
      "Epoch 425/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.1217 - acc: 0.1600 - val_loss: 0.9902 - val_acc: 0.0000e+00\n",
      "Epoch 426/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.1198 - acc: 0.1733 - val_loss: 1.0360 - val_acc: 0.0000e+00\n",
      "Epoch 427/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.1197 - acc: 0.1867 - val_loss: 1.0042 - val_acc: 0.0000e+00\n",
      "Epoch 428/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.1193 - acc: 0.1600 - val_loss: 1.0240 - val_acc: 0.0000e+00\n",
      "Epoch 429/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.1185 - acc: 0.1600 - val_loss: 1.0218 - val_acc: 0.0000e+00\n",
      "Epoch 430/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.1176 - acc: 0.1733 - val_loss: 1.0315 - val_acc: 0.0000e+00\n",
      "Epoch 431/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.1182 - acc: 0.1600 - val_loss: 0.9780 - val_acc: 0.0000e+00\n",
      "Epoch 432/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.1186 - acc: 0.1867 - val_loss: 1.0379 - val_acc: 0.0000e+00\n",
      "Epoch 433/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.1184 - acc: 0.1733 - val_loss: 1.0132 - val_acc: 0.0000e+00\n",
      "Epoch 434/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.1159 - acc: 0.1733 - val_loss: 1.0319 - val_acc: 0.0000e+00\n",
      "Epoch 435/1000\n",
      "75/75 [==============================] - 0s 126us/step - loss: 0.1160 - acc: 0.1867 - val_loss: 1.0151 - val_acc: 0.0000e+00\n",
      "Epoch 436/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.1157 - acc: 0.1733 - val_loss: 1.0303 - val_acc: 0.0000e+00\n",
      "Epoch 437/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1169 - acc: 0.1733 - val_loss: 0.9780 - val_acc: 0.0000e+00\n",
      "Epoch 438/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.1168 - acc: 0.1733 - val_loss: 1.0350 - val_acc: 0.0000e+00\n",
      "Epoch 439/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.1155 - acc: 0.2000 - val_loss: 1.0093 - val_acc: 0.0000e+00\n",
      "Epoch 440/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.1137 - acc: 0.1733 - val_loss: 1.0229 - val_acc: 0.0000e+00\n",
      "Epoch 441/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.1133 - acc: 0.1867 - val_loss: 1.0052 - val_acc: 0.0000e+00\n",
      "Epoch 442/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.1134 - acc: 0.1867 - val_loss: 1.0508 - val_acc: 0.0000e+00\n",
      "Epoch 443/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.1164 - acc: 0.1867 - val_loss: 1.0208 - val_acc: 0.0000e+00\n",
      "Epoch 444/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.1121 - acc: 0.1733 - val_loss: 1.0283 - val_acc: 0.0000e+00\n",
      "Epoch 445/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.1119 - acc: 0.1733 - val_loss: 1.0232 - val_acc: 0.0000e+00\n",
      "Epoch 446/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.1113 - acc: 0.1733 - val_loss: 0.9981 - val_acc: 0.0000e+00\n",
      "Epoch 447/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.1136 - acc: 0.1867 - val_loss: 1.0486 - val_acc: 0.0000e+00\n",
      "Epoch 448/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1131 - acc: 0.2000 - val_loss: 1.0039 - val_acc: 0.0000e+00\n",
      "Epoch 449/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.1109 - acc: 0.2000 - val_loss: 1.0359 - val_acc: 0.0000e+00\n",
      "Epoch 450/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1099 - acc: 0.1600 - val_loss: 1.0048 - val_acc: 0.0000e+00\n",
      "Epoch 451/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.1095 - acc: 0.2000 - val_loss: 1.0223 - val_acc: 0.0000e+00\n",
      "Epoch 452/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.1089 - acc: 0.1867 - val_loss: 1.0180 - val_acc: 0.0000e+00\n",
      "Epoch 453/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.1090 - acc: 0.1867 - val_loss: 1.0061 - val_acc: 0.0000e+00\n",
      "Epoch 454/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.1104 - acc: 0.2267 - val_loss: 1.0453 - val_acc: 0.0000e+00\n",
      "Epoch 455/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.1097 - acc: 0.1733 - val_loss: 1.0268 - val_acc: 0.0000e+00\n",
      "Epoch 456/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.1078 - acc: 0.2000 - val_loss: 1.0229 - val_acc: 0.0000e+00\n",
      "Epoch 457/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.1077 - acc: 0.2000 - val_loss: 0.9964 - val_acc: 0.0000e+00\n",
      "Epoch 458/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.1089 - acc: 0.1867 - val_loss: 1.0440 - val_acc: 0.0000e+00\n",
      "Epoch 459/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.1074 - acc: 0.1467 - val_loss: 1.0302 - val_acc: 0.0000e+00\n",
      "Epoch 460/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.1061 - acc: 0.1867 - val_loss: 1.0185 - val_acc: 0.0000e+00\n",
      "Epoch 461/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.1062 - acc: 0.2000 - val_loss: 1.0417 - val_acc: 0.0000e+00\n",
      "Epoch 462/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.1078 - acc: 0.2133 - val_loss: 0.9963 - val_acc: 0.0000e+00\n",
      "Epoch 463/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.1087 - acc: 0.2000 - val_loss: 1.0285 - val_acc: 0.0000e+00\n",
      "Epoch 464/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.1047 - acc: 0.2000 - val_loss: 1.0504 - val_acc: 0.0000e+00\n",
      "Epoch 465/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.1056 - acc: 0.2267 - val_loss: 1.0136 - val_acc: 0.0000e+00\n",
      "Epoch 466/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.1050 - acc: 0.2267 - val_loss: 1.0388 - val_acc: 0.0000e+00\n",
      "Epoch 467/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 134us/step - loss: 0.1037 - acc: 0.2000 - val_loss: 1.0359 - val_acc: 0.0000e+00\n",
      "Epoch 468/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.1036 - acc: 0.2000 - val_loss: 1.0056 - val_acc: 0.0000e+00\n",
      "Epoch 469/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.1031 - acc: 0.2133 - val_loss: 1.0349 - val_acc: 0.0000e+00\n",
      "Epoch 470/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.1038 - acc: 0.2133 - val_loss: 1.0223 - val_acc: 0.0000e+00\n",
      "Epoch 471/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.1028 - acc: 0.2133 - val_loss: 1.0524 - val_acc: 0.0000e+00\n",
      "Epoch 472/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.1039 - acc: 0.2000 - val_loss: 0.9864 - val_acc: 0.0000e+00\n",
      "Epoch 473/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.1058 - acc: 0.2133 - val_loss: 1.0327 - val_acc: 0.0000e+00\n",
      "Epoch 474/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.1012 - acc: 0.2267 - val_loss: 1.0465 - val_acc: 0.0000e+00\n",
      "Epoch 475/1000\n",
      "75/75 [==============================] - 0s 157us/step - loss: 0.1019 - acc: 0.2133 - val_loss: 1.0359 - val_acc: 0.0000e+00\n",
      "Epoch 476/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.1011 - acc: 0.2400 - val_loss: 1.0422 - val_acc: 0.0000e+00\n",
      "Epoch 477/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.1010 - acc: 0.2000 - val_loss: 1.0153 - val_acc: 0.0000e+00\n",
      "Epoch 478/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.1005 - acc: 0.2133 - val_loss: 1.0570 - val_acc: 0.0000e+00\n",
      "Epoch 479/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.1009 - acc: 0.2533 - val_loss: 1.0009 - val_acc: 0.0000e+00\n",
      "Epoch 480/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.1011 - acc: 0.2000 - val_loss: 1.0716 - val_acc: 0.0000e+00\n",
      "Epoch 481/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.1018 - acc: 0.1600 - val_loss: 1.0395 - val_acc: 0.0000e+00\n",
      "Epoch 482/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0986 - acc: 0.2000 - val_loss: 1.0312 - val_acc: 0.0000e+00\n",
      "Epoch 483/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.0984 - acc: 0.2400 - val_loss: 1.0265 - val_acc: 0.0000e+00\n",
      "Epoch 484/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0982 - acc: 0.2133 - val_loss: 1.0704 - val_acc: 0.0000e+00\n",
      "Epoch 485/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.1000 - acc: 0.2400 - val_loss: 1.0224 - val_acc: 0.0000e+00\n",
      "Epoch 486/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0990 - acc: 0.2667 - val_loss: 1.0848 - val_acc: 0.0000e+00\n",
      "Epoch 487/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.1013 - acc: 0.2267 - val_loss: 1.0185 - val_acc: 0.0000e+00\n",
      "Epoch 488/1000\n",
      "75/75 [==============================] - 0s 157us/step - loss: 0.0972 - acc: 0.2533 - val_loss: 1.0334 - val_acc: 0.0000e+00\n",
      "Epoch 489/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0963 - acc: 0.2267 - val_loss: 1.0221 - val_acc: 0.0000e+00\n",
      "Epoch 490/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0963 - acc: 0.2267 - val_loss: 1.0274 - val_acc: 0.0000e+00\n",
      "Epoch 491/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.0964 - acc: 0.2133 - val_loss: 1.0514 - val_acc: 0.0000e+00\n",
      "Epoch 492/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0972 - acc: 0.2533 - val_loss: 1.0137 - val_acc: 0.0000e+00\n",
      "Epoch 493/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0977 - acc: 0.2533 - val_loss: 1.0883 - val_acc: 0.0000e+00\n",
      "Epoch 494/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0988 - acc: 0.2400 - val_loss: 1.0555 - val_acc: 0.0000e+00\n",
      "Epoch 495/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.0949 - acc: 0.2133 - val_loss: 1.0453 - val_acc: 0.0000e+00\n",
      "Epoch 496/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0944 - acc: 0.2133 - val_loss: 1.0357 - val_acc: 0.0000e+00\n",
      "Epoch 497/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0942 - acc: 0.2400 - val_loss: 1.0277 - val_acc: 0.0000e+00\n",
      "Epoch 498/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0950 - acc: 0.2000 - val_loss: 1.0500 - val_acc: 0.0000e+00\n",
      "Epoch 499/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.0943 - acc: 0.2267 - val_loss: 1.0076 - val_acc: 0.0000e+00\n",
      "Epoch 500/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0968 - acc: 0.2533 - val_loss: 1.0533 - val_acc: 0.0000e+00\n",
      "Epoch 501/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0932 - acc: 0.2267 - val_loss: 1.0325 - val_acc: 0.0000e+00\n",
      "Epoch 502/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0927 - acc: 0.2533 - val_loss: 1.0380 - val_acc: 0.0000e+00\n",
      "Epoch 503/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0931 - acc: 0.2267 - val_loss: 1.0379 - val_acc: 0.0000e+00\n",
      "Epoch 504/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0928 - acc: 0.2400 - val_loss: 1.0131 - val_acc: 0.0000e+00\n",
      "Epoch 505/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0949 - acc: 0.2667 - val_loss: 1.1024 - val_acc: 0.0000e+00\n",
      "Epoch 506/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.0944 - acc: 0.2267 - val_loss: 1.0292 - val_acc: 0.0000e+00\n",
      "Epoch 507/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.0921 - acc: 0.2400 - val_loss: 1.0508 - val_acc: 0.0000e+00\n",
      "Epoch 508/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0912 - acc: 0.2400 - val_loss: 1.0231 - val_acc: 0.0000e+00\n",
      "Epoch 509/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0911 - acc: 0.2400 - val_loss: 1.0513 - val_acc: 0.0000e+00\n",
      "Epoch 510/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0913 - acc: 0.2533 - val_loss: 1.0190 - val_acc: 0.0000e+00\n",
      "Epoch 511/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0920 - acc: 0.2400 - val_loss: 1.0965 - val_acc: 0.0000e+00\n",
      "Epoch 512/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0960 - acc: 0.2533 - val_loss: 1.0307 - val_acc: 0.0000e+00\n",
      "Epoch 513/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.0898 - acc: 0.2667 - val_loss: 1.0688 - val_acc: 0.0000e+00\n",
      "Epoch 514/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0901 - acc: 0.2133 - val_loss: 1.0358 - val_acc: 0.0000e+00\n",
      "Epoch 515/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0892 - acc: 0.2667 - val_loss: 1.0377 - val_acc: 0.0000e+00\n",
      "Epoch 516/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0889 - acc: 0.2800 - val_loss: 1.0395 - val_acc: 0.0000e+00\n",
      "Epoch 517/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.0891 - acc: 0.2533 - val_loss: 1.0677 - val_acc: 0.0000e+00\n",
      "Epoch 518/1000\n",
      "75/75 [==============================] - 0s 153us/step - loss: 0.0902 - acc: 0.2800 - val_loss: 1.0255 - val_acc: 0.0000e+00\n",
      "Epoch 519/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0898 - acc: 0.2400 - val_loss: 1.0810 - val_acc: 0.0000e+00\n",
      "Epoch 520/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.0913 - acc: 0.2667 - val_loss: 1.0215 - val_acc: 0.0000e+00\n",
      "Epoch 521/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0889 - acc: 0.2400 - val_loss: 1.0673 - val_acc: 0.0000e+00\n",
      "Epoch 522/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0878 - acc: 0.2400 - val_loss: 1.0388 - val_acc: 0.0000e+00\n",
      "Epoch 523/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.0871 - acc: 0.2533 - val_loss: 1.0517 - val_acc: 0.0000e+00\n",
      "Epoch 524/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0873 - acc: 0.2667 - val_loss: 1.0359 - val_acc: 0.0000e+00\n",
      "Epoch 525/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 135us/step - loss: 0.0874 - acc: 0.2667 - val_loss: 1.0916 - val_acc: 0.0000e+00\n",
      "Epoch 526/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0898 - acc: 0.2800 - val_loss: 1.0333 - val_acc: 0.0000e+00\n",
      "Epoch 527/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0864 - acc: 0.2400 - val_loss: 1.0762 - val_acc: 0.0000e+00\n",
      "Epoch 528/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0869 - acc: 0.2667 - val_loss: 1.0247 - val_acc: 0.0000e+00\n",
      "Epoch 529/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.0865 - acc: 0.2800 - val_loss: 1.0456 - val_acc: 0.0000e+00\n",
      "Epoch 530/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.0855 - acc: 0.2933 - val_loss: 1.0219 - val_acc: 0.0000e+00\n",
      "Epoch 531/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.0868 - acc: 0.2667 - val_loss: 1.0926 - val_acc: 0.0000e+00\n",
      "Epoch 532/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0882 - acc: 0.2933 - val_loss: 1.0248 - val_acc: 0.0000e+00\n",
      "Epoch 533/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.0854 - acc: 0.2800 - val_loss: 1.0465 - val_acc: 0.0000e+00\n",
      "Epoch 534/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0843 - acc: 0.2933 - val_loss: 1.0432 - val_acc: 0.0000e+00\n",
      "Epoch 535/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0845 - acc: 0.2667 - val_loss: 1.0514 - val_acc: 0.0000e+00\n",
      "Epoch 536/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0848 - acc: 0.2800 - val_loss: 1.0263 - val_acc: 0.0000e+00\n",
      "Epoch 537/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0853 - acc: 0.2800 - val_loss: 1.0702 - val_acc: 0.0000e+00\n",
      "Epoch 538/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0847 - acc: 0.2800 - val_loss: 1.0184 - val_acc: 0.0000e+00\n",
      "Epoch 539/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0853 - acc: 0.2800 - val_loss: 1.0901 - val_acc: 0.0000e+00\n",
      "Epoch 540/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0845 - acc: 0.2533 - val_loss: 1.0330 - val_acc: 0.0000e+00\n",
      "Epoch 541/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.0833 - acc: 0.2800 - val_loss: 1.0586 - val_acc: 0.0000e+00\n",
      "Epoch 542/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0823 - acc: 0.2933 - val_loss: 1.0473 - val_acc: 0.0000e+00\n",
      "Epoch 543/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0821 - acc: 0.2667 - val_loss: 1.0546 - val_acc: 0.0000e+00\n",
      "Epoch 544/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.0820 - acc: 0.2933 - val_loss: 1.0476 - val_acc: 0.0000e+00\n",
      "Epoch 545/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0816 - acc: 0.2800 - val_loss: 1.0554 - val_acc: 0.0000e+00\n",
      "Epoch 546/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0820 - acc: 0.3067 - val_loss: 1.0057 - val_acc: 0.0000e+00\n",
      "Epoch 547/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.0878 - acc: 0.2667 - val_loss: 1.0552 - val_acc: 0.0000e+00\n",
      "Epoch 548/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0810 - acc: 0.2800 - val_loss: 1.0461 - val_acc: 0.0000e+00\n",
      "Epoch 549/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0804 - acc: 0.2933 - val_loss: 1.0576 - val_acc: 0.0000e+00\n",
      "Epoch 550/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.0803 - acc: 0.2800 - val_loss: 1.0395 - val_acc: 0.0000e+00\n",
      "Epoch 551/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0817 - acc: 0.2800 - val_loss: 1.1031 - val_acc: 0.0000e+00\n",
      "Epoch 552/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.0830 - acc: 0.2933 - val_loss: 1.0290 - val_acc: 0.0000e+00\n",
      "Epoch 553/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0819 - acc: 0.3067 - val_loss: 1.0675 - val_acc: 0.0000e+00\n",
      "Epoch 554/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0797 - acc: 0.2800 - val_loss: 1.0447 - val_acc: 0.0000e+00\n",
      "Epoch 555/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0791 - acc: 0.3067 - val_loss: 1.0478 - val_acc: 0.0000e+00\n",
      "Epoch 556/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0791 - acc: 0.2933 - val_loss: 1.0940 - val_acc: 0.0000e+00\n",
      "Epoch 557/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0821 - acc: 0.2667 - val_loss: 1.0187 - val_acc: 0.0000e+00\n",
      "Epoch 558/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0815 - acc: 0.2800 - val_loss: 1.0692 - val_acc: 0.0000e+00\n",
      "Epoch 559/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0789 - acc: 0.2800 - val_loss: 1.0473 - val_acc: 0.0000e+00\n",
      "Epoch 560/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0780 - acc: 0.2667 - val_loss: 1.0564 - val_acc: 0.0000e+00\n",
      "Epoch 561/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0778 - acc: 0.3067 - val_loss: 1.0712 - val_acc: 0.0000e+00\n",
      "Epoch 562/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0786 - acc: 0.2667 - val_loss: 1.0172 - val_acc: 0.0000e+00\n",
      "Epoch 563/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0793 - acc: 0.2800 - val_loss: 1.0842 - val_acc: 0.0000e+00\n",
      "Epoch 564/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.0791 - acc: 0.2933 - val_loss: 1.0294 - val_acc: 0.0000e+00\n",
      "Epoch 565/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0796 - acc: 0.2933 - val_loss: 1.0619 - val_acc: 0.0000e+00\n",
      "Epoch 566/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0766 - acc: 0.2933 - val_loss: 1.0691 - val_acc: 0.0000e+00\n",
      "Epoch 567/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0767 - acc: 0.2800 - val_loss: 1.0258 - val_acc: 0.0000e+00\n",
      "Epoch 568/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0776 - acc: 0.2933 - val_loss: 1.0794 - val_acc: 0.0000e+00\n",
      "Epoch 569/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0788 - acc: 0.2667 - val_loss: 1.0319 - val_acc: 0.0000e+00\n",
      "Epoch 570/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0769 - acc: 0.2800 - val_loss: 1.0743 - val_acc: 0.0000e+00\n",
      "Epoch 571/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0765 - acc: 0.3067 - val_loss: 1.0276 - val_acc: 0.0000e+00\n",
      "Epoch 572/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0770 - acc: 0.3067 - val_loss: 1.0951 - val_acc: 0.0000e+00\n",
      "Epoch 573/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0768 - acc: 0.2933 - val_loss: 1.0275 - val_acc: 0.0000e+00\n",
      "Epoch 574/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.0757 - acc: 0.2933 - val_loss: 1.0815 - val_acc: 0.0000e+00\n",
      "Epoch 575/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.0758 - acc: 0.2667 - val_loss: 1.0300 - val_acc: 0.0000e+00\n",
      "Epoch 576/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0769 - acc: 0.3200 - val_loss: 1.0837 - val_acc: 0.0000e+00\n",
      "Epoch 577/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0763 - acc: 0.3067 - val_loss: 1.0468 - val_acc: 0.0000e+00\n",
      "Epoch 578/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0744 - acc: 0.2800 - val_loss: 1.0631 - val_acc: 0.0000e+00\n",
      "Epoch 579/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.0740 - acc: 0.2800 - val_loss: 1.0657 - val_acc: 0.0000e+00\n",
      "Epoch 580/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0741 - acc: 0.2933 - val_loss: 1.0693 - val_acc: 0.0000e+00\n",
      "Epoch 581/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0757 - acc: 0.2800 - val_loss: 1.0332 - val_acc: 0.0000e+00\n",
      "Epoch 582/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0758 - acc: 0.2933 - val_loss: 1.0813 - val_acc: 0.0000e+00\n",
      "Epoch 583/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 142us/step - loss: 0.0745 - acc: 0.3200 - val_loss: 1.0417 - val_acc: 0.0000e+00\n",
      "Epoch 584/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0738 - acc: 0.2933 - val_loss: 1.0782 - val_acc: 0.0000e+00\n",
      "Epoch 585/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.0731 - acc: 0.3200 - val_loss: 1.0301 - val_acc: 0.0000e+00\n",
      "Epoch 586/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0744 - acc: 0.3067 - val_loss: 1.0847 - val_acc: 0.0000e+00\n",
      "Epoch 587/1000\n",
      "75/75 [==============================] - 0s 157us/step - loss: 0.0739 - acc: 0.3200 - val_loss: 1.0245 - val_acc: 0.0000e+00\n",
      "Epoch 588/1000\n",
      "75/75 [==============================] - 0s 126us/step - loss: 0.0740 - acc: 0.3200 - val_loss: 1.0933 - val_acc: 0.0000e+00\n",
      "Epoch 589/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0733 - acc: 0.3067 - val_loss: 1.0341 - val_acc: 0.0000e+00\n",
      "Epoch 590/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.0748 - acc: 0.2933 - val_loss: 1.0990 - val_acc: 0.0000e+00\n",
      "Epoch 591/1000\n",
      "75/75 [==============================] - 0s 126us/step - loss: 0.0726 - acc: 0.3200 - val_loss: 1.0523 - val_acc: 0.0000e+00\n",
      "Epoch 592/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0715 - acc: 0.2933 - val_loss: 1.0544 - val_acc: 0.0000e+00\n",
      "Epoch 593/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0716 - acc: 0.2933 - val_loss: 1.0863 - val_acc: 0.0000e+00\n",
      "Epoch 594/1000\n",
      "75/75 [==============================] - 0s 126us/step - loss: 0.0726 - acc: 0.3067 - val_loss: 1.0120 - val_acc: 0.0000e+00\n",
      "Epoch 595/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0738 - acc: 0.2800 - val_loss: 1.0701 - val_acc: 0.0000e+00\n",
      "Epoch 596/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0713 - acc: 0.3067 - val_loss: 1.0504 - val_acc: 0.0000e+00\n",
      "Epoch 597/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.0706 - acc: 0.2800 - val_loss: 1.0602 - val_acc: 0.0000e+00\n",
      "Epoch 598/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0704 - acc: 0.2933 - val_loss: 1.0655 - val_acc: 0.0000e+00\n",
      "Epoch 599/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0701 - acc: 0.2933 - val_loss: 1.0364 - val_acc: 0.0000e+00\n",
      "Epoch 600/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.0725 - acc: 0.2800 - val_loss: 1.1046 - val_acc: 0.0000e+00\n",
      "Epoch 601/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0744 - acc: 0.2933 - val_loss: 1.0569 - val_acc: 0.0000e+00\n",
      "Epoch 602/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0696 - acc: 0.3200 - val_loss: 1.0599 - val_acc: 0.0000e+00\n",
      "Epoch 603/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0695 - acc: 0.3067 - val_loss: 1.0769 - val_acc: 0.0000e+00\n",
      "Epoch 604/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0701 - acc: 0.3200 - val_loss: 1.0370 - val_acc: 0.0000e+00\n",
      "Epoch 605/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0716 - acc: 0.2933 - val_loss: 1.0903 - val_acc: 0.0000e+00\n",
      "Epoch 606/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0701 - acc: 0.3200 - val_loss: 1.0336 - val_acc: 0.0000e+00\n",
      "Epoch 607/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.0704 - acc: 0.2933 - val_loss: 1.0916 - val_acc: 0.0000e+00\n",
      "Epoch 608/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0704 - acc: 0.3467 - val_loss: 1.0390 - val_acc: 0.0000e+00\n",
      "Epoch 609/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0694 - acc: 0.3067 - val_loss: 1.0795 - val_acc: 0.0000e+00\n",
      "Epoch 610/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0683 - acc: 0.3200 - val_loss: 1.0742 - val_acc: 0.0000e+00\n",
      "Epoch 611/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0684 - acc: 0.3067 - val_loss: 1.0632 - val_acc: 0.0000e+00\n",
      "Epoch 612/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.0680 - acc: 0.2933 - val_loss: 1.1007 - val_acc: 0.0000e+00\n",
      "Epoch 613/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0715 - acc: 0.2933 - val_loss: 1.0332 - val_acc: 0.0000e+00\n",
      "Epoch 614/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0709 - acc: 0.2933 - val_loss: 1.0845 - val_acc: 0.0000e+00\n",
      "Epoch 615/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0683 - acc: 0.2933 - val_loss: 1.0650 - val_acc: 0.0000e+00\n",
      "Epoch 616/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.0673 - acc: 0.3067 - val_loss: 1.0774 - val_acc: 0.0000e+00\n",
      "Epoch 617/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0673 - acc: 0.3067 - val_loss: 1.0469 - val_acc: 0.0000e+00\n",
      "Epoch 618/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0678 - acc: 0.3333 - val_loss: 1.1195 - val_acc: 0.0000e+00\n",
      "Epoch 619/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0699 - acc: 0.3067 - val_loss: 1.0625 - val_acc: 0.0000e+00\n",
      "Epoch 620/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0673 - acc: 0.3067 - val_loss: 1.0877 - val_acc: 0.0000e+00\n",
      "Epoch 621/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0672 - acc: 0.2800 - val_loss: 1.0402 - val_acc: 0.0000e+00\n",
      "Epoch 622/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0694 - acc: 0.2933 - val_loss: 1.0827 - val_acc: 0.0000e+00\n",
      "Epoch 623/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0665 - acc: 0.3200 - val_loss: 1.0547 - val_acc: 0.0000e+00\n",
      "Epoch 624/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0662 - acc: 0.2933 - val_loss: 1.1018 - val_acc: 0.0000e+00\n",
      "Epoch 625/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0676 - acc: 0.2933 - val_loss: 1.0388 - val_acc: 0.0000e+00\n",
      "Epoch 626/1000\n",
      "75/75 [==============================] - 0s 155us/step - loss: 0.0685 - acc: 0.3067 - val_loss: 1.0864 - val_acc: 0.0000e+00\n",
      "Epoch 627/1000\n",
      "75/75 [==============================] - 0s 158us/step - loss: 0.0660 - acc: 0.3333 - val_loss: 1.0596 - val_acc: 0.0000e+00\n",
      "Epoch 628/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0672 - acc: 0.3067 - val_loss: 1.0940 - val_acc: 0.0000e+00\n",
      "Epoch 629/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.0662 - acc: 0.3067 - val_loss: 1.0632 - val_acc: 0.0000e+00\n",
      "Epoch 630/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.0652 - acc: 0.3333 - val_loss: 1.0846 - val_acc: 0.0000e+00\n",
      "Epoch 631/1000\n",
      "75/75 [==============================] - 0s 195us/step - loss: 0.0670 - acc: 0.2933 - val_loss: 1.0444 - val_acc: 0.0000e+00\n",
      "Epoch 632/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0657 - acc: 0.3200 - val_loss: 1.0834 - val_acc: 0.0000e+00\n",
      "Epoch 633/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0652 - acc: 0.3200 - val_loss: 1.0410 - val_acc: 0.0000e+00\n",
      "Epoch 634/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0658 - acc: 0.2667 - val_loss: 1.0869 - val_acc: 0.0000e+00\n",
      "Epoch 635/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0661 - acc: 0.3067 - val_loss: 1.0726 - val_acc: 0.0000e+00\n",
      "Epoch 636/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0642 - acc: 0.3200 - val_loss: 1.0753 - val_acc: 0.0000e+00\n",
      "Epoch 637/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0641 - acc: 0.2933 - val_loss: 1.0529 - val_acc: 0.0000e+00\n",
      "Epoch 638/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0665 - acc: 0.3067 - val_loss: 1.1039 - val_acc: 0.0000e+00\n",
      "Epoch 639/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0652 - acc: 0.3333 - val_loss: 1.0573 - val_acc: 0.0000e+00\n",
      "Epoch 640/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0647 - acc: 0.3200 - val_loss: 1.0976 - val_acc: 0.0000e+00\n",
      "Epoch 641/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 144us/step - loss: 0.0639 - acc: 0.3333 - val_loss: 1.0677 - val_acc: 0.0000e+00\n",
      "Epoch 642/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.0635 - acc: 0.3333 - val_loss: 1.1073 - val_acc: 0.0000e+00\n",
      "Epoch 643/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0658 - acc: 0.3067 - val_loss: 1.0530 - val_acc: 0.0000e+00\n",
      "Epoch 644/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.0632 - acc: 0.3200 - val_loss: 1.0809 - val_acc: 0.0400\n",
      "Epoch 645/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0630 - acc: 0.3333 - val_loss: 1.0421 - val_acc: 0.0000e+00\n",
      "Epoch 646/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0649 - acc: 0.3200 - val_loss: 1.1219 - val_acc: 0.0000e+00\n",
      "Epoch 647/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0659 - acc: 0.3333 - val_loss: 1.0570 - val_acc: 0.0000e+00\n",
      "Epoch 648/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0626 - acc: 0.3333 - val_loss: 1.0598 - val_acc: 0.0000e+00\n",
      "Epoch 649/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0625 - acc: 0.3067 - val_loss: 1.0680 - val_acc: 0.0000e+00\n",
      "Epoch 650/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0619 - acc: 0.3200 - val_loss: 1.0690 - val_acc: 0.0000e+00\n",
      "Epoch 651/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0619 - acc: 0.2933 - val_loss: 1.0699 - val_acc: 0.0400\n",
      "Epoch 652/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.0618 - acc: 0.3067 - val_loss: 1.0898 - val_acc: 0.0000e+00\n",
      "Epoch 653/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0631 - acc: 0.3200 - val_loss: 1.0210 - val_acc: 0.0000e+00\n",
      "Epoch 654/1000\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.0662 - acc: 0.3200 - val_loss: 1.1220 - val_acc: 0.0400\n",
      "Epoch 655/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.0629 - acc: 0.3333 - val_loss: 1.0644 - val_acc: 0.0000e+00\n",
      "Epoch 656/1000\n",
      "75/75 [==============================] - 0s 153us/step - loss: 0.0614 - acc: 0.3067 - val_loss: 1.0835 - val_acc: 0.0400\n",
      "Epoch 657/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0612 - acc: 0.3333 - val_loss: 1.0689 - val_acc: 0.0000e+00\n",
      "Epoch 658/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0612 - acc: 0.2933 - val_loss: 1.1145 - val_acc: 0.0400\n",
      "Epoch 659/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0632 - acc: 0.3067 - val_loss: 1.0442 - val_acc: 0.0000e+00\n",
      "Epoch 660/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.0625 - acc: 0.3333 - val_loss: 1.1012 - val_acc: 0.0400\n",
      "Epoch 661/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0619 - acc: 0.3333 - val_loss: 1.0640 - val_acc: 0.0000e+00\n",
      "Epoch 662/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.0609 - acc: 0.3200 - val_loss: 1.1048 - val_acc: 0.0400\n",
      "Epoch 663/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0621 - acc: 0.3067 - val_loss: 1.0325 - val_acc: 0.0000e+00\n",
      "Epoch 664/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0638 - acc: 0.3467 - val_loss: 1.0921 - val_acc: 0.0400\n",
      "Epoch 665/1000\n",
      "75/75 [==============================] - 0s 153us/step - loss: 0.0600 - acc: 0.3333 - val_loss: 1.0659 - val_acc: 0.0400\n",
      "Epoch 666/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0602 - acc: 0.3333 - val_loss: 1.1052 - val_acc: 0.0400\n",
      "Epoch 667/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0612 - acc: 0.3067 - val_loss: 1.0545 - val_acc: 0.0000e+00\n",
      "Epoch 668/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0607 - acc: 0.3333 - val_loss: 1.1073 - val_acc: 0.0400\n",
      "Epoch 669/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0605 - acc: 0.3200 - val_loss: 1.0497 - val_acc: 0.0400\n",
      "Epoch 670/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0623 - acc: 0.3200 - val_loss: 1.0914 - val_acc: 0.0400\n",
      "Epoch 671/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0594 - acc: 0.3333 - val_loss: 1.0733 - val_acc: 0.0000e+00\n",
      "Epoch 672/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.0599 - acc: 0.3067 - val_loss: 1.1218 - val_acc: 0.0400\n",
      "Epoch 673/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0616 - acc: 0.3467 - val_loss: 1.0480 - val_acc: 0.0000e+00\n",
      "Epoch 674/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.0612 - acc: 0.3333 - val_loss: 1.0820 - val_acc: 0.0400\n",
      "Epoch 675/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0587 - acc: 0.3200 - val_loss: 1.0834 - val_acc: 0.0400\n",
      "Epoch 676/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0584 - acc: 0.3200 - val_loss: 1.0923 - val_acc: 0.0400\n",
      "Epoch 677/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0585 - acc: 0.3333 - val_loss: 1.0598 - val_acc: 0.0400\n",
      "Epoch 678/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0598 - acc: 0.3600 - val_loss: 1.1276 - val_acc: 0.0400\n",
      "Epoch 679/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.0630 - acc: 0.3600 - val_loss: 1.0512 - val_acc: 0.0400\n",
      "Epoch 680/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0596 - acc: 0.3200 - val_loss: 1.1044 - val_acc: 0.0400\n",
      "Epoch 681/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0587 - acc: 0.3467 - val_loss: 1.0737 - val_acc: 0.0400\n",
      "Epoch 682/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0579 - acc: 0.3467 - val_loss: 1.0881 - val_acc: 0.0400\n",
      "Epoch 683/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.0590 - acc: 0.3333 - val_loss: 1.0653 - val_acc: 0.0000e+00\n",
      "Epoch 684/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0582 - acc: 0.3333 - val_loss: 1.1191 - val_acc: 0.0400\n",
      "Epoch 685/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0584 - acc: 0.3467 - val_loss: 1.0568 - val_acc: 0.0400\n",
      "Epoch 686/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.0595 - acc: 0.3467 - val_loss: 1.1136 - val_acc: 0.0400\n",
      "Epoch 687/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0590 - acc: 0.3200 - val_loss: 1.0720 - val_acc: 0.0400\n",
      "Epoch 688/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.0572 - acc: 0.3200 - val_loss: 1.0896 - val_acc: 0.0400\n",
      "Epoch 689/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0576 - acc: 0.3467 - val_loss: 1.0602 - val_acc: 0.0400\n",
      "Epoch 690/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0581 - acc: 0.3600 - val_loss: 1.1299 - val_acc: 0.0400\n",
      "Epoch 691/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0588 - acc: 0.3733 - val_loss: 1.0436 - val_acc: 0.0000e+00\n",
      "Epoch 692/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0606 - acc: 0.3333 - val_loss: 1.1063 - val_acc: 0.0400\n",
      "Epoch 693/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0580 - acc: 0.3333 - val_loss: 1.0630 - val_acc: 0.0400\n",
      "Epoch 694/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.0568 - acc: 0.3200 - val_loss: 1.0840 - val_acc: 0.0400\n",
      "Epoch 695/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0563 - acc: 0.3200 - val_loss: 1.0796 - val_acc: 0.0400\n",
      "Epoch 696/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0565 - acc: 0.3200 - val_loss: 1.0811 - val_acc: 0.0400\n",
      "Epoch 697/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0565 - acc: 0.3467 - val_loss: 1.1415 - val_acc: 0.0400\n",
      "Epoch 698/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0616 - acc: 0.3733 - val_loss: 1.0533 - val_acc: 0.0400\n",
      "Epoch 699/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0577 - acc: 0.3333 - val_loss: 1.0926 - val_acc: 0.0400\n",
      "Epoch 700/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.0558 - acc: 0.3200 - val_loss: 1.0877 - val_acc: 0.0400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 701/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.0555 - acc: 0.3467 - val_loss: 1.0860 - val_acc: 0.0400\n",
      "Epoch 702/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0554 - acc: 0.3333 - val_loss: 1.0863 - val_acc: 0.0400\n",
      "Epoch 703/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0555 - acc: 0.3867 - val_loss: 1.0727 - val_acc: 0.0400\n",
      "Epoch 704/1000\n",
      "75/75 [==============================] - 0s 153us/step - loss: 0.0555 - acc: 0.3200 - val_loss: 1.1074 - val_acc: 0.0400\n",
      "Epoch 705/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0567 - acc: 0.3467 - val_loss: 1.0355 - val_acc: 0.0400\n",
      "Epoch 706/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0615 - acc: 0.3600 - val_loss: 1.1012 - val_acc: 0.0400\n",
      "Epoch 707/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0556 - acc: 0.3200 - val_loss: 1.0633 - val_acc: 0.0400\n",
      "Epoch 708/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0552 - acc: 0.3600 - val_loss: 1.0946 - val_acc: 0.0400\n",
      "Epoch 709/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0551 - acc: 0.3333 - val_loss: 1.0549 - val_acc: 0.0400\n",
      "Epoch 710/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.0567 - acc: 0.3467 - val_loss: 1.1319 - val_acc: 0.0400\n",
      "Epoch 711/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0580 - acc: 0.3467 - val_loss: 1.0653 - val_acc: 0.0400\n",
      "Epoch 712/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.0551 - acc: 0.3733 - val_loss: 1.1070 - val_acc: 0.0400\n",
      "Epoch 713/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0547 - acc: 0.3600 - val_loss: 1.0577 - val_acc: 0.0400\n",
      "Epoch 714/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.0561 - acc: 0.3600 - val_loss: 1.1011 - val_acc: 0.0400\n",
      "Epoch 715/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.0563 - acc: 0.3733 - val_loss: 1.0773 - val_acc: 0.0400\n",
      "Epoch 716/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0542 - acc: 0.3600 - val_loss: 1.1033 - val_acc: 0.0400\n",
      "Epoch 717/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0549 - acc: 0.3867 - val_loss: 1.0717 - val_acc: 0.0400\n",
      "Epoch 718/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0548 - acc: 0.3733 - val_loss: 1.1091 - val_acc: 0.0400\n",
      "Epoch 719/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0544 - acc: 0.3467 - val_loss: 1.0531 - val_acc: 0.0400\n",
      "Epoch 720/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0573 - acc: 0.4000 - val_loss: 1.1060 - val_acc: 0.0400\n",
      "Epoch 721/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0543 - acc: 0.3600 - val_loss: 1.0519 - val_acc: 0.0400\n",
      "Epoch 722/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.0549 - acc: 0.3733 - val_loss: 1.1001 - val_acc: 0.0400\n",
      "Epoch 723/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.0538 - acc: 0.3600 - val_loss: 1.0718 - val_acc: 0.0400\n",
      "Epoch 724/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0537 - acc: 0.3333 - val_loss: 1.1102 - val_acc: 0.0400\n",
      "Epoch 725/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0548 - acc: 0.3867 - val_loss: 1.0599 - val_acc: 0.0400\n",
      "Epoch 726/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0562 - acc: 0.3867 - val_loss: 1.1085 - val_acc: 0.0400\n",
      "Epoch 727/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.0535 - acc: 0.3600 - val_loss: 1.0601 - val_acc: 0.0400\n",
      "Epoch 728/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0539 - acc: 0.3600 - val_loss: 1.1257 - val_acc: 0.0400\n",
      "Epoch 729/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0537 - acc: 0.3733 - val_loss: 1.0497 - val_acc: 0.0400\n",
      "Epoch 730/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0548 - acc: 0.3600 - val_loss: 1.1272 - val_acc: 0.0400\n",
      "Epoch 731/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0546 - acc: 0.3467 - val_loss: 1.0705 - val_acc: 0.0400\n",
      "Epoch 732/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0542 - acc: 0.3467 - val_loss: 1.0960 - val_acc: 0.0400\n",
      "Epoch 733/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0522 - acc: 0.3600 - val_loss: 1.0821 - val_acc: 0.0400\n",
      "Epoch 734/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0524 - acc: 0.3733 - val_loss: 1.1331 - val_acc: 0.0400\n",
      "Epoch 735/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0562 - acc: 0.3867 - val_loss: 1.0674 - val_acc: 0.0400\n",
      "Epoch 736/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0525 - acc: 0.3867 - val_loss: 1.1213 - val_acc: 0.0400\n",
      "Epoch 737/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0530 - acc: 0.3600 - val_loss: 1.0701 - val_acc: 0.0400\n",
      "Epoch 738/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0525 - acc: 0.3733 - val_loss: 1.1283 - val_acc: 0.0400\n",
      "Epoch 739/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0540 - acc: 0.3600 - val_loss: 1.0694 - val_acc: 0.0400\n",
      "Epoch 740/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0521 - acc: 0.3600 - val_loss: 1.1115 - val_acc: 0.0400\n",
      "Epoch 741/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0539 - acc: 0.3867 - val_loss: 1.0776 - val_acc: 0.0400\n",
      "Epoch 742/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0537 - acc: 0.3733 - val_loss: 1.1125 - val_acc: 0.0400\n",
      "Epoch 743/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0520 - acc: 0.3333 - val_loss: 1.0455 - val_acc: 0.0400\n",
      "Epoch 744/1000\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.0539 - acc: 0.3733 - val_loss: 1.0971 - val_acc: 0.0400\n",
      "Epoch 745/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0512 - acc: 0.3467 - val_loss: 1.0825 - val_acc: 0.0400\n",
      "Epoch 746/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0510 - acc: 0.3600 - val_loss: 1.1042 - val_acc: 0.0400\n",
      "Epoch 747/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0513 - acc: 0.3467 - val_loss: 1.0589 - val_acc: 0.0400\n",
      "Epoch 748/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0547 - acc: 0.3467 - val_loss: 1.1429 - val_acc: 0.0400\n",
      "Epoch 749/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0538 - acc: 0.3733 - val_loss: 1.0715 - val_acc: 0.0400\n",
      "Epoch 750/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0511 - acc: 0.3867 - val_loss: 1.0923 - val_acc: 0.0400\n",
      "Epoch 751/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.0504 - acc: 0.3733 - val_loss: 1.0953 - val_acc: 0.0400\n",
      "Epoch 752/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0506 - acc: 0.3867 - val_loss: 1.0841 - val_acc: 0.0400\n",
      "Epoch 753/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0505 - acc: 0.3867 - val_loss: 1.1416 - val_acc: 0.0400\n",
      "Epoch 754/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.0541 - acc: 0.3467 - val_loss: 1.0542 - val_acc: 0.0400\n",
      "Epoch 755/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0524 - acc: 0.3600 - val_loss: 1.1073 - val_acc: 0.0400\n",
      "Epoch 756/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0516 - acc: 0.3600 - val_loss: 1.0813 - val_acc: 0.0400\n",
      "Epoch 757/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0501 - acc: 0.3733 - val_loss: 1.1002 - val_acc: 0.0400\n",
      "Epoch 758/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.0506 - acc: 0.3467 - val_loss: 1.0924 - val_acc: 0.0400\n",
      "Epoch 759/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0501 - acc: 0.3867 - val_loss: 1.0901 - val_acc: 0.0400\n",
      "Epoch 760/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0506 - acc: 0.3733 - val_loss: 1.0505 - val_acc: 0.0400\n",
      "Epoch 761/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 150us/step - loss: 0.0556 - acc: 0.3733 - val_loss: 1.1051 - val_acc: 0.0400\n",
      "Epoch 762/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0498 - acc: 0.3733 - val_loss: 1.0940 - val_acc: 0.0400\n",
      "Epoch 763/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.0493 - acc: 0.3867 - val_loss: 1.0880 - val_acc: 0.0400\n",
      "Epoch 764/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0494 - acc: 0.3733 - val_loss: 1.1000 - val_acc: 0.0400\n",
      "Epoch 765/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0502 - acc: 0.3600 - val_loss: 1.1089 - val_acc: 0.0400\n",
      "Epoch 766/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0514 - acc: 0.3867 - val_loss: 1.0301 - val_acc: 0.0400\n",
      "Epoch 767/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0540 - acc: 0.3600 - val_loss: 1.1229 - val_acc: 0.0400\n",
      "Epoch 768/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.0499 - acc: 0.3600 - val_loss: 1.0646 - val_acc: 0.0400\n",
      "Epoch 769/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0498 - acc: 0.3467 - val_loss: 1.1129 - val_acc: 0.0400\n",
      "Epoch 770/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0491 - acc: 0.3733 - val_loss: 1.0735 - val_acc: 0.0400\n",
      "Epoch 771/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0499 - acc: 0.3867 - val_loss: 1.1258 - val_acc: 0.0400\n",
      "Epoch 772/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0504 - acc: 0.3600 - val_loss: 1.0628 - val_acc: 0.0400\n",
      "Epoch 773/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0519 - acc: 0.3600 - val_loss: 1.0887 - val_acc: 0.0400\n",
      "Epoch 774/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0485 - acc: 0.4000 - val_loss: 1.0748 - val_acc: 0.0400\n",
      "Epoch 775/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0486 - acc: 0.3867 - val_loss: 1.1388 - val_acc: 0.0400\n",
      "Epoch 776/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0513 - acc: 0.3733 - val_loss: 1.0747 - val_acc: 0.0400\n",
      "Epoch 777/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0488 - acc: 0.3733 - val_loss: 1.1221 - val_acc: 0.0400\n",
      "Epoch 778/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.0505 - acc: 0.4000 - val_loss: 1.0720 - val_acc: 0.0400\n",
      "Epoch 779/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0487 - acc: 0.3867 - val_loss: 1.1099 - val_acc: 0.0400\n",
      "Epoch 780/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.0486 - acc: 0.4000 - val_loss: 1.0898 - val_acc: 0.0400\n",
      "Epoch 781/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0484 - acc: 0.4133 - val_loss: 1.1459 - val_acc: 0.0400\n",
      "Epoch 782/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0515 - acc: 0.3867 - val_loss: 1.0630 - val_acc: 0.0400\n",
      "Epoch 783/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0500 - acc: 0.3733 - val_loss: 1.1275 - val_acc: 0.0400\n",
      "Epoch 784/1000\n",
      "75/75 [==============================] - 0s 155us/step - loss: 0.0500 - acc: 0.4000 - val_loss: 1.0650 - val_acc: 0.0400\n",
      "Epoch 785/1000\n",
      "75/75 [==============================] - 0s 195us/step - loss: 0.0485 - acc: 0.3733 - val_loss: 1.0984 - val_acc: 0.0400\n",
      "Epoch 786/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.0477 - acc: 0.3867 - val_loss: 1.0917 - val_acc: 0.0400\n",
      "Epoch 787/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0473 - acc: 0.4133 - val_loss: 1.1190 - val_acc: 0.0400\n",
      "Epoch 788/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0481 - acc: 0.3867 - val_loss: 1.0603 - val_acc: 0.0400\n",
      "Epoch 789/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0508 - acc: 0.4000 - val_loss: 1.1215 - val_acc: 0.0400\n",
      "Epoch 790/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0490 - acc: 0.4133 - val_loss: 1.0752 - val_acc: 0.0400\n",
      "Epoch 791/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0476 - acc: 0.4000 - val_loss: 1.0911 - val_acc: 0.0400\n",
      "Epoch 792/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0470 - acc: 0.3867 - val_loss: 1.0958 - val_acc: 0.0400\n",
      "Epoch 793/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0468 - acc: 0.4133 - val_loss: 1.1382 - val_acc: 0.0400\n",
      "Epoch 794/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0487 - acc: 0.4000 - val_loss: 1.0668 - val_acc: 0.0400\n",
      "Epoch 795/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0494 - acc: 0.3733 - val_loss: 1.1454 - val_acc: 0.0400\n",
      "Epoch 796/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.0498 - acc: 0.4000 - val_loss: 1.0791 - val_acc: 0.0400\n",
      "Epoch 797/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0469 - acc: 0.4000 - val_loss: 1.0965 - val_acc: 0.0400\n",
      "Epoch 798/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0465 - acc: 0.4133 - val_loss: 1.0988 - val_acc: 0.0400\n",
      "Epoch 799/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.0468 - acc: 0.4133 - val_loss: 1.0930 - val_acc: 0.0400\n",
      "Epoch 800/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0464 - acc: 0.4000 - val_loss: 1.1055 - val_acc: 0.0400\n",
      "Epoch 801/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0483 - acc: 0.4133 - val_loss: 1.0288 - val_acc: 0.0400\n",
      "Epoch 802/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0512 - acc: 0.4133 - val_loss: 1.1163 - val_acc: 0.0400\n",
      "Epoch 803/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0467 - acc: 0.3733 - val_loss: 1.0846 - val_acc: 0.0400\n",
      "Epoch 804/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0464 - acc: 0.3867 - val_loss: 1.1115 - val_acc: 0.0400\n",
      "Epoch 805/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0464 - acc: 0.4133 - val_loss: 1.0753 - val_acc: 0.0400\n",
      "Epoch 806/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0465 - acc: 0.4133 - val_loss: 1.1178 - val_acc: 0.0400\n",
      "Epoch 807/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0472 - acc: 0.4133 - val_loss: 1.0658 - val_acc: 0.0400\n",
      "Epoch 808/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0481 - acc: 0.4133 - val_loss: 1.1084 - val_acc: 0.0400\n",
      "Epoch 809/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0466 - acc: 0.4000 - val_loss: 1.0951 - val_acc: 0.0400\n",
      "Epoch 810/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0457 - acc: 0.4000 - val_loss: 1.1176 - val_acc: 0.0400\n",
      "Epoch 811/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0463 - acc: 0.3867 - val_loss: 1.0652 - val_acc: 0.0400\n",
      "Epoch 812/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0487 - acc: 0.4000 - val_loss: 1.1366 - val_acc: 0.0400\n",
      "Epoch 813/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0472 - acc: 0.4000 - val_loss: 1.0809 - val_acc: 0.0400\n",
      "Epoch 814/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0461 - acc: 0.4000 - val_loss: 1.1296 - val_acc: 0.0400\n",
      "Epoch 815/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0467 - acc: 0.4133 - val_loss: 1.0721 - val_acc: 0.0400\n",
      "Epoch 816/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0463 - acc: 0.4000 - val_loss: 1.1016 - val_acc: 0.0400\n",
      "Epoch 817/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.0450 - acc: 0.4000 - val_loss: 1.0912 - val_acc: 0.0400\n",
      "Epoch 818/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.0451 - acc: 0.4133 - val_loss: 1.1618 - val_acc: 0.0400\n",
      "Epoch 819/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0495 - acc: 0.3733 - val_loss: 1.0872 - val_acc: 0.0400\n",
      "Epoch 820/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0452 - acc: 0.4133 - val_loss: 1.1069 - val_acc: 0.0400\n",
      "Epoch 821/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 140us/step - loss: 0.0447 - acc: 0.4133 - val_loss: 1.0826 - val_acc: 0.0400\n",
      "Epoch 822/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0466 - acc: 0.4133 - val_loss: 1.1360 - val_acc: 0.0400\n",
      "Epoch 823/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.0461 - acc: 0.4000 - val_loss: 1.0598 - val_acc: 0.0400\n",
      "Epoch 824/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0475 - acc: 0.4000 - val_loss: 1.1141 - val_acc: 0.0400\n",
      "Epoch 825/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0450 - acc: 0.3867 - val_loss: 1.0929 - val_acc: 0.0400\n",
      "Epoch 826/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.0445 - acc: 0.4133 - val_loss: 1.1130 - val_acc: 0.0400\n",
      "Epoch 827/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.0448 - acc: 0.4133 - val_loss: 1.0782 - val_acc: 0.0400\n",
      "Epoch 828/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0473 - acc: 0.4400 - val_loss: 1.1431 - val_acc: 0.0400\n",
      "Epoch 829/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0461 - acc: 0.4133 - val_loss: 1.0586 - val_acc: 0.0400\n",
      "Epoch 830/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.0458 - acc: 0.4000 - val_loss: 1.1193 - val_acc: 0.0400\n",
      "Epoch 831/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0448 - acc: 0.4267 - val_loss: 1.0605 - val_acc: 0.0400\n",
      "Epoch 832/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0484 - acc: 0.4267 - val_loss: 1.1160 - val_acc: 0.0400\n",
      "Epoch 833/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.0444 - acc: 0.4133 - val_loss: 1.0921 - val_acc: 0.0400\n",
      "Epoch 834/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.0441 - acc: 0.4400 - val_loss: 1.1073 - val_acc: 0.0400\n",
      "Epoch 835/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0437 - acc: 0.4133 - val_loss: 1.1023 - val_acc: 0.0400\n",
      "Epoch 836/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.0436 - acc: 0.4000 - val_loss: 1.1124 - val_acc: 0.0400\n",
      "Epoch 837/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0441 - acc: 0.4267 - val_loss: 1.0592 - val_acc: 0.0400\n",
      "Epoch 838/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0483 - acc: 0.4400 - val_loss: 1.1316 - val_acc: 0.0400\n",
      "Epoch 839/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.0455 - acc: 0.4133 - val_loss: 1.0830 - val_acc: 0.0400\n",
      "Epoch 840/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0449 - acc: 0.4000 - val_loss: 1.1218 - val_acc: 0.0400\n",
      "Epoch 841/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0438 - acc: 0.4133 - val_loss: 1.0997 - val_acc: 0.0400\n",
      "Epoch 842/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0438 - acc: 0.4267 - val_loss: 1.1223 - val_acc: 0.0400\n",
      "Epoch 843/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0440 - acc: 0.4533 - val_loss: 1.0528 - val_acc: 0.0400\n",
      "Epoch 844/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.0488 - acc: 0.4533 - val_loss: 1.1300 - val_acc: 0.0400\n",
      "Epoch 845/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0438 - acc: 0.4000 - val_loss: 1.0936 - val_acc: 0.0400\n",
      "Epoch 846/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0438 - acc: 0.4267 - val_loss: 1.1066 - val_acc: 0.0400\n",
      "Epoch 847/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0432 - acc: 0.4267 - val_loss: 1.0994 - val_acc: 0.0400\n",
      "Epoch 848/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.0433 - acc: 0.4267 - val_loss: 1.1107 - val_acc: 0.0400\n",
      "Epoch 849/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0435 - acc: 0.4133 - val_loss: 1.0735 - val_acc: 0.0400\n",
      "Epoch 850/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.0467 - acc: 0.4000 - val_loss: 1.1491 - val_acc: 0.0400\n",
      "Epoch 851/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.0455 - acc: 0.4133 - val_loss: 1.0740 - val_acc: 0.0400\n",
      "Epoch 852/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0439 - acc: 0.4267 - val_loss: 1.1130 - val_acc: 0.0400\n",
      "Epoch 853/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0425 - acc: 0.4000 - val_loss: 1.1056 - val_acc: 0.0400\n",
      "Epoch 854/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0424 - acc: 0.4133 - val_loss: 1.1196 - val_acc: 0.0400\n",
      "Epoch 855/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0435 - acc: 0.4267 - val_loss: 1.0712 - val_acc: 0.0400\n",
      "Epoch 856/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0448 - acc: 0.4267 - val_loss: 1.1797 - val_acc: 0.0400\n",
      "Epoch 857/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0476 - acc: 0.3867 - val_loss: 1.0824 - val_acc: 0.0400\n",
      "Epoch 858/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0428 - acc: 0.4267 - val_loss: 1.1182 - val_acc: 0.0400\n",
      "Epoch 859/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.0423 - acc: 0.4533 - val_loss: 1.1116 - val_acc: 0.0400\n",
      "Epoch 860/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0422 - acc: 0.4533 - val_loss: 1.1123 - val_acc: 0.0400\n",
      "Epoch 861/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0428 - acc: 0.4400 - val_loss: 1.1173 - val_acc: 0.0400\n",
      "Epoch 862/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.0433 - acc: 0.4667 - val_loss: 1.0485 - val_acc: 0.0400\n",
      "Epoch 863/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0474 - acc: 0.4400 - val_loss: 1.1209 - val_acc: 0.0400\n",
      "Epoch 864/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0420 - acc: 0.4133 - val_loss: 1.0861 - val_acc: 0.0400\n",
      "Epoch 865/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0422 - acc: 0.4533 - val_loss: 1.1393 - val_acc: 0.0400\n",
      "Epoch 866/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.0424 - acc: 0.4400 - val_loss: 1.0743 - val_acc: 0.0400\n",
      "Epoch 867/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0436 - acc: 0.4400 - val_loss: 1.1287 - val_acc: 0.0400\n",
      "Epoch 868/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.0422 - acc: 0.4267 - val_loss: 1.0926 - val_acc: 0.0400\n",
      "Epoch 869/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0434 - acc: 0.4267 - val_loss: 1.1633 - val_acc: 0.0400\n",
      "Epoch 870/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.0432 - acc: 0.4400 - val_loss: 1.0815 - val_acc: 0.0400\n",
      "Epoch 871/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0429 - acc: 0.4267 - val_loss: 1.1127 - val_acc: 0.0400\n",
      "Epoch 872/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0416 - acc: 0.4533 - val_loss: 1.0943 - val_acc: 0.0400\n",
      "Epoch 873/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0415 - acc: 0.4133 - val_loss: 1.1493 - val_acc: 0.0400\n",
      "Epoch 874/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.0446 - acc: 0.4400 - val_loss: 1.0679 - val_acc: 0.0400\n",
      "Epoch 875/1000\n",
      "75/75 [==============================] - 0s 153us/step - loss: 0.0432 - acc: 0.4533 - val_loss: 1.1395 - val_acc: 0.0400\n",
      "Epoch 876/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.0427 - acc: 0.4533 - val_loss: 1.0975 - val_acc: 0.0400\n",
      "Epoch 877/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0412 - acc: 0.4267 - val_loss: 1.1025 - val_acc: 0.0400\n",
      "Epoch 878/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0410 - acc: 0.4267 - val_loss: 1.1125 - val_acc: 0.0400\n",
      "Epoch 879/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0409 - acc: 0.4400 - val_loss: 1.0872 - val_acc: 0.0400\n",
      "Epoch 880/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0434 - acc: 0.4533 - val_loss: 1.1802 - val_acc: 0.0400\n",
      "Epoch 881/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 139us/step - loss: 0.0469 - acc: 0.3867 - val_loss: 1.1083 - val_acc: 0.0400\n",
      "Epoch 882/1000\n",
      "75/75 [==============================] - 0s 127us/step - loss: 0.0407 - acc: 0.4267 - val_loss: 1.1056 - val_acc: 0.0400\n",
      "Epoch 883/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0406 - acc: 0.4400 - val_loss: 1.1153 - val_acc: 0.0400\n",
      "Epoch 884/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0407 - acc: 0.4667 - val_loss: 1.0801 - val_acc: 0.0400\n",
      "Epoch 885/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0420 - acc: 0.4400 - val_loss: 1.1538 - val_acc: 0.0400\n",
      "Epoch 886/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0429 - acc: 0.4533 - val_loss: 1.0859 - val_acc: 0.0400\n",
      "Epoch 887/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0433 - acc: 0.4400 - val_loss: 1.1259 - val_acc: 0.0400\n",
      "Epoch 888/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0415 - acc: 0.4267 - val_loss: 1.0958 - val_acc: 0.0400\n",
      "Epoch 889/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0406 - acc: 0.4533 - val_loss: 1.1232 - val_acc: 0.0400\n",
      "Epoch 890/1000\n",
      "75/75 [==============================] - 0s 154us/step - loss: 0.0405 - acc: 0.4000 - val_loss: 1.0722 - val_acc: 0.0400\n",
      "Epoch 891/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0436 - acc: 0.4133 - val_loss: 1.1505 - val_acc: 0.0400\n",
      "Epoch 892/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.0440 - acc: 0.4400 - val_loss: 1.1060 - val_acc: 0.0400\n",
      "Epoch 893/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0401 - acc: 0.4667 - val_loss: 1.1355 - val_acc: 0.0400\n",
      "Epoch 894/1000\n",
      "75/75 [==============================] - 0s 126us/step - loss: 0.0404 - acc: 0.4533 - val_loss: 1.0865 - val_acc: 0.0400\n",
      "Epoch 895/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.0408 - acc: 0.4267 - val_loss: 1.1720 - val_acc: 0.0400\n",
      "Epoch 896/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0427 - acc: 0.4400 - val_loss: 1.0954 - val_acc: 0.0400\n",
      "Epoch 897/1000\n",
      "75/75 [==============================] - 0s 124us/step - loss: 0.0407 - acc: 0.4400 - val_loss: 1.1365 - val_acc: 0.0400\n",
      "Epoch 898/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0417 - acc: 0.4533 - val_loss: 1.1017 - val_acc: 0.0400\n",
      "Epoch 899/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0400 - acc: 0.4267 - val_loss: 1.1205 - val_acc: 0.0400\n",
      "Epoch 900/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0401 - acc: 0.4400 - val_loss: 1.1019 - val_acc: 0.0400\n",
      "Epoch 901/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.0404 - acc: 0.4533 - val_loss: 1.1834 - val_acc: 0.0400\n",
      "Epoch 902/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0449 - acc: 0.4667 - val_loss: 1.0808 - val_acc: 0.0400\n",
      "Epoch 903/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0417 - acc: 0.4667 - val_loss: 1.1143 - val_acc: 0.0400\n",
      "Epoch 904/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0396 - acc: 0.4667 - val_loss: 1.1230 - val_acc: 0.0400\n",
      "Epoch 905/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0394 - acc: 0.4533 - val_loss: 1.1225 - val_acc: 0.0400\n",
      "Epoch 906/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0393 - acc: 0.4667 - val_loss: 1.1010 - val_acc: 0.0400\n",
      "Epoch 907/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.0405 - acc: 0.4667 - val_loss: 1.1746 - val_acc: 0.0400\n",
      "Epoch 908/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0439 - acc: 0.4533 - val_loss: 1.1020 - val_acc: 0.0400\n",
      "Epoch 909/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0397 - acc: 0.4533 - val_loss: 1.1276 - val_acc: 0.0400\n",
      "Epoch 910/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0398 - acc: 0.4400 - val_loss: 1.0898 - val_acc: 0.0400\n",
      "Epoch 911/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0408 - acc: 0.4800 - val_loss: 1.1319 - val_acc: 0.0400\n",
      "Epoch 912/1000\n",
      "75/75 [==============================] - 0s 133us/step - loss: 0.0398 - acc: 0.4667 - val_loss: 1.0966 - val_acc: 0.0400\n",
      "Epoch 913/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0404 - acc: 0.4533 - val_loss: 1.1724 - val_acc: 0.0400\n",
      "Epoch 914/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0423 - acc: 0.4667 - val_loss: 1.0848 - val_acc: 0.0400\n",
      "Epoch 915/1000\n",
      "75/75 [==============================] - 0s 131us/step - loss: 0.0396 - acc: 0.4667 - val_loss: 1.1354 - val_acc: 0.0400\n",
      "Epoch 916/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0393 - acc: 0.4533 - val_loss: 1.0997 - val_acc: 0.0400\n",
      "Epoch 917/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0394 - acc: 0.4667 - val_loss: 1.1490 - val_acc: 0.0400\n",
      "Epoch 918/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0403 - acc: 0.4667 - val_loss: 1.0929 - val_acc: 0.0400\n",
      "Epoch 919/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0391 - acc: 0.4533 - val_loss: 1.1570 - val_acc: 0.0400\n",
      "Epoch 920/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0411 - acc: 0.4667 - val_loss: 1.0724 - val_acc: 0.0400\n",
      "Epoch 921/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0406 - acc: 0.4267 - val_loss: 1.1283 - val_acc: 0.0400\n",
      "Epoch 922/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.0394 - acc: 0.4533 - val_loss: 1.0996 - val_acc: 0.0400\n",
      "Epoch 923/1000\n",
      "75/75 [==============================] - 0s 136us/step - loss: 0.0393 - acc: 0.4800 - val_loss: 1.1185 - val_acc: 0.0400\n",
      "Epoch 924/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0384 - acc: 0.4800 - val_loss: 1.1100 - val_acc: 0.0400\n",
      "Epoch 925/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0387 - acc: 0.4800 - val_loss: 1.1443 - val_acc: 0.0400\n",
      "Epoch 926/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0395 - acc: 0.4133 - val_loss: 1.0888 - val_acc: 0.0400\n",
      "Epoch 927/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0400 - acc: 0.4800 - val_loss: 1.1880 - val_acc: 0.0400\n",
      "Epoch 928/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.0442 - acc: 0.4533 - val_loss: 1.0993 - val_acc: 0.0400\n",
      "Epoch 929/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0385 - acc: 0.4933 - val_loss: 1.1334 - val_acc: 0.0400\n",
      "Epoch 930/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0380 - acc: 0.4667 - val_loss: 1.1085 - val_acc: 0.0400\n",
      "Epoch 931/1000\n",
      "75/75 [==============================] - 0s 151us/step - loss: 0.0379 - acc: 0.4933 - val_loss: 1.1314 - val_acc: 0.0400\n",
      "Epoch 932/1000\n",
      "75/75 [==============================] - 0s 132us/step - loss: 0.0381 - acc: 0.4933 - val_loss: 1.1045 - val_acc: 0.0400\n",
      "Epoch 933/1000\n",
      "75/75 [==============================] - 0s 155us/step - loss: 0.0389 - acc: 0.4933 - val_loss: 1.1217 - val_acc: 0.0400\n",
      "Epoch 934/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0380 - acc: 0.4800 - val_loss: 1.1322 - val_acc: 0.0400\n",
      "Epoch 935/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0385 - acc: 0.4800 - val_loss: 1.0955 - val_acc: 0.0400\n",
      "Epoch 936/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0404 - acc: 0.4800 - val_loss: 1.1409 - val_acc: 0.0400\n",
      "Epoch 937/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0390 - acc: 0.4800 - val_loss: 1.0888 - val_acc: 0.0400\n",
      "Epoch 938/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0399 - acc: 0.4667 - val_loss: 1.1408 - val_acc: 0.0400\n",
      "Epoch 939/1000\n",
      "75/75 [==============================] - 0s 146us/step - loss: 0.0386 - acc: 0.4400 - val_loss: 1.0785 - val_acc: 0.0400\n",
      "Epoch 940/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0391 - acc: 0.4667 - val_loss: 1.1262 - val_acc: 0.0400\n",
      "Epoch 941/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 161us/step - loss: 0.0374 - acc: 0.4533 - val_loss: 1.1140 - val_acc: 0.0400\n",
      "Epoch 942/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.0382 - acc: 0.4533 - val_loss: 1.1418 - val_acc: 0.0400\n",
      "Epoch 943/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.0382 - acc: 0.4533 - val_loss: 1.1246 - val_acc: 0.0400\n",
      "Epoch 944/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.0381 - acc: 0.4667 - val_loss: 1.1713 - val_acc: 0.0400\n",
      "Epoch 945/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0396 - acc: 0.4667 - val_loss: 1.0665 - val_acc: 0.0400\n",
      "Epoch 946/1000\n",
      "75/75 [==============================] - 0s 152us/step - loss: 0.0416 - acc: 0.4533 - val_loss: 1.1242 - val_acc: 0.0400\n",
      "Epoch 947/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0371 - acc: 0.4800 - val_loss: 1.1308 - val_acc: 0.0400\n",
      "Epoch 948/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0369 - acc: 0.4533 - val_loss: 1.1209 - val_acc: 0.0400\n",
      "Epoch 949/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0369 - acc: 0.4800 - val_loss: 1.1483 - val_acc: 0.0400\n",
      "Epoch 950/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0374 - acc: 0.4667 - val_loss: 1.0858 - val_acc: 0.0400\n",
      "Epoch 951/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0402 - acc: 0.4800 - val_loss: 1.1344 - val_acc: 0.0400\n",
      "Epoch 952/1000\n",
      "75/75 [==============================] - 0s 157us/step - loss: 0.0371 - acc: 0.4800 - val_loss: 1.1231 - val_acc: 0.0400\n",
      "Epoch 953/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0375 - acc: 0.4667 - val_loss: 1.1455 - val_acc: 0.0400\n",
      "Epoch 954/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0386 - acc: 0.4400 - val_loss: 1.0758 - val_acc: 0.0400\n",
      "Epoch 955/1000\n",
      "75/75 [==============================] - 0s 158us/step - loss: 0.0412 - acc: 0.4667 - val_loss: 1.1261 - val_acc: 0.0400\n",
      "Epoch 956/1000\n",
      "75/75 [==============================] - 0s 145us/step - loss: 0.0366 - acc: 0.4533 - val_loss: 1.1425 - val_acc: 0.0400\n",
      "Epoch 957/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0368 - acc: 0.4533 - val_loss: 1.0931 - val_acc: 0.0400\n",
      "Epoch 958/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0392 - acc: 0.4533 - val_loss: 1.1707 - val_acc: 0.0400\n",
      "Epoch 959/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0384 - acc: 0.4533 - val_loss: 1.0982 - val_acc: 0.0400\n",
      "Epoch 960/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0390 - acc: 0.4667 - val_loss: 1.1320 - val_acc: 0.0400\n",
      "Epoch 961/1000\n",
      "75/75 [==============================] - 0s 143us/step - loss: 0.0365 - acc: 0.4800 - val_loss: 1.1040 - val_acc: 0.0400\n",
      "Epoch 962/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.0368 - acc: 0.4400 - val_loss: 1.1462 - val_acc: 0.0400\n",
      "Epoch 963/1000\n",
      "75/75 [==============================] - 0s 149us/step - loss: 0.0372 - acc: 0.5067 - val_loss: 1.0663 - val_acc: 0.0400\n",
      "Epoch 964/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0405 - acc: 0.4667 - val_loss: 1.1723 - val_acc: 0.0400\n",
      "Epoch 965/1000\n",
      "75/75 [==============================] - 0s 155us/step - loss: 0.0379 - acc: 0.4533 - val_loss: 1.1209 - val_acc: 0.0400\n",
      "Epoch 966/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0363 - acc: 0.4533 - val_loss: 1.1251 - val_acc: 0.0400\n",
      "Epoch 967/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0361 - acc: 0.4667 - val_loss: 1.1226 - val_acc: 0.0400\n",
      "Epoch 968/1000\n",
      "75/75 [==============================] - 0s 158us/step - loss: 0.0378 - acc: 0.4667 - val_loss: 1.1755 - val_acc: 0.0400\n",
      "Epoch 969/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0383 - acc: 0.4933 - val_loss: 1.0913 - val_acc: 0.0400\n",
      "Epoch 970/1000\n",
      "75/75 [==============================] - 0s 134us/step - loss: 0.0370 - acc: 0.4667 - val_loss: 1.1665 - val_acc: 0.0400\n",
      "Epoch 971/1000\n",
      "75/75 [==============================] - 0s 153us/step - loss: 0.0373 - acc: 0.4533 - val_loss: 1.0849 - val_acc: 0.0400\n",
      "Epoch 972/1000\n",
      "75/75 [==============================] - 0s 148us/step - loss: 0.0382 - acc: 0.4800 - val_loss: 1.1770 - val_acc: 0.0400\n",
      "Epoch 973/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0378 - acc: 0.4533 - val_loss: 1.1256 - val_acc: 0.0400\n",
      "Epoch 974/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0358 - acc: 0.4667 - val_loss: 1.1215 - val_acc: 0.0400\n",
      "Epoch 975/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0355 - acc: 0.4800 - val_loss: 1.1429 - val_acc: 0.0400\n",
      "Epoch 976/1000\n",
      "75/75 [==============================] - 0s 139us/step - loss: 0.0359 - acc: 0.4667 - val_loss: 1.0914 - val_acc: 0.0400\n",
      "Epoch 977/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0382 - acc: 0.4667 - val_loss: 1.1837 - val_acc: 0.0400\n",
      "Epoch 978/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0396 - acc: 0.5067 - val_loss: 1.1096 - val_acc: 0.0400\n",
      "Epoch 979/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0368 - acc: 0.4933 - val_loss: 1.1618 - val_acc: 0.0400\n",
      "Epoch 980/1000\n",
      "75/75 [==============================] - 0s 129us/step - loss: 0.0365 - acc: 0.4800 - val_loss: 1.1125 - val_acc: 0.0400\n",
      "Epoch 981/1000\n",
      "75/75 [==============================] - 0s 153us/step - loss: 0.0354 - acc: 0.4800 - val_loss: 1.1457 - val_acc: 0.0400\n",
      "Epoch 982/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0360 - acc: 0.4667 - val_loss: 1.0828 - val_acc: 0.0400\n",
      "Epoch 983/1000\n",
      "75/75 [==============================] - 0s 128us/step - loss: 0.0380 - acc: 0.4667 - val_loss: 1.1815 - val_acc: 0.0400\n",
      "Epoch 984/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0370 - acc: 0.4667 - val_loss: 1.1035 - val_acc: 0.0400\n",
      "Epoch 985/1000\n",
      "75/75 [==============================] - 0s 142us/step - loss: 0.0368 - acc: 0.4800 - val_loss: 1.1380 - val_acc: 0.0400\n",
      "Epoch 986/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0351 - acc: 0.4800 - val_loss: 1.1262 - val_acc: 0.0400\n",
      "Epoch 987/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.0356 - acc: 0.4667 - val_loss: 1.1482 - val_acc: 0.0400\n",
      "Epoch 988/1000\n",
      "75/75 [==============================] - 0s 150us/step - loss: 0.0362 - acc: 0.4800 - val_loss: 1.0814 - val_acc: 0.0400\n",
      "Epoch 989/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0395 - acc: 0.4933 - val_loss: 1.1592 - val_acc: 0.0400\n",
      "Epoch 990/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.0354 - acc: 0.4667 - val_loss: 1.1177 - val_acc: 0.0400\n",
      "Epoch 991/1000\n",
      "75/75 [==============================] - 0s 147us/step - loss: 0.0350 - acc: 0.4933 - val_loss: 1.1394 - val_acc: 0.0400\n",
      "Epoch 992/1000\n",
      "75/75 [==============================] - 0s 141us/step - loss: 0.0358 - acc: 0.5067 - val_loss: 1.0991 - val_acc: 0.0400\n",
      "Epoch 993/1000\n",
      "75/75 [==============================] - 0s 137us/step - loss: 0.0371 - acc: 0.4800 - val_loss: 1.2072 - val_acc: 0.0400\n",
      "Epoch 994/1000\n",
      "75/75 [==============================] - 0s 144us/step - loss: 0.0400 - acc: 0.4933 - val_loss: 1.1164 - val_acc: 0.0400\n",
      "Epoch 995/1000\n",
      "75/75 [==============================] - 0s 140us/step - loss: 0.0347 - acc: 0.4800 - val_loss: 1.1562 - val_acc: 0.0400\n",
      "Epoch 996/1000\n",
      "75/75 [==============================] - 0s 138us/step - loss: 0.0351 - acc: 0.4667 - val_loss: 1.1294 - val_acc: 0.0400\n",
      "Epoch 997/1000\n",
      "75/75 [==============================] - 0s 155us/step - loss: 0.0347 - acc: 0.4933 - val_loss: 1.1468 - val_acc: 0.0400\n",
      "Epoch 998/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0346 - acc: 0.4800 - val_loss: 1.1395 - val_acc: 0.0400\n",
      "Epoch 999/1000\n",
      "75/75 [==============================] - 0s 130us/step - loss: 0.0354 - acc: 0.4800 - val_loss: 1.0979 - val_acc: 0.0400\n",
      "Epoch 1000/1000\n",
      "75/75 [==============================] - 0s 135us/step - loss: 0.0394 - acc: 0.4667 - val_loss: 1.1650 - val_acc: 0.0400\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.25, epochs=1000, batch_size=32, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75 samples, validate on 25 samples\n",
      "Epoch 1/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.7885 - acc: 0.0000e+00 - val_loss: 0.7481 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.7682 - acc: 0.0000e+00 - val_loss: 0.7424 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "75/75 [==============================] - 0s 201us/step - loss: 0.7556 - acc: 0.0000e+00 - val_loss: 0.7364 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.7421 - acc: 0.0133 - val_loss: 0.7307 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.7301 - acc: 0.0267 - val_loss: 0.7272 - val_acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.7197 - acc: 0.0000e+00 - val_loss: 0.7255 - val_acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "75/75 [==============================] - 0s 197us/step - loss: 0.7082 - acc: 0.0000e+00 - val_loss: 0.7183 - val_acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "75/75 [==============================] - 0s 202us/step - loss: 0.7006 - acc: 0.0000e+00 - val_loss: 0.7175 - val_acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "75/75 [==============================] - 0s 210us/step - loss: 0.6921 - acc: 0.0000e+00 - val_loss: 0.7191 - val_acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "75/75 [==============================] - 0s 227us/step - loss: 0.6850 - acc: 0.0000e+00 - val_loss: 0.7148 - val_acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.6782 - acc: 0.0000e+00 - val_loss: 0.7211 - val_acc: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "75/75 [==============================] - 0s 211us/step - loss: 0.6716 - acc: 0.0000e+00 - val_loss: 0.7195 - val_acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "75/75 [==============================] - 0s 204us/step - loss: 0.6638 - acc: 0.0000e+00 - val_loss: 0.7136 - val_acc: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "75/75 [==============================] - 0s 211us/step - loss: 0.6585 - acc: 0.0000e+00 - val_loss: 0.7124 - val_acc: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.6544 - acc: 0.0000e+00 - val_loss: 0.7105 - val_acc: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "75/75 [==============================] - 0s 202us/step - loss: 0.6523 - acc: 0.0000e+00 - val_loss: 0.7102 - val_acc: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "75/75 [==============================] - 0s 194us/step - loss: 0.6471 - acc: 0.0000e+00 - val_loss: 0.7119 - val_acc: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.6434 - acc: 0.0000e+00 - val_loss: 0.7193 - val_acc: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "75/75 [==============================] - 0s 204us/step - loss: 0.6377 - acc: 0.0000e+00 - val_loss: 0.7188 - val_acc: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.6337 - acc: 0.0000e+00 - val_loss: 0.7252 - val_acc: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.6320 - acc: 0.0000e+00 - val_loss: 0.7296 - val_acc: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.6274 - acc: 0.0000e+00 - val_loss: 0.7209 - val_acc: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.6222 - acc: 0.0000e+00 - val_loss: 0.7261 - val_acc: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "75/75 [==============================] - 0s 210us/step - loss: 0.6190 - acc: 0.0000e+00 - val_loss: 0.7176 - val_acc: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "75/75 [==============================] - 0s 203us/step - loss: 0.6149 - acc: 0.0000e+00 - val_loss: 0.7213 - val_acc: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.6100 - acc: 0.0000e+00 - val_loss: 0.7182 - val_acc: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "75/75 [==============================] - 0s 205us/step - loss: 0.6085 - acc: 0.0000e+00 - val_loss: 0.7182 - val_acc: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "75/75 [==============================] - 0s 197us/step - loss: 0.6025 - acc: 0.0000e+00 - val_loss: 0.7252 - val_acc: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "75/75 [==============================] - 0s 197us/step - loss: 0.6019 - acc: 0.0000e+00 - val_loss: 0.7283 - val_acc: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.5958 - acc: 0.0000e+00 - val_loss: 0.7179 - val_acc: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.5923 - acc: 0.0000e+00 - val_loss: 0.7278 - val_acc: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.5904 - acc: 0.0000e+00 - val_loss: 0.7288 - val_acc: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "75/75 [==============================] - 0s 207us/step - loss: 0.5851 - acc: 0.0000e+00 - val_loss: 0.7129 - val_acc: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.5861 - acc: 0.0000e+00 - val_loss: 0.7263 - val_acc: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "75/75 [==============================] - 0s 205us/step - loss: 0.5815 - acc: 0.0000e+00 - val_loss: 0.7172 - val_acc: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "75/75 [==============================] - 0s 202us/step - loss: 0.5770 - acc: 0.0000e+00 - val_loss: 0.7184 - val_acc: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "75/75 [==============================] - 0s 197us/step - loss: 0.5749 - acc: 0.0133 - val_loss: 0.7296 - val_acc: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.5701 - acc: 0.0133 - val_loss: 0.7256 - val_acc: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.5653 - acc: 0.0133 - val_loss: 0.7173 - val_acc: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.5637 - acc: 0.0267 - val_loss: 0.7250 - val_acc: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.5578 - acc: 0.0133 - val_loss: 0.7430 - val_acc: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.5558 - acc: 0.0133 - val_loss: 0.7409 - val_acc: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.5516 - acc: 0.0267 - val_loss: 0.7278 - val_acc: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.5470 - acc: 0.0133 - val_loss: 0.7343 - val_acc: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.5473 - acc: 0.0267 - val_loss: 0.7315 - val_acc: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.5402 - acc: 0.0133 - val_loss: 0.7606 - val_acc: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.5388 - acc: 0.0133 - val_loss: 0.7395 - val_acc: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.5329 - acc: 0.0133 - val_loss: 0.7360 - val_acc: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.5317 - acc: 0.0133 - val_loss: 0.7399 - val_acc: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.5247 - acc: 0.0133 - val_loss: 0.7461 - val_acc: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.5236 - acc: 0.0133 - val_loss: 0.7422 - val_acc: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.5179 - acc: 0.0133 - val_loss: 0.7338 - val_acc: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.5159 - acc: 0.0133 - val_loss: 0.7477 - val_acc: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.5130 - acc: 0.0000e+00 - val_loss: 0.7481 - val_acc: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.5079 - acc: 0.0133 - val_loss: 0.7299 - val_acc: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.5069 - acc: 0.0267 - val_loss: 0.7457 - val_acc: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.5018 - acc: 0.0267 - val_loss: 0.7472 - val_acc: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.4981 - acc: 0.0400 - val_loss: 0.7590 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.4986 - acc: 0.0267 - val_loss: 0.7487 - val_acc: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.4930 - acc: 0.0267 - val_loss: 0.7509 - val_acc: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.4874 - acc: 0.0267 - val_loss: 0.7761 - val_acc: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.4854 - acc: 0.0267 - val_loss: 0.7387 - val_acc: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.4820 - acc: 0.0400 - val_loss: 0.7402 - val_acc: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.4786 - acc: 0.0400 - val_loss: 0.7537 - val_acc: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.4746 - acc: 0.0400 - val_loss: 0.7323 - val_acc: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.4752 - acc: 0.0267 - val_loss: 0.7507 - val_acc: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.4686 - acc: 0.0400 - val_loss: 0.7308 - val_acc: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.4703 - acc: 0.0267 - val_loss: 0.7440 - val_acc: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.4619 - acc: 0.0400 - val_loss: 0.7729 - val_acc: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.4589 - acc: 0.0400 - val_loss: 0.7526 - val_acc: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.4570 - acc: 0.0267 - val_loss: 0.7429 - val_acc: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.4536 - acc: 0.0400 - val_loss: 0.7685 - val_acc: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.4507 - acc: 0.0400 - val_loss: 0.7479 - val_acc: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.4478 - acc: 0.0400 - val_loss: 0.7656 - val_acc: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.4433 - acc: 0.0267 - val_loss: 0.7526 - val_acc: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.4413 - acc: 0.0400 - val_loss: 0.7577 - val_acc: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.4368 - acc: 0.0400 - val_loss: 0.7427 - val_acc: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "75/75 [==============================] - 0s 156us/step - loss: 0.4372 - acc: 0.0267 - val_loss: 0.7554 - val_acc: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.4324 - acc: 0.0267 - val_loss: 0.7859 - val_acc: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.4311 - acc: 0.0400 - val_loss: 0.7941 - val_acc: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.4256 - acc: 0.0400 - val_loss: 0.7554 - val_acc: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.4249 - acc: 0.0267 - val_loss: 0.8141 - val_acc: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.4258 - acc: 0.0267 - val_loss: 0.7853 - val_acc: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.4173 - acc: 0.0400 - val_loss: 0.7793 - val_acc: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.4148 - acc: 0.0400 - val_loss: 0.7783 - val_acc: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.4118 - acc: 0.0400 - val_loss: 0.7763 - val_acc: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.4080 - acc: 0.0267 - val_loss: 0.7818 - val_acc: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.4063 - acc: 0.0267 - val_loss: 0.7601 - val_acc: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.4046 - acc: 0.0267 - val_loss: 0.7963 - val_acc: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "75/75 [==============================] - 0s 195us/step - loss: 0.4058 - acc: 0.0400 - val_loss: 0.7598 - val_acc: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.3997 - acc: 0.0267 - val_loss: 0.7697 - val_acc: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.3974 - acc: 0.0267 - val_loss: 0.7707 - val_acc: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.3953 - acc: 0.0400 - val_loss: 0.7577 - val_acc: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.3922 - acc: 0.0533 - val_loss: 0.7936 - val_acc: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.3905 - acc: 0.0400 - val_loss: 0.7807 - val_acc: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.3880 - acc: 0.0533 - val_loss: 0.8236 - val_acc: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.3858 - acc: 0.0400 - val_loss: 0.7901 - val_acc: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.3872 - acc: 0.0400 - val_loss: 0.7600 - val_acc: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.3809 - acc: 0.0533 - val_loss: 0.7807 - val_acc: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.3774 - acc: 0.0533 - val_loss: 0.7745 - val_acc: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.3750 - acc: 0.0533 - val_loss: 0.7719 - val_acc: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.3734 - acc: 0.0533 - val_loss: 0.7708 - val_acc: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.3705 - acc: 0.0533 - val_loss: 0.7816 - val_acc: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.3685 - acc: 0.0533 - val_loss: 0.7628 - val_acc: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.3721 - acc: 0.0667 - val_loss: 0.7881 - val_acc: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.3635 - acc: 0.0533 - val_loss: 0.7751 - val_acc: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.3626 - acc: 0.0533 - val_loss: 0.7671 - val_acc: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.3638 - acc: 0.0533 - val_loss: 0.7801 - val_acc: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.3583 - acc: 0.0667 - val_loss: 0.7836 - val_acc: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.3569 - acc: 0.0667 - val_loss: 0.8092 - val_acc: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.3540 - acc: 0.0533 - val_loss: 0.7672 - val_acc: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.3532 - acc: 0.0667 - val_loss: 0.7864 - val_acc: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.3494 - acc: 0.0533 - val_loss: 0.8169 - val_acc: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.3481 - acc: 0.0667 - val_loss: 0.8124 - val_acc: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.3433 - acc: 0.0533 - val_loss: 0.8050 - val_acc: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.3410 - acc: 0.0667 - val_loss: 0.7737 - val_acc: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.3427 - acc: 0.0667 - val_loss: 0.7933 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.3379 - acc: 0.0667 - val_loss: 0.8096 - val_acc: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.3354 - acc: 0.0533 - val_loss: 0.8108 - val_acc: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.3338 - acc: 0.0533 - val_loss: 0.8284 - val_acc: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.3340 - acc: 0.0533 - val_loss: 0.7668 - val_acc: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "75/75 [==============================] - 0s 158us/step - loss: 0.3334 - acc: 0.0800 - val_loss: 0.8020 - val_acc: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.3271 - acc: 0.0667 - val_loss: 0.8117 - val_acc: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.3247 - acc: 0.0667 - val_loss: 0.7844 - val_acc: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.3269 - acc: 0.0533 - val_loss: 0.8128 - val_acc: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.3222 - acc: 0.0667 - val_loss: 0.8000 - val_acc: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.3192 - acc: 0.0667 - val_loss: 0.8009 - val_acc: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.3186 - acc: 0.0667 - val_loss: 0.8290 - val_acc: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.3198 - acc: 0.0800 - val_loss: 0.7873 - val_acc: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.3151 - acc: 0.0667 - val_loss: 0.8219 - val_acc: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.3118 - acc: 0.0667 - val_loss: 0.7991 - val_acc: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.3103 - acc: 0.0533 - val_loss: 0.8020 - val_acc: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.3083 - acc: 0.0667 - val_loss: 0.8460 - val_acc: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.3096 - acc: 0.0667 - val_loss: 0.7916 - val_acc: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.3053 - acc: 0.0800 - val_loss: 0.8417 - val_acc: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "75/75 [==============================] - 0s 201us/step - loss: 0.3016 - acc: 0.0800 - val_loss: 0.8008 - val_acc: 0.0400\n",
      "Epoch 137/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.3020 - acc: 0.0533 - val_loss: 0.8462 - val_acc: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.2978 - acc: 0.0667 - val_loss: 0.8019 - val_acc: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.2973 - acc: 0.0800 - val_loss: 0.8583 - val_acc: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.2963 - acc: 0.0800 - val_loss: 0.8194 - val_acc: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.2921 - acc: 0.0800 - val_loss: 0.8072 - val_acc: 0.0400\n",
      "Epoch 142/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.2905 - acc: 0.0933 - val_loss: 0.8465 - val_acc: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.2909 - acc: 0.0800 - val_loss: 0.8126 - val_acc: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.2884 - acc: 0.0667 - val_loss: 0.8588 - val_acc: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.2864 - acc: 0.0800 - val_loss: 0.8204 - val_acc: 0.0400\n",
      "Epoch 146/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.2832 - acc: 0.0800 - val_loss: 0.8026 - val_acc: 0.0400\n",
      "Epoch 147/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.2832 - acc: 0.0800 - val_loss: 0.8224 - val_acc: 0.0400\n",
      "Epoch 148/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.2797 - acc: 0.0800 - val_loss: 0.8450 - val_acc: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.2795 - acc: 0.0533 - val_loss: 0.7851 - val_acc: 0.0400\n",
      "Epoch 150/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.2839 - acc: 0.0667 - val_loss: 0.8546 - val_acc: 0.0400\n",
      "Epoch 151/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.2765 - acc: 0.0667 - val_loss: 0.8152 - val_acc: 0.0400\n",
      "Epoch 152/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.2737 - acc: 0.0933 - val_loss: 0.8355 - val_acc: 0.0400\n",
      "Epoch 153/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.2726 - acc: 0.0667 - val_loss: 0.8042 - val_acc: 0.0400\n",
      "Epoch 154/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.2725 - acc: 0.0800 - val_loss: 0.8665 - val_acc: 0.0000e+00\n",
      "Epoch 155/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.2713 - acc: 0.0667 - val_loss: 0.8299 - val_acc: 0.0000e+00\n",
      "Epoch 156/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.2675 - acc: 0.0933 - val_loss: 0.8283 - val_acc: 0.0400\n",
      "Epoch 157/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.2654 - acc: 0.0933 - val_loss: 0.8710 - val_acc: 0.0000e+00\n",
      "Epoch 158/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.2703 - acc: 0.0933 - val_loss: 0.8114 - val_acc: 0.0400\n",
      "Epoch 159/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.2640 - acc: 0.0933 - val_loss: 0.8306 - val_acc: 0.0400\n",
      "Epoch 160/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.2603 - acc: 0.0800 - val_loss: 0.8418 - val_acc: 0.0400\n",
      "Epoch 161/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.2579 - acc: 0.0933 - val_loss: 0.8582 - val_acc: 0.0400\n",
      "Epoch 162/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.2580 - acc: 0.0800 - val_loss: 0.8189 - val_acc: 0.0400\n",
      "Epoch 163/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.2569 - acc: 0.1067 - val_loss: 0.8890 - val_acc: 0.0000e+00\n",
      "Epoch 164/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.2605 - acc: 0.0800 - val_loss: 0.8141 - val_acc: 0.0400\n",
      "Epoch 165/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.2563 - acc: 0.0933 - val_loss: 0.8338 - val_acc: 0.0400\n",
      "Epoch 166/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.2515 - acc: 0.1067 - val_loss: 0.8460 - val_acc: 0.0000e+00\n",
      "Epoch 167/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.2497 - acc: 0.1067 - val_loss: 0.8494 - val_acc: 0.0400\n",
      "Epoch 168/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.2486 - acc: 0.1067 - val_loss: 0.8330 - val_acc: 0.0400\n",
      "Epoch 169/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.2467 - acc: 0.1067 - val_loss: 0.8636 - val_acc: 0.0400\n",
      "Epoch 170/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.2458 - acc: 0.1067 - val_loss: 0.8365 - val_acc: 0.0400\n",
      "Epoch 171/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.2466 - acc: 0.1200 - val_loss: 0.8780 - val_acc: 0.0400\n",
      "Epoch 172/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.2461 - acc: 0.1200 - val_loss: 0.8305 - val_acc: 0.0400\n",
      "Epoch 173/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.2456 - acc: 0.1467 - val_loss: 0.8566 - val_acc: 0.0400\n",
      "Epoch 174/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.2404 - acc: 0.1067 - val_loss: 0.8361 - val_acc: 0.0400\n",
      "Epoch 175/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.2388 - acc: 0.1067 - val_loss: 0.8353 - val_acc: 0.0400\n",
      "Epoch 176/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.2369 - acc: 0.1333 - val_loss: 0.8659 - val_acc: 0.0400\n",
      "Epoch 177/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 176us/step - loss: 0.2369 - acc: 0.1333 - val_loss: 0.8207 - val_acc: 0.0400\n",
      "Epoch 178/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.2416 - acc: 0.1067 - val_loss: 0.8863 - val_acc: 0.0400\n",
      "Epoch 179/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.2383 - acc: 0.1333 - val_loss: 0.8306 - val_acc: 0.0400\n",
      "Epoch 180/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.2327 - acc: 0.1200 - val_loss: 0.8579 - val_acc: 0.0400\n",
      "Epoch 181/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.2317 - acc: 0.1333 - val_loss: 0.8490 - val_acc: 0.0400\n",
      "Epoch 182/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.2318 - acc: 0.1067 - val_loss: 0.8550 - val_acc: 0.0400\n",
      "Epoch 183/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.2298 - acc: 0.1200 - val_loss: 0.8189 - val_acc: 0.0400\n",
      "Epoch 184/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.2311 - acc: 0.1200 - val_loss: 0.8886 - val_acc: 0.0000e+00\n",
      "Epoch 185/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.2300 - acc: 0.1467 - val_loss: 0.8373 - val_acc: 0.0000e+00\n",
      "Epoch 186/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.2271 - acc: 0.1467 - val_loss: 0.8482 - val_acc: 0.0000e+00\n",
      "Epoch 187/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.2237 - acc: 0.1333 - val_loss: 0.8747 - val_acc: 0.0000e+00\n",
      "Epoch 188/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.2229 - acc: 0.1333 - val_loss: 0.8559 - val_acc: 0.0000e+00\n",
      "Epoch 189/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.2209 - acc: 0.1467 - val_loss: 0.8449 - val_acc: 0.0400\n",
      "Epoch 190/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.2212 - acc: 0.1200 - val_loss: 0.8556 - val_acc: 0.0000e+00\n",
      "Epoch 191/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.2202 - acc: 0.1067 - val_loss: 0.8190 - val_acc: 0.0400\n",
      "Epoch 192/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.2237 - acc: 0.1333 - val_loss: 0.8875 - val_acc: 0.0000e+00\n",
      "Epoch 193/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.2193 - acc: 0.1467 - val_loss: 0.8574 - val_acc: 0.0000e+00\n",
      "Epoch 194/1000\n",
      "75/75 [==============================] - 0s 252us/step - loss: 0.2158 - acc: 0.1333 - val_loss: 0.8422 - val_acc: 0.0400\n",
      "Epoch 195/1000\n",
      "75/75 [==============================] - 0s 212us/step - loss: 0.2148 - acc: 0.1200 - val_loss: 0.8758 - val_acc: 0.0000e+00\n",
      "Epoch 196/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.2141 - acc: 0.1333 - val_loss: 0.8671 - val_acc: 0.0400\n",
      "Epoch 197/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.2130 - acc: 0.1200 - val_loss: 0.8764 - val_acc: 0.0000e+00\n",
      "Epoch 198/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.2138 - acc: 0.1333 - val_loss: 0.8663 - val_acc: 0.0000e+00\n",
      "Epoch 199/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.2149 - acc: 0.1333 - val_loss: 0.8125 - val_acc: 0.0400\n",
      "Epoch 200/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.2143 - acc: 0.1200 - val_loss: 0.8734 - val_acc: 0.0000e+00\n",
      "Epoch 201/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.2083 - acc: 0.1333 - val_loss: 0.8773 - val_acc: 0.0000e+00\n",
      "Epoch 202/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.2072 - acc: 0.1333 - val_loss: 0.8562 - val_acc: 0.0400\n",
      "Epoch 203/1000\n",
      "75/75 [==============================] - 0s 303us/step - loss: 0.2062 - acc: 0.1333 - val_loss: 0.8968 - val_acc: 0.0000e+00\n",
      "Epoch 204/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.2073 - acc: 0.1200 - val_loss: 0.8326 - val_acc: 0.0400\n",
      "Epoch 205/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.2124 - acc: 0.1200 - val_loss: 0.8757 - val_acc: 0.0400\n",
      "Epoch 206/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.2030 - acc: 0.1200 - val_loss: 0.8730 - val_acc: 0.0000e+00\n",
      "Epoch 207/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.2027 - acc: 0.1200 - val_loss: 0.8921 - val_acc: 0.0400\n",
      "Epoch 208/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.2044 - acc: 0.1333 - val_loss: 0.8598 - val_acc: 0.0400\n",
      "Epoch 209/1000\n",
      "75/75 [==============================] - 0s 211us/step - loss: 0.2013 - acc: 0.1067 - val_loss: 0.8906 - val_acc: 0.0000e+00\n",
      "Epoch 210/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.2022 - acc: 0.1200 - val_loss: 0.8388 - val_acc: 0.0400\n",
      "Epoch 211/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.2020 - acc: 0.1200 - val_loss: 0.8912 - val_acc: 0.0000e+00\n",
      "Epoch 212/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.2020 - acc: 0.1200 - val_loss: 0.8606 - val_acc: 0.0400\n",
      "Epoch 213/1000\n",
      "75/75 [==============================] - 0s 200us/step - loss: 0.1968 - acc: 0.1200 - val_loss: 0.8946 - val_acc: 0.0000e+00\n",
      "Epoch 214/1000\n",
      "75/75 [==============================] - 0s 202us/step - loss: 0.1982 - acc: 0.1200 - val_loss: 0.8632 - val_acc: 0.0400\n",
      "Epoch 215/1000\n",
      "75/75 [==============================] - 0s 209us/step - loss: 0.1949 - acc: 0.1333 - val_loss: 0.8695 - val_acc: 0.0000e+00\n",
      "Epoch 216/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.1940 - acc: 0.1333 - val_loss: 0.8609 - val_acc: 0.0000e+00\n",
      "Epoch 217/1000\n",
      "75/75 [==============================] - 0s 194us/step - loss: 0.1945 - acc: 0.1333 - val_loss: 0.8765 - val_acc: 0.0000e+00\n",
      "Epoch 218/1000\n",
      "75/75 [==============================] - 0s 212us/step - loss: 0.1976 - acc: 0.1200 - val_loss: 0.8308 - val_acc: 0.0400\n",
      "Epoch 219/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.1951 - acc: 0.1200 - val_loss: 0.9298 - val_acc: 0.0000e+00\n",
      "Epoch 220/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.1993 - acc: 0.1200 - val_loss: 0.8497 - val_acc: 0.0400\n",
      "Epoch 221/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.1931 - acc: 0.1067 - val_loss: 0.8600 - val_acc: 0.0400\n",
      "Epoch 222/1000\n",
      "75/75 [==============================] - 0s 216us/step - loss: 0.1891 - acc: 0.1200 - val_loss: 0.8709 - val_acc: 0.0400\n",
      "Epoch 223/1000\n",
      "75/75 [==============================] - 0s 226us/step - loss: 0.1886 - acc: 0.1200 - val_loss: 0.8815 - val_acc: 0.0000e+00\n",
      "Epoch 224/1000\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.1872 - acc: 0.1200 - val_loss: 0.8702 - val_acc: 0.0400\n",
      "Epoch 225/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.1871 - acc: 0.1200 - val_loss: 0.9334 - val_acc: 0.0000e+00\n",
      "Epoch 226/1000\n",
      "75/75 [==============================] - 0s 200us/step - loss: 0.1915 - acc: 0.1200 - val_loss: 0.8432 - val_acc: 0.0400\n",
      "Epoch 227/1000\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.1902 - acc: 0.1333 - val_loss: 0.9067 - val_acc: 0.0000e+00\n",
      "Epoch 228/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.1874 - acc: 0.1333 - val_loss: 0.8666 - val_acc: 0.0400\n",
      "Epoch 229/1000\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.1833 - acc: 0.1333 - val_loss: 0.8745 - val_acc: 0.0400\n",
      "Epoch 230/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.1825 - acc: 0.1333 - val_loss: 0.8809 - val_acc: 0.0400\n",
      "Epoch 231/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.1832 - acc: 0.1333 - val_loss: 0.9284 - val_acc: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.1892 - acc: 0.1333 - val_loss: 0.8511 - val_acc: 0.0400\n",
      "Epoch 233/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.1835 - acc: 0.1467 - val_loss: 0.8997 - val_acc: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.1810 - acc: 0.1333 - val_loss: 0.8433 - val_acc: 0.0400\n",
      "Epoch 235/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.1856 - acc: 0.1200 - val_loss: 0.9031 - val_acc: 0.0000e+00\n",
      "Epoch 236/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 176us/step - loss: 0.1796 - acc: 0.1333 - val_loss: 0.8842 - val_acc: 0.0400\n",
      "Epoch 237/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.1773 - acc: 0.1333 - val_loss: 0.8818 - val_acc: 0.0400\n",
      "Epoch 238/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.1778 - acc: 0.1333 - val_loss: 0.9316 - val_acc: 0.0000e+00\n",
      "Epoch 239/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.1832 - acc: 0.1467 - val_loss: 0.8485 - val_acc: 0.0400\n",
      "Epoch 240/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.1780 - acc: 0.1333 - val_loss: 0.9144 - val_acc: 0.0000e+00\n",
      "Epoch 241/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.1761 - acc: 0.1200 - val_loss: 0.8918 - val_acc: 0.0000e+00\n",
      "Epoch 242/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.1747 - acc: 0.1333 - val_loss: 0.8771 - val_acc: 0.0400\n",
      "Epoch 243/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.1739 - acc: 0.1333 - val_loss: 0.8866 - val_acc: 0.0400\n",
      "Epoch 244/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.1730 - acc: 0.1333 - val_loss: 0.9087 - val_acc: 0.0000e+00\n",
      "Epoch 245/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.1771 - acc: 0.1467 - val_loss: 0.8667 - val_acc: 0.0000e+00\n",
      "Epoch 246/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.1748 - acc: 0.1333 - val_loss: 0.9017 - val_acc: 0.0000e+00\n",
      "Epoch 247/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.1722 - acc: 0.1333 - val_loss: 0.8708 - val_acc: 0.0400\n",
      "Epoch 248/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.1709 - acc: 0.1467 - val_loss: 0.8980 - val_acc: 0.0000e+00\n",
      "Epoch 249/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.1695 - acc: 0.1333 - val_loss: 0.8679 - val_acc: 0.0400\n",
      "Epoch 250/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.1711 - acc: 0.1467 - val_loss: 0.9493 - val_acc: 0.0000e+00\n",
      "Epoch 251/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.1783 - acc: 0.1333 - val_loss: 0.8581 - val_acc: 0.0400\n",
      "Epoch 252/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.1713 - acc: 0.1333 - val_loss: 0.8961 - val_acc: 0.0400\n",
      "Epoch 253/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.1671 - acc: 0.1333 - val_loss: 0.9190 - val_acc: 0.0000e+00\n",
      "Epoch 254/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.1698 - acc: 0.1333 - val_loss: 0.9023 - val_acc: 0.0400\n",
      "Epoch 255/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.1658 - acc: 0.1333 - val_loss: 0.8795 - val_acc: 0.0400\n",
      "Epoch 256/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.1665 - acc: 0.1467 - val_loss: 0.9269 - val_acc: 0.0400\n",
      "Epoch 257/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.1680 - acc: 0.1467 - val_loss: 0.8464 - val_acc: 0.0400\n",
      "Epoch 258/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.1674 - acc: 0.1467 - val_loss: 0.9038 - val_acc: 0.0400\n",
      "Epoch 259/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.1649 - acc: 0.1333 - val_loss: 0.8673 - val_acc: 0.0000e+00\n",
      "Epoch 260/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.1652 - acc: 0.1333 - val_loss: 0.9531 - val_acc: 0.0000e+00\n",
      "Epoch 261/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.1667 - acc: 0.1333 - val_loss: 0.8594 - val_acc: 0.0400\n",
      "Epoch 262/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.1669 - acc: 0.1467 - val_loss: 0.9302 - val_acc: 0.0000e+00\n",
      "Epoch 263/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.1612 - acc: 0.1467 - val_loss: 0.8830 - val_acc: 0.0400\n",
      "Epoch 264/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.1598 - acc: 0.1467 - val_loss: 0.9224 - val_acc: 0.0400\n",
      "Epoch 265/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.1600 - acc: 0.1200 - val_loss: 0.8728 - val_acc: 0.0400\n",
      "Epoch 266/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.1636 - acc: 0.1333 - val_loss: 0.9718 - val_acc: 0.0000e+00\n",
      "Epoch 267/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.1629 - acc: 0.1333 - val_loss: 0.8645 - val_acc: 0.0400\n",
      "Epoch 268/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.1587 - acc: 0.1333 - val_loss: 0.9225 - val_acc: 0.0000e+00\n",
      "Epoch 269/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.1576 - acc: 0.1467 - val_loss: 0.8721 - val_acc: 0.0400\n",
      "Epoch 270/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.1590 - acc: 0.1333 - val_loss: 0.9268 - val_acc: 0.0400\n",
      "Epoch 271/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.1568 - acc: 0.1467 - val_loss: 0.8897 - val_acc: 0.0400\n",
      "Epoch 272/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.1571 - acc: 0.1333 - val_loss: 0.9198 - val_acc: 0.0000e+00\n",
      "Epoch 273/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.1580 - acc: 0.1333 - val_loss: 0.8584 - val_acc: 0.0400\n",
      "Epoch 274/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.1586 - acc: 0.1600 - val_loss: 0.9257 - val_acc: 0.0000e+00\n",
      "Epoch 275/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.1561 - acc: 0.1333 - val_loss: 0.8710 - val_acc: 0.0400\n",
      "Epoch 276/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.1551 - acc: 0.1333 - val_loss: 0.9109 - val_acc: 0.0000e+00\n",
      "Epoch 277/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.1548 - acc: 0.1200 - val_loss: 0.8623 - val_acc: 0.0000e+00\n",
      "Epoch 278/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.1571 - acc: 0.1200 - val_loss: 0.9189 - val_acc: 0.0000e+00\n",
      "Epoch 279/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.1519 - acc: 0.1333 - val_loss: 0.8932 - val_acc: 0.0000e+00\n",
      "Epoch 280/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.1510 - acc: 0.1333 - val_loss: 0.9085 - val_acc: 0.0400\n",
      "Epoch 281/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.1512 - acc: 0.1200 - val_loss: 0.8715 - val_acc: 0.0400\n",
      "Epoch 282/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.1545 - acc: 0.1200 - val_loss: 0.9468 - val_acc: 0.0000e+00\n",
      "Epoch 283/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.1531 - acc: 0.1200 - val_loss: 0.8727 - val_acc: 0.0400\n",
      "Epoch 284/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.1489 - acc: 0.1333 - val_loss: 0.8987 - val_acc: 0.0000e+00\n",
      "Epoch 285/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.1477 - acc: 0.1333 - val_loss: 0.8903 - val_acc: 0.0400\n",
      "Epoch 286/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.1477 - acc: 0.1333 - val_loss: 0.9371 - val_acc: 0.0000e+00\n",
      "Epoch 287/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.1491 - acc: 0.1333 - val_loss: 0.8661 - val_acc: 0.0400\n",
      "Epoch 288/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.1549 - acc: 0.1333 - val_loss: 0.9294 - val_acc: 0.0400\n",
      "Epoch 289/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.1463 - acc: 0.1467 - val_loss: 0.9214 - val_acc: 0.0000e+00\n",
      "Epoch 290/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.1447 - acc: 0.1333 - val_loss: 0.8962 - val_acc: 0.0400\n",
      "Epoch 291/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.1444 - acc: 0.1333 - val_loss: 0.8982 - val_acc: 0.0400\n",
      "Epoch 292/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.1442 - acc: 0.1467 - val_loss: 0.9409 - val_acc: 0.0000e+00\n",
      "Epoch 293/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.1468 - acc: 0.1200 - val_loss: 0.8780 - val_acc: 0.0400\n",
      "Epoch 294/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.1441 - acc: 0.1467 - val_loss: 0.9517 - val_acc: 0.0000e+00\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 187us/step - loss: 0.1530 - acc: 0.1333 - val_loss: 0.8581 - val_acc: 0.0400\n",
      "Epoch 296/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.1447 - acc: 0.1333 - val_loss: 0.9152 - val_acc: 0.0400\n",
      "Epoch 297/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.1410 - acc: 0.1467 - val_loss: 0.9170 - val_acc: 0.0400\n",
      "Epoch 298/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.1422 - acc: 0.1467 - val_loss: 0.8908 - val_acc: 0.0400\n",
      "Epoch 299/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.1429 - acc: 0.1200 - val_loss: 0.9632 - val_acc: 0.0000e+00\n",
      "Epoch 300/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.1419 - acc: 0.1200 - val_loss: 0.8933 - val_acc: 0.0400\n",
      "Epoch 301/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.1420 - acc: 0.1333 - val_loss: 0.9391 - val_acc: 0.0400\n",
      "Epoch 302/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.1406 - acc: 0.1467 - val_loss: 0.8730 - val_acc: 0.0400\n",
      "Epoch 303/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.1421 - acc: 0.1333 - val_loss: 0.9324 - val_acc: 0.0000e+00\n",
      "Epoch 304/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.1385 - acc: 0.1200 - val_loss: 0.8741 - val_acc: 0.0400\n",
      "Epoch 305/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.1416 - acc: 0.1200 - val_loss: 0.9321 - val_acc: 0.0000e+00\n",
      "Epoch 306/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.1392 - acc: 0.1200 - val_loss: 0.8958 - val_acc: 0.0000e+00\n",
      "Epoch 307/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.1392 - acc: 0.1467 - val_loss: 0.9480 - val_acc: 0.0000e+00\n",
      "Epoch 308/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.1381 - acc: 0.1200 - val_loss: 0.8889 - val_acc: 0.0000e+00\n",
      "Epoch 309/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.1383 - acc: 0.1333 - val_loss: 0.9624 - val_acc: 0.0000e+00\n",
      "Epoch 310/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.1370 - acc: 0.1467 - val_loss: 0.8844 - val_acc: 0.0000e+00\n",
      "Epoch 311/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.1367 - acc: 0.1467 - val_loss: 0.9769 - val_acc: 0.0000e+00\n",
      "Epoch 312/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.1370 - acc: 0.1333 - val_loss: 0.8756 - val_acc: 0.0400\n",
      "Epoch 313/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.1382 - acc: 0.1200 - val_loss: 0.9156 - val_acc: 0.0400\n",
      "Epoch 314/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.1333 - acc: 0.1467 - val_loss: 0.8962 - val_acc: 0.0400\n",
      "Epoch 315/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.1348 - acc: 0.1600 - val_loss: 0.9411 - val_acc: 0.0000e+00\n",
      "Epoch 316/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.1342 - acc: 0.1333 - val_loss: 0.8819 - val_acc: 0.0400\n",
      "Epoch 317/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.1342 - acc: 0.1333 - val_loss: 0.9447 - val_acc: 0.0000e+00\n",
      "Epoch 318/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.1338 - acc: 0.1467 - val_loss: 0.8918 - val_acc: 0.0000e+00\n",
      "Epoch 319/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.1315 - acc: 0.1467 - val_loss: 0.9509 - val_acc: 0.0000e+00\n",
      "Epoch 320/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.1327 - acc: 0.1333 - val_loss: 0.8654 - val_acc: 0.0400\n",
      "Epoch 321/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.1331 - acc: 0.1467 - val_loss: 0.9193 - val_acc: 0.0000e+00\n",
      "Epoch 322/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.1306 - acc: 0.1600 - val_loss: 0.9117 - val_acc: 0.0000e+00\n",
      "Epoch 323/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.1295 - acc: 0.1333 - val_loss: 0.9331 - val_acc: 0.0000e+00\n",
      "Epoch 324/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.1323 - acc: 0.1600 - val_loss: 0.8700 - val_acc: 0.0400\n",
      "Epoch 325/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.1378 - acc: 0.1600 - val_loss: 0.9166 - val_acc: 0.0000e+00\n",
      "Epoch 326/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.1273 - acc: 0.1733 - val_loss: 0.9285 - val_acc: 0.0000e+00\n",
      "Epoch 327/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.1272 - acc: 0.1600 - val_loss: 0.8921 - val_acc: 0.0400\n",
      "Epoch 328/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.1292 - acc: 0.1467 - val_loss: 0.9292 - val_acc: 0.0400\n",
      "Epoch 329/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.1270 - acc: 0.1600 - val_loss: 0.9039 - val_acc: 0.0400\n",
      "Epoch 330/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.1271 - acc: 0.1333 - val_loss: 0.9614 - val_acc: 0.0000e+00\n",
      "Epoch 331/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.1298 - acc: 0.1333 - val_loss: 0.8714 - val_acc: 0.0000e+00\n",
      "Epoch 332/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.1273 - acc: 0.1600 - val_loss: 0.9568 - val_acc: 0.0000e+00\n",
      "Epoch 333/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.1258 - acc: 0.1333 - val_loss: 0.9096 - val_acc: 0.0000e+00\n",
      "Epoch 334/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.1240 - acc: 0.1733 - val_loss: 0.9426 - val_acc: 0.0400\n",
      "Epoch 335/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.1256 - acc: 0.1600 - val_loss: 0.9042 - val_acc: 0.0000e+00\n",
      "Epoch 336/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.1283 - acc: 0.1733 - val_loss: 0.9391 - val_acc: 0.0000e+00\n",
      "Epoch 337/1000\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.1233 - acc: 0.1600 - val_loss: 0.8875 - val_acc: 0.0000e+00\n",
      "Epoch 338/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.1248 - acc: 0.1467 - val_loss: 0.9844 - val_acc: 0.0000e+00\n",
      "Epoch 339/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.1262 - acc: 0.1600 - val_loss: 0.8885 - val_acc: 0.0000e+00\n",
      "Epoch 340/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.1232 - acc: 0.1600 - val_loss: 0.9475 - val_acc: 0.0000e+00\n",
      "Epoch 341/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.1213 - acc: 0.1733 - val_loss: 0.9305 - val_acc: 0.0000e+00\n",
      "Epoch 342/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.1205 - acc: 0.1600 - val_loss: 0.9341 - val_acc: 0.0400\n",
      "Epoch 343/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.1261 - acc: 0.1733 - val_loss: 0.8770 - val_acc: 0.0000e+00\n",
      "Epoch 344/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.1258 - acc: 0.1600 - val_loss: 0.9723 - val_acc: 0.0000e+00\n",
      "Epoch 345/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.1221 - acc: 0.1467 - val_loss: 0.9328 - val_acc: 0.0000e+00\n",
      "Epoch 346/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.1182 - acc: 0.1733 - val_loss: 0.9109 - val_acc: 0.0000e+00\n",
      "Epoch 347/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.1179 - acc: 0.1733 - val_loss: 0.9406 - val_acc: 0.0000e+00\n",
      "Epoch 348/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.1193 - acc: 0.1467 - val_loss: 0.8731 - val_acc: 0.0000e+00\n",
      "Epoch 349/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.1251 - acc: 0.1733 - val_loss: 0.9616 - val_acc: 0.0000e+00\n",
      "Epoch 350/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.1225 - acc: 0.1733 - val_loss: 0.9006 - val_acc: 0.0000e+00\n",
      "Epoch 351/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.1168 - acc: 0.1600 - val_loss: 0.9062 - val_acc: 0.0000e+00\n",
      "Epoch 352/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.1165 - acc: 0.1467 - val_loss: 0.9507 - val_acc: 0.0000e+00\n",
      "Epoch 353/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.1169 - acc: 0.1600 - val_loss: 0.8818 - val_acc: 0.0000e+00\n",
      "Epoch 354/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 191us/step - loss: 0.1181 - acc: 0.1467 - val_loss: 0.9373 - val_acc: 0.0000e+00\n",
      "Epoch 355/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.1157 - acc: 0.1733 - val_loss: 0.9066 - val_acc: 0.0000e+00\n",
      "Epoch 356/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.1215 - acc: 0.1600 - val_loss: 0.9662 - val_acc: 0.0000e+00\n",
      "Epoch 357/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.1169 - acc: 0.1733 - val_loss: 0.9012 - val_acc: 0.0000e+00\n",
      "Epoch 358/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.1142 - acc: 0.1600 - val_loss: 0.9309 - val_acc: 0.0000e+00\n",
      "Epoch 359/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.1131 - acc: 0.1733 - val_loss: 0.9072 - val_acc: 0.0000e+00\n",
      "Epoch 360/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.1166 - acc: 0.1467 - val_loss: 0.9676 - val_acc: 0.0000e+00\n",
      "Epoch 361/1000\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.1146 - acc: 0.1600 - val_loss: 0.9145 - val_acc: 0.0000e+00\n",
      "Epoch 362/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.1126 - acc: 0.1733 - val_loss: 0.9700 - val_acc: 0.0000e+00\n",
      "Epoch 363/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.1157 - acc: 0.1600 - val_loss: 0.8956 - val_acc: 0.0400\n",
      "Epoch 364/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.1146 - acc: 0.1867 - val_loss: 0.9506 - val_acc: 0.0000e+00\n",
      "Epoch 365/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.1118 - acc: 0.1733 - val_loss: 0.9137 - val_acc: 0.0000e+00\n",
      "Epoch 366/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.1120 - acc: 0.1600 - val_loss: 0.9488 - val_acc: 0.0000e+00\n",
      "Epoch 367/1000\n",
      "75/75 [==============================] - 0s 197us/step - loss: 0.1171 - acc: 0.1733 - val_loss: 0.9032 - val_acc: 0.0000e+00\n",
      "Epoch 368/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.1118 - acc: 0.1467 - val_loss: 0.9546 - val_acc: 0.0000e+00\n",
      "Epoch 369/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.1103 - acc: 0.1600 - val_loss: 0.8857 - val_acc: 0.0400\n",
      "Epoch 370/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.1153 - acc: 0.1733 - val_loss: 0.9744 - val_acc: 0.0000e+00\n",
      "Epoch 371/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.1110 - acc: 0.1600 - val_loss: 0.9280 - val_acc: 0.0000e+00\n",
      "Epoch 372/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.1099 - acc: 0.1733 - val_loss: 0.9643 - val_acc: 0.0000e+00\n",
      "Epoch 373/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.1095 - acc: 0.1733 - val_loss: 0.9055 - val_acc: 0.0000e+00\n",
      "Epoch 374/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.1118 - acc: 0.1733 - val_loss: 1.0026 - val_acc: 0.0000e+00\n",
      "Epoch 375/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.1134 - acc: 0.1733 - val_loss: 0.9194 - val_acc: 0.0000e+00\n",
      "Epoch 376/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.1072 - acc: 0.2000 - val_loss: 0.9390 - val_acc: 0.0000e+00\n",
      "Epoch 377/1000\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.1061 - acc: 0.1867 - val_loss: 0.9123 - val_acc: 0.0000e+00\n",
      "Epoch 378/1000\n",
      "75/75 [==============================] - 0s 208us/step - loss: 0.1086 - acc: 0.1867 - val_loss: 0.9880 - val_acc: 0.0000e+00\n",
      "Epoch 379/1000\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.1133 - acc: 0.2000 - val_loss: 0.9160 - val_acc: 0.0000e+00\n",
      "Epoch 380/1000\n",
      "75/75 [==============================] - 0s 217us/step - loss: 0.1063 - acc: 0.1867 - val_loss: 0.9358 - val_acc: 0.0000e+00\n",
      "Epoch 381/1000\n",
      "75/75 [==============================] - 0s 206us/step - loss: 0.1047 - acc: 0.1733 - val_loss: 0.9145 - val_acc: 0.0400\n",
      "Epoch 382/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.1068 - acc: 0.1733 - val_loss: 0.9887 - val_acc: 0.0000e+00\n",
      "Epoch 383/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.1084 - acc: 0.1867 - val_loss: 0.8880 - val_acc: 0.0400\n",
      "Epoch 384/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.1131 - acc: 0.1467 - val_loss: 0.9585 - val_acc: 0.0000e+00\n",
      "Epoch 385/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.1051 - acc: 0.1600 - val_loss: 0.9443 - val_acc: 0.0000e+00\n",
      "Epoch 386/1000\n",
      "75/75 [==============================] - 0s 194us/step - loss: 0.1033 - acc: 0.1733 - val_loss: 0.9189 - val_acc: 0.0400\n",
      "Epoch 387/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.1034 - acc: 0.1867 - val_loss: 0.9659 - val_acc: 0.0000e+00\n",
      "Epoch 388/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.1068 - acc: 0.1867 - val_loss: 0.8671 - val_acc: 0.0400\n",
      "Epoch 389/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.1123 - acc: 0.1867 - val_loss: 0.9568 - val_acc: 0.0000e+00\n",
      "Epoch 390/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.1049 - acc: 0.1600 - val_loss: 0.9256 - val_acc: 0.0000e+00\n",
      "Epoch 391/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.1021 - acc: 0.1867 - val_loss: 0.9434 - val_acc: 0.0400\n",
      "Epoch 392/1000\n",
      "75/75 [==============================] - 0s 194us/step - loss: 0.1013 - acc: 0.1867 - val_loss: 0.9282 - val_acc: 0.0400\n",
      "Epoch 393/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.1029 - acc: 0.1867 - val_loss: 0.9921 - val_acc: 0.0000e+00\n",
      "Epoch 394/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.1061 - acc: 0.2267 - val_loss: 0.8795 - val_acc: 0.0400\n",
      "Epoch 395/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.1092 - acc: 0.2000 - val_loss: 0.9536 - val_acc: 0.0000e+00\n",
      "Epoch 396/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.1002 - acc: 0.1867 - val_loss: 0.9334 - val_acc: 0.0400\n",
      "Epoch 397/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0998 - acc: 0.1867 - val_loss: 0.9626 - val_acc: 0.0000e+00\n",
      "Epoch 398/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0995 - acc: 0.1867 - val_loss: 0.9035 - val_acc: 0.0400\n",
      "Epoch 399/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.1021 - acc: 0.1600 - val_loss: 0.9599 - val_acc: 0.0400\n",
      "Epoch 400/1000\n",
      "75/75 [==============================] - 0s 195us/step - loss: 0.0992 - acc: 0.2000 - val_loss: 0.9330 - val_acc: 0.0400\n",
      "Epoch 401/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0983 - acc: 0.1867 - val_loss: 0.9935 - val_acc: 0.0000e+00\n",
      "Epoch 402/1000\n",
      "75/75 [==============================] - 0s 204us/step - loss: 0.1086 - acc: 0.1867 - val_loss: 0.9064 - val_acc: 0.0400\n",
      "Epoch 403/1000\n",
      "75/75 [==============================] - 0s 231us/step - loss: 0.1010 - acc: 0.1733 - val_loss: 0.9610 - val_acc: 0.0400\n",
      "Epoch 404/1000\n",
      "75/75 [==============================] - 0s 202us/step - loss: 0.0986 - acc: 0.1867 - val_loss: 0.9296 - val_acc: 0.0000e+00\n",
      "Epoch 405/1000\n",
      "75/75 [==============================] - 0s 213us/step - loss: 0.0981 - acc: 0.1733 - val_loss: 0.9682 - val_acc: 0.0000e+00\n",
      "Epoch 406/1000\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.0985 - acc: 0.2000 - val_loss: 0.9108 - val_acc: 0.0400\n",
      "Epoch 407/1000\n",
      "75/75 [==============================] - 0s 195us/step - loss: 0.1002 - acc: 0.2000 - val_loss: 1.0111 - val_acc: 0.0000e+00\n",
      "Epoch 408/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.1025 - acc: 0.2133 - val_loss: 0.9009 - val_acc: 0.0000e+00\n",
      "Epoch 409/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.0978 - acc: 0.2133 - val_loss: 0.9553 - val_acc: 0.0000e+00\n",
      "Epoch 410/1000\n",
      "75/75 [==============================] - 0s 210us/step - loss: 0.0955 - acc: 0.2000 - val_loss: 0.9065 - val_acc: 0.0400\n",
      "Epoch 411/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.0959 - acc: 0.2400 - val_loss: 0.9760 - val_acc: 0.0000e+00\n",
      "Epoch 412/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0986 - acc: 0.1733 - val_loss: 0.9051 - val_acc: 0.0000e+00\n",
      "Epoch 413/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 192us/step - loss: 0.1007 - acc: 0.2133 - val_loss: 0.9566 - val_acc: 0.0400\n",
      "Epoch 414/1000\n",
      "75/75 [==============================] - 0s 197us/step - loss: 0.0955 - acc: 0.2133 - val_loss: 0.9186 - val_acc: 0.0400\n",
      "Epoch 415/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.0944 - acc: 0.2133 - val_loss: 0.9531 - val_acc: 0.0400\n",
      "Epoch 416/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0939 - acc: 0.2000 - val_loss: 0.8962 - val_acc: 0.0400\n",
      "Epoch 417/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.1020 - acc: 0.2400 - val_loss: 1.0455 - val_acc: 0.0000e+00\n",
      "Epoch 418/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.1020 - acc: 0.2133 - val_loss: 0.9236 - val_acc: 0.0400\n",
      "Epoch 419/1000\n",
      "75/75 [==============================] - 0s 204us/step - loss: 0.0935 - acc: 0.2133 - val_loss: 0.9610 - val_acc: 0.0000e+00\n",
      "Epoch 420/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.0924 - acc: 0.1867 - val_loss: 0.9391 - val_acc: 0.0400\n",
      "Epoch 421/1000\n",
      "75/75 [==============================] - 0s 212us/step - loss: 0.0929 - acc: 0.2000 - val_loss: 1.0045 - val_acc: 0.0000e+00\n",
      "Epoch 422/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.0979 - acc: 0.2400 - val_loss: 0.9226 - val_acc: 0.0400\n",
      "Epoch 423/1000\n",
      "75/75 [==============================] - 0s 202us/step - loss: 0.0940 - acc: 0.2000 - val_loss: 0.9900 - val_acc: 0.0000e+00\n",
      "Epoch 424/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0995 - acc: 0.2000 - val_loss: 0.9076 - val_acc: 0.0000e+00\n",
      "Epoch 425/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0932 - acc: 0.2133 - val_loss: 0.9423 - val_acc: 0.0000e+00\n",
      "Epoch 426/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0908 - acc: 0.2267 - val_loss: 0.9539 - val_acc: 0.0000e+00\n",
      "Epoch 427/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0912 - acc: 0.2267 - val_loss: 0.9129 - val_acc: 0.0400\n",
      "Epoch 428/1000\n",
      "75/75 [==============================] - 0s 223us/step - loss: 0.0922 - acc: 0.2800 - val_loss: 1.0165 - val_acc: 0.0000e+00\n",
      "Epoch 429/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0977 - acc: 0.2533 - val_loss: 0.9094 - val_acc: 0.0400\n",
      "Epoch 430/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0968 - acc: 0.2400 - val_loss: 0.9714 - val_acc: 0.0000e+00\n",
      "Epoch 431/1000\n",
      "75/75 [==============================] - 0s 204us/step - loss: 0.0902 - acc: 0.2133 - val_loss: 0.9219 - val_acc: 0.0400\n",
      "Epoch 432/1000\n",
      "75/75 [==============================] - 0s 195us/step - loss: 0.0910 - acc: 0.2133 - val_loss: 1.0068 - val_acc: 0.0000e+00\n",
      "Epoch 433/1000\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.0931 - acc: 0.2133 - val_loss: 0.9004 - val_acc: 0.0400\n",
      "Epoch 434/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0938 - acc: 0.2267 - val_loss: 0.9737 - val_acc: 0.0000e+00\n",
      "Epoch 435/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0901 - acc: 0.2267 - val_loss: 0.9360 - val_acc: 0.0000e+00\n",
      "Epoch 436/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0884 - acc: 0.2267 - val_loss: 0.9585 - val_acc: 0.0400\n",
      "Epoch 437/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.0899 - acc: 0.2267 - val_loss: 0.9570 - val_acc: 0.0000e+00\n",
      "Epoch 438/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0925 - acc: 0.2400 - val_loss: 0.9565 - val_acc: 0.0000e+00\n",
      "Epoch 439/1000\n",
      "75/75 [==============================] - 0s 194us/step - loss: 0.0930 - acc: 0.2267 - val_loss: 0.8800 - val_acc: 0.0400\n",
      "Epoch 440/1000\n",
      "75/75 [==============================] - 0s 200us/step - loss: 0.0939 - acc: 0.2667 - val_loss: 0.9663 - val_acc: 0.0000e+00\n",
      "Epoch 441/1000\n",
      "75/75 [==============================] - 0s 207us/step - loss: 0.0876 - acc: 0.2133 - val_loss: 0.9347 - val_acc: 0.0000e+00\n",
      "Epoch 442/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0879 - acc: 0.2533 - val_loss: 0.9845 - val_acc: 0.0000e+00\n",
      "Epoch 443/1000\n",
      "75/75 [==============================] - 0s 197us/step - loss: 0.0912 - acc: 0.2400 - val_loss: 0.9363 - val_acc: 0.0000e+00\n",
      "Epoch 444/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.0882 - acc: 0.2267 - val_loss: 1.0151 - val_acc: 0.0000e+00\n",
      "Epoch 445/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0933 - acc: 0.2400 - val_loss: 0.9104 - val_acc: 0.0400\n",
      "Epoch 446/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0909 - acc: 0.2400 - val_loss: 0.9967 - val_acc: 0.0000e+00\n",
      "Epoch 447/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.0916 - acc: 0.2667 - val_loss: 0.9381 - val_acc: 0.0000e+00\n",
      "Epoch 448/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.0863 - acc: 0.2267 - val_loss: 0.9693 - val_acc: 0.0000e+00\n",
      "Epoch 449/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0856 - acc: 0.2667 - val_loss: 0.9335 - val_acc: 0.0400\n",
      "Epoch 450/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0859 - acc: 0.2400 - val_loss: 0.9845 - val_acc: 0.0000e+00\n",
      "Epoch 451/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0875 - acc: 0.2667 - val_loss: 0.9062 - val_acc: 0.0400\n",
      "Epoch 452/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0909 - acc: 0.2400 - val_loss: 1.0374 - val_acc: 0.0000e+00\n",
      "Epoch 453/1000\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.0930 - acc: 0.2667 - val_loss: 0.9289 - val_acc: 0.0400\n",
      "Epoch 454/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.0874 - acc: 0.2133 - val_loss: 0.9605 - val_acc: 0.0000e+00\n",
      "Epoch 455/1000\n",
      "75/75 [==============================] - 0s 204us/step - loss: 0.0848 - acc: 0.2667 - val_loss: 0.9633 - val_acc: 0.0000e+00\n",
      "Epoch 456/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0842 - acc: 0.2267 - val_loss: 0.9482 - val_acc: 0.0000e+00\n",
      "Epoch 457/1000\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.0839 - acc: 0.2400 - val_loss: 0.9666 - val_acc: 0.0000e+00\n",
      "Epoch 458/1000\n",
      "75/75 [==============================] - 0s 200us/step - loss: 0.0842 - acc: 0.2667 - val_loss: 0.9175 - val_acc: 0.0400\n",
      "Epoch 459/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0874 - acc: 0.2800 - val_loss: 1.0291 - val_acc: 0.0000e+00\n",
      "Epoch 460/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0902 - acc: 0.2400 - val_loss: 0.9678 - val_acc: 0.0000e+00\n",
      "Epoch 461/1000\n",
      "75/75 [==============================] - 0s 243us/step - loss: 0.0827 - acc: 0.2800 - val_loss: 0.9789 - val_acc: 0.0000e+00\n",
      "Epoch 462/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0846 - acc: 0.2267 - val_loss: 0.9479 - val_acc: 0.0400\n",
      "Epoch 463/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.0842 - acc: 0.2667 - val_loss: 0.9479 - val_acc: 0.0400\n",
      "Epoch 464/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0839 - acc: 0.2667 - val_loss: 1.0345 - val_acc: 0.0000e+00\n",
      "Epoch 465/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0927 - acc: 0.2667 - val_loss: 0.9197 - val_acc: 0.0400\n",
      "Epoch 466/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0838 - acc: 0.2400 - val_loss: 0.9937 - val_acc: 0.0000e+00\n",
      "Epoch 467/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0823 - acc: 0.2400 - val_loss: 0.9404 - val_acc: 0.0000e+00\n",
      "Epoch 468/1000\n",
      "75/75 [==============================] - 0s 218us/step - loss: 0.0821 - acc: 0.2667 - val_loss: 0.9936 - val_acc: 0.0400\n",
      "Epoch 469/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0828 - acc: 0.2533 - val_loss: 0.9130 - val_acc: 0.0400\n",
      "Epoch 470/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.0896 - acc: 0.3067 - val_loss: 1.0169 - val_acc: 0.0000e+00\n",
      "Epoch 471/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.0834 - acc: 0.2667 - val_loss: 0.9698 - val_acc: 0.0000e+00\n",
      "Epoch 472/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 176us/step - loss: 0.0807 - acc: 0.2667 - val_loss: 0.9633 - val_acc: 0.0000e+00\n",
      "Epoch 473/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0808 - acc: 0.2533 - val_loss: 0.9614 - val_acc: 0.0000e+00\n",
      "Epoch 474/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0826 - acc: 0.2533 - val_loss: 0.9715 - val_acc: 0.0400\n",
      "Epoch 475/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0804 - acc: 0.2667 - val_loss: 0.9319 - val_acc: 0.0400\n",
      "Epoch 476/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.0868 - acc: 0.2667 - val_loss: 1.0882 - val_acc: 0.0000e+00\n",
      "Epoch 477/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0941 - acc: 0.3067 - val_loss: 0.9651 - val_acc: 0.0400\n",
      "Epoch 478/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0792 - acc: 0.2933 - val_loss: 0.9471 - val_acc: 0.0400\n",
      "Epoch 479/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0788 - acc: 0.2667 - val_loss: 0.9610 - val_acc: 0.0400\n",
      "Epoch 480/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0792 - acc: 0.2800 - val_loss: 0.9435 - val_acc: 0.0400\n",
      "Epoch 481/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.0800 - acc: 0.2667 - val_loss: 1.0193 - val_acc: 0.0000e+00\n",
      "Epoch 482/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0847 - acc: 0.2800 - val_loss: 0.9223 - val_acc: 0.0400\n",
      "Epoch 483/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0814 - acc: 0.3200 - val_loss: 0.9633 - val_acc: 0.0000e+00\n",
      "Epoch 484/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0785 - acc: 0.2800 - val_loss: 0.9269 - val_acc: 0.0400\n",
      "Epoch 485/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.0803 - acc: 0.2933 - val_loss: 0.9715 - val_acc: 0.0400\n",
      "Epoch 486/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0791 - acc: 0.2800 - val_loss: 0.9479 - val_acc: 0.0400\n",
      "Epoch 487/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0785 - acc: 0.3200 - val_loss: 0.9347 - val_acc: 0.0400\n",
      "Epoch 488/1000\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.0845 - acc: 0.2667 - val_loss: 1.0483 - val_acc: 0.0000e+00\n",
      "Epoch 489/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0860 - acc: 0.2533 - val_loss: 0.9400 - val_acc: 0.0400\n",
      "Epoch 490/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0773 - acc: 0.3067 - val_loss: 0.9647 - val_acc: 0.0400\n",
      "Epoch 491/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0765 - acc: 0.2933 - val_loss: 0.9628 - val_acc: 0.0000e+00\n",
      "Epoch 492/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0774 - acc: 0.2933 - val_loss: 0.9427 - val_acc: 0.0400\n",
      "Epoch 493/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0793 - acc: 0.2667 - val_loss: 0.9907 - val_acc: 0.0400\n",
      "Epoch 494/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0785 - acc: 0.2800 - val_loss: 0.9088 - val_acc: 0.0400\n",
      "Epoch 495/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0847 - acc: 0.3067 - val_loss: 0.9951 - val_acc: 0.0000e+00\n",
      "Epoch 496/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0785 - acc: 0.3600 - val_loss: 0.9513 - val_acc: 0.0400\n",
      "Epoch 497/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0758 - acc: 0.2933 - val_loss: 0.9746 - val_acc: 0.0400\n",
      "Epoch 498/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0769 - acc: 0.3200 - val_loss: 0.9539 - val_acc: 0.0400\n",
      "Epoch 499/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0763 - acc: 0.2933 - val_loss: 1.0196 - val_acc: 0.0000e+00\n",
      "Epoch 500/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0850 - acc: 0.3067 - val_loss: 0.9571 - val_acc: 0.0400\n",
      "Epoch 501/1000\n",
      "75/75 [==============================] - 0s 232us/step - loss: 0.0747 - acc: 0.3067 - val_loss: 0.9641 - val_acc: 0.0400\n",
      "Epoch 502/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0744 - acc: 0.3200 - val_loss: 0.9929 - val_acc: 0.0000e+00\n",
      "Epoch 503/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0775 - acc: 0.2933 - val_loss: 0.8947 - val_acc: 0.0400\n",
      "Epoch 504/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0854 - acc: 0.3200 - val_loss: 0.9973 - val_acc: 0.0400\n",
      "Epoch 505/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0763 - acc: 0.2933 - val_loss: 0.9585 - val_acc: 0.0400\n",
      "Epoch 506/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0764 - acc: 0.3067 - val_loss: 0.9728 - val_acc: 0.0400\n",
      "Epoch 507/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0737 - acc: 0.3200 - val_loss: 0.9430 - val_acc: 0.0400\n",
      "Epoch 508/1000\n",
      "75/75 [==============================] - 0s 197us/step - loss: 0.0754 - acc: 0.3067 - val_loss: 1.0065 - val_acc: 0.0400\n",
      "Epoch 509/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0770 - acc: 0.3067 - val_loss: 0.9280 - val_acc: 0.0400\n",
      "Epoch 510/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0763 - acc: 0.2667 - val_loss: 0.9598 - val_acc: 0.0400\n",
      "Epoch 511/1000\n",
      "75/75 [==============================] - 0s 160us/step - loss: 0.0746 - acc: 0.2933 - val_loss: 0.9794 - val_acc: 0.0400\n",
      "Epoch 512/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0756 - acc: 0.2800 - val_loss: 0.9647 - val_acc: 0.0400\n",
      "Epoch 513/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0776 - acc: 0.2933 - val_loss: 0.9236 - val_acc: 0.0400\n",
      "Epoch 514/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0796 - acc: 0.2933 - val_loss: 1.0304 - val_acc: 0.0400\n",
      "Epoch 515/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.0769 - acc: 0.2933 - val_loss: 0.9546 - val_acc: 0.0400\n",
      "Epoch 516/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0722 - acc: 0.3333 - val_loss: 0.9626 - val_acc: 0.0400\n",
      "Epoch 517/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0723 - acc: 0.3067 - val_loss: 1.0220 - val_acc: 0.0400\n",
      "Epoch 518/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0790 - acc: 0.2933 - val_loss: 0.9138 - val_acc: 0.0400\n",
      "Epoch 519/1000\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.0765 - acc: 0.3467 - val_loss: 0.9889 - val_acc: 0.0000e+00\n",
      "Epoch 520/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.0721 - acc: 0.3200 - val_loss: 0.9424 - val_acc: 0.0400\n",
      "Epoch 521/1000\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.0725 - acc: 0.3333 - val_loss: 0.9870 - val_acc: 0.0000e+00\n",
      "Epoch 522/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0752 - acc: 0.3067 - val_loss: 0.9606 - val_acc: 0.0000e+00\n",
      "Epoch 523/1000\n",
      "75/75 [==============================] - 0s 195us/step - loss: 0.0734 - acc: 0.2800 - val_loss: 0.9811 - val_acc: 0.0400\n",
      "Epoch 524/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0717 - acc: 0.3067 - val_loss: 0.9692 - val_acc: 0.0000e+00\n",
      "Epoch 525/1000\n",
      "75/75 [==============================] - 0s 207us/step - loss: 0.0721 - acc: 0.3067 - val_loss: 0.9635 - val_acc: 0.0400\n",
      "Epoch 526/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0770 - acc: 0.3067 - val_loss: 0.9439 - val_acc: 0.0400\n",
      "Epoch 527/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0751 - acc: 0.3200 - val_loss: 1.0297 - val_acc: 0.0400\n",
      "Epoch 528/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0754 - acc: 0.3467 - val_loss: 0.9504 - val_acc: 0.0400\n",
      "Epoch 529/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0706 - acc: 0.3200 - val_loss: 0.9855 - val_acc: 0.0400\n",
      "Epoch 530/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.0709 - acc: 0.3333 - val_loss: 0.9373 - val_acc: 0.0400\n",
      "Epoch 531/1000\n",
      "75/75 [==============================] - 0s 203us/step - loss: 0.0723 - acc: 0.3067 - val_loss: 1.0334 - val_acc: 0.0400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532/1000\n",
      "75/75 [==============================] - 0s 194us/step - loss: 0.0764 - acc: 0.3333 - val_loss: 0.9366 - val_acc: 0.0400\n",
      "Epoch 533/1000\n",
      "75/75 [==============================] - 0s 195us/step - loss: 0.0714 - acc: 0.3600 - val_loss: 1.0633 - val_acc: 0.0000e+00\n",
      "Epoch 534/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0766 - acc: 0.3067 - val_loss: 0.9444 - val_acc: 0.0400\n",
      "Epoch 535/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.0733 - acc: 0.3200 - val_loss: 1.0095 - val_acc: 0.0400\n",
      "Epoch 536/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0721 - acc: 0.3333 - val_loss: 0.9644 - val_acc: 0.0400\n",
      "Epoch 537/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0692 - acc: 0.2933 - val_loss: 0.9812 - val_acc: 0.0400\n",
      "Epoch 538/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0707 - acc: 0.3333 - val_loss: 0.9970 - val_acc: 0.0000e+00\n",
      "Epoch 539/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0693 - acc: 0.3333 - val_loss: 0.9602 - val_acc: 0.0400\n",
      "Epoch 540/1000\n",
      "75/75 [==============================] - 0s 197us/step - loss: 0.0702 - acc: 0.3333 - val_loss: 1.0698 - val_acc: 0.0000e+00\n",
      "Epoch 541/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0815 - acc: 0.3200 - val_loss: 0.9331 - val_acc: 0.0400\n",
      "Epoch 542/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0730 - acc: 0.3467 - val_loss: 0.9826 - val_acc: 0.0400\n",
      "Epoch 543/1000\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.0694 - acc: 0.3600 - val_loss: 1.0080 - val_acc: 0.0000e+00\n",
      "Epoch 544/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0694 - acc: 0.3600 - val_loss: 0.9319 - val_acc: 0.0400\n",
      "Epoch 545/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0699 - acc: 0.3600 - val_loss: 1.0187 - val_acc: 0.0400\n",
      "Epoch 546/1000\n",
      "75/75 [==============================] - 0s 201us/step - loss: 0.0717 - acc: 0.3067 - val_loss: 0.9438 - val_acc: 0.0400\n",
      "Epoch 547/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0703 - acc: 0.3200 - val_loss: 1.0038 - val_acc: 0.0400\n",
      "Epoch 548/1000\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.0698 - acc: 0.3200 - val_loss: 0.9293 - val_acc: 0.0400\n",
      "Epoch 549/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0761 - acc: 0.3600 - val_loss: 0.9872 - val_acc: 0.0400\n",
      "Epoch 550/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0669 - acc: 0.2933 - val_loss: 0.9945 - val_acc: 0.0400\n",
      "Epoch 551/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0675 - acc: 0.2933 - val_loss: 0.9732 - val_acc: 0.0400\n",
      "Epoch 552/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0681 - acc: 0.3333 - val_loss: 0.9828 - val_acc: 0.0400\n",
      "Epoch 553/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0701 - acc: 0.3067 - val_loss: 0.9798 - val_acc: 0.0400\n",
      "Epoch 554/1000\n",
      "75/75 [==============================] - 0s 194us/step - loss: 0.0746 - acc: 0.3200 - val_loss: 1.0228 - val_acc: 0.0400\n",
      "Epoch 555/1000\n",
      "75/75 [==============================] - 0s 210us/step - loss: 0.0714 - acc: 0.3333 - val_loss: 0.8952 - val_acc: 0.0400\n",
      "Epoch 556/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0745 - acc: 0.3600 - val_loss: 1.0070 - val_acc: 0.0400\n",
      "Epoch 557/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0669 - acc: 0.3600 - val_loss: 0.9637 - val_acc: 0.0400\n",
      "Epoch 558/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0668 - acc: 0.3600 - val_loss: 1.0103 - val_acc: 0.0400\n",
      "Epoch 559/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0682 - acc: 0.4000 - val_loss: 0.9352 - val_acc: 0.0400\n",
      "Epoch 560/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0691 - acc: 0.3867 - val_loss: 1.0308 - val_acc: 0.0400\n",
      "Epoch 561/1000\n",
      "75/75 [==============================] - 0s 204us/step - loss: 0.0693 - acc: 0.3200 - val_loss: 0.9682 - val_acc: 0.0400\n",
      "Epoch 562/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.0664 - acc: 0.3467 - val_loss: 1.0624 - val_acc: 0.0000e+00\n",
      "Epoch 563/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0714 - acc: 0.3600 - val_loss: 0.9464 - val_acc: 0.0400\n",
      "Epoch 564/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0688 - acc: 0.3600 - val_loss: 1.0356 - val_acc: 0.0400\n",
      "Epoch 565/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0697 - acc: 0.3467 - val_loss: 0.9538 - val_acc: 0.0400\n",
      "Epoch 566/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0674 - acc: 0.3467 - val_loss: 1.0275 - val_acc: 0.0400\n",
      "Epoch 567/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0707 - acc: 0.3600 - val_loss: 0.9468 - val_acc: 0.0400\n",
      "Epoch 568/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0675 - acc: 0.3733 - val_loss: 0.9989 - val_acc: 0.0400\n",
      "Epoch 569/1000\n",
      "75/75 [==============================] - 0s 210us/step - loss: 0.0664 - acc: 0.3200 - val_loss: 0.9314 - val_acc: 0.0400\n",
      "Epoch 570/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0675 - acc: 0.3600 - val_loss: 1.0582 - val_acc: 0.0400\n",
      "Epoch 571/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0696 - acc: 0.3467 - val_loss: 0.9498 - val_acc: 0.0400\n",
      "Epoch 572/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0652 - acc: 0.3600 - val_loss: 0.9949 - val_acc: 0.0400\n",
      "Epoch 573/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0666 - acc: 0.3600 - val_loss: 0.9579 - val_acc: 0.0400\n",
      "Epoch 574/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0673 - acc: 0.3467 - val_loss: 1.0409 - val_acc: 0.0400\n",
      "Epoch 575/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.0706 - acc: 0.3600 - val_loss: 0.9403 - val_acc: 0.0400\n",
      "Epoch 576/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0679 - acc: 0.3733 - val_loss: 1.0022 - val_acc: 0.0400\n",
      "Epoch 577/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0647 - acc: 0.3600 - val_loss: 0.9531 - val_acc: 0.0400\n",
      "Epoch 578/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0694 - acc: 0.3733 - val_loss: 1.0244 - val_acc: 0.0400\n",
      "Epoch 579/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0651 - acc: 0.3867 - val_loss: 0.9492 - val_acc: 0.0400\n",
      "Epoch 580/1000\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.0653 - acc: 0.3733 - val_loss: 1.0118 - val_acc: 0.0400\n",
      "Epoch 581/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0664 - acc: 0.3600 - val_loss: 0.9277 - val_acc: 0.0400\n",
      "Epoch 582/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0697 - acc: 0.3467 - val_loss: 1.0099 - val_acc: 0.0400\n",
      "Epoch 583/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0646 - acc: 0.4000 - val_loss: 0.9563 - val_acc: 0.0400\n",
      "Epoch 584/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0649 - acc: 0.3733 - val_loss: 1.0269 - val_acc: 0.0400\n",
      "Epoch 585/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.0678 - acc: 0.4000 - val_loss: 0.9782 - val_acc: 0.0400\n",
      "Epoch 586/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0636 - acc: 0.3600 - val_loss: 1.0174 - val_acc: 0.0400\n",
      "Epoch 587/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0653 - acc: 0.4000 - val_loss: 0.9368 - val_acc: 0.0400\n",
      "Epoch 588/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0690 - acc: 0.3867 - val_loss: 1.0408 - val_acc: 0.0400\n",
      "Epoch 589/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0684 - acc: 0.3733 - val_loss: 0.9768 - val_acc: 0.0400\n",
      "Epoch 590/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0634 - acc: 0.3733 - val_loss: 0.9986 - val_acc: 0.0400\n",
      "Epoch 591/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0627 - acc: 0.3600 - val_loss: 0.9497 - val_acc: 0.0400\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 191us/step - loss: 0.0666 - acc: 0.3467 - val_loss: 1.0253 - val_acc: 0.0400\n",
      "Epoch 593/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0676 - acc: 0.3467 - val_loss: 0.9556 - val_acc: 0.0400\n",
      "Epoch 594/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0639 - acc: 0.3867 - val_loss: 1.0063 - val_acc: 0.0400\n",
      "Epoch 595/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0620 - acc: 0.3867 - val_loss: 0.9883 - val_acc: 0.0400\n",
      "Epoch 596/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0618 - acc: 0.3467 - val_loss: 0.9593 - val_acc: 0.0400\n",
      "Epoch 597/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0662 - acc: 0.3867 - val_loss: 1.0387 - val_acc: 0.0400\n",
      "Epoch 598/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0668 - acc: 0.3600 - val_loss: 0.9373 - val_acc: 0.0400\n",
      "Epoch 599/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0701 - acc: 0.3467 - val_loss: 1.0361 - val_acc: 0.0400\n",
      "Epoch 600/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0643 - acc: 0.3467 - val_loss: 0.9403 - val_acc: 0.0400\n",
      "Epoch 601/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0632 - acc: 0.4133 - val_loss: 0.9994 - val_acc: 0.0400\n",
      "Epoch 602/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0616 - acc: 0.4000 - val_loss: 0.9581 - val_acc: 0.0400\n",
      "Epoch 603/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0622 - acc: 0.3467 - val_loss: 1.0301 - val_acc: 0.0400\n",
      "Epoch 604/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0655 - acc: 0.3867 - val_loss: 0.9671 - val_acc: 0.0400\n",
      "Epoch 605/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0619 - acc: 0.3600 - val_loss: 1.0396 - val_acc: 0.0400\n",
      "Epoch 606/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0643 - acc: 0.3600 - val_loss: 0.9266 - val_acc: 0.0400\n",
      "Epoch 607/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0715 - acc: 0.3467 - val_loss: 1.0128 - val_acc: 0.0400\n",
      "Epoch 608/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0607 - acc: 0.4133 - val_loss: 0.9766 - val_acc: 0.0400\n",
      "Epoch 609/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0622 - acc: 0.3867 - val_loss: 0.9944 - val_acc: 0.0400\n",
      "Epoch 610/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.0604 - acc: 0.3867 - val_loss: 0.9921 - val_acc: 0.0400\n",
      "Epoch 611/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.0603 - acc: 0.3733 - val_loss: 1.0127 - val_acc: 0.0400\n",
      "Epoch 612/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0615 - acc: 0.3867 - val_loss: 0.9070 - val_acc: 0.0400\n",
      "Epoch 613/1000\n",
      "75/75 [==============================] - 0s 199us/step - loss: 0.0683 - acc: 0.4533 - val_loss: 1.1091 - val_acc: 0.0000e+00\n",
      "Epoch 614/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0714 - acc: 0.3867 - val_loss: 0.9866 - val_acc: 0.0400\n",
      "Epoch 615/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0602 - acc: 0.3867 - val_loss: 1.0089 - val_acc: 0.0400\n",
      "Epoch 616/1000\n",
      "75/75 [==============================] - 0s 189us/step - loss: 0.0597 - acc: 0.3867 - val_loss: 0.9908 - val_acc: 0.0400\n",
      "Epoch 617/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0614 - acc: 0.3733 - val_loss: 0.9899 - val_acc: 0.0400\n",
      "Epoch 618/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0606 - acc: 0.3467 - val_loss: 1.0152 - val_acc: 0.0400\n",
      "Epoch 619/1000\n",
      "75/75 [==============================] - 0s 197us/step - loss: 0.0626 - acc: 0.3600 - val_loss: 1.0005 - val_acc: 0.0400\n",
      "Epoch 620/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0594 - acc: 0.4133 - val_loss: 0.9782 - val_acc: 0.0400\n",
      "Epoch 621/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.0615 - acc: 0.4267 - val_loss: 1.1100 - val_acc: 0.0000e+00\n",
      "Epoch 622/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0684 - acc: 0.4000 - val_loss: 0.9532 - val_acc: 0.0400\n",
      "Epoch 623/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0616 - acc: 0.3867 - val_loss: 1.0280 - val_acc: 0.0400\n",
      "Epoch 624/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0603 - acc: 0.4133 - val_loss: 0.9410 - val_acc: 0.0400\n",
      "Epoch 625/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0630 - acc: 0.3733 - val_loss: 1.0764 - val_acc: 0.0400\n",
      "Epoch 626/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0658 - acc: 0.3600 - val_loss: 0.9709 - val_acc: 0.0400\n",
      "Epoch 627/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0589 - acc: 0.4000 - val_loss: 1.0336 - val_acc: 0.0400\n",
      "Epoch 628/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0610 - acc: 0.3867 - val_loss: 0.9512 - val_acc: 0.0400\n",
      "Epoch 629/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.0622 - acc: 0.3867 - val_loss: 1.0418 - val_acc: 0.0400\n",
      "Epoch 630/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0660 - acc: 0.3333 - val_loss: 0.9983 - val_acc: 0.0400\n",
      "Epoch 631/1000\n",
      "75/75 [==============================] - 0s 207us/step - loss: 0.0585 - acc: 0.3867 - val_loss: 0.9795 - val_acc: 0.0400\n",
      "Epoch 632/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.0591 - acc: 0.4133 - val_loss: 1.0202 - val_acc: 0.0400\n",
      "Epoch 633/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0587 - acc: 0.3867 - val_loss: 0.9463 - val_acc: 0.0400\n",
      "Epoch 634/1000\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.0654 - acc: 0.3733 - val_loss: 1.0941 - val_acc: 0.0400\n",
      "Epoch 635/1000\n",
      "75/75 [==============================] - 0s 190us/step - loss: 0.0677 - acc: 0.4133 - val_loss: 0.9999 - val_acc: 0.0400\n",
      "Epoch 636/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.0585 - acc: 0.3867 - val_loss: 0.9854 - val_acc: 0.0400\n",
      "Epoch 637/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0575 - acc: 0.4133 - val_loss: 0.9943 - val_acc: 0.0400\n",
      "Epoch 638/1000\n",
      "75/75 [==============================] - 0s 191us/step - loss: 0.0573 - acc: 0.3733 - val_loss: 0.9676 - val_acc: 0.0400\n",
      "Epoch 639/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0590 - acc: 0.4000 - val_loss: 1.0271 - val_acc: 0.0400\n",
      "Epoch 640/1000\n",
      "75/75 [==============================] - 0s 202us/step - loss: 0.0613 - acc: 0.3867 - val_loss: 0.9362 - val_acc: 0.0400\n",
      "Epoch 641/1000\n",
      "75/75 [==============================] - 0s 205us/step - loss: 0.0630 - acc: 0.3733 - val_loss: 1.0864 - val_acc: 0.0400\n",
      "Epoch 642/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0665 - acc: 0.4000 - val_loss: 0.9589 - val_acc: 0.0400\n",
      "Epoch 643/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0582 - acc: 0.4000 - val_loss: 1.0080 - val_acc: 0.0400\n",
      "Epoch 644/1000\n",
      "75/75 [==============================] - 0s 193us/step - loss: 0.0572 - acc: 0.3867 - val_loss: 0.9643 - val_acc: 0.0400\n",
      "Epoch 645/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0595 - acc: 0.3600 - val_loss: 1.0494 - val_acc: 0.0400\n",
      "Epoch 646/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0627 - acc: 0.4000 - val_loss: 0.9892 - val_acc: 0.0400\n",
      "Epoch 647/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0574 - acc: 0.4400 - val_loss: 1.0156 - val_acc: 0.0400\n",
      "Epoch 648/1000\n",
      "75/75 [==============================] - 0s 211us/step - loss: 0.0612 - acc: 0.3867 - val_loss: 1.0056 - val_acc: 0.0400\n",
      "Epoch 649/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.0570 - acc: 0.4400 - val_loss: 0.9620 - val_acc: 0.0400\n",
      "Epoch 650/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0610 - acc: 0.3733 - val_loss: 1.0910 - val_acc: 0.0000e+00\n",
      "Epoch 651/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0623 - acc: 0.3733 - val_loss: 0.9632 - val_acc: 0.0400\n",
      "Epoch 652/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 178us/step - loss: 0.0601 - acc: 0.4267 - val_loss: 1.0357 - val_acc: 0.0000e+00\n",
      "Epoch 653/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0584 - acc: 0.4400 - val_loss: 1.0041 - val_acc: 0.0400\n",
      "Epoch 654/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0565 - acc: 0.4000 - val_loss: 0.9706 - val_acc: 0.0400\n",
      "Epoch 655/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0573 - acc: 0.3733 - val_loss: 1.0167 - val_acc: 0.0400\n",
      "Epoch 656/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0570 - acc: 0.4400 - val_loss: 0.9489 - val_acc: 0.0400\n",
      "Epoch 657/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0616 - acc: 0.4267 - val_loss: 1.0872 - val_acc: 0.0400\n",
      "Epoch 658/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0682 - acc: 0.4267 - val_loss: 0.9680 - val_acc: 0.0400\n",
      "Epoch 659/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0563 - acc: 0.4133 - val_loss: 1.0190 - val_acc: 0.0400\n",
      "Epoch 660/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0570 - acc: 0.3867 - val_loss: 0.9908 - val_acc: 0.0400\n",
      "Epoch 661/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0555 - acc: 0.4000 - val_loss: 0.9753 - val_acc: 0.0400\n",
      "Epoch 662/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0575 - acc: 0.3733 - val_loss: 1.1023 - val_acc: 0.0000e+00\n",
      "Epoch 663/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0659 - acc: 0.3733 - val_loss: 0.9335 - val_acc: 0.0400\n",
      "Epoch 664/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0610 - acc: 0.4000 - val_loss: 1.0104 - val_acc: 0.0400\n",
      "Epoch 665/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0551 - acc: 0.4000 - val_loss: 1.0007 - val_acc: 0.0400\n",
      "Epoch 666/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0554 - acc: 0.3867 - val_loss: 0.9918 - val_acc: 0.0400\n",
      "Epoch 667/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0579 - acc: 0.4000 - val_loss: 1.0510 - val_acc: 0.0400\n",
      "Epoch 668/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0594 - acc: 0.4133 - val_loss: 0.9526 - val_acc: 0.0400\n",
      "Epoch 669/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0593 - acc: 0.4133 - val_loss: 1.0341 - val_acc: 0.0400\n",
      "Epoch 670/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0575 - acc: 0.4000 - val_loss: 0.9597 - val_acc: 0.0400\n",
      "Epoch 671/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0610 - acc: 0.4000 - val_loss: 1.0619 - val_acc: 0.0000e+00\n",
      "Epoch 672/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0582 - acc: 0.4000 - val_loss: 0.9835 - val_acc: 0.0400\n",
      "Epoch 673/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0554 - acc: 0.3733 - val_loss: 1.0327 - val_acc: 0.0000e+00\n",
      "Epoch 674/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0554 - acc: 0.3467 - val_loss: 0.9627 - val_acc: 0.0400\n",
      "Epoch 675/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0568 - acc: 0.3733 - val_loss: 1.0641 - val_acc: 0.0400\n",
      "Epoch 676/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0599 - acc: 0.4400 - val_loss: 0.9872 - val_acc: 0.0400\n",
      "Epoch 677/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0599 - acc: 0.4267 - val_loss: 1.0061 - val_acc: 0.0400\n",
      "Epoch 678/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0547 - acc: 0.4267 - val_loss: 0.9960 - val_acc: 0.0400\n",
      "Epoch 679/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0541 - acc: 0.4000 - val_loss: 1.0271 - val_acc: 0.0400\n",
      "Epoch 680/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0558 - acc: 0.4000 - val_loss: 0.9318 - val_acc: 0.0400\n",
      "Epoch 681/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0629 - acc: 0.4533 - val_loss: 0.9947 - val_acc: 0.0400\n",
      "Epoch 682/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0550 - acc: 0.3867 - val_loss: 1.0066 - val_acc: 0.0400\n",
      "Epoch 683/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0547 - acc: 0.4267 - val_loss: 1.0202 - val_acc: 0.0400\n",
      "Epoch 684/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0599 - acc: 0.4533 - val_loss: 0.9812 - val_acc: 0.0400\n",
      "Epoch 685/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0565 - acc: 0.4000 - val_loss: 1.1127 - val_acc: 0.0000e+00\n",
      "Epoch 686/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0630 - acc: 0.4000 - val_loss: 0.9802 - val_acc: 0.0400\n",
      "Epoch 687/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0562 - acc: 0.4267 - val_loss: 1.0653 - val_acc: 0.0400\n",
      "Epoch 688/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.0583 - acc: 0.3867 - val_loss: 0.9920 - val_acc: 0.0400\n",
      "Epoch 689/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0536 - acc: 0.3867 - val_loss: 1.0313 - val_acc: 0.0400\n",
      "Epoch 690/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0549 - acc: 0.4133 - val_loss: 0.9511 - val_acc: 0.0400\n",
      "Epoch 691/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0590 - acc: 0.4267 - val_loss: 1.0573 - val_acc: 0.0400\n",
      "Epoch 692/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0580 - acc: 0.4133 - val_loss: 0.9790 - val_acc: 0.0400\n",
      "Epoch 693/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0542 - acc: 0.4267 - val_loss: 1.0050 - val_acc: 0.0400\n",
      "Epoch 694/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.0549 - acc: 0.4800 - val_loss: 1.0184 - val_acc: 0.0400\n",
      "Epoch 695/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.0562 - acc: 0.4000 - val_loss: 0.9918 - val_acc: 0.0400\n",
      "Epoch 696/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0572 - acc: 0.4533 - val_loss: 1.0081 - val_acc: 0.0400\n",
      "Epoch 697/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0532 - acc: 0.4400 - val_loss: 0.9537 - val_acc: 0.0400\n",
      "Epoch 698/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0576 - acc: 0.3733 - val_loss: 1.1606 - val_acc: 0.0000e+00\n",
      "Epoch 699/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.0647 - acc: 0.3867 - val_loss: 0.9846 - val_acc: 0.0400\n",
      "Epoch 700/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0540 - acc: 0.4533 - val_loss: 1.0281 - val_acc: 0.0400\n",
      "Epoch 701/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0530 - acc: 0.4133 - val_loss: 0.9696 - val_acc: 0.0400\n",
      "Epoch 702/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0549 - acc: 0.4400 - val_loss: 1.0510 - val_acc: 0.0400\n",
      "Epoch 703/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0539 - acc: 0.3867 - val_loss: 0.9745 - val_acc: 0.0400\n",
      "Epoch 704/1000\n",
      "75/75 [==============================] - 0s 202us/step - loss: 0.0551 - acc: 0.4267 - val_loss: 1.0777 - val_acc: 0.0000e+00\n",
      "Epoch 705/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.0582 - acc: 0.4400 - val_loss: 0.9568 - val_acc: 0.0400\n",
      "Epoch 706/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0573 - acc: 0.4400 - val_loss: 1.0558 - val_acc: 0.0400\n",
      "Epoch 707/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0553 - acc: 0.4800 - val_loss: 0.9795 - val_acc: 0.0400\n",
      "Epoch 708/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0535 - acc: 0.4667 - val_loss: 1.0383 - val_acc: 0.0400\n",
      "Epoch 709/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0550 - acc: 0.4667 - val_loss: 0.9569 - val_acc: 0.0400\n",
      "Epoch 710/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0548 - acc: 0.4800 - val_loss: 1.0442 - val_acc: 0.0400\n",
      "Epoch 711/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.0540 - acc: 0.4800 - val_loss: 0.9558 - val_acc: 0.0400\n",
      "Epoch 712/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 173us/step - loss: 0.0572 - acc: 0.4667 - val_loss: 1.0928 - val_acc: 0.0400\n",
      "Epoch 713/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0595 - acc: 0.4533 - val_loss: 0.9499 - val_acc: 0.0400\n",
      "Epoch 714/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0536 - acc: 0.4267 - val_loss: 1.0394 - val_acc: 0.0400\n",
      "Epoch 715/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0536 - acc: 0.4267 - val_loss: 0.9774 - val_acc: 0.0400\n",
      "Epoch 716/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0532 - acc: 0.4933 - val_loss: 1.0219 - val_acc: 0.0400\n",
      "Epoch 717/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0519 - acc: 0.4667 - val_loss: 0.9474 - val_acc: 0.0400\n",
      "Epoch 718/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0583 - acc: 0.4533 - val_loss: 1.1063 - val_acc: 0.0000e+00\n",
      "Epoch 719/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0567 - acc: 0.4533 - val_loss: 0.9678 - val_acc: 0.0400\n",
      "Epoch 720/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0538 - acc: 0.4533 - val_loss: 1.0319 - val_acc: 0.0400\n",
      "Epoch 721/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.0517 - acc: 0.4667 - val_loss: 0.9917 - val_acc: 0.0400\n",
      "Epoch 722/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0520 - acc: 0.4400 - val_loss: 1.0162 - val_acc: 0.0400\n",
      "Epoch 723/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0533 - acc: 0.4667 - val_loss: 1.0032 - val_acc: 0.0000e+00\n",
      "Epoch 724/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0576 - acc: 0.4533 - val_loss: 1.0578 - val_acc: 0.0400\n",
      "Epoch 725/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0567 - acc: 0.4667 - val_loss: 0.9170 - val_acc: 0.0400\n",
      "Epoch 726/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0599 - acc: 0.4933 - val_loss: 1.0469 - val_acc: 0.0400\n",
      "Epoch 727/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0523 - acc: 0.4667 - val_loss: 1.0036 - val_acc: 0.0400\n",
      "Epoch 728/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0507 - acc: 0.4667 - val_loss: 0.9905 - val_acc: 0.0400\n",
      "Epoch 729/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0510 - acc: 0.4667 - val_loss: 1.0390 - val_acc: 0.0400\n",
      "Epoch 730/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0524 - acc: 0.4533 - val_loss: 0.9609 - val_acc: 0.0400\n",
      "Epoch 731/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0565 - acc: 0.4533 - val_loss: 1.0731 - val_acc: 0.0400\n",
      "Epoch 732/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.0542 - acc: 0.4667 - val_loss: 0.9856 - val_acc: 0.0400\n",
      "Epoch 733/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0534 - acc: 0.4533 - val_loss: 0.9963 - val_acc: 0.0400\n",
      "Epoch 734/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0515 - acc: 0.5067 - val_loss: 1.0418 - val_acc: 0.0400\n",
      "Epoch 735/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0530 - acc: 0.4267 - val_loss: 0.9437 - val_acc: 0.0400\n",
      "Epoch 736/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0573 - acc: 0.4667 - val_loss: 1.0690 - val_acc: 0.0400\n",
      "Epoch 737/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0568 - acc: 0.4667 - val_loss: 1.0101 - val_acc: 0.0400\n",
      "Epoch 738/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0506 - acc: 0.4667 - val_loss: 1.0051 - val_acc: 0.0400\n",
      "Epoch 739/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0507 - acc: 0.4400 - val_loss: 1.0432 - val_acc: 0.0400\n",
      "Epoch 740/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0515 - acc: 0.4533 - val_loss: 0.9351 - val_acc: 0.0400\n",
      "Epoch 741/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0615 - acc: 0.4800 - val_loss: 1.0691 - val_acc: 0.0000e+00\n",
      "Epoch 742/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.0520 - acc: 0.5067 - val_loss: 0.9872 - val_acc: 0.0400\n",
      "Epoch 743/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.0511 - acc: 0.4133 - val_loss: 1.0296 - val_acc: 0.0400\n",
      "Epoch 744/1000\n",
      "75/75 [==============================] - 0s 256us/step - loss: 0.0500 - acc: 0.4800 - val_loss: 1.0452 - val_acc: 0.0400\n",
      "Epoch 745/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0528 - acc: 0.4400 - val_loss: 0.9704 - val_acc: 0.0400\n",
      "Epoch 746/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0526 - acc: 0.4667 - val_loss: 1.0746 - val_acc: 0.0400\n",
      "Epoch 747/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0557 - acc: 0.4667 - val_loss: 0.9680 - val_acc: 0.0400\n",
      "Epoch 748/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0511 - acc: 0.4400 - val_loss: 1.0351 - val_acc: 0.0400\n",
      "Epoch 749/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0524 - acc: 0.4667 - val_loss: 0.9834 - val_acc: 0.0400\n",
      "Epoch 750/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0540 - acc: 0.4667 - val_loss: 1.0397 - val_acc: 0.0400\n",
      "Epoch 751/1000\n",
      "75/75 [==============================] - 0s 192us/step - loss: 0.0522 - acc: 0.4667 - val_loss: 0.9604 - val_acc: 0.0400\n",
      "Epoch 752/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0541 - acc: 0.4133 - val_loss: 1.0847 - val_acc: 0.0400\n",
      "Epoch 753/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0552 - acc: 0.4267 - val_loss: 0.9629 - val_acc: 0.0400\n",
      "Epoch 754/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0529 - acc: 0.5200 - val_loss: 1.0455 - val_acc: 0.0400\n",
      "Epoch 755/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0517 - acc: 0.4533 - val_loss: 0.9993 - val_acc: 0.0400\n",
      "Epoch 756/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0502 - acc: 0.4667 - val_loss: 1.0504 - val_acc: 0.0400\n",
      "Epoch 757/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0521 - acc: 0.4533 - val_loss: 0.9590 - val_acc: 0.0400\n",
      "Epoch 758/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0528 - acc: 0.4667 - val_loss: 1.0963 - val_acc: 0.0000e+00\n",
      "Epoch 759/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0567 - acc: 0.4267 - val_loss: 1.0161 - val_acc: 0.0400\n",
      "Epoch 760/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0494 - acc: 0.4533 - val_loss: 1.0515 - val_acc: 0.0400\n",
      "Epoch 761/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.0495 - acc: 0.4133 - val_loss: 0.9719 - val_acc: 0.0400\n",
      "Epoch 762/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0529 - acc: 0.4667 - val_loss: 1.0463 - val_acc: 0.0400\n",
      "Epoch 763/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0506 - acc: 0.4533 - val_loss: 0.9533 - val_acc: 0.0400\n",
      "Epoch 764/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0576 - acc: 0.4533 - val_loss: 1.0476 - val_acc: 0.0400\n",
      "Epoch 765/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0495 - acc: 0.5067 - val_loss: 0.9908 - val_acc: 0.0400\n",
      "Epoch 766/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0499 - acc: 0.4667 - val_loss: 1.0553 - val_acc: 0.0000e+00\n",
      "Epoch 767/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0508 - acc: 0.4933 - val_loss: 1.0000 - val_acc: 0.0400\n",
      "Epoch 768/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0498 - acc: 0.4667 - val_loss: 1.0794 - val_acc: 0.0400\n",
      "Epoch 769/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0535 - acc: 0.4400 - val_loss: 0.9399 - val_acc: 0.0400\n",
      "Epoch 770/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0569 - acc: 0.4533 - val_loss: 1.0206 - val_acc: 0.0400\n",
      "Epoch 771/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0489 - acc: 0.4667 - val_loss: 0.9857 - val_acc: 0.0400\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 165us/step - loss: 0.0492 - acc: 0.5067 - val_loss: 1.0325 - val_acc: 0.0400\n",
      "Epoch 773/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0492 - acc: 0.4667 - val_loss: 0.9958 - val_acc: 0.0400\n",
      "Epoch 774/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0502 - acc: 0.4533 - val_loss: 1.0577 - val_acc: 0.0400\n",
      "Epoch 775/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0515 - acc: 0.4400 - val_loss: 0.9200 - val_acc: 0.0400\n",
      "Epoch 776/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0628 - acc: 0.4800 - val_loss: 1.0195 - val_acc: 0.0400\n",
      "Epoch 777/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0483 - acc: 0.4800 - val_loss: 0.9769 - val_acc: 0.0400\n",
      "Epoch 778/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0486 - acc: 0.4667 - val_loss: 1.0202 - val_acc: 0.0400\n",
      "Epoch 779/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0478 - acc: 0.4933 - val_loss: 1.0669 - val_acc: 0.0400\n",
      "Epoch 780/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0497 - acc: 0.4267 - val_loss: 0.9686 - val_acc: 0.0400\n",
      "Epoch 781/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0518 - acc: 0.4400 - val_loss: 1.0747 - val_acc: 0.0000e+00\n",
      "Epoch 782/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0517 - acc: 0.4533 - val_loss: 0.9688 - val_acc: 0.0400\n",
      "Epoch 783/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0536 - acc: 0.5200 - val_loss: 1.0957 - val_acc: 0.0400\n",
      "Epoch 784/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0559 - acc: 0.4533 - val_loss: 0.9871 - val_acc: 0.0400\n",
      "Epoch 785/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0487 - acc: 0.5067 - val_loss: 1.0445 - val_acc: 0.0400\n",
      "Epoch 786/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0481 - acc: 0.5333 - val_loss: 0.9860 - val_acc: 0.0400\n",
      "Epoch 787/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0502 - acc: 0.4800 - val_loss: 1.0683 - val_acc: 0.0400\n",
      "Epoch 788/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0518 - acc: 0.4800 - val_loss: 0.9681 - val_acc: 0.0400\n",
      "Epoch 789/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0514 - acc: 0.4533 - val_loss: 1.0902 - val_acc: 0.0000e+00\n",
      "Epoch 790/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0528 - acc: 0.4533 - val_loss: 1.0008 - val_acc: 0.0400\n",
      "Epoch 791/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0472 - acc: 0.5200 - val_loss: 1.0494 - val_acc: 0.0400\n",
      "Epoch 792/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0494 - acc: 0.4533 - val_loss: 1.0044 - val_acc: 0.0400\n",
      "Epoch 793/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0502 - acc: 0.4800 - val_loss: 1.1064 - val_acc: 0.0400\n",
      "Epoch 794/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0536 - acc: 0.4800 - val_loss: 0.9565 - val_acc: 0.0400\n",
      "Epoch 795/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0493 - acc: 0.4800 - val_loss: 1.0759 - val_acc: 0.0400\n",
      "Epoch 796/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0495 - acc: 0.4533 - val_loss: 0.9931 - val_acc: 0.0400\n",
      "Epoch 797/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0477 - acc: 0.4800 - val_loss: 1.0117 - val_acc: 0.0400\n",
      "Epoch 798/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0507 - acc: 0.5067 - val_loss: 1.0697 - val_acc: 0.0400\n",
      "Epoch 799/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0529 - acc: 0.4533 - val_loss: 0.9466 - val_acc: 0.0400\n",
      "Epoch 800/1000\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.0523 - acc: 0.5067 - val_loss: 1.0984 - val_acc: 0.0000e+00\n",
      "Epoch 801/1000\n",
      "75/75 [==============================] - 0s 186us/step - loss: 0.0509 - acc: 0.4400 - val_loss: 0.9790 - val_acc: 0.0400\n",
      "Epoch 802/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0483 - acc: 0.4800 - val_loss: 1.0453 - val_acc: 0.0400\n",
      "Epoch 803/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0475 - acc: 0.4800 - val_loss: 0.9957 - val_acc: 0.0400\n",
      "Epoch 804/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0475 - acc: 0.4933 - val_loss: 1.0614 - val_acc: 0.0400\n",
      "Epoch 805/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0510 - acc: 0.4800 - val_loss: 0.9745 - val_acc: 0.0400\n",
      "Epoch 806/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0507 - acc: 0.5200 - val_loss: 1.0715 - val_acc: 0.0400\n",
      "Epoch 807/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0520 - acc: 0.4933 - val_loss: 0.9862 - val_acc: 0.0400\n",
      "Epoch 808/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0479 - acc: 0.4667 - val_loss: 1.0691 - val_acc: 0.0400\n",
      "Epoch 809/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0486 - acc: 0.4533 - val_loss: 1.0066 - val_acc: 0.0400\n",
      "Epoch 810/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0461 - acc: 0.4667 - val_loss: 1.0119 - val_acc: 0.0400\n",
      "Epoch 811/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0458 - acc: 0.4800 - val_loss: 1.0070 - val_acc: 0.0400\n",
      "Epoch 812/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0470 - acc: 0.4933 - val_loss: 1.1587 - val_acc: 0.0400\n",
      "Epoch 813/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0642 - acc: 0.4800 - val_loss: 0.9650 - val_acc: 0.0400\n",
      "Epoch 814/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0486 - acc: 0.4800 - val_loss: 1.0141 - val_acc: 0.0400\n",
      "Epoch 815/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0456 - acc: 0.4800 - val_loss: 0.9922 - val_acc: 0.0400\n",
      "Epoch 816/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0476 - acc: 0.4667 - val_loss: 1.0323 - val_acc: 0.0400\n",
      "Epoch 817/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0461 - acc: 0.4800 - val_loss: 1.0037 - val_acc: 0.0400\n",
      "Epoch 818/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0459 - acc: 0.4800 - val_loss: 1.0682 - val_acc: 0.0400\n",
      "Epoch 819/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0492 - acc: 0.4933 - val_loss: 0.9702 - val_acc: 0.0400\n",
      "Epoch 820/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0524 - acc: 0.4667 - val_loss: 1.0531 - val_acc: 0.0400\n",
      "Epoch 821/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.0462 - acc: 0.5067 - val_loss: 0.9785 - val_acc: 0.0400\n",
      "Epoch 822/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0486 - acc: 0.4800 - val_loss: 1.0667 - val_acc: 0.0400\n",
      "Epoch 823/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0500 - acc: 0.4533 - val_loss: 0.9733 - val_acc: 0.0400\n",
      "Epoch 824/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0510 - acc: 0.4400 - val_loss: 1.0700 - val_acc: 0.0000e+00\n",
      "Epoch 825/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0475 - acc: 0.4933 - val_loss: 0.9693 - val_acc: 0.0400\n",
      "Epoch 826/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0482 - acc: 0.5067 - val_loss: 1.0694 - val_acc: 0.0400\n",
      "Epoch 827/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0478 - acc: 0.4400 - val_loss: 0.9994 - val_acc: 0.0400\n",
      "Epoch 828/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0468 - acc: 0.5067 - val_loss: 1.0273 - val_acc: 0.0400\n",
      "Epoch 829/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0478 - acc: 0.5333 - val_loss: 1.0569 - val_acc: 0.0400\n",
      "Epoch 830/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0500 - acc: 0.4800 - val_loss: 0.9710 - val_acc: 0.0400\n",
      "Epoch 831/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.0507 - acc: 0.4800 - val_loss: 1.0536 - val_acc: 0.0000e+00\n",
      "Epoch 832/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 173us/step - loss: 0.0456 - acc: 0.4933 - val_loss: 1.0240 - val_acc: 0.0400\n",
      "Epoch 833/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0448 - acc: 0.4667 - val_loss: 1.0021 - val_acc: 0.0400\n",
      "Epoch 834/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0460 - acc: 0.4800 - val_loss: 1.0947 - val_acc: 0.0000e+00\n",
      "Epoch 835/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0504 - acc: 0.4800 - val_loss: 0.9597 - val_acc: 0.0400\n",
      "Epoch 836/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.0550 - acc: 0.4800 - val_loss: 1.0516 - val_acc: 0.0400\n",
      "Epoch 837/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.0457 - acc: 0.5200 - val_loss: 1.0457 - val_acc: 0.0000e+00\n",
      "Epoch 838/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0476 - acc: 0.4800 - val_loss: 0.9985 - val_acc: 0.0400\n",
      "Epoch 839/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0448 - acc: 0.5200 - val_loss: 1.0588 - val_acc: 0.0400\n",
      "Epoch 840/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0461 - acc: 0.4933 - val_loss: 0.9548 - val_acc: 0.0400\n",
      "Epoch 841/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0524 - acc: 0.5200 - val_loss: 1.0887 - val_acc: 0.0000e+00\n",
      "Epoch 842/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0483 - acc: 0.4800 - val_loss: 1.0044 - val_acc: 0.0400\n",
      "Epoch 843/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0463 - acc: 0.5200 - val_loss: 1.0716 - val_acc: 0.0400\n",
      "Epoch 844/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0483 - acc: 0.4800 - val_loss: 0.9665 - val_acc: 0.0400\n",
      "Epoch 845/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0471 - acc: 0.4933 - val_loss: 1.0781 - val_acc: 0.0000e+00\n",
      "Epoch 846/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0470 - acc: 0.4800 - val_loss: 0.9722 - val_acc: 0.0400\n",
      "Epoch 847/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.0477 - acc: 0.5200 - val_loss: 1.0492 - val_acc: 0.0400\n",
      "Epoch 848/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0468 - acc: 0.4800 - val_loss: 0.9877 - val_acc: 0.0400\n",
      "Epoch 849/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0484 - acc: 0.4800 - val_loss: 1.1012 - val_acc: 0.0400\n",
      "Epoch 850/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0485 - acc: 0.4400 - val_loss: 0.9590 - val_acc: 0.0400\n",
      "Epoch 851/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0482 - acc: 0.5067 - val_loss: 1.1133 - val_acc: 0.0000e+00\n",
      "Epoch 852/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0481 - acc: 0.4800 - val_loss: 0.9811 - val_acc: 0.0400\n",
      "Epoch 853/1000\n",
      "75/75 [==============================] - 0s 198us/step - loss: 0.0466 - acc: 0.5200 - val_loss: 1.0534 - val_acc: 0.0400\n",
      "Epoch 854/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0461 - acc: 0.5467 - val_loss: 0.9808 - val_acc: 0.0400\n",
      "Epoch 855/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0463 - acc: 0.4933 - val_loss: 1.1290 - val_acc: 0.0000e+00\n",
      "Epoch 856/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0514 - acc: 0.4667 - val_loss: 0.9492 - val_acc: 0.0400\n",
      "Epoch 857/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0478 - acc: 0.4933 - val_loss: 1.0563 - val_acc: 0.0400\n",
      "Epoch 858/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.0449 - acc: 0.4800 - val_loss: 1.0020 - val_acc: 0.0400\n",
      "Epoch 859/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0448 - acc: 0.5067 - val_loss: 1.0663 - val_acc: 0.0400\n",
      "Epoch 860/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0473 - acc: 0.4533 - val_loss: 0.9737 - val_acc: 0.0400\n",
      "Epoch 861/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0475 - acc: 0.4667 - val_loss: 1.0336 - val_acc: 0.0400\n",
      "Epoch 862/1000\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.0438 - acc: 0.4933 - val_loss: 1.0156 - val_acc: 0.0400\n",
      "Epoch 863/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0457 - acc: 0.5067 - val_loss: 1.0447 - val_acc: 0.0400\n",
      "Epoch 864/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0442 - acc: 0.5067 - val_loss: 0.9790 - val_acc: 0.0400\n",
      "Epoch 865/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0469 - acc: 0.5067 - val_loss: 1.1272 - val_acc: 0.0400\n",
      "Epoch 866/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0542 - acc: 0.4667 - val_loss: 1.0100 - val_acc: 0.0400\n",
      "Epoch 867/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0432 - acc: 0.5200 - val_loss: 1.0429 - val_acc: 0.0400\n",
      "Epoch 868/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.0437 - acc: 0.5067 - val_loss: 1.0147 - val_acc: 0.0400\n",
      "Epoch 869/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0469 - acc: 0.5067 - val_loss: 1.0294 - val_acc: 0.0400\n",
      "Epoch 870/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0441 - acc: 0.5067 - val_loss: 0.9834 - val_acc: 0.0400\n",
      "Epoch 871/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0481 - acc: 0.4800 - val_loss: 1.0970 - val_acc: 0.0000e+00\n",
      "Epoch 872/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0471 - acc: 0.5067 - val_loss: 0.9928 - val_acc: 0.0400\n",
      "Epoch 873/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0449 - acc: 0.4933 - val_loss: 1.0651 - val_acc: 0.0400\n",
      "Epoch 874/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.0445 - acc: 0.4933 - val_loss: 0.9689 - val_acc: 0.0400\n",
      "Epoch 875/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0469 - acc: 0.5067 - val_loss: 1.0772 - val_acc: 0.0400\n",
      "Epoch 876/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0446 - acc: 0.5067 - val_loss: 1.0030 - val_acc: 0.0400\n",
      "Epoch 877/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0440 - acc: 0.5067 - val_loss: 1.1096 - val_acc: 0.0400\n",
      "Epoch 878/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0507 - acc: 0.4933 - val_loss: 0.9995 - val_acc: 0.0400\n",
      "Epoch 879/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.0451 - acc: 0.4800 - val_loss: 1.0530 - val_acc: 0.0400\n",
      "Epoch 880/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0461 - acc: 0.4800 - val_loss: 1.0097 - val_acc: 0.0400\n",
      "Epoch 881/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0425 - acc: 0.4933 - val_loss: 1.0524 - val_acc: 0.0000e+00\n",
      "Epoch 882/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0439 - acc: 0.5200 - val_loss: 0.9713 - val_acc: 0.0400\n",
      "Epoch 883/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0485 - acc: 0.4933 - val_loss: 1.0756 - val_acc: 0.0000e+00\n",
      "Epoch 884/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.0459 - acc: 0.5200 - val_loss: 0.9440 - val_acc: 0.0400\n",
      "Epoch 885/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0516 - acc: 0.5067 - val_loss: 1.0410 - val_acc: 0.0400\n",
      "Epoch 886/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0422 - acc: 0.5200 - val_loss: 1.0837 - val_acc: 0.0000e+00\n",
      "Epoch 887/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0446 - acc: 0.4933 - val_loss: 1.0138 - val_acc: 0.0400\n",
      "Epoch 888/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0427 - acc: 0.4800 - val_loss: 1.1114 - val_acc: 0.0400\n",
      "Epoch 889/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.0519 - acc: 0.4667 - val_loss: 0.9985 - val_acc: 0.0400\n",
      "Epoch 890/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0432 - acc: 0.4800 - val_loss: 1.0687 - val_acc: 0.0400\n",
      "Epoch 891/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0424 - acc: 0.4800 - val_loss: 0.9950 - val_acc: 0.0400\n",
      "Epoch 892/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 170us/step - loss: 0.0445 - acc: 0.5067 - val_loss: 1.1099 - val_acc: 0.0000e+00\n",
      "Epoch 893/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0459 - acc: 0.4533 - val_loss: 1.0141 - val_acc: 0.0400\n",
      "Epoch 894/1000\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.0417 - acc: 0.4800 - val_loss: 1.0308 - val_acc: 0.0400\n",
      "Epoch 895/1000\n",
      "75/75 [==============================] - 0s 158us/step - loss: 0.0425 - acc: 0.5600 - val_loss: 0.9692 - val_acc: 0.0400\n",
      "Epoch 896/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0520 - acc: 0.5333 - val_loss: 1.0958 - val_acc: 0.0000e+00\n",
      "Epoch 897/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0444 - acc: 0.5067 - val_loss: 1.0059 - val_acc: 0.0400\n",
      "Epoch 898/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0425 - acc: 0.5333 - val_loss: 1.0501 - val_acc: 0.0400\n",
      "Epoch 899/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0416 - acc: 0.5200 - val_loss: 1.0233 - val_acc: 0.0400\n",
      "Epoch 900/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0414 - acc: 0.5333 - val_loss: 1.0990 - val_acc: 0.0000e+00\n",
      "Epoch 901/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0466 - acc: 0.5467 - val_loss: 0.9302 - val_acc: 0.0800\n",
      "Epoch 902/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0523 - acc: 0.5467 - val_loss: 1.0915 - val_acc: 0.0400\n",
      "Epoch 903/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0469 - acc: 0.5467 - val_loss: 1.0143 - val_acc: 0.0400\n",
      "Epoch 904/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0417 - acc: 0.5467 - val_loss: 1.0580 - val_acc: 0.0400\n",
      "Epoch 905/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0428 - acc: 0.5467 - val_loss: 1.0104 - val_acc: 0.0400\n",
      "Epoch 906/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0425 - acc: 0.5467 - val_loss: 1.0968 - val_acc: 0.0400\n",
      "Epoch 907/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0464 - acc: 0.5333 - val_loss: 0.9962 - val_acc: 0.0400\n",
      "Epoch 908/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0448 - acc: 0.5333 - val_loss: 1.1396 - val_acc: 0.0400\n",
      "Epoch 909/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0503 - acc: 0.4667 - val_loss: 0.9899 - val_acc: 0.0400\n",
      "Epoch 910/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0427 - acc: 0.5333 - val_loss: 1.0568 - val_acc: 0.0400\n",
      "Epoch 911/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0437 - acc: 0.5200 - val_loss: 1.0196 - val_acc: 0.0400\n",
      "Epoch 912/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0411 - acc: 0.5333 - val_loss: 1.0400 - val_acc: 0.0400\n",
      "Epoch 913/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0410 - acc: 0.5333 - val_loss: 0.9979 - val_acc: 0.0400\n",
      "Epoch 914/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0448 - acc: 0.5200 - val_loss: 1.0568 - val_acc: 0.0400\n",
      "Epoch 915/1000\n",
      "75/75 [==============================] - 0s 181us/step - loss: 0.0415 - acc: 0.4933 - val_loss: 0.9877 - val_acc: 0.0400\n",
      "Epoch 916/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0451 - acc: 0.4667 - val_loss: 1.1067 - val_acc: 0.0400\n",
      "Epoch 917/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0476 - acc: 0.4933 - val_loss: 0.9925 - val_acc: 0.0400\n",
      "Epoch 918/1000\n",
      "75/75 [==============================] - 0s 183us/step - loss: 0.0421 - acc: 0.5200 - val_loss: 1.0679 - val_acc: 0.0400\n",
      "Epoch 919/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0456 - acc: 0.5733 - val_loss: 1.0241 - val_acc: 0.0400\n",
      "Epoch 920/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0409 - acc: 0.5200 - val_loss: 1.0937 - val_acc: 0.0400\n",
      "Epoch 921/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0441 - acc: 0.5067 - val_loss: 0.9776 - val_acc: 0.0400\n",
      "Epoch 922/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0452 - acc: 0.5067 - val_loss: 1.0961 - val_acc: 0.0400\n",
      "Epoch 923/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0430 - acc: 0.4933 - val_loss: 0.9900 - val_acc: 0.0400\n",
      "Epoch 924/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0421 - acc: 0.4933 - val_loss: 1.0883 - val_acc: 0.0400\n",
      "Epoch 925/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0423 - acc: 0.5467 - val_loss: 0.9633 - val_acc: 0.0400\n",
      "Epoch 926/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0470 - acc: 0.4933 - val_loss: 1.0575 - val_acc: 0.0400\n",
      "Epoch 927/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0416 - acc: 0.5200 - val_loss: 0.9760 - val_acc: 0.0400\n",
      "Epoch 928/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0429 - acc: 0.4933 - val_loss: 1.0740 - val_acc: 0.0400\n",
      "Epoch 929/1000\n",
      "75/75 [==============================] - 0s 194us/step - loss: 0.0428 - acc: 0.5333 - val_loss: 0.9913 - val_acc: 0.0400\n",
      "Epoch 930/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0414 - acc: 0.4800 - val_loss: 1.0839 - val_acc: 0.0400\n",
      "Epoch 931/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0439 - acc: 0.5333 - val_loss: 0.9785 - val_acc: 0.0400\n",
      "Epoch 932/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0463 - acc: 0.4800 - val_loss: 1.1143 - val_acc: 0.0400\n",
      "Epoch 933/1000\n",
      "75/75 [==============================] - 0s 163us/step - loss: 0.0421 - acc: 0.5333 - val_loss: 1.0346 - val_acc: 0.0400\n",
      "Epoch 934/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0392 - acc: 0.5200 - val_loss: 1.0565 - val_acc: 0.0400\n",
      "Epoch 935/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0391 - acc: 0.5600 - val_loss: 1.0226 - val_acc: 0.0400\n",
      "Epoch 936/1000\n",
      "75/75 [==============================] - 0s 185us/step - loss: 0.0418 - acc: 0.4933 - val_loss: 1.0818 - val_acc: 0.0400\n",
      "Epoch 937/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0427 - acc: 0.5067 - val_loss: 1.0098 - val_acc: 0.0400\n",
      "Epoch 938/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.0405 - acc: 0.5467 - val_loss: 1.1292 - val_acc: 0.0400\n",
      "Epoch 939/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0488 - acc: 0.4933 - val_loss: 0.9967 - val_acc: 0.0400\n",
      "Epoch 940/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0407 - acc: 0.5467 - val_loss: 1.0625 - val_acc: 0.0400\n",
      "Epoch 941/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0397 - acc: 0.5067 - val_loss: 0.9934 - val_acc: 0.0400\n",
      "Epoch 942/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0409 - acc: 0.5467 - val_loss: 1.0911 - val_acc: 0.0400\n",
      "Epoch 943/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0415 - acc: 0.5333 - val_loss: 0.9906 - val_acc: 0.0400\n",
      "Epoch 944/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0426 - acc: 0.5200 - val_loss: 1.0950 - val_acc: 0.0400\n",
      "Epoch 945/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0419 - acc: 0.4800 - val_loss: 0.9852 - val_acc: 0.0400\n",
      "Epoch 946/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0419 - acc: 0.5200 - val_loss: 1.0480 - val_acc: 0.0400\n",
      "Epoch 947/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0388 - acc: 0.5333 - val_loss: 1.0073 - val_acc: 0.0400\n",
      "Epoch 948/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0409 - acc: 0.5333 - val_loss: 1.1046 - val_acc: 0.0400\n",
      "Epoch 949/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0438 - acc: 0.5333 - val_loss: 1.0118 - val_acc: 0.0400\n",
      "Epoch 950/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0416 - acc: 0.5333 - val_loss: 1.0836 - val_acc: 0.0400\n",
      "Epoch 951/1000\n",
      "75/75 [==============================] - 0s 184us/step - loss: 0.0409 - acc: 0.4800 - val_loss: 0.9573 - val_acc: 0.0400\n",
      "Epoch 952/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 175us/step - loss: 0.0447 - acc: 0.4667 - val_loss: 1.1343 - val_acc: 0.0000e+00\n",
      "Epoch 953/1000\n",
      "75/75 [==============================] - 0s 180us/step - loss: 0.0448 - acc: 0.4400 - val_loss: 1.0282 - val_acc: 0.0400\n",
      "Epoch 954/1000\n",
      "75/75 [==============================] - 0s 166us/step - loss: 0.0378 - acc: 0.5467 - val_loss: 1.0225 - val_acc: 0.0400\n",
      "Epoch 955/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0384 - acc: 0.5333 - val_loss: 1.0680 - val_acc: 0.0400\n",
      "Epoch 956/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0386 - acc: 0.5067 - val_loss: 0.9849 - val_acc: 0.0400\n",
      "Epoch 957/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0443 - acc: 0.5200 - val_loss: 1.1213 - val_acc: 0.0000e+00\n",
      "Epoch 958/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0412 - acc: 0.5333 - val_loss: 0.9745 - val_acc: 0.0400\n",
      "Epoch 959/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0435 - acc: 0.5200 - val_loss: 1.0978 - val_acc: 0.0400\n",
      "Epoch 960/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0397 - acc: 0.5067 - val_loss: 1.0182 - val_acc: 0.0400\n",
      "Epoch 961/1000\n",
      "75/75 [==============================] - 0s 174us/step - loss: 0.0379 - acc: 0.5067 - val_loss: 1.0556 - val_acc: 0.0400\n",
      "Epoch 962/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0375 - acc: 0.5333 - val_loss: 1.0713 - val_acc: 0.0400\n",
      "Epoch 963/1000\n",
      "75/75 [==============================] - 0s 187us/step - loss: 0.0426 - acc: 0.5867 - val_loss: 1.0318 - val_acc: 0.0400\n",
      "Epoch 964/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0426 - acc: 0.5333 - val_loss: 1.0397 - val_acc: 0.0400\n",
      "Epoch 965/1000\n",
      "75/75 [==============================] - 0s 161us/step - loss: 0.0370 - acc: 0.5200 - val_loss: 1.0200 - val_acc: 0.0400\n",
      "Epoch 966/1000\n",
      "75/75 [==============================] - 0s 175us/step - loss: 0.0411 - acc: 0.5333 - val_loss: 1.0575 - val_acc: 0.0400\n",
      "Epoch 967/1000\n",
      "75/75 [==============================] - 0s 176us/step - loss: 0.0383 - acc: 0.5200 - val_loss: 1.0118 - val_acc: 0.0400\n",
      "Epoch 968/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.0404 - acc: 0.4933 - val_loss: 1.1076 - val_acc: 0.0400\n",
      "Epoch 969/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0421 - acc: 0.4800 - val_loss: 0.9577 - val_acc: 0.0400\n",
      "Epoch 970/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0432 - acc: 0.5200 - val_loss: 1.0886 - val_acc: 0.0400\n",
      "Epoch 971/1000\n",
      "75/75 [==============================] - 0s 167us/step - loss: 0.0385 - acc: 0.5067 - val_loss: 1.0000 - val_acc: 0.0400\n",
      "Epoch 972/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0387 - acc: 0.4933 - val_loss: 1.1415 - val_acc: 0.0400\n",
      "Epoch 973/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0427 - acc: 0.4800 - val_loss: 0.9959 - val_acc: 0.0400\n",
      "Epoch 974/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0408 - acc: 0.5333 - val_loss: 1.0671 - val_acc: 0.0400\n",
      "Epoch 975/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0366 - acc: 0.4800 - val_loss: 1.0216 - val_acc: 0.0400\n",
      "Epoch 976/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0375 - acc: 0.5200 - val_loss: 1.1265 - val_acc: 0.0400\n",
      "Epoch 977/1000\n",
      "75/75 [==============================] - 0s 168us/step - loss: 0.0436 - acc: 0.4800 - val_loss: 1.0034 - val_acc: 0.0400\n",
      "Epoch 978/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0410 - acc: 0.5200 - val_loss: 1.0728 - val_acc: 0.0400\n",
      "Epoch 979/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0391 - acc: 0.5200 - val_loss: 1.0954 - val_acc: 0.0400\n",
      "Epoch 980/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0406 - acc: 0.5467 - val_loss: 1.0369 - val_acc: 0.0400\n",
      "Epoch 981/1000\n",
      "75/75 [==============================] - 0s 165us/step - loss: 0.0370 - acc: 0.5333 - val_loss: 1.0825 - val_acc: 0.0400\n",
      "Epoch 982/1000\n",
      "75/75 [==============================] - 0s 173us/step - loss: 0.0372 - acc: 0.4933 - val_loss: 0.9842 - val_acc: 0.0400\n",
      "Epoch 983/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0438 - acc: 0.5067 - val_loss: 1.1919 - val_acc: 0.0000e+00\n",
      "Epoch 984/1000\n",
      "75/75 [==============================] - 0s 178us/step - loss: 0.0466 - acc: 0.4800 - val_loss: 1.0172 - val_acc: 0.0400\n",
      "Epoch 985/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0364 - acc: 0.5467 - val_loss: 1.0362 - val_acc: 0.0400\n",
      "Epoch 986/1000\n",
      "75/75 [==============================] - 0s 159us/step - loss: 0.0362 - acc: 0.5333 - val_loss: 1.0410 - val_acc: 0.0400\n",
      "Epoch 987/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0363 - acc: 0.5067 - val_loss: 1.0252 - val_acc: 0.0400\n",
      "Epoch 988/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0382 - acc: 0.4933 - val_loss: 1.0898 - val_acc: 0.0000e+00\n",
      "Epoch 989/1000\n",
      "75/75 [==============================] - 0s 196us/step - loss: 0.0404 - acc: 0.4800 - val_loss: 1.0138 - val_acc: 0.0400\n",
      "Epoch 990/1000\n",
      "75/75 [==============================] - 0s 188us/step - loss: 0.0383 - acc: 0.5200 - val_loss: 1.0769 - val_acc: 0.0400\n",
      "Epoch 991/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0399 - acc: 0.5200 - val_loss: 0.9778 - val_acc: 0.0400\n",
      "Epoch 992/1000\n",
      "75/75 [==============================] - 0s 177us/step - loss: 0.0430 - acc: 0.5067 - val_loss: 1.0680 - val_acc: 0.0400\n",
      "Epoch 993/1000\n",
      "75/75 [==============================] - 0s 162us/step - loss: 0.0360 - acc: 0.5200 - val_loss: 1.0267 - val_acc: 0.0400\n",
      "Epoch 994/1000\n",
      "75/75 [==============================] - 0s 179us/step - loss: 0.0380 - acc: 0.5200 - val_loss: 1.1217 - val_acc: 0.0400\n",
      "Epoch 995/1000\n",
      "75/75 [==============================] - 0s 170us/step - loss: 0.0396 - acc: 0.4400 - val_loss: 0.9598 - val_acc: 0.0400\n",
      "Epoch 996/1000\n",
      "75/75 [==============================] - 0s 169us/step - loss: 0.0457 - acc: 0.4800 - val_loss: 1.0924 - val_acc: 0.0400\n",
      "Epoch 997/1000\n",
      "75/75 [==============================] - 0s 164us/step - loss: 0.0374 - acc: 0.5333 - val_loss: 1.0087 - val_acc: 0.0400\n",
      "Epoch 998/1000\n",
      "75/75 [==============================] - 0s 171us/step - loss: 0.0372 - acc: 0.5333 - val_loss: 1.1042 - val_acc: 0.0400\n",
      "Epoch 999/1000\n",
      "75/75 [==============================] - 0s 182us/step - loss: 0.0395 - acc: 0.4933 - val_loss: 0.9889 - val_acc: 0.0400\n",
      "Epoch 1000/1000\n",
      "75/75 [==============================] - 0s 172us/step - loss: 0.0395 - acc: 0.4800 - val_loss: 1.1267 - val_acc: 0.0400\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(100, input_dim=2470),\n",
    "    Activation('relu'), #,sigmoid softmax\n",
    "    Dense(247),\n",
    "    Activation('relu'),\n",
    "    Dense(2470),\n",
    "    Activation('relu'),\n",
    "    ])\n",
    "\n",
    "# optimizer\n",
    "rmsprop = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(\n",
    "    optimizer= rmsprop,\n",
    "    loss = 'mean_squared_error',\n",
    "    metrics=['accuracy']#, mean_pred]\n",
    "    )\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.25, epochs=1000, batch_size=32, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
