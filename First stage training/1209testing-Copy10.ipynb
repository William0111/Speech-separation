{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.09 testing 1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import part\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loading data\n",
    "X_train = np.loadtxt(\"1209.2_spec_train_1000.txt\")\n",
    "y_train = np.loadtxt(\"1209.2_mask_train_1000.txt\")\n",
    "\n",
    "X_test = np.loadtxt(\"1209.2_spec_test_1000.txt\")\n",
    "y_test = np.loadtxt(\"1209.2_mask_test_1000.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No hiden layer. just fully connected\n",
    "# sigmoid as activation function\n",
    "model = Sequential([\n",
    "    Dense(1024, input_dim=1024),\n",
    "    Activation('relu'), \n",
    "    Dense(1024),\n",
    "    Activation('hard_sigmoid'),  # ,sigmoid softmax\n",
    "    #Dense(247),\n",
    "    #Activation('relu'),\n",
    "    #Dense(2470),\n",
    "    #Activation('sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-------------------------\n",
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/2000\n",
      "750/750 [==============================] - 1s 764us/step - loss: 0.2327 - acc: 0.0027 - val_loss: 0.2131 - val_acc: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "750/750 [==============================] - 0s 94us/step - loss: 0.1934 - acc: 0.0027 - val_loss: 0.1713 - val_acc: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.1531 - acc: 0.0013 - val_loss: 0.1338 - val_acc: 0.0040\n",
      "Epoch 4/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.1208 - acc: 0.0120 - val_loss: 0.1043 - val_acc: 0.0080\n",
      "Epoch 5/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0957 - acc: 0.0547 - val_loss: 0.0811 - val_acc: 0.0200\n",
      "Epoch 6/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0764 - acc: 0.0800 - val_loss: 0.0636 - val_acc: 0.0200\n",
      "Epoch 7/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0625 - acc: 0.0853 - val_loss: 0.0515 - val_acc: 0.0200\n",
      "Epoch 8/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0526 - acc: 0.0747 - val_loss: 0.0433 - val_acc: 0.0200\n",
      "Epoch 9/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0458 - acc: 0.0653 - val_loss: 0.0378 - val_acc: 0.0200\n",
      "Epoch 10/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0411 - acc: 0.0813 - val_loss: 0.0341 - val_acc: 0.0240\n",
      "Epoch 11/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0380 - acc: 0.0787 - val_loss: 0.0316 - val_acc: 0.0240\n",
      "Epoch 12/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0359 - acc: 0.0893 - val_loss: 0.0299 - val_acc: 0.0240\n",
      "Epoch 13/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0344 - acc: 0.0800 - val_loss: 0.0287 - val_acc: 0.0240\n",
      "Epoch 14/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0334 - acc: 0.0933 - val_loss: 0.0279 - val_acc: 0.0240\n",
      "Epoch 15/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0326 - acc: 0.0827 - val_loss: 0.0274 - val_acc: 0.0280\n",
      "Epoch 16/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0320 - acc: 0.0920 - val_loss: 0.0269 - val_acc: 0.0320\n",
      "Epoch 17/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0315 - acc: 0.0933 - val_loss: 0.0266 - val_acc: 0.0320\n",
      "Epoch 18/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0311 - acc: 0.1053 - val_loss: 0.0262 - val_acc: 0.0360\n",
      "Epoch 19/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0306 - acc: 0.1000 - val_loss: 0.0259 - val_acc: 0.0400\n",
      "Epoch 20/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0303 - acc: 0.0960 - val_loss: 0.0256 - val_acc: 0.0520\n",
      "Epoch 21/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0299 - acc: 0.0893 - val_loss: 0.0253 - val_acc: 0.0560\n",
      "Epoch 22/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0296 - acc: 0.0947 - val_loss: 0.0250 - val_acc: 0.0600\n",
      "Epoch 23/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0292 - acc: 0.0907 - val_loss: 0.0248 - val_acc: 0.0600\n",
      "Epoch 24/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0289 - acc: 0.0827 - val_loss: 0.0245 - val_acc: 0.0640\n",
      "Epoch 25/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0286 - acc: 0.0880 - val_loss: 0.0243 - val_acc: 0.0600\n",
      "Epoch 26/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0283 - acc: 0.0920 - val_loss: 0.0241 - val_acc: 0.0600\n",
      "Epoch 27/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0281 - acc: 0.0800 - val_loss: 0.0239 - val_acc: 0.0600\n",
      "Epoch 28/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0278 - acc: 0.0920 - val_loss: 0.0237 - val_acc: 0.0560\n",
      "Epoch 29/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0276 - acc: 0.0880 - val_loss: 0.0234 - val_acc: 0.0560\n",
      "Epoch 30/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0273 - acc: 0.0840 - val_loss: 0.0233 - val_acc: 0.0680\n",
      "Epoch 31/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0271 - acc: 0.0973 - val_loss: 0.0231 - val_acc: 0.0680\n",
      "Epoch 32/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0269 - acc: 0.0880 - val_loss: 0.0229 - val_acc: 0.0800\n",
      "Epoch 33/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0266 - acc: 0.0960 - val_loss: 0.0228 - val_acc: 0.0760\n",
      "Epoch 34/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0264 - acc: 0.0960 - val_loss: 0.0226 - val_acc: 0.0800\n",
      "Epoch 35/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0262 - acc: 0.0920 - val_loss: 0.0225 - val_acc: 0.0840\n",
      "Epoch 36/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0260 - acc: 0.1000 - val_loss: 0.0224 - val_acc: 0.0840\n",
      "Epoch 37/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0258 - acc: 0.0920 - val_loss: 0.0222 - val_acc: 0.0800\n",
      "Epoch 38/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0256 - acc: 0.0987 - val_loss: 0.0221 - val_acc: 0.0840\n",
      "Epoch 39/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0254 - acc: 0.1080 - val_loss: 0.0220 - val_acc: 0.0960\n",
      "Epoch 40/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0252 - acc: 0.1093 - val_loss: 0.0218 - val_acc: 0.0880\n",
      "Epoch 41/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0250 - acc: 0.1120 - val_loss: 0.0218 - val_acc: 0.0840\n",
      "Epoch 42/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0248 - acc: 0.1080 - val_loss: 0.0216 - val_acc: 0.0920\n",
      "Epoch 43/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0246 - acc: 0.1120 - val_loss: 0.0215 - val_acc: 0.0880\n",
      "Epoch 44/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0245 - acc: 0.1080 - val_loss: 0.0215 - val_acc: 0.0880\n",
      "Epoch 45/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0243 - acc: 0.1093 - val_loss: 0.0214 - val_acc: 0.0920\n",
      "Epoch 46/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0242 - acc: 0.1133 - val_loss: 0.0213 - val_acc: 0.1040\n",
      "Epoch 47/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0240 - acc: 0.1120 - val_loss: 0.0212 - val_acc: 0.1040\n",
      "Epoch 48/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0239 - acc: 0.1160 - val_loss: 0.0212 - val_acc: 0.1040\n",
      "Epoch 49/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0237 - acc: 0.1173 - val_loss: 0.0211 - val_acc: 0.1160\n",
      "Epoch 50/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0236 - acc: 0.1373 - val_loss: 0.0210 - val_acc: 0.1120\n",
      "Epoch 51/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0234 - acc: 0.1373 - val_loss: 0.0210 - val_acc: 0.1160\n",
      "Epoch 52/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0233 - acc: 0.1400 - val_loss: 0.0209 - val_acc: 0.1200\n",
      "Epoch 53/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0232 - acc: 0.1347 - val_loss: 0.0208 - val_acc: 0.1200\n",
      "Epoch 54/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0231 - acc: 0.1360 - val_loss: 0.0208 - val_acc: 0.1200\n",
      "Epoch 55/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0229 - acc: 0.1507 - val_loss: 0.0207 - val_acc: 0.1320\n",
      "Epoch 56/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0228 - acc: 0.1467 - val_loss: 0.0206 - val_acc: 0.1240\n",
      "Epoch 57/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0227 - acc: 0.1333 - val_loss: 0.0206 - val_acc: 0.1240\n",
      "Epoch 58/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0226 - acc: 0.1400 - val_loss: 0.0206 - val_acc: 0.0960\n",
      "Epoch 59/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0225 - acc: 0.1347 - val_loss: 0.0205 - val_acc: 0.0920\n",
      "Epoch 60/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 81us/step - loss: 0.0224 - acc: 0.1293 - val_loss: 0.0205 - val_acc: 0.0960\n",
      "Epoch 61/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0223 - acc: 0.1320 - val_loss: 0.0204 - val_acc: 0.0920\n",
      "Epoch 62/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0222 - acc: 0.1307 - val_loss: 0.0204 - val_acc: 0.0920\n",
      "Epoch 63/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0221 - acc: 0.1347 - val_loss: 0.0204 - val_acc: 0.0960\n",
      "Epoch 64/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0221 - acc: 0.1360 - val_loss: 0.0204 - val_acc: 0.0880\n",
      "Epoch 65/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0220 - acc: 0.1360 - val_loss: 0.0204 - val_acc: 0.0960\n",
      "Epoch 66/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0219 - acc: 0.1493 - val_loss: 0.0203 - val_acc: 0.0960\n",
      "Epoch 67/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0218 - acc: 0.1347 - val_loss: 0.0202 - val_acc: 0.1040\n",
      "Epoch 68/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0218 - acc: 0.1400 - val_loss: 0.0202 - val_acc: 0.1040\n",
      "Epoch 69/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0217 - acc: 0.1400 - val_loss: 0.0202 - val_acc: 0.1040\n",
      "Epoch 70/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0216 - acc: 0.1427 - val_loss: 0.0202 - val_acc: 0.1040\n",
      "Epoch 71/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0215 - acc: 0.1427 - val_loss: 0.0202 - val_acc: 0.1040\n",
      "Epoch 72/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0215 - acc: 0.1467 - val_loss: 0.0201 - val_acc: 0.1080\n",
      "Epoch 73/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0214 - acc: 0.1507 - val_loss: 0.0201 - val_acc: 0.1080\n",
      "Epoch 74/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0214 - acc: 0.1493 - val_loss: 0.0201 - val_acc: 0.1000\n",
      "Epoch 75/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0213 - acc: 0.1573 - val_loss: 0.0201 - val_acc: 0.1080\n",
      "Epoch 76/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0212 - acc: 0.1547 - val_loss: 0.0201 - val_acc: 0.1120\n",
      "Epoch 77/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0212 - acc: 0.1600 - val_loss: 0.0201 - val_acc: 0.1080\n",
      "Epoch 78/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0211 - acc: 0.1613 - val_loss: 0.0200 - val_acc: 0.1080\n",
      "Epoch 79/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0211 - acc: 0.1560 - val_loss: 0.0200 - val_acc: 0.1200\n",
      "Epoch 80/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0210 - acc: 0.1627 - val_loss: 0.0200 - val_acc: 0.1160\n",
      "Epoch 81/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0210 - acc: 0.1680 - val_loss: 0.0200 - val_acc: 0.1160\n",
      "Epoch 82/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0209 - acc: 0.1707 - val_loss: 0.0200 - val_acc: 0.1200\n",
      "Epoch 83/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0209 - acc: 0.1680 - val_loss: 0.0200 - val_acc: 0.1200\n",
      "Epoch 84/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0208 - acc: 0.1733 - val_loss: 0.0200 - val_acc: 0.1240\n",
      "Epoch 85/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0208 - acc: 0.1747 - val_loss: 0.0199 - val_acc: 0.1320\n",
      "Epoch 86/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0207 - acc: 0.1787 - val_loss: 0.0199 - val_acc: 0.1240\n",
      "Epoch 87/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0207 - acc: 0.1827 - val_loss: 0.0199 - val_acc: 0.1280\n",
      "Epoch 88/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0206 - acc: 0.1840 - val_loss: 0.0199 - val_acc: 0.1280\n",
      "Epoch 89/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0206 - acc: 0.1880 - val_loss: 0.0199 - val_acc: 0.1320\n",
      "Epoch 90/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0205 - acc: 0.1867 - val_loss: 0.0199 - val_acc: 0.1360\n",
      "Epoch 91/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0205 - acc: 0.1933 - val_loss: 0.0199 - val_acc: 0.1280\n",
      "Epoch 92/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0204 - acc: 0.1933 - val_loss: 0.0199 - val_acc: 0.1400\n",
      "Epoch 93/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0204 - acc: 0.2000 - val_loss: 0.0199 - val_acc: 0.1400\n",
      "Epoch 94/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0204 - acc: 0.1947 - val_loss: 0.0198 - val_acc: 0.1440\n",
      "Epoch 95/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0203 - acc: 0.1987 - val_loss: 0.0198 - val_acc: 0.1440\n",
      "Epoch 96/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0203 - acc: 0.1973 - val_loss: 0.0198 - val_acc: 0.1440\n",
      "Epoch 97/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0202 - acc: 0.2027 - val_loss: 0.0198 - val_acc: 0.1480\n",
      "Epoch 98/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0202 - acc: 0.2040 - val_loss: 0.0198 - val_acc: 0.1560\n",
      "Epoch 99/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0201 - acc: 0.2027 - val_loss: 0.0198 - val_acc: 0.1600\n",
      "Epoch 100/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0201 - acc: 0.2067 - val_loss: 0.0198 - val_acc: 0.1560\n",
      "Epoch 101/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0201 - acc: 0.2200 - val_loss: 0.0198 - val_acc: 0.1600\n",
      "Epoch 102/2000\n",
      "750/750 [==============================] - 0s 89us/step - loss: 0.0200 - acc: 0.2120 - val_loss: 0.0197 - val_acc: 0.1640\n",
      "Epoch 103/2000\n",
      "750/750 [==============================] - 0s 90us/step - loss: 0.0200 - acc: 0.2253 - val_loss: 0.0198 - val_acc: 0.1720\n",
      "Epoch 104/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0200 - acc: 0.2267 - val_loss: 0.0197 - val_acc: 0.1680\n",
      "Epoch 105/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0199 - acc: 0.2147 - val_loss: 0.0197 - val_acc: 0.1680\n",
      "Epoch 106/2000\n",
      "750/750 [==============================] - 0s 89us/step - loss: 0.0199 - acc: 0.2240 - val_loss: 0.0197 - val_acc: 0.1720\n",
      "Epoch 107/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0198 - acc: 0.2213 - val_loss: 0.0197 - val_acc: 0.1640\n",
      "Epoch 108/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0198 - acc: 0.2227 - val_loss: 0.0197 - val_acc: 0.1760\n",
      "Epoch 109/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0198 - acc: 0.2293 - val_loss: 0.0197 - val_acc: 0.1640\n",
      "Epoch 110/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0197 - acc: 0.2280 - val_loss: 0.0197 - val_acc: 0.1800\n",
      "Epoch 111/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0197 - acc: 0.2267 - val_loss: 0.0197 - val_acc: 0.1760\n",
      "Epoch 112/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0197 - acc: 0.2307 - val_loss: 0.0197 - val_acc: 0.1840\n",
      "Epoch 113/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0196 - acc: 0.2213 - val_loss: 0.0197 - val_acc: 0.1840\n",
      "Epoch 114/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0196 - acc: 0.2240 - val_loss: 0.0197 - val_acc: 0.1840\n",
      "Epoch 115/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0196 - acc: 0.2253 - val_loss: 0.0197 - val_acc: 0.2000\n",
      "Epoch 116/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0195 - acc: 0.2333 - val_loss: 0.0197 - val_acc: 0.2000\n",
      "Epoch 117/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0195 - acc: 0.2413 - val_loss: 0.0197 - val_acc: 0.2040\n",
      "Epoch 118/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0195 - acc: 0.2387 - val_loss: 0.0197 - val_acc: 0.1960\n",
      "Epoch 119/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0194 - acc: 0.2360 - val_loss: 0.0197 - val_acc: 0.1960\n",
      "Epoch 120/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 86us/step - loss: 0.0194 - acc: 0.2347 - val_loss: 0.0197 - val_acc: 0.1960\n",
      "Epoch 121/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0194 - acc: 0.2280 - val_loss: 0.0196 - val_acc: 0.2080\n",
      "Epoch 122/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0193 - acc: 0.2320 - val_loss: 0.0196 - val_acc: 0.1960\n",
      "Epoch 123/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0193 - acc: 0.2360 - val_loss: 0.0196 - val_acc: 0.2040\n",
      "Epoch 124/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0193 - acc: 0.2427 - val_loss: 0.0196 - val_acc: 0.2040\n",
      "Epoch 125/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0192 - acc: 0.2387 - val_loss: 0.0196 - val_acc: 0.2000\n",
      "Epoch 126/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0192 - acc: 0.2413 - val_loss: 0.0196 - val_acc: 0.2000\n",
      "Epoch 127/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0192 - acc: 0.2360 - val_loss: 0.0196 - val_acc: 0.1960\n",
      "Epoch 128/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0192 - acc: 0.2307 - val_loss: 0.0196 - val_acc: 0.2000\n",
      "Epoch 129/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0191 - acc: 0.2347 - val_loss: 0.0196 - val_acc: 0.2040\n",
      "Epoch 130/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0191 - acc: 0.2360 - val_loss: 0.0196 - val_acc: 0.2120\n",
      "Epoch 131/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0191 - acc: 0.2347 - val_loss: 0.0196 - val_acc: 0.2120\n",
      "Epoch 132/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0190 - acc: 0.2427 - val_loss: 0.0195 - val_acc: 0.2240\n",
      "Epoch 133/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0190 - acc: 0.2507 - val_loss: 0.0196 - val_acc: 0.2120\n",
      "Epoch 134/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0190 - acc: 0.2453 - val_loss: 0.0196 - val_acc: 0.2080\n",
      "Epoch 135/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0190 - acc: 0.2520 - val_loss: 0.0195 - val_acc: 0.2120\n",
      "Epoch 136/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0189 - acc: 0.2440 - val_loss: 0.0195 - val_acc: 0.2120\n",
      "Epoch 137/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0189 - acc: 0.2440 - val_loss: 0.0195 - val_acc: 0.2120\n",
      "Epoch 138/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0189 - acc: 0.2453 - val_loss: 0.0195 - val_acc: 0.2160\n",
      "Epoch 139/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0188 - acc: 0.2507 - val_loss: 0.0195 - val_acc: 0.2240\n",
      "Epoch 140/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0188 - acc: 0.2493 - val_loss: 0.0195 - val_acc: 0.2240\n",
      "Epoch 141/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0188 - acc: 0.2520 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 142/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0188 - acc: 0.2493 - val_loss: 0.0195 - val_acc: 0.2240\n",
      "Epoch 143/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0187 - acc: 0.2560 - val_loss: 0.0195 - val_acc: 0.2240\n",
      "Epoch 144/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0187 - acc: 0.2547 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 145/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0187 - acc: 0.2547 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 146/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0187 - acc: 0.2600 - val_loss: 0.0195 - val_acc: 0.2240\n",
      "Epoch 147/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0187 - acc: 0.2640 - val_loss: 0.0195 - val_acc: 0.2240\n",
      "Epoch 148/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0186 - acc: 0.2680 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 149/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0186 - acc: 0.2627 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 150/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0186 - acc: 0.2667 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 151/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0186 - acc: 0.2653 - val_loss: 0.0195 - val_acc: 0.2320\n",
      "Epoch 152/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0185 - acc: 0.2693 - val_loss: 0.0195 - val_acc: 0.2320\n",
      "Epoch 153/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0185 - acc: 0.2667 - val_loss: 0.0195 - val_acc: 0.2360\n",
      "Epoch 154/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0185 - acc: 0.2733 - val_loss: 0.0195 - val_acc: 0.2360\n",
      "Epoch 155/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0185 - acc: 0.2733 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 156/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0184 - acc: 0.2707 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 157/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0184 - acc: 0.2760 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 158/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0184 - acc: 0.2733 - val_loss: 0.0195 - val_acc: 0.2360\n",
      "Epoch 159/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0184 - acc: 0.2800 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 160/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0184 - acc: 0.2707 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 161/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0183 - acc: 0.2773 - val_loss: 0.0194 - val_acc: 0.2320\n",
      "Epoch 162/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0183 - acc: 0.2760 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 163/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0183 - acc: 0.2800 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 164/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0183 - acc: 0.2813 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 165/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0183 - acc: 0.2787 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 166/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0182 - acc: 0.2800 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 167/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0182 - acc: 0.2800 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 168/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0182 - acc: 0.2880 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 169/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0182 - acc: 0.2827 - val_loss: 0.0194 - val_acc: 0.2520\n",
      "Epoch 170/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0182 - acc: 0.2867 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 171/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0181 - acc: 0.2800 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 172/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0181 - acc: 0.2867 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 173/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0181 - acc: 0.2947 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 174/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0181 - acc: 0.2853 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 175/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0181 - acc: 0.2867 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 176/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0180 - acc: 0.2867 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 177/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0180 - acc: 0.2933 - val_loss: 0.0194 - val_acc: 0.2520\n",
      "Epoch 178/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0180 - acc: 0.2933 - val_loss: 0.0194 - val_acc: 0.2520\n",
      "Epoch 179/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0180 - acc: 0.2947 - val_loss: 0.0194 - val_acc: 0.2440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0180 - acc: 0.2973 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 181/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0180 - acc: 0.2907 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 182/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0179 - acc: 0.3000 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 183/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0179 - acc: 0.2973 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 184/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0179 - acc: 0.3053 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 185/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0179 - acc: 0.2973 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 186/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0179 - acc: 0.2947 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 187/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0178 - acc: 0.3040 - val_loss: 0.0194 - val_acc: 0.2280\n",
      "Epoch 188/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0178 - acc: 0.2973 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 189/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0178 - acc: 0.2920 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 190/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0178 - acc: 0.3053 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 191/2000\n",
      "750/750 [==============================] - 0s 90us/step - loss: 0.0178 - acc: 0.2987 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 192/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0178 - acc: 0.3107 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 193/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0177 - acc: 0.2987 - val_loss: 0.0194 - val_acc: 0.2320\n",
      "Epoch 194/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0177 - acc: 0.3013 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 195/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0177 - acc: 0.3027 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 196/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0177 - acc: 0.3000 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 197/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0177 - acc: 0.2987 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 198/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0177 - acc: 0.3120 - val_loss: 0.0194 - val_acc: 0.2320\n",
      "Epoch 199/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0177 - acc: 0.3013 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 200/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0176 - acc: 0.3053 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 201/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0176 - acc: 0.3013 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 202/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0176 - acc: 0.2947 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 203/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0176 - acc: 0.3013 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 204/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0176 - acc: 0.2933 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 205/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0175 - acc: 0.3053 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 206/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0175 - acc: 0.3000 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 207/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0175 - acc: 0.2987 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 208/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0175 - acc: 0.3093 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 209/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0175 - acc: 0.2987 - val_loss: 0.0194 - val_acc: 0.2320\n",
      "Epoch 210/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0175 - acc: 0.3053 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 211/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0175 - acc: 0.3040 - val_loss: 0.0194 - val_acc: 0.2320\n",
      "Epoch 212/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0175 - acc: 0.3053 - val_loss: 0.0194 - val_acc: 0.2320\n",
      "Epoch 213/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0174 - acc: 0.2987 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 214/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0174 - acc: 0.3067 - val_loss: 0.0194 - val_acc: 0.2280\n",
      "Epoch 215/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0174 - acc: 0.3080 - val_loss: 0.0194 - val_acc: 0.2320\n",
      "Epoch 216/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0174 - acc: 0.3040 - val_loss: 0.0194 - val_acc: 0.2320\n",
      "Epoch 217/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0174 - acc: 0.3053 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 218/2000\n",
      "750/750 [==============================] - 0s 89us/step - loss: 0.0174 - acc: 0.3000 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 219/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0173 - acc: 0.3013 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 220/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0173 - acc: 0.3067 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 221/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0173 - acc: 0.3053 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 222/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0173 - acc: 0.3067 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 223/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0173 - acc: 0.3067 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 224/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0173 - acc: 0.3040 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 225/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0173 - acc: 0.3107 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 226/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0172 - acc: 0.3080 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 227/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0172 - acc: 0.3120 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 228/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0172 - acc: 0.3120 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 229/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0172 - acc: 0.3147 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 230/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0172 - acc: 0.3173 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 231/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0172 - acc: 0.3147 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 232/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0172 - acc: 0.3213 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 233/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0171 - acc: 0.3187 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 234/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0171 - acc: 0.3200 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 235/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0171 - acc: 0.3187 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 236/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0171 - acc: 0.3173 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 237/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0171 - acc: 0.3213 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 238/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0171 - acc: 0.3240 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 239/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0171 - acc: 0.3187 - val_loss: 0.0194 - val_acc: 0.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0171 - acc: 0.3227 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 241/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0170 - acc: 0.3173 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 242/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0170 - acc: 0.3267 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 243/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0170 - acc: 0.3173 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 244/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0170 - acc: 0.3267 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 245/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0170 - acc: 0.3293 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 246/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0170 - acc: 0.3227 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 247/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0170 - acc: 0.3240 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 248/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0170 - acc: 0.3267 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 249/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0169 - acc: 0.3280 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 250/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0169 - acc: 0.3267 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 251/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0169 - acc: 0.3240 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 252/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0169 - acc: 0.3253 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 253/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0169 - acc: 0.3267 - val_loss: 0.0194 - val_acc: 0.2520\n",
      "Epoch 254/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0169 - acc: 0.3320 - val_loss: 0.0194 - val_acc: 0.2560\n",
      "Epoch 255/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0169 - acc: 0.3267 - val_loss: 0.0194 - val_acc: 0.2560\n",
      "Epoch 256/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0168 - acc: 0.3227 - val_loss: 0.0194 - val_acc: 0.2560\n",
      "Epoch 257/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0168 - acc: 0.3293 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 258/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0168 - acc: 0.3307 - val_loss: 0.0194 - val_acc: 0.2520\n",
      "Epoch 259/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0168 - acc: 0.3280 - val_loss: 0.0194 - val_acc: 0.2560\n",
      "Epoch 260/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0168 - acc: 0.3467 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 261/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0168 - acc: 0.3253 - val_loss: 0.0195 - val_acc: 0.2480\n",
      "Epoch 262/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0168 - acc: 0.3333 - val_loss: 0.0194 - val_acc: 0.2520\n",
      "Epoch 263/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0168 - acc: 0.3347 - val_loss: 0.0194 - val_acc: 0.2560\n",
      "Epoch 264/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0168 - acc: 0.3373 - val_loss: 0.0194 - val_acc: 0.2600\n",
      "Epoch 265/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0167 - acc: 0.3413 - val_loss: 0.0194 - val_acc: 0.2680\n",
      "Epoch 266/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0167 - acc: 0.3480 - val_loss: 0.0194 - val_acc: 0.2760\n",
      "Epoch 267/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0167 - acc: 0.3493 - val_loss: 0.0194 - val_acc: 0.2680\n",
      "Epoch 268/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0167 - acc: 0.3547 - val_loss: 0.0194 - val_acc: 0.2720\n",
      "Epoch 269/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0167 - acc: 0.3573 - val_loss: 0.0195 - val_acc: 0.2800\n",
      "Epoch 270/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0167 - acc: 0.3613 - val_loss: 0.0194 - val_acc: 0.2800\n",
      "Epoch 271/2000\n",
      "750/750 [==============================] - 0s 89us/step - loss: 0.0167 - acc: 0.3533 - val_loss: 0.0194 - val_acc: 0.2840\n",
      "Epoch 272/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0167 - acc: 0.3507 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 273/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0167 - acc: 0.3653 - val_loss: 0.0194 - val_acc: 0.2800\n",
      "Epoch 274/2000\n",
      "750/750 [==============================] - 0s 89us/step - loss: 0.0166 - acc: 0.3573 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 275/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0166 - acc: 0.3560 - val_loss: 0.0194 - val_acc: 0.2800\n",
      "Epoch 276/2000\n",
      "750/750 [==============================] - 0s 89us/step - loss: 0.0166 - acc: 0.3587 - val_loss: 0.0194 - val_acc: 0.2800\n",
      "Epoch 277/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0166 - acc: 0.3560 - val_loss: 0.0194 - val_acc: 0.2800\n",
      "Epoch 278/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0166 - acc: 0.3533 - val_loss: 0.0194 - val_acc: 0.2760\n",
      "Epoch 279/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0166 - acc: 0.3587 - val_loss: 0.0194 - val_acc: 0.2760\n",
      "Epoch 280/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0166 - acc: 0.3547 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 281/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0166 - acc: 0.3640 - val_loss: 0.0194 - val_acc: 0.2760\n",
      "Epoch 282/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0165 - acc: 0.3613 - val_loss: 0.0194 - val_acc: 0.2720\n",
      "Epoch 283/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0165 - acc: 0.3627 - val_loss: 0.0194 - val_acc: 0.2680\n",
      "Epoch 284/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0165 - acc: 0.3533 - val_loss: 0.0194 - val_acc: 0.2680\n",
      "Epoch 285/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0165 - acc: 0.3613 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 286/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0165 - acc: 0.3547 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 287/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0165 - acc: 0.3653 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 288/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0165 - acc: 0.3613 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 289/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0165 - acc: 0.3600 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 290/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0165 - acc: 0.3653 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 291/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0164 - acc: 0.3547 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 292/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0164 - acc: 0.3613 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 293/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0164 - acc: 0.3587 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 294/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0164 - acc: 0.3573 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 295/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0164 - acc: 0.3613 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 296/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0164 - acc: 0.3613 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 297/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0164 - acc: 0.3507 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 298/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0164 - acc: 0.3587 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 299/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0164 - acc: 0.3680 - val_loss: 0.0194 - val_acc: 0.2680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0163 - acc: 0.3547 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 301/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0163 - acc: 0.3587 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 302/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0163 - acc: 0.3573 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 303/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0163 - acc: 0.3680 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 304/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0163 - acc: 0.3547 - val_loss: 0.0195 - val_acc: 0.2640\n",
      "Epoch 305/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0163 - acc: 0.3587 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 306/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0163 - acc: 0.3640 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 307/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0163 - acc: 0.3627 - val_loss: 0.0194 - val_acc: 0.2640\n",
      "Epoch 308/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0163 - acc: 0.3587 - val_loss: 0.0195 - val_acc: 0.2640\n",
      "Epoch 309/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0162 - acc: 0.3600 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 310/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0162 - acc: 0.3560 - val_loss: 0.0195 - val_acc: 0.2640\n",
      "Epoch 311/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0162 - acc: 0.3600 - val_loss: 0.0195 - val_acc: 0.2640\n",
      "Epoch 312/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0162 - acc: 0.3613 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 313/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0162 - acc: 0.3627 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 314/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0162 - acc: 0.3627 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 315/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0162 - acc: 0.3627 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 316/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0162 - acc: 0.3573 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 317/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0162 - acc: 0.3640 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 318/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0162 - acc: 0.3653 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 319/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0161 - acc: 0.3587 - val_loss: 0.0195 - val_acc: 0.2800\n",
      "Epoch 320/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0161 - acc: 0.3667 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 321/2000\n",
      "750/750 [==============================] - 0s 89us/step - loss: 0.0161 - acc: 0.3627 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 322/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0161 - acc: 0.3747 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 323/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0161 - acc: 0.3613 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 324/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0161 - acc: 0.3680 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 325/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0161 - acc: 0.3667 - val_loss: 0.0195 - val_acc: 0.2800\n",
      "Epoch 326/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0161 - acc: 0.3653 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 327/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0161 - acc: 0.3680 - val_loss: 0.0195 - val_acc: 0.2640\n",
      "Epoch 328/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0161 - acc: 0.3653 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 329/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0160 - acc: 0.3720 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 330/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0160 - acc: 0.3733 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 331/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0160 - acc: 0.3600 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 332/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0160 - acc: 0.3680 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 333/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0160 - acc: 0.3693 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 334/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0160 - acc: 0.3733 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 335/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0160 - acc: 0.3693 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 336/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0160 - acc: 0.3653 - val_loss: 0.0195 - val_acc: 0.2640\n",
      "Epoch 337/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0160 - acc: 0.3640 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 338/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0160 - acc: 0.3653 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 339/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0159 - acc: 0.3693 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 340/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0159 - acc: 0.3773 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 341/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0159 - acc: 0.3747 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 342/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0159 - acc: 0.3760 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 343/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0159 - acc: 0.3667 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 344/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0159 - acc: 0.3680 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 345/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0159 - acc: 0.3773 - val_loss: 0.0196 - val_acc: 0.2680\n",
      "Epoch 346/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0159 - acc: 0.3707 - val_loss: 0.0195 - val_acc: 0.2600\n",
      "Epoch 347/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0159 - acc: 0.3733 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 348/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0159 - acc: 0.3760 - val_loss: 0.0196 - val_acc: 0.2680\n",
      "Epoch 349/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0158 - acc: 0.3827 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 350/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0158 - acc: 0.3747 - val_loss: 0.0196 - val_acc: 0.2680\n",
      "Epoch 351/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0158 - acc: 0.3733 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 352/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0158 - acc: 0.3733 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 353/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0158 - acc: 0.3720 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 354/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0158 - acc: 0.3773 - val_loss: 0.0196 - val_acc: 0.2680\n",
      "Epoch 355/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0158 - acc: 0.3787 - val_loss: 0.0196 - val_acc: 0.2680\n",
      "Epoch 356/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0158 - acc: 0.3733 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 357/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0158 - acc: 0.3733 - val_loss: 0.0196 - val_acc: 0.2680\n",
      "Epoch 358/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0158 - acc: 0.3760 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 359/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0158 - acc: 0.3760 - val_loss: 0.0195 - val_acc: 0.2840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0157 - acc: 0.3827 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 361/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0157 - acc: 0.3680 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 362/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0157 - acc: 0.3720 - val_loss: 0.0196 - val_acc: 0.2760\n",
      "Epoch 363/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0157 - acc: 0.3747 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 364/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0157 - acc: 0.3787 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 365/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0157 - acc: 0.3773 - val_loss: 0.0196 - val_acc: 0.2760\n",
      "Epoch 366/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0157 - acc: 0.3813 - val_loss: 0.0196 - val_acc: 0.2680\n",
      "Epoch 367/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0157 - acc: 0.3800 - val_loss: 0.0196 - val_acc: 0.2680\n",
      "Epoch 368/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0157 - acc: 0.3840 - val_loss: 0.0196 - val_acc: 0.2680\n",
      "Epoch 369/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0157 - acc: 0.3867 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 370/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0156 - acc: 0.3773 - val_loss: 0.0196 - val_acc: 0.2680\n",
      "Epoch 371/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0156 - acc: 0.3773 - val_loss: 0.0196 - val_acc: 0.2640\n",
      "Epoch 372/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0156 - acc: 0.3747 - val_loss: 0.0196 - val_acc: 0.2760\n",
      "Epoch 373/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0156 - acc: 0.3907 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 374/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0156 - acc: 0.3773 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 375/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0156 - acc: 0.3827 - val_loss: 0.0196 - val_acc: 0.2640\n",
      "Epoch 376/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0156 - acc: 0.3813 - val_loss: 0.0196 - val_acc: 0.2840\n",
      "Epoch 377/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0156 - acc: 0.3840 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 378/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0156 - acc: 0.3827 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 379/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0156 - acc: 0.3867 - val_loss: 0.0196 - val_acc: 0.2800\n",
      "Epoch 380/2000\n",
      "750/750 [==============================] - 0s 77us/step - loss: 0.0156 - acc: 0.3787 - val_loss: 0.0196 - val_acc: 0.2800\n",
      "Epoch 381/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0155 - acc: 0.3813 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 382/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0155 - acc: 0.3867 - val_loss: 0.0196 - val_acc: 0.2760\n",
      "Epoch 383/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0155 - acc: 0.3907 - val_loss: 0.0196 - val_acc: 0.2760\n",
      "Epoch 384/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0155 - acc: 0.3840 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 385/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0155 - acc: 0.3920 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 386/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0155 - acc: 0.3813 - val_loss: 0.0196 - val_acc: 0.2760\n",
      "Epoch 387/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0155 - acc: 0.3920 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 388/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0155 - acc: 0.3947 - val_loss: 0.0196 - val_acc: 0.2760\n",
      "Epoch 389/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0155 - acc: 0.3893 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 390/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0155 - acc: 0.3933 - val_loss: 0.0196 - val_acc: 0.2680\n",
      "Epoch 391/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0155 - acc: 0.3893 - val_loss: 0.0196 - val_acc: 0.2800\n",
      "Epoch 392/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0155 - acc: 0.3973 - val_loss: 0.0196 - val_acc: 0.2760\n",
      "Epoch 393/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0154 - acc: 0.3960 - val_loss: 0.0196 - val_acc: 0.2760\n",
      "Epoch 394/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0154 - acc: 0.3880 - val_loss: 0.0196 - val_acc: 0.2840\n",
      "Epoch 395/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0154 - acc: 0.3907 - val_loss: 0.0196 - val_acc: 0.2720\n",
      "Epoch 396/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0154 - acc: 0.4000 - val_loss: 0.0196 - val_acc: 0.2880\n",
      "Epoch 397/2000\n",
      "750/750 [==============================] - 0s 93us/step - loss: 0.0154 - acc: 0.3973 - val_loss: 0.0197 - val_acc: 0.2800\n",
      "Epoch 398/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0154 - acc: 0.3960 - val_loss: 0.0196 - val_acc: 0.2880\n",
      "Epoch 399/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0154 - acc: 0.3973 - val_loss: 0.0197 - val_acc: 0.2720\n",
      "Epoch 400/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0154 - acc: 0.3880 - val_loss: 0.0196 - val_acc: 0.2880\n",
      "Epoch 401/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0154 - acc: 0.4027 - val_loss: 0.0197 - val_acc: 0.2880\n",
      "Epoch 402/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0154 - acc: 0.3907 - val_loss: 0.0197 - val_acc: 0.2960\n",
      "Epoch 403/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0154 - acc: 0.3947 - val_loss: 0.0196 - val_acc: 0.2840\n",
      "Epoch 404/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0154 - acc: 0.3973 - val_loss: 0.0197 - val_acc: 0.2880\n",
      "Epoch 405/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0153 - acc: 0.4000 - val_loss: 0.0196 - val_acc: 0.2880\n",
      "Epoch 406/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0153 - acc: 0.3947 - val_loss: 0.0196 - val_acc: 0.2800\n",
      "Epoch 407/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0153 - acc: 0.3947 - val_loss: 0.0196 - val_acc: 0.2880\n",
      "Epoch 408/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0153 - acc: 0.3973 - val_loss: 0.0197 - val_acc: 0.2880\n",
      "Epoch 409/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0153 - acc: 0.3960 - val_loss: 0.0197 - val_acc: 0.2880\n",
      "Epoch 410/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0153 - acc: 0.3973 - val_loss: 0.0197 - val_acc: 0.2920\n",
      "Epoch 411/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0153 - acc: 0.3973 - val_loss: 0.0196 - val_acc: 0.2880\n",
      "Epoch 412/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0153 - acc: 0.3973 - val_loss: 0.0197 - val_acc: 0.2960\n",
      "Epoch 413/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0153 - acc: 0.3987 - val_loss: 0.0197 - val_acc: 0.2920\n",
      "Epoch 414/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0153 - acc: 0.3973 - val_loss: 0.0196 - val_acc: 0.2880\n",
      "Epoch 415/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0153 - acc: 0.3960 - val_loss: 0.0196 - val_acc: 0.2880\n",
      "Epoch 416/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0153 - acc: 0.4027 - val_loss: 0.0197 - val_acc: 0.2960\n",
      "Epoch 417/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0152 - acc: 0.4000 - val_loss: 0.0196 - val_acc: 0.2920\n",
      "Epoch 418/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0152 - acc: 0.3973 - val_loss: 0.0197 - val_acc: 0.2960\n",
      "Epoch 419/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0152 - acc: 0.4000 - val_loss: 0.0197 - val_acc: 0.2920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0152 - acc: 0.3960 - val_loss: 0.0196 - val_acc: 0.3000\n",
      "Epoch 421/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0152 - acc: 0.4000 - val_loss: 0.0197 - val_acc: 0.2840\n",
      "Epoch 422/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0152 - acc: 0.3880 - val_loss: 0.0197 - val_acc: 0.3040\n",
      "Epoch 423/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0152 - acc: 0.4040 - val_loss: 0.0197 - val_acc: 0.3040\n",
      "Epoch 424/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0152 - acc: 0.4027 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 425/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0152 - acc: 0.4120 - val_loss: 0.0197 - val_acc: 0.2960\n",
      "Epoch 426/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0152 - acc: 0.3907 - val_loss: 0.0197 - val_acc: 0.3080\n",
      "Epoch 427/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0152 - acc: 0.4000 - val_loss: 0.0197 - val_acc: 0.3040\n",
      "Epoch 428/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0152 - acc: 0.3960 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 429/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0151 - acc: 0.4013 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 430/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0151 - acc: 0.4053 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 431/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0151 - acc: 0.4093 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 432/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0151 - acc: 0.4000 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 433/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0151 - acc: 0.4013 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 434/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0151 - acc: 0.4080 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 435/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0151 - acc: 0.4027 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 436/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0151 - acc: 0.4040 - val_loss: 0.0197 - val_acc: 0.3040\n",
      "Epoch 437/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0151 - acc: 0.4040 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 438/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0151 - acc: 0.4013 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 439/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0151 - acc: 0.3987 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 440/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0151 - acc: 0.4133 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 441/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0151 - acc: 0.4080 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 442/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0150 - acc: 0.4040 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 443/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0150 - acc: 0.4093 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 444/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0150 - acc: 0.4147 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 445/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0150 - acc: 0.4133 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 446/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0150 - acc: 0.4053 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 447/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0150 - acc: 0.4093 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 448/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0150 - acc: 0.4120 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 449/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0150 - acc: 0.4093 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 450/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0150 - acc: 0.4160 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 451/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0150 - acc: 0.4053 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 452/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0150 - acc: 0.4107 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 453/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0150 - acc: 0.4093 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 454/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0150 - acc: 0.4133 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 455/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0149 - acc: 0.4107 - val_loss: 0.0198 - val_acc: 0.3160\n",
      "Epoch 456/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0149 - acc: 0.4093 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 457/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0149 - acc: 0.4147 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 458/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0149 - acc: 0.4120 - val_loss: 0.0198 - val_acc: 0.3160\n",
      "Epoch 459/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0149 - acc: 0.4080 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 460/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0149 - acc: 0.4133 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 461/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0149 - acc: 0.4120 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 462/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0149 - acc: 0.4227 - val_loss: 0.0198 - val_acc: 0.3160\n",
      "Epoch 463/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0149 - acc: 0.4173 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 464/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0149 - acc: 0.4053 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 465/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0149 - acc: 0.4147 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 466/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0149 - acc: 0.4160 - val_loss: 0.0197 - val_acc: 0.3040\n",
      "Epoch 467/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0149 - acc: 0.4093 - val_loss: 0.0197 - val_acc: 0.3000\n",
      "Epoch 468/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0148 - acc: 0.4147 - val_loss: 0.0198 - val_acc: 0.3000\n",
      "Epoch 469/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0148 - acc: 0.4147 - val_loss: 0.0198 - val_acc: 0.3000\n",
      "Epoch 470/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0148 - acc: 0.4147 - val_loss: 0.0198 - val_acc: 0.3000\n",
      "Epoch 471/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0148 - acc: 0.4200 - val_loss: 0.0198 - val_acc: 0.3000\n",
      "Epoch 472/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0148 - acc: 0.4160 - val_loss: 0.0198 - val_acc: 0.2960\n",
      "Epoch 473/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0148 - acc: 0.4160 - val_loss: 0.0198 - val_acc: 0.3000\n",
      "Epoch 474/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0148 - acc: 0.4173 - val_loss: 0.0198 - val_acc: 0.3000\n",
      "Epoch 475/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0148 - acc: 0.4240 - val_loss: 0.0197 - val_acc: 0.3040\n",
      "Epoch 476/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0148 - acc: 0.4227 - val_loss: 0.0197 - val_acc: 0.3040\n",
      "Epoch 477/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0148 - acc: 0.4200 - val_loss: 0.0198 - val_acc: 0.3040\n",
      "Epoch 478/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0148 - acc: 0.4200 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 479/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0148 - acc: 0.4173 - val_loss: 0.0198 - val_acc: 0.3080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0148 - acc: 0.4200 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 481/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0148 - acc: 0.4200 - val_loss: 0.0197 - val_acc: 0.3080\n",
      "Epoch 482/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0147 - acc: 0.4200 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 483/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0148 - acc: 0.4253 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 484/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0147 - acc: 0.4107 - val_loss: 0.0198 - val_acc: 0.3000\n",
      "Epoch 485/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0147 - acc: 0.4240 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 486/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0147 - acc: 0.4227 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 487/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0147 - acc: 0.4200 - val_loss: 0.0198 - val_acc: 0.3120\n",
      "Epoch 488/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0147 - acc: 0.4227 - val_loss: 0.0198 - val_acc: 0.3120\n",
      "Epoch 489/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0147 - acc: 0.4227 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 490/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0147 - acc: 0.4240 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 491/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0147 - acc: 0.4280 - val_loss: 0.0197 - val_acc: 0.3120\n",
      "Epoch 492/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0147 - acc: 0.4280 - val_loss: 0.0198 - val_acc: 0.3040\n",
      "Epoch 493/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0147 - acc: 0.4253 - val_loss: 0.0198 - val_acc: 0.3040\n",
      "Epoch 494/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0147 - acc: 0.4173 - val_loss: 0.0198 - val_acc: 0.3040\n",
      "Epoch 495/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0147 - acc: 0.4280 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 496/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0147 - acc: 0.4267 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 497/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0147 - acc: 0.4307 - val_loss: 0.0198 - val_acc: 0.3120\n",
      "Epoch 498/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0146 - acc: 0.4200 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 499/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0146 - acc: 0.4213 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 500/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0146 - acc: 0.4253 - val_loss: 0.0198 - val_acc: 0.3040\n",
      "Epoch 501/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0146 - acc: 0.4267 - val_loss: 0.0198 - val_acc: 0.3040\n",
      "Epoch 502/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0146 - acc: 0.4240 - val_loss: 0.0198 - val_acc: 0.3120\n",
      "Epoch 503/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0146 - acc: 0.4320 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 504/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0146 - acc: 0.4293 - val_loss: 0.0198 - val_acc: 0.3040\n",
      "Epoch 505/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0146 - acc: 0.4253 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 506/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0146 - acc: 0.4307 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 507/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0146 - acc: 0.4213 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 508/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0146 - acc: 0.4267 - val_loss: 0.0198 - val_acc: 0.3040\n",
      "Epoch 509/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0146 - acc: 0.4227 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 510/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0146 - acc: 0.4400 - val_loss: 0.0198 - val_acc: 0.3120\n",
      "Epoch 511/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0146 - acc: 0.4307 - val_loss: 0.0198 - val_acc: 0.3120\n",
      "Epoch 512/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0145 - acc: 0.4293 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 513/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0145 - acc: 0.4307 - val_loss: 0.0198 - val_acc: 0.3160\n",
      "Epoch 514/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0145 - acc: 0.4280 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 515/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0145 - acc: 0.4333 - val_loss: 0.0199 - val_acc: 0.3080\n",
      "Epoch 516/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0145 - acc: 0.4320 - val_loss: 0.0198 - val_acc: 0.3160\n",
      "Epoch 517/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0145 - acc: 0.4293 - val_loss: 0.0198 - val_acc: 0.3120\n",
      "Epoch 518/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0145 - acc: 0.4427 - val_loss: 0.0198 - val_acc: 0.3120\n",
      "Epoch 519/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0145 - acc: 0.4293 - val_loss: 0.0198 - val_acc: 0.3120\n",
      "Epoch 520/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0145 - acc: 0.4267 - val_loss: 0.0198 - val_acc: 0.3200\n",
      "Epoch 521/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0145 - acc: 0.4200 - val_loss: 0.0199 - val_acc: 0.3120\n",
      "Epoch 522/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0145 - acc: 0.4347 - val_loss: 0.0199 - val_acc: 0.3080\n",
      "Epoch 523/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0145 - acc: 0.4347 - val_loss: 0.0199 - val_acc: 0.3120\n",
      "Epoch 524/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0145 - acc: 0.4333 - val_loss: 0.0198 - val_acc: 0.3240\n",
      "Epoch 525/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0145 - acc: 0.4280 - val_loss: 0.0198 - val_acc: 0.3080\n",
      "Epoch 526/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0144 - acc: 0.4427 - val_loss: 0.0198 - val_acc: 0.3160\n",
      "Epoch 527/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0145 - acc: 0.4320 - val_loss: 0.0199 - val_acc: 0.3120\n",
      "Epoch 528/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0144 - acc: 0.4307 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 529/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0144 - acc: 0.4267 - val_loss: 0.0199 - val_acc: 0.3120\n",
      "Epoch 530/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0144 - acc: 0.4427 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 531/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0144 - acc: 0.4280 - val_loss: 0.0199 - val_acc: 0.3120\n",
      "Epoch 532/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0144 - acc: 0.4347 - val_loss: 0.0199 - val_acc: 0.3120\n",
      "Epoch 533/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0144 - acc: 0.4427 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 534/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0144 - acc: 0.4360 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 535/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0144 - acc: 0.4427 - val_loss: 0.0199 - val_acc: 0.3080\n",
      "Epoch 536/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0144 - acc: 0.4347 - val_loss: 0.0199 - val_acc: 0.3120\n",
      "Epoch 537/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0144 - acc: 0.4387 - val_loss: 0.0199 - val_acc: 0.3200\n",
      "Epoch 538/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0144 - acc: 0.4427 - val_loss: 0.0199 - val_acc: 0.3120\n",
      "Epoch 539/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0144 - acc: 0.4493 - val_loss: 0.0199 - val_acc: 0.3160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0144 - acc: 0.4293 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 541/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0144 - acc: 0.4307 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 542/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0144 - acc: 0.4333 - val_loss: 0.0199 - val_acc: 0.3200\n",
      "Epoch 543/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0144 - acc: 0.4387 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 544/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0143 - acc: 0.4427 - val_loss: 0.0199 - val_acc: 0.3200\n",
      "Epoch 545/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0143 - acc: 0.4360 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 546/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0143 - acc: 0.4360 - val_loss: 0.0199 - val_acc: 0.3200\n",
      "Epoch 547/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0143 - acc: 0.4413 - val_loss: 0.0200 - val_acc: 0.3160\n",
      "Epoch 548/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0143 - acc: 0.4493 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 549/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0143 - acc: 0.4400 - val_loss: 0.0199 - val_acc: 0.3200\n",
      "Epoch 550/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0143 - acc: 0.4333 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 551/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0143 - acc: 0.4427 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 552/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0143 - acc: 0.4387 - val_loss: 0.0199 - val_acc: 0.3200\n",
      "Epoch 553/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0143 - acc: 0.4440 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 554/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0143 - acc: 0.4440 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 555/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0143 - acc: 0.4400 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 556/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0143 - acc: 0.4453 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 557/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0143 - acc: 0.4400 - val_loss: 0.0199 - val_acc: 0.3200\n",
      "Epoch 558/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0143 - acc: 0.4427 - val_loss: 0.0199 - val_acc: 0.3200\n",
      "Epoch 559/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0143 - acc: 0.4453 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 560/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0142 - acc: 0.4387 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 561/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0142 - acc: 0.4427 - val_loss: 0.0199 - val_acc: 0.3200\n",
      "Epoch 562/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0142 - acc: 0.4427 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 563/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0142 - acc: 0.4373 - val_loss: 0.0200 - val_acc: 0.3160\n",
      "Epoch 564/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0142 - acc: 0.4427 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 565/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0142 - acc: 0.4427 - val_loss: 0.0200 - val_acc: 0.3120\n",
      "Epoch 566/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0142 - acc: 0.4493 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 567/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0142 - acc: 0.4467 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 568/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0142 - acc: 0.4467 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 569/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0142 - acc: 0.4573 - val_loss: 0.0199 - val_acc: 0.3160\n",
      "Epoch 570/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0142 - acc: 0.4480 - val_loss: 0.0199 - val_acc: 0.3200\n",
      "Epoch 571/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0142 - acc: 0.4520 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 572/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0142 - acc: 0.4467 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 573/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0142 - acc: 0.4587 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 574/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0142 - acc: 0.4520 - val_loss: 0.0200 - val_acc: 0.3160\n",
      "Epoch 575/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0142 - acc: 0.4547 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 576/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0142 - acc: 0.4520 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 577/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0141 - acc: 0.4547 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 578/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0141 - acc: 0.4480 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 579/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0141 - acc: 0.4493 - val_loss: 0.0200 - val_acc: 0.3280\n",
      "Epoch 580/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0141 - acc: 0.4520 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 581/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0141 - acc: 0.4493 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 582/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0141 - acc: 0.4547 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 583/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0141 - acc: 0.4520 - val_loss: 0.0200 - val_acc: 0.3240\n",
      "Epoch 584/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0141 - acc: 0.4613 - val_loss: 0.0200 - val_acc: 0.3160\n",
      "Epoch 585/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0141 - acc: 0.4493 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 586/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0141 - acc: 0.4560 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 587/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0141 - acc: 0.4547 - val_loss: 0.0200 - val_acc: 0.3240\n",
      "Epoch 588/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0141 - acc: 0.4587 - val_loss: 0.0200 - val_acc: 0.3240\n",
      "Epoch 589/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0141 - acc: 0.4627 - val_loss: 0.0200 - val_acc: 0.3240\n",
      "Epoch 590/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0141 - acc: 0.4653 - val_loss: 0.0201 - val_acc: 0.3240\n",
      "Epoch 591/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0141 - acc: 0.4520 - val_loss: 0.0200 - val_acc: 0.3240\n",
      "Epoch 592/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0141 - acc: 0.4667 - val_loss: 0.0200 - val_acc: 0.3280\n",
      "Epoch 593/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0141 - acc: 0.4547 - val_loss: 0.0200 - val_acc: 0.3280\n",
      "Epoch 594/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0140 - acc: 0.4573 - val_loss: 0.0200 - val_acc: 0.3240\n",
      "Epoch 595/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0140 - acc: 0.4600 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 596/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0140 - acc: 0.4573 - val_loss: 0.0200 - val_acc: 0.3320\n",
      "Epoch 597/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0140 - acc: 0.4573 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 598/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0140 - acc: 0.4520 - val_loss: 0.0200 - val_acc: 0.3280\n",
      "Epoch 599/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0140 - acc: 0.4627 - val_loss: 0.0200 - val_acc: 0.3280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0140 - acc: 0.4587 - val_loss: 0.0200 - val_acc: 0.3240\n",
      "Epoch 601/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0140 - acc: 0.4653 - val_loss: 0.0200 - val_acc: 0.3200\n",
      "Epoch 602/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0140 - acc: 0.4653 - val_loss: 0.0200 - val_acc: 0.3280\n",
      "Epoch 603/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0140 - acc: 0.4680 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 604/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0140 - acc: 0.4573 - val_loss: 0.0200 - val_acc: 0.3280\n",
      "Epoch 605/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0140 - acc: 0.4573 - val_loss: 0.0201 - val_acc: 0.3240\n",
      "Epoch 606/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0140 - acc: 0.4747 - val_loss: 0.0200 - val_acc: 0.3280\n",
      "Epoch 607/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0140 - acc: 0.4693 - val_loss: 0.0200 - val_acc: 0.3280\n",
      "Epoch 608/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0140 - acc: 0.4707 - val_loss: 0.0200 - val_acc: 0.3280\n",
      "Epoch 609/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0140 - acc: 0.4587 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 610/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0140 - acc: 0.4667 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 611/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0140 - acc: 0.4640 - val_loss: 0.0200 - val_acc: 0.3240\n",
      "Epoch 612/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0140 - acc: 0.4787 - val_loss: 0.0200 - val_acc: 0.3280\n",
      "Epoch 613/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0139 - acc: 0.4653 - val_loss: 0.0200 - val_acc: 0.3320\n",
      "Epoch 614/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0139 - acc: 0.4653 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 615/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0139 - acc: 0.4693 - val_loss: 0.0201 - val_acc: 0.3360\n",
      "Epoch 616/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0139 - acc: 0.4733 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 617/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0139 - acc: 0.4720 - val_loss: 0.0201 - val_acc: 0.3360\n",
      "Epoch 618/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0139 - acc: 0.4693 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 619/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0139 - acc: 0.4693 - val_loss: 0.0200 - val_acc: 0.3360\n",
      "Epoch 620/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0139 - acc: 0.4613 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 621/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0139 - acc: 0.4693 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 622/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0139 - acc: 0.4600 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 623/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0139 - acc: 0.4787 - val_loss: 0.0201 - val_acc: 0.3240\n",
      "Epoch 624/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0139 - acc: 0.4720 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 625/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0139 - acc: 0.4627 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 626/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0139 - acc: 0.4653 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 627/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0139 - acc: 0.4667 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 628/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0139 - acc: 0.4787 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 629/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0139 - acc: 0.4600 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 630/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0138 - acc: 0.4733 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 631/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0138 - acc: 0.4640 - val_loss: 0.0201 - val_acc: 0.3240\n",
      "Epoch 632/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0138 - acc: 0.4760 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 633/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0138 - acc: 0.4760 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 634/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0138 - acc: 0.4747 - val_loss: 0.0201 - val_acc: 0.3240\n",
      "Epoch 635/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0138 - acc: 0.4760 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 636/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0138 - acc: 0.4707 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 637/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0138 - acc: 0.4680 - val_loss: 0.0202 - val_acc: 0.3320\n",
      "Epoch 638/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0138 - acc: 0.4707 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 639/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0138 - acc: 0.4773 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 640/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0138 - acc: 0.4693 - val_loss: 0.0201 - val_acc: 0.3240\n",
      "Epoch 641/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0138 - acc: 0.4720 - val_loss: 0.0202 - val_acc: 0.3320\n",
      "Epoch 642/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0138 - acc: 0.4827 - val_loss: 0.0201 - val_acc: 0.3240\n",
      "Epoch 643/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0138 - acc: 0.4707 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 644/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0138 - acc: 0.4773 - val_loss: 0.0201 - val_acc: 0.3400\n",
      "Epoch 645/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0138 - acc: 0.4840 - val_loss: 0.0201 - val_acc: 0.3240\n",
      "Epoch 646/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0138 - acc: 0.4747 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 647/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0138 - acc: 0.4720 - val_loss: 0.0202 - val_acc: 0.3240\n",
      "Epoch 648/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0138 - acc: 0.4800 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 649/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0137 - acc: 0.4827 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 650/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0138 - acc: 0.4787 - val_loss: 0.0202 - val_acc: 0.3360\n",
      "Epoch 651/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0137 - acc: 0.4787 - val_loss: 0.0201 - val_acc: 0.3240\n",
      "Epoch 652/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0137 - acc: 0.4760 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 653/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0137 - acc: 0.4800 - val_loss: 0.0202 - val_acc: 0.3240\n",
      "Epoch 654/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0137 - acc: 0.4787 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 655/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0137 - acc: 0.4813 - val_loss: 0.0202 - val_acc: 0.3280\n",
      "Epoch 656/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0137 - acc: 0.4840 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 657/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0137 - acc: 0.4800 - val_loss: 0.0201 - val_acc: 0.3280\n",
      "Epoch 658/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0137 - acc: 0.4733 - val_loss: 0.0202 - val_acc: 0.3240\n",
      "Epoch 659/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0137 - acc: 0.4787 - val_loss: 0.0202 - val_acc: 0.3240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0137 - acc: 0.4813 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 661/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0137 - acc: 0.4880 - val_loss: 0.0201 - val_acc: 0.3360\n",
      "Epoch 662/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0137 - acc: 0.4853 - val_loss: 0.0201 - val_acc: 0.3480\n",
      "Epoch 663/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0137 - acc: 0.4813 - val_loss: 0.0202 - val_acc: 0.3240\n",
      "Epoch 664/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0137 - acc: 0.4840 - val_loss: 0.0202 - val_acc: 0.3320\n",
      "Epoch 665/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0137 - acc: 0.4773 - val_loss: 0.0202 - val_acc: 0.3320\n",
      "Epoch 666/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0137 - acc: 0.4760 - val_loss: 0.0201 - val_acc: 0.3360\n",
      "Epoch 667/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0137 - acc: 0.4867 - val_loss: 0.0202 - val_acc: 0.3320\n",
      "Epoch 668/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0137 - acc: 0.4787 - val_loss: 0.0201 - val_acc: 0.3320\n",
      "Epoch 669/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0136 - acc: 0.4827 - val_loss: 0.0202 - val_acc: 0.3320\n",
      "Epoch 670/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0136 - acc: 0.4800 - val_loss: 0.0202 - val_acc: 0.3240\n",
      "Epoch 671/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0136 - acc: 0.4800 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 672/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0136 - acc: 0.4853 - val_loss: 0.0201 - val_acc: 0.3400\n",
      "Epoch 673/2000\n",
      "750/750 [==============================] - 0s 90us/step - loss: 0.0136 - acc: 0.4800 - val_loss: 0.0202 - val_acc: 0.3280\n",
      "Epoch 674/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0136 - acc: 0.4760 - val_loss: 0.0201 - val_acc: 0.3400\n",
      "Epoch 675/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0136 - acc: 0.4880 - val_loss: 0.0201 - val_acc: 0.3360\n",
      "Epoch 676/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0136 - acc: 0.4867 - val_loss: 0.0202 - val_acc: 0.3280\n",
      "Epoch 677/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0136 - acc: 0.4813 - val_loss: 0.0202 - val_acc: 0.3320\n",
      "Epoch 678/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0136 - acc: 0.4853 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 679/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0136 - acc: 0.4933 - val_loss: 0.0202 - val_acc: 0.3360\n",
      "Epoch 680/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0136 - acc: 0.4827 - val_loss: 0.0202 - val_acc: 0.3240\n",
      "Epoch 681/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0136 - acc: 0.4907 - val_loss: 0.0202 - val_acc: 0.3440\n",
      "Epoch 682/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0136 - acc: 0.4813 - val_loss: 0.0203 - val_acc: 0.3320\n",
      "Epoch 683/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0136 - acc: 0.4787 - val_loss: 0.0202 - val_acc: 0.3320\n",
      "Epoch 684/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0136 - acc: 0.4947 - val_loss: 0.0202 - val_acc: 0.3440\n",
      "Epoch 685/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0136 - acc: 0.4747 - val_loss: 0.0202 - val_acc: 0.3280\n",
      "Epoch 686/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0136 - acc: 0.4800 - val_loss: 0.0202 - val_acc: 0.3440\n",
      "Epoch 687/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0135 - acc: 0.4893 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 688/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0135 - acc: 0.4840 - val_loss: 0.0202 - val_acc: 0.3360\n",
      "Epoch 689/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0135 - acc: 0.4867 - val_loss: 0.0202 - val_acc: 0.3360\n",
      "Epoch 690/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0135 - acc: 0.4960 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 691/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0135 - acc: 0.4867 - val_loss: 0.0202 - val_acc: 0.3320\n",
      "Epoch 692/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0135 - acc: 0.4987 - val_loss: 0.0202 - val_acc: 0.3360\n",
      "Epoch 693/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0135 - acc: 0.4813 - val_loss: 0.0203 - val_acc: 0.3360\n",
      "Epoch 694/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0135 - acc: 0.4920 - val_loss: 0.0202 - val_acc: 0.3320\n",
      "Epoch 695/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0135 - acc: 0.4893 - val_loss: 0.0202 - val_acc: 0.3360\n",
      "Epoch 696/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0135 - acc: 0.4880 - val_loss: 0.0202 - val_acc: 0.3360\n",
      "Epoch 697/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0135 - acc: 0.4840 - val_loss: 0.0202 - val_acc: 0.3320\n",
      "Epoch 698/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0135 - acc: 0.4907 - val_loss: 0.0202 - val_acc: 0.3360\n",
      "Epoch 699/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0135 - acc: 0.4973 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 700/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0135 - acc: 0.4827 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 701/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0135 - acc: 0.4867 - val_loss: 0.0202 - val_acc: 0.3360\n",
      "Epoch 702/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0135 - acc: 0.4893 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 703/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0135 - acc: 0.4827 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 704/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0135 - acc: 0.4800 - val_loss: 0.0203 - val_acc: 0.3320\n",
      "Epoch 705/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0135 - acc: 0.4907 - val_loss: 0.0203 - val_acc: 0.3440\n",
      "Epoch 706/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0135 - acc: 0.4933 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 707/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0135 - acc: 0.4880 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 708/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0134 - acc: 0.4960 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 709/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0134 - acc: 0.5000 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 710/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0134 - acc: 0.4973 - val_loss: 0.0203 - val_acc: 0.3360\n",
      "Epoch 711/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0134 - acc: 0.5000 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 712/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0134 - acc: 0.4920 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 713/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0134 - acc: 0.4933 - val_loss: 0.0203 - val_acc: 0.3400\n",
      "Epoch 714/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0134 - acc: 0.4840 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 715/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0134 - acc: 0.5013 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 716/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0134 - acc: 0.4853 - val_loss: 0.0203 - val_acc: 0.3400\n",
      "Epoch 717/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0134 - acc: 0.5027 - val_loss: 0.0203 - val_acc: 0.3360\n",
      "Epoch 718/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0134 - acc: 0.4853 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 719/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0134 - acc: 0.4960 - val_loss: 0.0203 - val_acc: 0.3480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0134 - acc: 0.5000 - val_loss: 0.0203 - val_acc: 0.3360\n",
      "Epoch 721/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0134 - acc: 0.4907 - val_loss: 0.0203 - val_acc: 0.3400\n",
      "Epoch 722/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0134 - acc: 0.4987 - val_loss: 0.0202 - val_acc: 0.3400\n",
      "Epoch 723/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0134 - acc: 0.5027 - val_loss: 0.0203 - val_acc: 0.3440\n",
      "Epoch 724/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0134 - acc: 0.4987 - val_loss: 0.0203 - val_acc: 0.3400\n",
      "Epoch 725/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0134 - acc: 0.4893 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 726/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0134 - acc: 0.5053 - val_loss: 0.0203 - val_acc: 0.3400\n",
      "Epoch 727/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0134 - acc: 0.5000 - val_loss: 0.0203 - val_acc: 0.3320\n",
      "Epoch 728/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0134 - acc: 0.5000 - val_loss: 0.0203 - val_acc: 0.3440\n",
      "Epoch 729/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0134 - acc: 0.5013 - val_loss: 0.0203 - val_acc: 0.3440\n",
      "Epoch 730/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0133 - acc: 0.4987 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 731/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0133 - acc: 0.4987 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 732/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0133 - acc: 0.5040 - val_loss: 0.0203 - val_acc: 0.3440\n",
      "Epoch 733/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0133 - acc: 0.4973 - val_loss: 0.0203 - val_acc: 0.3440\n",
      "Epoch 734/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0133 - acc: 0.4880 - val_loss: 0.0203 - val_acc: 0.3440\n",
      "Epoch 735/2000\n",
      "750/750 [==============================] - 0s 77us/step - loss: 0.0133 - acc: 0.4933 - val_loss: 0.0203 - val_acc: 0.3440\n",
      "Epoch 736/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0133 - acc: 0.5027 - val_loss: 0.0203 - val_acc: 0.3400\n",
      "Epoch 737/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0133 - acc: 0.5013 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 738/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0133 - acc: 0.5027 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 739/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0133 - acc: 0.4947 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 740/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0133 - acc: 0.4987 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 741/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0133 - acc: 0.4987 - val_loss: 0.0203 - val_acc: 0.3440\n",
      "Epoch 742/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0133 - acc: 0.5027 - val_loss: 0.0203 - val_acc: 0.3440\n",
      "Epoch 743/2000\n",
      "750/750 [==============================] - 0s 77us/step - loss: 0.0133 - acc: 0.5013 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 744/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0133 - acc: 0.5000 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 745/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0133 - acc: 0.5013 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 746/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0133 - acc: 0.5040 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 747/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0133 - acc: 0.5120 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 748/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0133 - acc: 0.5080 - val_loss: 0.0203 - val_acc: 0.3440\n",
      "Epoch 749/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0133 - acc: 0.4947 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 750/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0133 - acc: 0.5107 - val_loss: 0.0202 - val_acc: 0.3440\n",
      "Epoch 751/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0133 - acc: 0.5013 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 752/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0132 - acc: 0.5053 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 753/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0132 - acc: 0.5093 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 754/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0132 - acc: 0.5040 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 755/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0132 - acc: 0.5013 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 756/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0132 - acc: 0.5120 - val_loss: 0.0204 - val_acc: 0.3480\n",
      "Epoch 757/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0132 - acc: 0.5120 - val_loss: 0.0203 - val_acc: 0.3600\n",
      "Epoch 758/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0132 - acc: 0.5107 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 759/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0132 - acc: 0.5107 - val_loss: 0.0203 - val_acc: 0.3440\n",
      "Epoch 760/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0132 - acc: 0.5080 - val_loss: 0.0203 - val_acc: 0.3600\n",
      "Epoch 761/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0132 - acc: 0.5107 - val_loss: 0.0204 - val_acc: 0.3520\n",
      "Epoch 762/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0132 - acc: 0.5107 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 763/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0132 - acc: 0.5013 - val_loss: 0.0204 - val_acc: 0.3560\n",
      "Epoch 764/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0132 - acc: 0.5080 - val_loss: 0.0204 - val_acc: 0.3480\n",
      "Epoch 765/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0132 - acc: 0.5133 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 766/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0132 - acc: 0.5093 - val_loss: 0.0203 - val_acc: 0.3480\n",
      "Epoch 767/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0132 - acc: 0.5080 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 768/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0132 - acc: 0.5040 - val_loss: 0.0203 - val_acc: 0.3600\n",
      "Epoch 769/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0132 - acc: 0.5107 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 770/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0132 - acc: 0.5173 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 771/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0132 - acc: 0.5080 - val_loss: 0.0203 - val_acc: 0.3640\n",
      "Epoch 772/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0132 - acc: 0.5040 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 773/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0132 - acc: 0.5107 - val_loss: 0.0203 - val_acc: 0.3520\n",
      "Epoch 774/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0132 - acc: 0.5253 - val_loss: 0.0203 - val_acc: 0.3560\n",
      "Epoch 775/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0131 - acc: 0.4960 - val_loss: 0.0204 - val_acc: 0.3560\n",
      "Epoch 776/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0131 - acc: 0.5040 - val_loss: 0.0204 - val_acc: 0.3560\n",
      "Epoch 777/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0131 - acc: 0.5147 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 778/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0131 - acc: 0.5107 - val_loss: 0.0204 - val_acc: 0.3680\n",
      "Epoch 779/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0131 - acc: 0.5080 - val_loss: 0.0204 - val_acc: 0.3600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0131 - acc: 0.5080 - val_loss: 0.0204 - val_acc: 0.3560\n",
      "Epoch 781/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0131 - acc: 0.5160 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 782/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0131 - acc: 0.5120 - val_loss: 0.0203 - val_acc: 0.3600\n",
      "Epoch 783/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0131 - acc: 0.5133 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 784/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0131 - acc: 0.5267 - val_loss: 0.0204 - val_acc: 0.3560\n",
      "Epoch 785/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0131 - acc: 0.5093 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 786/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0131 - acc: 0.5173 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 787/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0131 - acc: 0.5200 - val_loss: 0.0203 - val_acc: 0.3600\n",
      "Epoch 788/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0131 - acc: 0.5227 - val_loss: 0.0204 - val_acc: 0.3560\n",
      "Epoch 789/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0131 - acc: 0.5093 - val_loss: 0.0204 - val_acc: 0.3560\n",
      "Epoch 790/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0131 - acc: 0.5133 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 791/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0131 - acc: 0.5160 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 792/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0131 - acc: 0.5133 - val_loss: 0.0204 - val_acc: 0.3560\n",
      "Epoch 793/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0131 - acc: 0.5133 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 794/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0131 - acc: 0.5200 - val_loss: 0.0204 - val_acc: 0.3680\n",
      "Epoch 795/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0131 - acc: 0.5093 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 796/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0131 - acc: 0.5160 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 797/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0131 - acc: 0.5240 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 798/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0131 - acc: 0.5200 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 799/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0130 - acc: 0.5173 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 800/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0130 - acc: 0.5133 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 801/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0130 - acc: 0.5107 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 802/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0130 - acc: 0.5120 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 803/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0130 - acc: 0.5307 - val_loss: 0.0204 - val_acc: 0.3680\n",
      "Epoch 804/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0130 - acc: 0.5107 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 805/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0130 - acc: 0.5187 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 806/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0130 - acc: 0.5173 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 807/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0130 - acc: 0.5187 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 808/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0130 - acc: 0.5293 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 809/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0130 - acc: 0.5160 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 810/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0130 - acc: 0.5227 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 811/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0130 - acc: 0.5213 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 812/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0130 - acc: 0.5160 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 813/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0130 - acc: 0.5227 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 814/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0130 - acc: 0.5240 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 815/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0130 - acc: 0.5267 - val_loss: 0.0204 - val_acc: 0.3680\n",
      "Epoch 816/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0130 - acc: 0.5280 - val_loss: 0.0204 - val_acc: 0.3680\n",
      "Epoch 817/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0130 - acc: 0.5187 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 818/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0130 - acc: 0.5200 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 819/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0130 - acc: 0.5280 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 820/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0130 - acc: 0.5307 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 821/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0130 - acc: 0.5200 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 822/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0130 - acc: 0.5253 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 823/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0130 - acc: 0.5320 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 824/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0130 - acc: 0.5293 - val_loss: 0.0204 - val_acc: 0.3600\n",
      "Epoch 825/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0129 - acc: 0.5200 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 826/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0129 - acc: 0.5320 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 827/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0129 - acc: 0.5280 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 828/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0129 - acc: 0.5280 - val_loss: 0.0204 - val_acc: 0.3560\n",
      "Epoch 829/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0129 - acc: 0.5267 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 830/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0129 - acc: 0.5280 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 831/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0129 - acc: 0.5253 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 832/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0129 - acc: 0.5240 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 833/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0129 - acc: 0.5333 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 834/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0129 - acc: 0.5173 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 835/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0129 - acc: 0.5253 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 836/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0129 - acc: 0.5267 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 837/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0129 - acc: 0.5320 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 838/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0129 - acc: 0.5293 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 839/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0129 - acc: 0.5293 - val_loss: 0.0205 - val_acc: 0.3600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0129 - acc: 0.5253 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 841/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0129 - acc: 0.5333 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 842/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0129 - acc: 0.5240 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 843/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0129 - acc: 0.5307 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 844/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0129 - acc: 0.5320 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 845/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0129 - acc: 0.5333 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 846/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0129 - acc: 0.5293 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 847/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0129 - acc: 0.5280 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 848/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0129 - acc: 0.5293 - val_loss: 0.0204 - val_acc: 0.3640\n",
      "Epoch 849/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0129 - acc: 0.5267 - val_loss: 0.0205 - val_acc: 0.3560\n",
      "Epoch 850/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0129 - acc: 0.5387 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 851/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0129 - acc: 0.5320 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 852/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0128 - acc: 0.5360 - val_loss: 0.0205 - val_acc: 0.3560\n",
      "Epoch 853/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0128 - acc: 0.5240 - val_loss: 0.0205 - val_acc: 0.3560\n",
      "Epoch 854/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0128 - acc: 0.5320 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 855/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0128 - acc: 0.5440 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 856/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0128 - acc: 0.5227 - val_loss: 0.0206 - val_acc: 0.3600\n",
      "Epoch 857/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0128 - acc: 0.5333 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 858/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0128 - acc: 0.5360 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 859/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0128 - acc: 0.5347 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 860/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0128 - acc: 0.5360 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 861/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0128 - acc: 0.5440 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 862/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0128 - acc: 0.5333 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 863/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0128 - acc: 0.5347 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 864/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0128 - acc: 0.5387 - val_loss: 0.0205 - val_acc: 0.3680\n",
      "Epoch 865/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0128 - acc: 0.5427 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 866/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0128 - acc: 0.5387 - val_loss: 0.0206 - val_acc: 0.3600\n",
      "Epoch 867/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0128 - acc: 0.5387 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 868/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0128 - acc: 0.5413 - val_loss: 0.0206 - val_acc: 0.3600\n",
      "Epoch 869/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0128 - acc: 0.5400 - val_loss: 0.0206 - val_acc: 0.3600\n",
      "Epoch 870/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0128 - acc: 0.5267 - val_loss: 0.0206 - val_acc: 0.3600\n",
      "Epoch 871/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0128 - acc: 0.5413 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 872/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0128 - acc: 0.5333 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 873/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0128 - acc: 0.5373 - val_loss: 0.0205 - val_acc: 0.3600\n",
      "Epoch 874/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0128 - acc: 0.5360 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 875/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0128 - acc: 0.5280 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 876/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0128 - acc: 0.5227 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 877/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0128 - acc: 0.5360 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 878/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0128 - acc: 0.5360 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 879/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0127 - acc: 0.5320 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 880/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0127 - acc: 0.5387 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 881/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0127 - acc: 0.5347 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 882/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0127 - acc: 0.5453 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 883/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0127 - acc: 0.5373 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 884/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0127 - acc: 0.5400 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 885/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0127 - acc: 0.5307 - val_loss: 0.0206 - val_acc: 0.3680\n",
      "Epoch 886/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0127 - acc: 0.5347 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 887/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0127 - acc: 0.5373 - val_loss: 0.0206 - val_acc: 0.3680\n",
      "Epoch 888/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0127 - acc: 0.5360 - val_loss: 0.0205 - val_acc: 0.3640\n",
      "Epoch 889/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0127 - acc: 0.5373 - val_loss: 0.0206 - val_acc: 0.3600\n",
      "Epoch 890/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0127 - acc: 0.5400 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 891/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0127 - acc: 0.5333 - val_loss: 0.0206 - val_acc: 0.3720\n",
      "Epoch 892/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0127 - acc: 0.5347 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 893/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0127 - acc: 0.5480 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 894/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0127 - acc: 0.5253 - val_loss: 0.0206 - val_acc: 0.3680\n",
      "Epoch 895/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0127 - acc: 0.5333 - val_loss: 0.0206 - val_acc: 0.3680\n",
      "Epoch 896/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0127 - acc: 0.5520 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 897/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0127 - acc: 0.5387 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 898/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0127 - acc: 0.5307 - val_loss: 0.0206 - val_acc: 0.3600\n",
      "Epoch 899/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0127 - acc: 0.5347 - val_loss: 0.0206 - val_acc: 0.3640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 900/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0127 - acc: 0.5400 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 901/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0127 - acc: 0.5387 - val_loss: 0.0206 - val_acc: 0.3680\n",
      "Epoch 902/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0127 - acc: 0.5400 - val_loss: 0.0207 - val_acc: 0.3680\n",
      "Epoch 903/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0127 - acc: 0.5507 - val_loss: 0.0206 - val_acc: 0.3720\n",
      "Epoch 904/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0127 - acc: 0.5360 - val_loss: 0.0207 - val_acc: 0.3680\n",
      "Epoch 905/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0126 - acc: 0.5440 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 906/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0126 - acc: 0.5427 - val_loss: 0.0206 - val_acc: 0.3680\n",
      "Epoch 907/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0126 - acc: 0.5387 - val_loss: 0.0206 - val_acc: 0.3720\n",
      "Epoch 908/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0126 - acc: 0.5467 - val_loss: 0.0206 - val_acc: 0.3680\n",
      "Epoch 909/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0126 - acc: 0.5480 - val_loss: 0.0207 - val_acc: 0.3640\n",
      "Epoch 910/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0126 - acc: 0.5493 - val_loss: 0.0207 - val_acc: 0.3600\n",
      "Epoch 911/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0126 - acc: 0.5347 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 912/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0126 - acc: 0.5507 - val_loss: 0.0206 - val_acc: 0.3680\n",
      "Epoch 913/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0126 - acc: 0.5413 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 914/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0126 - acc: 0.5453 - val_loss: 0.0207 - val_acc: 0.3680\n",
      "Epoch 915/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0126 - acc: 0.5307 - val_loss: 0.0207 - val_acc: 0.3680\n",
      "Epoch 916/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0126 - acc: 0.5453 - val_loss: 0.0206 - val_acc: 0.3680\n",
      "Epoch 917/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0126 - acc: 0.5480 - val_loss: 0.0206 - val_acc: 0.3680\n",
      "Epoch 918/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0126 - acc: 0.5427 - val_loss: 0.0207 - val_acc: 0.3680\n",
      "Epoch 919/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0126 - acc: 0.5453 - val_loss: 0.0206 - val_acc: 0.3720\n",
      "Epoch 920/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0126 - acc: 0.5453 - val_loss: 0.0207 - val_acc: 0.3680\n",
      "Epoch 921/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0126 - acc: 0.5440 - val_loss: 0.0206 - val_acc: 0.3640\n",
      "Epoch 922/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0126 - acc: 0.5480 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 923/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0126 - acc: 0.5507 - val_loss: 0.0206 - val_acc: 0.3720\n",
      "Epoch 924/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0126 - acc: 0.5560 - val_loss: 0.0206 - val_acc: 0.3680\n",
      "Epoch 925/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0126 - acc: 0.5467 - val_loss: 0.0207 - val_acc: 0.3680\n",
      "Epoch 926/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0126 - acc: 0.5507 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 927/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0126 - acc: 0.5427 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 928/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0126 - acc: 0.5507 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 929/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0126 - acc: 0.5453 - val_loss: 0.0207 - val_acc: 0.3680\n",
      "Epoch 930/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0126 - acc: 0.5560 - val_loss: 0.0207 - val_acc: 0.3680\n",
      "Epoch 931/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0126 - acc: 0.5547 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 932/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0126 - acc: 0.5413 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 933/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0125 - acc: 0.5413 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 934/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0125 - acc: 0.5467 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 935/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0125 - acc: 0.5533 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 936/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0125 - acc: 0.5587 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 937/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0125 - acc: 0.5493 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 938/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0125 - acc: 0.5573 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 939/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0125 - acc: 0.5467 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 940/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0125 - acc: 0.5560 - val_loss: 0.0207 - val_acc: 0.3640\n",
      "Epoch 941/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0125 - acc: 0.5467 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 942/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0125 - acc: 0.5573 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 943/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0125 - acc: 0.5480 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 944/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0125 - acc: 0.5560 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 945/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0125 - acc: 0.5480 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 946/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0125 - acc: 0.5480 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 947/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.5467 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 948/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0125 - acc: 0.5573 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 949/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0125 - acc: 0.5653 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 950/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0125 - acc: 0.5440 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 951/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0125 - acc: 0.5680 - val_loss: 0.0207 - val_acc: 0.3680\n",
      "Epoch 952/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0125 - acc: 0.5533 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 953/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0125 - acc: 0.5467 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 954/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0125 - acc: 0.5667 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 955/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0125 - acc: 0.5627 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 956/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0125 - acc: 0.5627 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 957/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.5693 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 958/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0125 - acc: 0.5653 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 959/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0125 - acc: 0.5680 - val_loss: 0.0207 - val_acc: 0.3760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 960/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.5640 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 961/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0125 - acc: 0.5693 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 962/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0125 - acc: 0.5667 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 963/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0125 - acc: 0.5653 - val_loss: 0.0207 - val_acc: 0.3720\n",
      "Epoch 964/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.5720 - val_loss: 0.0208 - val_acc: 0.3680\n",
      "Epoch 965/2000\n",
      "750/750 [==============================] - 0s 77us/step - loss: 0.0125 - acc: 0.5613 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 966/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0124 - acc: 0.5720 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 967/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0124 - acc: 0.5640 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 968/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.5573 - val_loss: 0.0207 - val_acc: 0.3680\n",
      "Epoch 969/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0124 - acc: 0.5680 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 970/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.5613 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 971/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0124 - acc: 0.5720 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 972/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.5533 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 973/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0124 - acc: 0.5707 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 974/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.5707 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 975/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.5667 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 976/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.5693 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 977/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.5667 - val_loss: 0.0207 - val_acc: 0.3760\n",
      "Epoch 978/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0124 - acc: 0.5600 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 979/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0124 - acc: 0.5747 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 980/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0124 - acc: 0.5560 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 981/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0124 - acc: 0.5787 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 982/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.5707 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 983/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.5600 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 984/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.5747 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 985/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.5760 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 986/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.5667 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 987/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.5760 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 988/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0124 - acc: 0.5573 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 989/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.5813 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 990/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.5813 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 991/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0124 - acc: 0.5720 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 992/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0124 - acc: 0.5733 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 993/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0124 - acc: 0.5693 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 994/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.5680 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 995/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0124 - acc: 0.5707 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 996/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.5800 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 997/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.5747 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 998/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.5680 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 999/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.5800 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 1000/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0124 - acc: 0.5693 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1001/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0123 - acc: 0.5840 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1002/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0123 - acc: 0.5627 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 1003/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0123 - acc: 0.5840 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 1004/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0123 - acc: 0.5667 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 1005/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0123 - acc: 0.5787 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 1006/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0123 - acc: 0.5773 - val_loss: 0.0208 - val_acc: 0.3720\n",
      "Epoch 1007/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0123 - acc: 0.5653 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1008/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.5733 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1009/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0123 - acc: 0.5893 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 1010/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.5787 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 1011/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0123 - acc: 0.5813 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1012/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0123 - acc: 0.5720 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1013/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0123 - acc: 0.5813 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1014/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0123 - acc: 0.5800 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 1015/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0123 - acc: 0.5720 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 1016/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0123 - acc: 0.5827 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1017/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0123 - acc: 0.5760 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1018/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0123 - acc: 0.5800 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1019/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 83us/step - loss: 0.0123 - acc: 0.5693 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1020/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0123 - acc: 0.5773 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 1021/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0123 - acc: 0.5880 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1022/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0123 - acc: 0.5800 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 1023/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.5680 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1024/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0123 - acc: 0.5773 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1025/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0123 - acc: 0.5893 - val_loss: 0.0208 - val_acc: 0.3760\n",
      "Epoch 1026/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0123 - acc: 0.5693 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1027/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0123 - acc: 0.5880 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1028/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0123 - acc: 0.5747 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1029/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0123 - acc: 0.5827 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1030/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0123 - acc: 0.5867 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1031/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.5867 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1032/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0123 - acc: 0.5760 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1033/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0123 - acc: 0.5787 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1034/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0123 - acc: 0.5787 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1035/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0123 - acc: 0.5827 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1036/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0123 - acc: 0.5707 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1037/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0123 - acc: 0.5813 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1038/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0122 - acc: 0.5787 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1039/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0122 - acc: 0.5893 - val_loss: 0.0208 - val_acc: 0.3800\n",
      "Epoch 1040/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5853 - val_loss: 0.0208 - val_acc: 0.3800\n",
      "Epoch 1041/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0122 - acc: 0.5707 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1042/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0122 - acc: 0.5840 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1043/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0122 - acc: 0.5947 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1044/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5693 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1045/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.5800 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1046/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5760 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1047/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0122 - acc: 0.5880 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1048/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.5853 - val_loss: 0.0210 - val_acc: 0.3720\n",
      "Epoch 1049/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.5880 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1050/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5960 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1051/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.5840 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1052/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0122 - acc: 0.5893 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1053/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5760 - val_loss: 0.0209 - val_acc: 0.3720\n",
      "Epoch 1054/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.5827 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1055/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0122 - acc: 0.5773 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1056/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5867 - val_loss: 0.0209 - val_acc: 0.3800\n",
      "Epoch 1057/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.5827 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1058/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5747 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1059/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5853 - val_loss: 0.0209 - val_acc: 0.3800\n",
      "Epoch 1060/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5787 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1061/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0122 - acc: 0.5973 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1062/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5813 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1063/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0122 - acc: 0.5813 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1064/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0122 - acc: 0.5880 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1065/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5827 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1066/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5893 - val_loss: 0.0209 - val_acc: 0.3760\n",
      "Epoch 1067/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.5987 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1068/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5827 - val_loss: 0.0209 - val_acc: 0.3800\n",
      "Epoch 1069/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0122 - acc: 0.5880 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1070/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.5867 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1071/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.5893 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1072/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.6053 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1073/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.5853 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1074/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.5880 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1075/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.5947 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1076/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0122 - acc: 0.5827 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1077/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0122 - acc: 0.5800 - val_loss: 0.0210 - val_acc: 0.3720\n",
      "Epoch 1078/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.5867 - val_loss: 0.0211 - val_acc: 0.3760\n",
      "Epoch 1079/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0122 - acc: 0.5973 - val_loss: 0.0210 - val_acc: 0.3840\n",
      "Epoch 1080/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0121 - acc: 0.5920 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1081/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0121 - acc: 0.5907 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1082/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0121 - acc: 0.5853 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1083/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0121 - acc: 0.5853 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1084/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0121 - acc: 0.6027 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1085/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0121 - acc: 0.5867 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1086/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0121 - acc: 0.5973 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1087/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0121 - acc: 0.5907 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1088/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0121 - acc: 0.5973 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1089/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0121 - acc: 0.5920 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1090/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0121 - acc: 0.5987 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1091/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0121 - acc: 0.5933 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1092/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0121 - acc: 0.5827 - val_loss: 0.0211 - val_acc: 0.3760\n",
      "Epoch 1093/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0121 - acc: 0.5947 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1094/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0121 - acc: 0.5907 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1095/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0121 - acc: 0.5880 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1096/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0121 - acc: 0.5947 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1097/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0121 - acc: 0.5893 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1098/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0121 - acc: 0.5880 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1099/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0121 - acc: 0.5933 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1100/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0121 - acc: 0.5920 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1101/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0121 - acc: 0.5893 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1102/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0121 - acc: 0.6053 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1103/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0121 - acc: 0.6000 - val_loss: 0.0210 - val_acc: 0.3840\n",
      "Epoch 1104/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0121 - acc: 0.6053 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1105/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0121 - acc: 0.5880 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1106/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0121 - acc: 0.5867 - val_loss: 0.0211 - val_acc: 0.3760\n",
      "Epoch 1107/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0121 - acc: 0.5960 - val_loss: 0.0211 - val_acc: 0.3760\n",
      "Epoch 1108/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0121 - acc: 0.5947 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1109/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0121 - acc: 0.6080 - val_loss: 0.0210 - val_acc: 0.3800\n",
      "Epoch 1110/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0121 - acc: 0.5947 - val_loss: 0.0210 - val_acc: 0.3760\n",
      "Epoch 1111/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0121 - acc: 0.6013 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1112/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0121 - acc: 0.6027 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1113/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0121 - acc: 0.5880 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1114/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0121 - acc: 0.6013 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1115/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0121 - acc: 0.5893 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1116/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0121 - acc: 0.6053 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1117/2000\n",
      "750/750 [==============================] - 0s 92us/step - loss: 0.0121 - acc: 0.6080 - val_loss: 0.0211 - val_acc: 0.3760\n",
      "Epoch 1118/2000\n",
      "750/750 [==============================] - 0s 93us/step - loss: 0.0121 - acc: 0.5987 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1119/2000\n",
      "750/750 [==============================] - 0s 94us/step - loss: 0.0121 - acc: 0.5960 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1120/2000\n",
      "750/750 [==============================] - 0s 90us/step - loss: 0.0121 - acc: 0.5973 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1121/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0121 - acc: 0.6067 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1122/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0121 - acc: 0.6027 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1123/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0121 - acc: 0.6053 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1124/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0121 - acc: 0.5973 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1125/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0121 - acc: 0.6093 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1126/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0120 - acc: 0.6000 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1127/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0121 - acc: 0.6107 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1128/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.5947 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1129/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0120 - acc: 0.5987 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1130/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0120 - acc: 0.6027 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1131/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0120 - acc: 0.6107 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1132/2000\n",
      "750/750 [==============================] - 0s 98us/step - loss: 0.0120 - acc: 0.6067 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1133/2000\n",
      "750/750 [==============================] - 0s 94us/step - loss: 0.0120 - acc: 0.6040 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1134/2000\n",
      "750/750 [==============================] - 0s 96us/step - loss: 0.0120 - acc: 0.6013 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1135/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0120 - acc: 0.6067 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1136/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0120 - acc: 0.6080 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1137/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 81us/step - loss: 0.0120 - acc: 0.5960 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1138/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.5987 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1139/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.5987 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1140/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.6120 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1141/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.6053 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1142/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.5973 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1143/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.6027 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1144/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.6120 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1145/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0120 - acc: 0.6067 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1146/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.6067 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1147/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.6093 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1148/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0120 - acc: 0.6067 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1149/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.6013 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1150/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.6173 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1151/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0120 - acc: 0.6080 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1152/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.6160 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1153/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0120 - acc: 0.6027 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1154/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.6147 - val_loss: 0.0211 - val_acc: 0.3840\n",
      "Epoch 1155/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.6000 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1156/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.6080 - val_loss: 0.0212 - val_acc: 0.3880\n",
      "Epoch 1157/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.6013 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1158/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0120 - acc: 0.6147 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1159/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0120 - acc: 0.5987 - val_loss: 0.0211 - val_acc: 0.3800\n",
      "Epoch 1160/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0120 - acc: 0.6107 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1161/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.6027 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1162/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.6080 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1163/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.6227 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1164/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0120 - acc: 0.6013 - val_loss: 0.0211 - val_acc: 0.3880\n",
      "Epoch 1165/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.6187 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1166/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0120 - acc: 0.6093 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1167/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.6173 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1168/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.6280 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1169/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0120 - acc: 0.6053 - val_loss: 0.0212 - val_acc: 0.3880\n",
      "Epoch 1170/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0120 - acc: 0.6133 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1171/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0120 - acc: 0.6120 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1172/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0120 - acc: 0.6107 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1173/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0120 - acc: 0.6107 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1174/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.6173 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1175/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.6120 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1176/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0120 - acc: 0.6200 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1177/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0120 - acc: 0.6133 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1178/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.6187 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1179/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0119 - acc: 0.6147 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1180/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0119 - acc: 0.6120 - val_loss: 0.0212 - val_acc: 0.3880\n",
      "Epoch 1181/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0119 - acc: 0.6027 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1182/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0119 - acc: 0.6133 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1183/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0119 - acc: 0.6093 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1184/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0119 - acc: 0.6120 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1185/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0119 - acc: 0.6173 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1186/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6093 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1187/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6173 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1188/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6093 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1189/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0119 - acc: 0.6133 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1190/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6133 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1191/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0119 - acc: 0.6080 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1192/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0119 - acc: 0.6213 - val_loss: 0.0212 - val_acc: 0.3720\n",
      "Epoch 1193/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0119 - acc: 0.6227 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1194/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6227 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1195/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6133 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1196/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 84us/step - loss: 0.0119 - acc: 0.6227 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1197/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0119 - acc: 0.6200 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1198/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6253 - val_loss: 0.0212 - val_acc: 0.3840\n",
      "Epoch 1199/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0119 - acc: 0.6360 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1200/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0119 - acc: 0.6160 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1201/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0119 - acc: 0.6307 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1202/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0119 - acc: 0.6253 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1203/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0119 - acc: 0.6187 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1204/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0119 - acc: 0.6200 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1205/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0119 - acc: 0.6240 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1206/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0119 - acc: 0.6107 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1207/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6320 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1208/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0119 - acc: 0.6187 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1209/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0119 - acc: 0.6253 - val_loss: 0.0212 - val_acc: 0.3760\n",
      "Epoch 1210/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6093 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1211/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6200 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1212/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0119 - acc: 0.6267 - val_loss: 0.0212 - val_acc: 0.3800\n",
      "Epoch 1213/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0119 - acc: 0.6293 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1214/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6160 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1215/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6293 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1216/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6213 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1217/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0119 - acc: 0.6160 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1218/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0119 - acc: 0.6160 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1219/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6240 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1220/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6240 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1221/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6253 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1222/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6267 - val_loss: 0.0213 - val_acc: 0.3720\n",
      "Epoch 1223/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6267 - val_loss: 0.0213 - val_acc: 0.3720\n",
      "Epoch 1224/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0119 - acc: 0.6293 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1225/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0119 - acc: 0.6293 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1226/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0119 - acc: 0.6333 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1227/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0119 - acc: 0.6307 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1228/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0119 - acc: 0.6200 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1229/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0119 - acc: 0.6453 - val_loss: 0.0213 - val_acc: 0.3720\n",
      "Epoch 1230/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0119 - acc: 0.6240 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1231/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0119 - acc: 0.6280 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1232/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0119 - acc: 0.6347 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1233/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0119 - acc: 0.6213 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1234/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0119 - acc: 0.6240 - val_loss: 0.0213 - val_acc: 0.3720\n",
      "Epoch 1235/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0118 - acc: 0.6333 - val_loss: 0.0214 - val_acc: 0.3760\n",
      "Epoch 1236/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0119 - acc: 0.6253 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1237/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0118 - acc: 0.6200 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1238/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0118 - acc: 0.6280 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1239/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0118 - acc: 0.6347 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1240/2000\n",
      "750/750 [==============================] - 0s 77us/step - loss: 0.0118 - acc: 0.6320 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1241/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6213 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1242/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0118 - acc: 0.6333 - val_loss: 0.0213 - val_acc: 0.3880\n",
      "Epoch 1243/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0118 - acc: 0.6413 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1244/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6240 - val_loss: 0.0213 - val_acc: 0.3720\n",
      "Epoch 1245/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0118 - acc: 0.6427 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1246/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6293 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1247/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6293 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1248/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6467 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1249/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0118 - acc: 0.6320 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1250/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.6387 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1251/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.6333 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1252/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.6333 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1253/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6307 - val_loss: 0.0213 - val_acc: 0.3800\n",
      "Epoch 1254/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.6280 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1255/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 84us/step - loss: 0.0118 - acc: 0.6227 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1256/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0118 - acc: 0.6453 - val_loss: 0.0213 - val_acc: 0.3840\n",
      "Epoch 1257/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.6280 - val_loss: 0.0214 - val_acc: 0.3760\n",
      "Epoch 1258/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0118 - acc: 0.6347 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1259/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6293 - val_loss: 0.0214 - val_acc: 0.3760\n",
      "Epoch 1260/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0118 - acc: 0.6507 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1261/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0118 - acc: 0.6280 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1262/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0118 - acc: 0.6387 - val_loss: 0.0214 - val_acc: 0.3720\n",
      "Epoch 1263/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6253 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1264/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6360 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1265/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0118 - acc: 0.6253 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1266/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6347 - val_loss: 0.0214 - val_acc: 0.3760\n",
      "Epoch 1267/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6427 - val_loss: 0.0214 - val_acc: 0.3760\n",
      "Epoch 1268/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.6387 - val_loss: 0.0214 - val_acc: 0.3760\n",
      "Epoch 1269/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6533 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1270/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6280 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1271/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.6373 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1272/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6360 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1273/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6280 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1274/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6440 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1275/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6347 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1276/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.6467 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1277/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6413 - val_loss: 0.0213 - val_acc: 0.3760\n",
      "Epoch 1278/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6453 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1279/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6413 - val_loss: 0.0214 - val_acc: 0.3760\n",
      "Epoch 1280/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6373 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1281/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0118 - acc: 0.6453 - val_loss: 0.0214 - val_acc: 0.3760\n",
      "Epoch 1282/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6267 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1283/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6360 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1284/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6467 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1285/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6440 - val_loss: 0.0214 - val_acc: 0.3880\n",
      "Epoch 1286/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6507 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1287/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6427 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1288/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6267 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1289/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6427 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1290/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6480 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1291/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6320 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1292/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6533 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1293/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6387 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1294/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6480 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1295/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0118 - acc: 0.6560 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1296/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6400 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1297/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6427 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1298/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0118 - acc: 0.6453 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1299/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6453 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1300/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0118 - acc: 0.6400 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1301/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0118 - acc: 0.6453 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1302/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.6387 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1303/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6507 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1304/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0117 - acc: 0.6493 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1305/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0117 - acc: 0.6440 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1306/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6480 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1307/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0117 - acc: 0.6520 - val_loss: 0.0215 - val_acc: 0.3760\n",
      "Epoch 1308/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0117 - acc: 0.6467 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1309/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0117 - acc: 0.6453 - val_loss: 0.0214 - val_acc: 0.3800\n",
      "Epoch 1310/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0117 - acc: 0.6413 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1311/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6560 - val_loss: 0.0214 - val_acc: 0.3880\n",
      "Epoch 1312/2000\n",
      "750/750 [==============================] - 0s 77us/step - loss: 0.0117 - acc: 0.6467 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1313/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0117 - acc: 0.6467 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1314/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6467 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1315/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0117 - acc: 0.6533 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1316/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0117 - acc: 0.6427 - val_loss: 0.0214 - val_acc: 0.3840\n",
      "Epoch 1317/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0117 - acc: 0.6480 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1318/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0117 - acc: 0.6533 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1319/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6507 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1320/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0117 - acc: 0.6533 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1321/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0117 - acc: 0.6520 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1322/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0117 - acc: 0.6440 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1323/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6480 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1324/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0117 - acc: 0.6467 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1325/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6387 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1326/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0117 - acc: 0.6587 - val_loss: 0.0215 - val_acc: 0.3760\n",
      "Epoch 1327/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6533 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1328/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0117 - acc: 0.6347 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1329/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0117 - acc: 0.6573 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1330/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0117 - acc: 0.6373 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1331/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6440 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1332/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0117 - acc: 0.6520 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1333/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6667 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1334/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0117 - acc: 0.6440 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1335/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6507 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1336/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0117 - acc: 0.6493 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1337/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0117 - acc: 0.6440 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1338/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0117 - acc: 0.6560 - val_loss: 0.0215 - val_acc: 0.3880\n",
      "Epoch 1339/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6427 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1340/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0117 - acc: 0.6520 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1341/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6533 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1342/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6533 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1343/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6600 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1344/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6480 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1345/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0117 - acc: 0.6600 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1346/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6600 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1347/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6533 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1348/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0117 - acc: 0.6587 - val_loss: 0.0215 - val_acc: 0.3880\n",
      "Epoch 1349/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6480 - val_loss: 0.0215 - val_acc: 0.3880\n",
      "Epoch 1350/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0117 - acc: 0.6533 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1351/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0117 - acc: 0.6453 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1352/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6613 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1353/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6467 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1354/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6573 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1355/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0117 - acc: 0.6493 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1356/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0117 - acc: 0.6493 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1357/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6467 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1358/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0117 - acc: 0.6533 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1359/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0117 - acc: 0.6547 - val_loss: 0.0215 - val_acc: 0.3760\n",
      "Epoch 1360/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0117 - acc: 0.6587 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1361/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6533 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1362/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0117 - acc: 0.6507 - val_loss: 0.0216 - val_acc: 0.3760\n",
      "Epoch 1363/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0117 - acc: 0.6587 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1364/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0117 - acc: 0.6613 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1365/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6667 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1366/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0117 - acc: 0.6533 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1367/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6547 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1368/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0117 - acc: 0.6573 - val_loss: 0.0215 - val_acc: 0.3800\n",
      "Epoch 1369/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0117 - acc: 0.6480 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1370/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0117 - acc: 0.6533 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1371/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0117 - acc: 0.6560 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1372/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6480 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1373/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 80us/step - loss: 0.0117 - acc: 0.6493 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1374/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6627 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1375/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0117 - acc: 0.6560 - val_loss: 0.0215 - val_acc: 0.3840\n",
      "Epoch 1376/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0117 - acc: 0.6667 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1377/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0117 - acc: 0.6600 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1378/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0117 - acc: 0.6453 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1379/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0117 - acc: 0.6600 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1380/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6507 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1381/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0116 - acc: 0.6600 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1382/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6627 - val_loss: 0.0215 - val_acc: 0.3880\n",
      "Epoch 1383/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6520 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1384/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0116 - acc: 0.6547 - val_loss: 0.0216 - val_acc: 0.3880\n",
      "Epoch 1385/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6680 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1386/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6640 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1387/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6680 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1388/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0116 - acc: 0.6613 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1389/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6613 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1390/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6627 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1391/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6533 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1392/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6600 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1393/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6733 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1394/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6627 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1395/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0116 - acc: 0.6533 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1396/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6600 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1397/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6560 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1398/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0116 - acc: 0.6640 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1399/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0116 - acc: 0.6640 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1400/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6547 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1401/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6573 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1402/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6680 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1403/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6600 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1404/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6627 - val_loss: 0.0216 - val_acc: 0.3880\n",
      "Epoch 1405/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6560 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1406/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6600 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1407/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6693 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1408/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0116 - acc: 0.6613 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1409/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6707 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1410/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6667 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1411/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6600 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1412/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6707 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1413/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6573 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1414/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6573 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1415/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6707 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1416/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6640 - val_loss: 0.0216 - val_acc: 0.3880\n",
      "Epoch 1417/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6613 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1418/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6627 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1419/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6760 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1420/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6640 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1421/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6680 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1422/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6760 - val_loss: 0.0216 - val_acc: 0.3880\n",
      "Epoch 1423/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6707 - val_loss: 0.0217 - val_acc: 0.3800\n",
      "Epoch 1424/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6613 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1425/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6733 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1426/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6640 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1427/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6747 - val_loss: 0.0216 - val_acc: 0.3800\n",
      "Epoch 1428/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6733 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1429/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6667 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1430/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6613 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1431/2000\n",
      "750/750 [==============================] - 0s 77us/step - loss: 0.0116 - acc: 0.6760 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1432/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6653 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1433/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6773 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1434/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6667 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1435/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6707 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1436/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6640 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1437/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0116 - acc: 0.6693 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1438/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0116 - acc: 0.6667 - val_loss: 0.0216 - val_acc: 0.3840\n",
      "Epoch 1439/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6640 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1440/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6773 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1441/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6680 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1442/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6747 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1443/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0116 - acc: 0.6747 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1444/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6667 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1445/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6773 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1446/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6680 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1447/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0116 - acc: 0.6720 - val_loss: 0.0217 - val_acc: 0.3920\n",
      "Epoch 1448/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6667 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1449/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6733 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1450/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6760 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1451/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6907 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1452/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6653 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1453/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0116 - acc: 0.6760 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1454/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6693 - val_loss: 0.0217 - val_acc: 0.3840\n",
      "Epoch 1455/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6667 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1456/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6720 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1457/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6707 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1458/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6747 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1459/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6760 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1460/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6787 - val_loss: 0.0217 - val_acc: 0.3920\n",
      "Epoch 1461/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6733 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1462/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6720 - val_loss: 0.0217 - val_acc: 0.3920\n",
      "Epoch 1463/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6840 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1464/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6653 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1465/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0116 - acc: 0.6747 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1466/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6773 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1467/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6773 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1468/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6773 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1469/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6813 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1470/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0116 - acc: 0.6733 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1471/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0116 - acc: 0.6827 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1472/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6800 - val_loss: 0.0217 - val_acc: 0.3920\n",
      "Epoch 1473/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0116 - acc: 0.6747 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1474/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6813 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1475/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0115 - acc: 0.6827 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1476/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6827 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1477/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6827 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1478/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6827 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1479/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6840 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1480/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6827 - val_loss: 0.0217 - val_acc: 0.3920\n",
      "Epoch 1481/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6720 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1482/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6827 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1483/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6707 - val_loss: 0.0217 - val_acc: 0.3920\n",
      "Epoch 1484/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6667 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1485/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6787 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1486/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6880 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1487/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0115 - acc: 0.6813 - val_loss: 0.0217 - val_acc: 0.3920\n",
      "Epoch 1488/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6773 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1489/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6840 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1490/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6827 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1491/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6933 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1492/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6827 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1493/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6747 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1494/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.6653 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1495/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6867 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1496/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6653 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1497/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6760 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1498/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6840 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1499/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6933 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1500/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.6853 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1501/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.6893 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1502/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6893 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1503/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6840 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1504/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.6773 - val_loss: 0.0218 - val_acc: 0.3960\n",
      "Epoch 1505/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6907 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1506/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6893 - val_loss: 0.0217 - val_acc: 0.3880\n",
      "Epoch 1507/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6787 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1508/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6960 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1509/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6747 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1510/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6880 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1511/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.6840 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1512/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6880 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1513/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6947 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1514/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6773 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1515/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6853 - val_loss: 0.0218 - val_acc: 0.3960\n",
      "Epoch 1516/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6947 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1517/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6813 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1518/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6827 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1519/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6880 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1520/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6840 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1521/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6973 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1522/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6813 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1523/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6880 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1524/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6907 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1525/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6947 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1526/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0115 - acc: 0.6827 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1527/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6840 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1528/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6760 - val_loss: 0.0218 - val_acc: 0.3800\n",
      "Epoch 1529/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6840 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1530/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6840 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1531/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6920 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1532/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6973 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1533/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.7013 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1534/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6920 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1535/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6853 - val_loss: 0.0218 - val_acc: 0.3960\n",
      "Epoch 1536/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6880 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1537/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6827 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1538/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6907 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1539/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6880 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1540/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.7093 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1541/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6813 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1542/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.7147 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1543/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.7000 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1544/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6907 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1545/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6947 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1546/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6933 - val_loss: 0.0218 - val_acc: 0.3800\n",
      "Epoch 1547/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6987 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1548/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6867 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1549/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.7000 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1550/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.7040 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1551/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6960 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1552/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6960 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1553/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6800 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1554/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6933 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1555/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.7027 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1556/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.6973 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1557/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6840 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1558/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6893 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1559/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.7080 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1560/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6907 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1561/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6987 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1562/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.7027 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1563/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6960 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1564/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6840 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1565/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.7013 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1566/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.7040 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1567/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6947 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1568/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6973 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1569/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.7067 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1570/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.7000 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1571/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.6987 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1572/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.7000 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1573/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6947 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1574/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.7013 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1575/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.7067 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1576/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.7080 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1577/2000\n",
      "750/750 [==============================] - 0s 77us/step - loss: 0.0115 - acc: 0.6907 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1578/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.6893 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1579/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.7013 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1580/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.6933 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1581/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0115 - acc: 0.7067 - val_loss: 0.0218 - val_acc: 0.3880\n",
      "Epoch 1582/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0115 - acc: 0.6933 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1583/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6920 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1584/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.6987 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1585/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6987 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1586/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6960 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1587/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0115 - acc: 0.6920 - val_loss: 0.0218 - val_acc: 0.3920\n",
      "Epoch 1588/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0115 - acc: 0.7053 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1589/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0115 - acc: 0.6973 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1590/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0115 - acc: 0.7040 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1591/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0115 - acc: 0.7053 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1592/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0115 - acc: 0.7080 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1593/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0115 - acc: 0.7053 - val_loss: 0.0218 - val_acc: 0.3840\n",
      "Epoch 1594/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0115 - acc: 0.6987 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1595/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0115 - acc: 0.7120 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1596/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0115 - acc: 0.6933 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1597/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.7067 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1598/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7040 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1599/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0115 - acc: 0.7080 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1600/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7200 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1601/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7013 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1602/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7027 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1603/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0114 - acc: 0.6947 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1604/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7000 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1605/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7107 - val_loss: 0.0218 - val_acc: 0.3800\n",
      "Epoch 1606/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.6987 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1607/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.6973 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1608/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7053 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1609/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.6987 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1610/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7013 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1611/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7053 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1612/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7147 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1613/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7120 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1614/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7040 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1615/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.6947 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1616/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7053 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1617/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7173 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1618/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7120 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1619/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7053 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1620/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7013 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1621/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7053 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1622/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7093 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1623/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7040 - val_loss: 0.0219 - val_acc: 0.3800\n",
      "Epoch 1624/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7053 - val_loss: 0.0219 - val_acc: 0.3800\n",
      "Epoch 1625/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7080 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1626/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7160 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1627/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7147 - val_loss: 0.0219 - val_acc: 0.3800\n",
      "Epoch 1628/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7040 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1629/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7027 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1630/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7080 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1631/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0114 - acc: 0.7147 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1632/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0114 - acc: 0.7080 - val_loss: 0.0219 - val_acc: 0.3800\n",
      "Epoch 1633/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7053 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1634/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7067 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1635/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7080 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1636/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0114 - acc: 0.7173 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1637/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7147 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1638/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7053 - val_loss: 0.0219 - val_acc: 0.3800\n",
      "Epoch 1639/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7067 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1640/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7267 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1641/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7080 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1642/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7053 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1643/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7080 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1644/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7133 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1645/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7173 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1646/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7000 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1647/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7053 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1648/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7013 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1649/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.6987 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1650/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.6960 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1651/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7133 - val_loss: 0.0219 - val_acc: 0.3840\n",
      "Epoch 1652/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7253 - val_loss: 0.0219 - val_acc: 0.3800\n",
      "Epoch 1653/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7227 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1654/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7227 - val_loss: 0.0219 - val_acc: 0.3800\n",
      "Epoch 1655/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7147 - val_loss: 0.0219 - val_acc: 0.3800\n",
      "Epoch 1656/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0114 - acc: 0.7093 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1657/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7080 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1658/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7253 - val_loss: 0.0219 - val_acc: 0.3800\n",
      "Epoch 1659/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7160 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1660/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7040 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1661/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7147 - val_loss: 0.0219 - val_acc: 0.3960\n",
      "Epoch 1662/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7080 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1663/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7120 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1664/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7240 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1665/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7187 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1666/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7120 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1667/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7160 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1668/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7240 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1669/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7067 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1670/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7307 - val_loss: 0.0219 - val_acc: 0.3800\n",
      "Epoch 1671/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0114 - acc: 0.7267 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1672/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7107 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1673/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7187 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1674/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0114 - acc: 0.7160 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1675/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7240 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1676/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7080 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1677/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7187 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1678/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.6960 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1679/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7187 - val_loss: 0.0220 - val_acc: 0.3840\n",
      "Epoch 1680/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7200 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1681/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0114 - acc: 0.7053 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1682/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0114 - acc: 0.7173 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1683/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7107 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1684/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7053 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1685/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7147 - val_loss: 0.0220 - val_acc: 0.3840\n",
      "Epoch 1686/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7293 - val_loss: 0.0219 - val_acc: 0.3880\n",
      "Epoch 1687/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0114 - acc: 0.7213 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1688/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7120 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1689/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7293 - val_loss: 0.0219 - val_acc: 0.3920\n",
      "Epoch 1690/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7227 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1691/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7173 - val_loss: 0.0220 - val_acc: 0.3800\n",
      "Epoch 1692/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0114 - acc: 0.7173 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1693/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7200 - val_loss: 0.0220 - val_acc: 0.3840\n",
      "Epoch 1694/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7187 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1695/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7013 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1696/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7267 - val_loss: 0.0220 - val_acc: 0.3840\n",
      "Epoch 1697/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7267 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1698/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7240 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1699/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7160 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1700/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7293 - val_loss: 0.0220 - val_acc: 0.3840\n",
      "Epoch 1701/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0114 - acc: 0.7227 - val_loss: 0.0220 - val_acc: 0.3800\n",
      "Epoch 1702/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7160 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1703/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7347 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1704/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7293 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1705/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7147 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1706/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7173 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1707/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7293 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1708/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7173 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1709/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7347 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1710/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7360 - val_loss: 0.0220 - val_acc: 0.3800\n",
      "Epoch 1711/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0114 - acc: 0.7293 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1712/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7093 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1713/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7307 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1714/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0114 - acc: 0.7240 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1715/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7240 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1716/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7200 - val_loss: 0.0220 - val_acc: 0.3840\n",
      "Epoch 1717/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7240 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1718/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0114 - acc: 0.7133 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1719/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7280 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1720/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7360 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1721/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7240 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1722/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7347 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1723/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7320 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1724/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7307 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1725/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7173 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1726/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7293 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1727/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 85us/step - loss: 0.0114 - acc: 0.7120 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1728/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7360 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1729/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7307 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1730/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7320 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1731/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7280 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1732/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7293 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1733/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7253 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1734/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7227 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1735/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7427 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1736/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7307 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1737/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0114 - acc: 0.7200 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1738/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7333 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1739/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0114 - acc: 0.7347 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1740/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7320 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1741/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7253 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1742/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0114 - acc: 0.7320 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1743/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7133 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1744/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7413 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1745/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7173 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1746/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7280 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1747/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7387 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1748/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0114 - acc: 0.7427 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1749/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7320 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1750/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7333 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1751/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7187 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1752/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7293 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1753/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7267 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1754/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7307 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1755/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7320 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1756/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7147 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1757/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7373 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1758/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7280 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1759/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0114 - acc: 0.7480 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1760/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7267 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1761/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0114 - acc: 0.7280 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1762/2000\n",
      "750/750 [==============================] - 0s 87us/step - loss: 0.0114 - acc: 0.7387 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1763/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7133 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1764/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7373 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1765/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7320 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1766/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7427 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1767/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7373 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1768/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7440 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1769/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7293 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1770/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7427 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1771/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7373 - val_loss: 0.0220 - val_acc: 0.3880\n",
      "Epoch 1772/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7347 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1773/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7347 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1774/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7467 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1775/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0114 - acc: 0.7240 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1776/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7413 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1777/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0114 - acc: 0.7240 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1778/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7347 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1779/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7533 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1780/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7427 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1781/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0114 - acc: 0.7253 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1782/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0114 - acc: 0.7480 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1783/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0114 - acc: 0.7400 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1784/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7413 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1785/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7573 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1786/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 86us/step - loss: 0.0113 - acc: 0.7280 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1787/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7347 - val_loss: 0.0220 - val_acc: 0.3920\n",
      "Epoch 1788/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7320 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1789/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7320 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1790/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7413 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1791/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7400 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1792/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7333 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1793/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7360 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1794/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7413 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1795/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7280 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1796/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7400 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1797/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7387 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1798/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7467 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1799/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7347 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1800/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7427 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1801/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7507 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1802/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7293 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1803/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7467 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1804/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7427 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1805/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0113 - acc: 0.7400 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1806/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7467 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1807/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7493 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1808/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7587 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1809/2000\n",
      "750/750 [==============================] - 0s 92us/step - loss: 0.0113 - acc: 0.7453 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1810/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0113 - acc: 0.7520 - val_loss: 0.0220 - val_acc: 0.4000\n",
      "Epoch 1811/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7453 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1812/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0113 - acc: 0.7453 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1813/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0113 - acc: 0.7467 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1814/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7520 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1815/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7467 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1816/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7413 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1817/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7453 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1818/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7533 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1819/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0113 - acc: 0.7293 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1820/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0113 - acc: 0.7373 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1821/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7427 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1822/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7360 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1823/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7507 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1824/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7560 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1825/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7333 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1826/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7413 - val_loss: 0.0221 - val_acc: 0.3880\n",
      "Epoch 1827/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7493 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1828/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7453 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1829/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7347 - val_loss: 0.0220 - val_acc: 0.3960\n",
      "Epoch 1830/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7347 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1831/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0113 - acc: 0.7533 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1832/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7493 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1833/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7360 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1834/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7453 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1835/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7520 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1836/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7573 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1837/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7480 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1838/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7413 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1839/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7507 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1840/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7493 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1841/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7440 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1842/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7480 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1843/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7573 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1844/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7440 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1845/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1846/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7373 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1847/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7493 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1848/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7533 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1849/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7387 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1850/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7560 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1851/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1852/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7400 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1853/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7613 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1854/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7320 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1855/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7533 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1856/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7533 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1857/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7480 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1858/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7480 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1859/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7533 - val_loss: 0.0221 - val_acc: 0.3880\n",
      "Epoch 1860/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7613 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1861/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7573 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1862/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7480 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1863/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7587 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1864/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7413 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1865/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7507 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1866/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7733 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1867/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7600 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1868/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1869/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7600 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1870/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7547 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1871/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7453 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1872/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7720 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1873/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7560 - val_loss: 0.0221 - val_acc: 0.3880\n",
      "Epoch 1874/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7547 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1875/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7507 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1876/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7547 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1877/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7587 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1878/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7573 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1879/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7493 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1880/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7547 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1881/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7680 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1882/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7613 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1883/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7653 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1884/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7573 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1885/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7667 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1886/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7600 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1887/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7533 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1888/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7613 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1889/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7667 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1890/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7520 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1891/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7640 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1892/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7653 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1893/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7640 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1894/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7587 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1895/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7587 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1896/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1897/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1898/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1899/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7560 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1900/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7600 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1901/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7560 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1902/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7747 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1903/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7760 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1904/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1905/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1906/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7667 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1907/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7587 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1908/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7493 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1909/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1910/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7373 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1911/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7733 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1912/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7547 - val_loss: 0.0221 - val_acc: 0.3880\n",
      "Epoch 1913/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7573 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1914/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7760 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1915/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7600 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1916/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7573 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1917/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7733 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1918/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7573 - val_loss: 0.0221 - val_acc: 0.3880\n",
      "Epoch 1919/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7680 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1920/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7613 - val_loss: 0.0222 - val_acc: 0.3880\n",
      "Epoch 1921/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1922/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7520 - val_loss: 0.0221 - val_acc: 0.3880\n",
      "Epoch 1923/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7800 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1924/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7493 - val_loss: 0.0222 - val_acc: 0.3960\n",
      "Epoch 1925/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7667 - val_loss: 0.0221 - val_acc: 0.3880\n",
      "Epoch 1926/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7507 - val_loss: 0.0221 - val_acc: 0.3880\n",
      "Epoch 1927/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7613 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1928/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7707 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1929/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7733 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1930/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7587 - val_loss: 0.0222 - val_acc: 0.3960\n",
      "Epoch 1931/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7653 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1932/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7573 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1933/2000\n",
      "750/750 [==============================] - 0s 88us/step - loss: 0.0113 - acc: 0.7733 - val_loss: 0.0222 - val_acc: 0.3960\n",
      "Epoch 1934/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7600 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1935/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7800 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1936/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7640 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1937/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7693 - val_loss: 0.0221 - val_acc: 0.3880\n",
      "Epoch 1938/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7573 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1939/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7653 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1940/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7493 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1941/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7787 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1942/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0113 - acc: 0.7733 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1943/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7733 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1944/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1945/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7587 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1946/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1947/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7773 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1948/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7680 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1949/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0113 - acc: 0.7667 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1950/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1951/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7560 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1952/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7653 - val_loss: 0.0222 - val_acc: 0.3880\n",
      "Epoch 1953/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7613 - val_loss: 0.0222 - val_acc: 0.3960\n",
      "Epoch 1954/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0113 - acc: 0.7693 - val_loss: 0.0222 - val_acc: 0.3960\n",
      "Epoch 1955/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7787 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1956/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7720 - val_loss: 0.0222 - val_acc: 0.3960\n",
      "Epoch 1957/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7680 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1958/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7693 - val_loss: 0.0222 - val_acc: 0.3880\n",
      "Epoch 1959/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7547 - val_loss: 0.0222 - val_acc: 0.4000\n",
      "Epoch 1960/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7600 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1961/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7693 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1962/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7747 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1963/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 86us/step - loss: 0.0113 - acc: 0.7760 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1964/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7600 - val_loss: 0.0221 - val_acc: 0.4000\n",
      "Epoch 1965/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7693 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1966/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7800 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1967/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7560 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1968/2000\n",
      "750/750 [==============================] - 0s 78us/step - loss: 0.0113 - acc: 0.7787 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1969/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7667 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1970/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7653 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1971/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7760 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1972/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7653 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1973/2000\n",
      "750/750 [==============================] - 0s 82us/step - loss: 0.0113 - acc: 0.7613 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1974/2000\n",
      "750/750 [==============================] - 0s 79us/step - loss: 0.0113 - acc: 0.7613 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1975/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7667 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1976/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7747 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1977/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7680 - val_loss: 0.0222 - val_acc: 0.3840\n",
      "Epoch 1978/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7600 - val_loss: 0.0222 - val_acc: 0.3880\n",
      "Epoch 1979/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7587 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1980/2000\n",
      "750/750 [==============================] - 0s 80us/step - loss: 0.0113 - acc: 0.7573 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1981/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7800 - val_loss: 0.0221 - val_acc: 0.3920\n",
      "Epoch 1982/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7533 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1983/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7773 - val_loss: 0.0222 - val_acc: 0.3960\n",
      "Epoch 1984/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7720 - val_loss: 0.0222 - val_acc: 0.3880\n",
      "Epoch 1985/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7747 - val_loss: 0.0222 - val_acc: 0.3840\n",
      "Epoch 1986/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7680 - val_loss: 0.0222 - val_acc: 0.3840\n",
      "Epoch 1987/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7733 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1988/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7800 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1989/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7680 - val_loss: 0.0222 - val_acc: 0.3960\n",
      "Epoch 1990/2000\n",
      "750/750 [==============================] - 0s 81us/step - loss: 0.0113 - acc: 0.7747 - val_loss: 0.0222 - val_acc: 0.4000\n",
      "Epoch 1991/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7533 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1992/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7733 - val_loss: 0.0221 - val_acc: 0.3960\n",
      "Epoch 1993/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7720 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1994/2000\n",
      "750/750 [==============================] - 0s 83us/step - loss: 0.0113 - acc: 0.7787 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1995/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7760 - val_loss: 0.0222 - val_acc: 0.3880\n",
      "Epoch 1996/2000\n",
      "750/750 [==============================] - 0s 86us/step - loss: 0.0113 - acc: 0.7693 - val_loss: 0.0222 - val_acc: 0.3840\n",
      "Epoch 1997/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7747 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1998/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7733 - val_loss: 0.0222 - val_acc: 0.3920\n",
      "Epoch 1999/2000\n",
      "750/750 [==============================] - 0s 85us/step - loss: 0.0113 - acc: 0.7627 - val_loss: 0.0222 - val_acc: 0.3880\n",
      "Epoch 2000/2000\n",
      "750/750 [==============================] - 0s 84us/step - loss: 0.0113 - acc: 0.7680 - val_loss: 0.0221 - val_acc: 0.3920\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49702471  0.5798176   0.44134718 ...  1.6309088   0.3339675\n",
      "   0.10296999]\n",
      " [ 1.1751893   0.          0.         ...  1.1878498   0.\n",
      "   0.7219786 ]\n",
      " [ 2.798327    4.5448885   2.7232072  ... 12.453723    2.3595257\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.30927628  1.8620036   0.46712303 ...  0.89451915  0.55833244\n",
      "   0.        ]\n",
      " [ 1.1959102   2.5861173   0.17272757 ...  2.4787257   1.0341916\n",
      "   0.        ]\n",
      " [ 0.          0.6565881   0.6021636  ...  1.2462636   0.7128194\n",
      "   0.82795006]]\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "\n",
    "rmsprop = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=rmsprop,\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy']  # , mean_pred]\n",
    ")\n",
    "print('Train-------------------------')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.25, epochs=2000, shuffle = True, batch_size=75, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[1].output])\n",
    "layer_output1 = get_3rd_layer_output([X_train])[0]\n",
    "\n",
    "print(layer_output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_mask = y_train.reshape(1000,1024)\n",
    "plt.imshow(abs(y_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of the model [[0.         0.         0.         ... 1.         0.         0.        ]\n",
      " [0.         0.         0.         ... 1.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.00362739 0.         0.        ]\n",
      " [1.         0.7183075  0.         ... 0.         0.         1.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "prediction size 1024000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_pred = model.predict(X_train[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1024)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Predicted_Training_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_mask = y_test.reshape(1000,1024)\n",
    "plt.imshow(abs(y_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of the model [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [1.         1.         0.         ... 0.6762014  0.         1.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.03223565]\n",
      " [0.         0.         0.         ... 0.59831154 0.         0.35895145]\n",
      " [0.         0.         0.44377396 ... 1.         0.         0.        ]]\n",
      "prediction size 1024000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_pred = model.predict(X_test[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1024)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Predicted_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
