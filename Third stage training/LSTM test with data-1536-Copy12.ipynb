{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM test by data-10*512\n",
    "# 1000 steps with lr = 0.001\n",
    "# batch size = 500\n",
    "# Added Dense layer after LSTM layer to use hard_sigmoid activetion\n",
    "# units = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are better than\n",
    "best run: \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-------------------------\n",
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/1000\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.2500 - acc: 0.0000e+00 - val_loss: 0.2399 - val_acc: 0.0020\n",
      "Epoch 2/1000\n",
      "500/500 [==============================] - 0s 494us/step - loss: 0.2402 - acc: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "500/500 [==============================] - 0s 470us/step - loss: 0.0429 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "500/500 [==============================] - 0s 463us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "500/500 [==============================] - 0s 464us/step - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "500/500 [==============================] - 0s 464us/step - loss: 0.0351 - acc: 0.0060 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "500/500 [==============================] - 0s 463us/step - loss: 0.0345 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "500/500 [==============================] - 0s 464us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "500/500 [==============================] - 0s 479us/step - loss: 0.0342 - acc: 0.0060 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "500/500 [==============================] - 0s 490us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "500/500 [==============================] - 0s 463us/step - loss: 0.0341 - acc: 0.0060 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "500/500 [==============================] - 0s 461us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "500/500 [==============================] - 0s 481us/step - loss: 0.0341 - acc: 0.0060 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "500/500 [==============================] - 0s 523us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "500/500 [==============================] - 0s 464us/step - loss: 0.0341 - acc: 0.0020 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "500/500 [==============================] - 0s 489us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0040\n",
      "Epoch 17/1000\n",
      "500/500 [==============================] - 0s 506us/step - loss: 0.0341 - acc: 0.0020 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "500/500 [==============================] - 0s 461us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0660\n",
      "Epoch 19/1000\n",
      "500/500 [==============================] - 0s 461us/step - loss: 0.0341 - acc: 0.0840 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "500/500 [==============================] - 0s 463us/step - loss: 0.0342 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "500/500 [==============================] - 0s 461us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "500/500 [==============================] - 0s 463us/step - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "500/500 [==============================] - 0s 464us/step - loss: 0.0345 - acc: 0.0060 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "500/500 [==============================] - 0s 461us/step - loss: 0.0344 - acc: 0.0020 - val_loss: 0.0316 - val_acc: 0.0020\n",
      "Epoch 25/1000\n",
      "500/500 [==============================] - 0s 461us/step - loss: 0.0343 - acc: 0.0020 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "500/500 [==============================] - 0s 461us/step - loss: 0.0342 - acc: 0.0020 - val_loss: 0.0315 - val_acc: 0.0020\n",
      "Epoch 27/1000\n",
      "500/500 [==============================] - 0s 464us/step - loss: 0.0342 - acc: 0.0020 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "500/500 [==============================] - 0s 512us/step - loss: 0.0341 - acc: 0.0020 - val_loss: 0.0315 - val_acc: 0.0020\n",
      "Epoch 29/1000\n",
      "500/500 [==============================] - 0s 518us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "500/500 [==============================] - 0s 521us/step - loss: 0.0342 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "500/500 [==============================] - 0s 512us/step - loss: 0.0343 - acc: 0.0020 - val_loss: 0.0315 - val_acc: 0.0040\n",
      "Epoch 32/1000\n",
      "500/500 [==============================] - 0s 524us/step - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "500/500 [==============================] - 0s 504us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0640\n",
      "Epoch 34/1000\n",
      "500/500 [==============================] - 0s 463us/step - loss: 0.0342 - acc: 0.0840 - val_loss: 0.0315 - val_acc: 0.0040\n",
      "Epoch 35/1000\n",
      "500/500 [==============================] - 0s 525us/step - loss: 0.0341 - acc: 0.0020 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "500/500 [==============================] - 0s 460us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0020\n",
      "Epoch 37/1000\n",
      "500/500 [==============================] - 0s 502us/step - loss: 0.0341 - acc: 0.0020 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "500/500 [==============================] - 0s 455us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "500/500 [==============================] - 0s 458us/step - loss: 0.0340 - acc: 0.0020 - val_loss: 0.0312 - val_acc: 0.0020\n",
      "Epoch 40/1000\n",
      "500/500 [==============================] - 0s 457us/step - loss: 0.0340 - acc: 0.0020 - val_loss: 0.0315 - val_acc: 0.0060\n",
      "Epoch 41/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0020\n",
      "Epoch 42/1000\n",
      "500/500 [==============================] - 0s 455us/step - loss: 0.0340 - acc: 0.0020 - val_loss: 0.0315 - val_acc: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "500/500 [==============================] - 0s 455us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0020\n",
      "Epoch 44/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0339 - acc: 0.0020 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "500/500 [==============================] - 0s 455us/step - loss: 0.0339 - acc: 0.0020 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "500/500 [==============================] - 0s 455us/step - loss: 0.0338 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0060\n",
      "Epoch 47/1000\n",
      "500/500 [==============================] - 0s 455us/step - loss: 0.0338 - acc: 0.0020 - val_loss: 0.0309 - val_acc: 0.0020\n",
      "Epoch 48/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0338 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0020\n",
      "Epoch 49/1000\n",
      "500/500 [==============================] - 0s 457us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0020\n",
      "Epoch 50/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0336 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0020\n",
      "Epoch 51/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0337 - acc: 0.0020 - val_loss: 0.0307 - val_acc: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "500/500 [==============================] - 0s 455us/step - loss: 0.0335 - acc: 0.0020 - val_loss: 0.0309 - val_acc: 0.0020\n",
      "Epoch 53/1000\n",
      "500/500 [==============================] - 0s 455us/step - loss: 0.0333 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0020\n",
      "Epoch 54/1000\n",
      "500/500 [==============================] - 0s 454us/step - loss: 0.0332 - acc: 0.0020 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0335 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0460\n",
      "Epoch 56/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0333 - acc: 0.0760 - val_loss: 0.0306 - val_acc: 0.0020\n",
      "Epoch 57/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0329 - acc: 0.0000e+00 - val_loss: 0.0300 - val_acc: 0.0820\n",
      "Epoch 58/1000\n",
      "500/500 [==============================] - 0s 458us/step - loss: 0.0327 - acc: 0.1240 - val_loss: 0.0304 - val_acc: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "500/500 [==============================] - 0s 458us/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0301 - val_acc: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0328 - acc: 0.0020 - val_loss: 0.0318 - val_acc: 0.0040\n",
      "Epoch 61/1000\n",
      "500/500 [==============================] - 0s 454us/step - loss: 0.0337 - acc: 0.0100 - val_loss: 0.0313 - val_acc: 0.0020\n",
      "Epoch 62/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "500/500 [==============================] - 0s 457us/step - loss: 0.0329 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0020\n",
      "Epoch 64/1000\n",
      "500/500 [==============================] - 0s 455us/step - loss: 0.0324 - acc: 0.0020 - val_loss: 0.0296 - val_acc: 0.0080\n",
      "Epoch 65/1000\n",
      "500/500 [==============================] - 0s 455us/step - loss: 0.0320 - acc: 0.0080 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "500/500 [==============================] - 0s 457us/step - loss: 0.0319 - acc: 0.0020 - val_loss: 0.0641 - val_acc: 0.0160\n",
      "Epoch 67/1000\n",
      "500/500 [==============================] - 0s 455us/step - loss: 0.0618 - acc: 0.0180 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "500/500 [==============================] - 0s 458us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0307 - val_acc: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "500/500 [==============================] - 0s 458us/step - loss: 0.0331 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0160\n",
      "Epoch 70/1000\n",
      "500/500 [==============================] - 0s 458us/step - loss: 0.0323 - acc: 0.0360 - val_loss: 0.0297 - val_acc: 0.0020\n",
      "Epoch 71/1000\n",
      "500/500 [==============================] - 0s 459us/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0295 - val_acc: 0.0040\n",
      "Epoch 72/1000\n",
      "500/500 [==============================] - 0s 457us/step - loss: 0.0319 - acc: 0.0020 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "500/500 [==============================] - 0s 458us/step - loss: 0.0320 - acc: 0.0020 - val_loss: 0.0299 - val_acc: 0.0520\n",
      "Epoch 74/1000\n",
      "500/500 [==============================] - 0s 457us/step - loss: 0.0325 - acc: 0.0820 - val_loss: 0.0307 - val_acc: 0.0040\n",
      "Epoch 75/1000\n",
      "500/500 [==============================] - 0s 457us/step - loss: 0.0327 - acc: 0.0020 - val_loss: 0.0304 - val_acc: 0.0020\n",
      "Epoch 76/1000\n",
      "500/500 [==============================] - 0s 459us/step - loss: 0.0331 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0400\n",
      "Epoch 77/1000\n",
      "500/500 [==============================] - 0s 458us/step - loss: 0.0335 - acc: 0.0760 - val_loss: 0.0296 - val_acc: 0.0020\n",
      "Epoch 78/1000\n",
      "500/500 [==============================] - 0s 458us/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0420\n",
      "Epoch 79/1000\n",
      "500/500 [==============================] - 0s 473us/step - loss: 0.0318 - acc: 0.0840 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "500/500 [==============================] - 0s 474us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0240\n",
      "Epoch 81/1000\n",
      "500/500 [==============================] - 0s 463us/step - loss: 0.0317 - acc: 0.0640 - val_loss: 0.0294 - val_acc: 0.0020\n",
      "Epoch 82/1000\n",
      "500/500 [==============================] - 0s 478us/step - loss: 0.0318 - acc: 0.0020 - val_loss: 0.0297 - val_acc: 0.0480\n",
      "Epoch 83/1000\n",
      "500/500 [==============================] - 0s 463us/step - loss: 0.0319 - acc: 0.0940 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "500/500 [==============================] - 0s 452us/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "500/500 [==============================] - 0s 455us/step - loss: 0.0327 - acc: 0.0020 - val_loss: 0.0295 - val_acc: 0.0220\n",
      "Epoch 86/1000\n",
      "500/500 [==============================] - 0s 453us/step - loss: 0.0320 - acc: 0.0260 - val_loss: 0.0295 - val_acc: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "500/500 [==============================] - 0s 464us/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0080\n",
      "Epoch 88/1000\n",
      "500/500 [==============================] - 0s 466us/step - loss: 0.0316 - acc: 0.0160 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "500/500 [==============================] - 0s 451us/step - loss: 0.0319 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0180\n",
      "Epoch 90/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0319 - acc: 0.0260 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "500/500 [==============================] - 0s 453us/step - loss: 0.0313 - acc: 0.0020 - val_loss: 0.0292 - val_acc: 0.0240\n",
      "Epoch 92/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0313 - acc: 0.0540 - val_loss: 0.0293 - val_acc: 0.0020\n",
      "Epoch 93/1000\n",
      "500/500 [==============================] - 0s 454us/step - loss: 0.0316 - acc: 0.0020 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0322 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0040\n",
      "Epoch 95/1000\n",
      "500/500 [==============================] - 0s 451us/step - loss: 0.0315 - acc: 0.0060 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "500/500 [==============================] - 0s 453us/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0040\n",
      "Epoch 97/1000\n",
      "500/500 [==============================] - 0s 454us/step - loss: 0.0312 - acc: 0.0120 - val_loss: 0.0291 - val_acc: 0.0080\n",
      "Epoch 98/1000\n",
      "500/500 [==============================] - 0s 453us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "500/500 [==============================] - 0s 452us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0200\n",
      "Epoch 100/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0317 - acc: 0.0680 - val_loss: 0.0295 - val_acc: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "500/500 [==============================] - 0s 454us/step - loss: 0.0313 - acc: 0.0020 - val_loss: 0.0287 - val_acc: 0.0020\n",
      "Epoch 102/1000\n",
      "500/500 [==============================] - 0s 454us/step - loss: 0.0310 - acc: 0.0020 - val_loss: 0.0297 - val_acc: 0.0080\n",
      "Epoch 103/1000\n",
      "500/500 [==============================] - 0s 453us/step - loss: 0.0312 - acc: 0.0100 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0312 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0020\n",
      "Epoch 105/1000\n",
      "500/500 [==============================] - 0s 453us/step - loss: 0.0313 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0040\n",
      "Epoch 106/1000\n",
      "500/500 [==============================] - 0s 458us/step - loss: 0.0308 - acc: 0.0020 - val_loss: 0.0283 - val_acc: 0.0020\n",
      "Epoch 107/1000\n",
      "500/500 [==============================] - 0s 472us/step - loss: 0.0302 - acc: 0.0040 - val_loss: 0.0279 - val_acc: 0.0020\n",
      "Epoch 108/1000\n",
      "500/500 [==============================] - 0s 481us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "500/500 [==============================] - 0s 476us/step - loss: 0.0298 - acc: 0.0040 - val_loss: 0.0283 - val_acc: 0.0060\n",
      "Epoch 110/1000\n",
      "500/500 [==============================] - 0s 473us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "500/500 [==============================] - 0s 494us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "500/500 [==============================] - 0s 479us/step - loss: 0.0300 - acc: 0.0020 - val_loss: 0.0280 - val_acc: 0.0040\n",
      "Epoch 113/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0296 - acc: 0.0060 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "500/500 [==============================] - 0s 459us/step - loss: 0.0303 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0260\n",
      "Epoch 115/1000\n",
      "500/500 [==============================] - 0s 472us/step - loss: 0.0302 - acc: 0.0500 - val_loss: 0.0280 - val_acc: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "500/500 [==============================] - 0s 466us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0100\n",
      "Epoch 117/1000\n",
      "500/500 [==============================] - 0s 464us/step - loss: 0.0311 - acc: 0.0440 - val_loss: 0.0301 - val_acc: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/1000\n",
      "500/500 [==============================] - 0s 456us/step - loss: 0.0313 - acc: 0.0020 - val_loss: 0.0273 - val_acc: 0.0180\n",
      "Epoch 119/1000\n",
      "500/500 [==============================] - 0s 461us/step - loss: 0.0291 - acc: 0.0320 - val_loss: 0.0281 - val_acc: 0.0020\n",
      "Epoch 120/1000\n",
      "500/500 [==============================] - 0s 476us/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0285 - val_acc: 0.0620\n",
      "Epoch 121/1000\n",
      "500/500 [==============================] - 0s 467us/step - loss: 0.0301 - acc: 0.0740 - val_loss: 0.0279 - val_acc: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "500/500 [==============================] - 0s 460us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0040\n",
      "Epoch 123/1000\n",
      "500/500 [==============================] - 0s 473us/step - loss: 0.0276 - acc: 0.0020 - val_loss: 0.0256 - val_acc: 0.0020\n",
      "Epoch 124/1000\n",
      "500/500 [==============================] - 0s 464us/step - loss: 0.0273 - acc: 0.0040 - val_loss: 0.0264 - val_acc: 0.0040\n",
      "Epoch 125/1000\n",
      "500/500 [==============================] - 0s 484us/step - loss: 0.0276 - acc: 0.0280 - val_loss: 0.0261 - val_acc: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "500/500 [==============================] - 0s 465us/step - loss: 0.0279 - acc: 0.0020 - val_loss: 0.0276 - val_acc: 0.0100\n",
      "Epoch 127/1000\n",
      "500/500 [==============================] - 0s 458us/step - loss: 0.0282 - acc: 0.0220 - val_loss: 0.0271 - val_acc: 0.0400\n",
      "Epoch 128/1000\n",
      "500/500 [==============================] - 0s 471us/step - loss: 0.0288 - acc: 0.0580 - val_loss: 0.0261 - val_acc: 0.0040\n",
      "Epoch 129/1000\n",
      "500/500 [==============================] - 0s 459us/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0160\n",
      "Epoch 130/1000\n",
      "500/500 [==============================] - 0s 452us/step - loss: 0.0274 - acc: 0.0060 - val_loss: 0.0262 - val_acc: 0.0060\n",
      "Epoch 131/1000\n",
      "500/500 [==============================] - 0s 465us/step - loss: 0.0273 - acc: 0.0080 - val_loss: 0.0268 - val_acc: 0.0120\n",
      "Epoch 132/1000\n",
      "500/500 [==============================] - 0s 464us/step - loss: 0.0282 - acc: 0.0120 - val_loss: 0.0256 - val_acc: 0.0020\n",
      "Epoch 133/1000\n",
      "500/500 [==============================] - 0s 454us/step - loss: 0.0267 - acc: 0.0020 - val_loss: 0.0256 - val_acc: 0.0100\n",
      "Epoch 134/1000\n",
      "500/500 [==============================] - 0s 450us/step - loss: 0.0267 - acc: 0.0280 - val_loss: 0.0260 - val_acc: 0.0020\n",
      "Epoch 135/1000\n",
      "500/500 [==============================] - 0s 466us/step - loss: 0.0270 - acc: 0.0060 - val_loss: 0.0257 - val_acc: 0.0440\n",
      "Epoch 136/1000\n",
      "500/500 [==============================] - 0s 460us/step - loss: 0.0267 - acc: 0.0560 - val_loss: 0.0257 - val_acc: 0.0020\n",
      "Epoch 137/1000\n",
      "500/500 [==============================] - 0s 476us/step - loss: 0.0269 - acc: 0.0040 - val_loss: 0.0267 - val_acc: 0.0620\n",
      "Epoch 138/1000\n",
      "500/500 [==============================] - 0s 464us/step - loss: 0.0273 - acc: 0.0940 - val_loss: 0.0254 - val_acc: 0.0060\n",
      "Epoch 139/1000\n",
      "500/500 [==============================] - 0s 472us/step - loss: 0.0268 - acc: 0.0080 - val_loss: 0.0357 - val_acc: 0.0140\n",
      "Epoch 140/1000\n",
      "500/500 [==============================] - 0s 472us/step - loss: 0.0364 - acc: 0.0200 - val_loss: 0.0273 - val_acc: 0.0260\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense, Flatten,LSTM, TimeDistributed, Dropout, Reshape\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TIME_STEPS = 10\n",
    "INPUT_SIZE = 512\n",
    "BATCH_SIZE = 500\n",
    "BATCH_INDEX = 0\n",
    "OUTPUT_SIZE = 5120\n",
    "#CELL_SIZE = 800\n",
    "LR = 0.001\n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "# loading data\n",
    "X_train = np.loadtxt(\"0131_spec_train_1000*5120.txt\")\n",
    "y_train = np.loadtxt(\"0131_mask_train_1000*5120.txt\")\n",
    "\n",
    "X_test = np.loadtxt(\"0131_spec_test_1000*5120.txt\")\n",
    "y_test = np.loadtxt(\"0131_mask_test_1000*5120.txt\")\n",
    "\n",
    "# batch_size=y_test.shape[0]\n",
    "\n",
    "# # data pre-processing\n",
    "# X_train = X_train.reshape(-1, 10, 512)\n",
    "# #y_train = y_train.reshape(-1, 3, 512)\n",
    "# X_test = X_test.reshape(-1, 10, 512)\n",
    "# #y_test = y_test.reshape(-1, 3, 512)\n",
    "\n",
    "\n",
    "#  build RNN model\n",
    "model = Sequential( )\n",
    "\n",
    "\n",
    "model.add(Reshape((10,512)))\n",
    "\n",
    "model.add(LSTM(\n",
    "    units =1000,\n",
    "    batch_input_shape=( BATCH_SIZE, TIME_STEPS, INPUT_SIZE),\n",
    "    #input_dim=INPUT_SIZE,\n",
    "    #input_length=TIME_STEPS,\n",
    "    #output_dim=CELL_SIZE,\n",
    "    #return_sequences=True,\n",
    "    #stateful=True \n",
    "    unroll=True\n",
    "))\n",
    "\n",
    "# output layer\n",
    "#model.add(Flatten())\n",
    "model.add((Dense(OUTPUT_SIZE)))#TimeDistributed\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add((Dense(5120)))\n",
    "\n",
    "\n",
    "model.add(Activation('hard_sigmoid'))\n",
    "\n",
    "\n",
    "# # optimizer\n",
    "#\n",
    "# optimizer\n",
    "\n",
    "rmsprop = RMSprop(lr=LR, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # training\n",
    "#\n",
    "\n",
    "# for step in range(51):\n",
    "#     # data shape = (batch_num, steps, inputs/outputs)\n",
    "#     X_batch = X_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :, :]\n",
    "#     Y_batch = y_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :]\n",
    "#     cost = model.train_on_batch(X_batch, Y_batch)\n",
    "#     BATCH_INDEX += BATCH_SIZE\n",
    "#     BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "\n",
    "#     if step % 50 == 0:\n",
    "#         print('Next_Train----------: step = ', step)\n",
    "#         train_cost, train_accuracy = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('train_cost: ', train_cost, 'train_accuracy: ', train_accuracy)\n",
    "#         cost, accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "        \n",
    "       \n",
    "\n",
    "print('Train-------------------------')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.5, epochs=1000, shuffle=False, batch_size=500, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "#                                   [model.layers[1].output])\n",
    "# layer_output1 = get_3rd_layer_output([X_train])[0]\n",
    "\n",
    "# print(layer_output1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = model.predict(X_train[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1536)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Predicted_Training_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mask = y_test.reshape(1000,1536)\n",
    "plt.imshow(abs(y_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = model.predict(X_test[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1536)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Predicted_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear_spec_input_250.txt\n",
    "#clear_mask_generated_from_threshold_250.txt\n",
    "\n",
    "y_c = np.loadtxt(\"clear_mask_generated_from_threshold_250.txt\")\n",
    "\n",
    "y_c = y_c.reshape(250,1024)\n",
    "plt.imshow(abs(y_c[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c = np.loadtxt(\"clear_spec_input_250.txt\")\n",
    "\n",
    "\n",
    "x_c = model.predict(x_c)\n",
    "print('prediction of the model', x_c)\n",
    "print('prediction size', x_c.size)\n",
    "\n",
    "x_c = x_c.reshape(250,1024)\n",
    "plt.imshow(abs(x_c[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Predicted_Mask_for_checking\", fontsize = 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
