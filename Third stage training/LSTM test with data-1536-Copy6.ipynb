{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN test by data-3*512\n",
    "# 5000 steps with lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are better than\n",
    "best run: \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-------------------------\n",
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/1000\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.0333 - acc: 0.0067 - val_loss: 0.0243 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0263 - acc: 0.0067 - val_loss: 0.0218 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 0.0233 - acc: 0.0293 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 4/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 0.0216 - acc: 0.0453 - val_loss: 0.0201 - val_acc: 0.0280\n",
      "Epoch 5/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 0.0203 - acc: 0.0320 - val_loss: 0.0198 - val_acc: 0.0040\n",
      "Epoch 6/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 0.0194 - acc: 0.0187 - val_loss: 0.0197 - val_acc: 0.0040\n",
      "Epoch 7/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 0.0187 - acc: 0.0147 - val_loss: 0.0198 - val_acc: 0.0080\n",
      "Epoch 8/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 0.0180 - acc: 0.0240 - val_loss: 0.0195 - val_acc: 0.0080\n",
      "Epoch 9/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 0.0173 - acc: 0.0173 - val_loss: 0.0193 - val_acc: 0.0120\n",
      "Epoch 10/1000\n",
      "750/750 [==============================] - 0s 630us/step - loss: 0.0167 - acc: 0.0253 - val_loss: 0.0195 - val_acc: 0.0120\n",
      "Epoch 11/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 0.0163 - acc: 0.0253 - val_loss: 0.0194 - val_acc: 0.0200\n",
      "Epoch 12/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 0.0157 - acc: 0.0227 - val_loss: 0.0189 - val_acc: 0.0200\n",
      "Epoch 13/1000\n",
      "750/750 [==============================] - 0s 618us/step - loss: 0.0151 - acc: 0.0293 - val_loss: 0.0190 - val_acc: 0.0160\n",
      "Epoch 14/1000\n",
      "750/750 [==============================] - 0s 638us/step - loss: 0.0146 - acc: 0.0253 - val_loss: 0.0189 - val_acc: 0.0200\n",
      "Epoch 15/1000\n",
      "750/750 [==============================] - 0s 625us/step - loss: 0.0141 - acc: 0.0200 - val_loss: 0.0187 - val_acc: 0.0200\n",
      "Epoch 16/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0136 - acc: 0.0267 - val_loss: 0.0186 - val_acc: 0.0120\n",
      "Epoch 17/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0131 - acc: 0.0320 - val_loss: 0.0189 - val_acc: 0.0240\n",
      "Epoch 18/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 0.0128 - acc: 0.0307 - val_loss: 0.0184 - val_acc: 0.0120\n",
      "Epoch 19/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 0.0126 - acc: 0.0333 - val_loss: 0.0183 - val_acc: 0.0280\n",
      "Epoch 20/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0122 - acc: 0.0253 - val_loss: 0.0183 - val_acc: 0.0280\n",
      "Epoch 21/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 0.0118 - acc: 0.0240 - val_loss: 0.0183 - val_acc: 0.0240\n",
      "Epoch 22/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0116 - acc: 0.0293 - val_loss: 0.0180 - val_acc: 0.0280\n",
      "Epoch 23/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 0.0113 - acc: 0.0320 - val_loss: 0.0184 - val_acc: 0.0320\n",
      "Epoch 24/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 0.0109 - acc: 0.0240 - val_loss: 0.0180 - val_acc: 0.0240\n",
      "Epoch 25/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 0.0106 - acc: 0.0293 - val_loss: 0.0183 - val_acc: 0.0400\n",
      "Epoch 26/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 0.0104 - acc: 0.0227 - val_loss: 0.0182 - val_acc: 0.0240\n",
      "Epoch 27/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0100 - acc: 0.0320 - val_loss: 0.0185 - val_acc: 0.0320\n",
      "Epoch 28/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 0.0097 - acc: 0.0320 - val_loss: 0.0184 - val_acc: 0.0280\n",
      "Epoch 29/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 0.0095 - acc: 0.0333 - val_loss: 0.0187 - val_acc: 0.0240\n",
      "Epoch 30/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 0.0093 - acc: 0.0333 - val_loss: 0.0186 - val_acc: 0.0240\n",
      "Epoch 31/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 0.0090 - acc: 0.0307 - val_loss: 0.0185 - val_acc: 0.0280\n",
      "Epoch 32/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0088 - acc: 0.0333 - val_loss: 0.0188 - val_acc: 0.0280\n",
      "Epoch 33/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0086 - acc: 0.0333 - val_loss: 0.0188 - val_acc: 0.0280\n",
      "Epoch 34/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0085 - acc: 0.0333 - val_loss: 0.0191 - val_acc: 0.0240\n",
      "Epoch 35/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 0.0084 - acc: 0.0267 - val_loss: 0.0191 - val_acc: 0.0200\n",
      "Epoch 36/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0081 - acc: 0.0280 - val_loss: 0.0186 - val_acc: 0.0240\n",
      "Epoch 37/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0078 - acc: 0.0360 - val_loss: 0.0190 - val_acc: 0.0240\n",
      "Epoch 38/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0075 - acc: 0.0280 - val_loss: 0.0190 - val_acc: 0.0240\n",
      "Epoch 39/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0073 - acc: 0.0347 - val_loss: 0.0191 - val_acc: 0.0320\n",
      "Epoch 40/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 0.0072 - acc: 0.0320 - val_loss: 0.0192 - val_acc: 0.0320\n",
      "Epoch 41/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 0.0070 - acc: 0.0413 - val_loss: 0.0199 - val_acc: 0.0360\n",
      "Epoch 42/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0068 - acc: 0.0280 - val_loss: 0.0192 - val_acc: 0.0360\n",
      "Epoch 43/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0066 - acc: 0.0320 - val_loss: 0.0193 - val_acc: 0.0360\n",
      "Epoch 44/1000\n",
      "750/750 [==============================] - 0s 616us/step - loss: 0.0064 - acc: 0.0360 - val_loss: 0.0195 - val_acc: 0.0240\n",
      "Epoch 45/1000\n",
      "750/750 [==============================] - 0s 619us/step - loss: 0.0063 - acc: 0.0387 - val_loss: 0.0197 - val_acc: 0.0280\n",
      "Epoch 46/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 0.0061 - acc: 0.0387 - val_loss: 0.0197 - val_acc: 0.0320\n",
      "Epoch 47/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 0.0061 - acc: 0.0347 - val_loss: 0.0199 - val_acc: 0.0320\n",
      "Epoch 48/1000\n",
      "750/750 [==============================] - 0s 600us/step - loss: 0.0059 - acc: 0.0387 - val_loss: 0.0196 - val_acc: 0.0240\n",
      "Epoch 49/1000\n",
      "750/750 [==============================] - 0s 627us/step - loss: 0.0057 - acc: 0.0333 - val_loss: 0.0200 - val_acc: 0.0240\n",
      "Epoch 50/1000\n",
      "750/750 [==============================] - 0s 601us/step - loss: 0.0056 - acc: 0.0400 - val_loss: 0.0199 - val_acc: 0.0320\n",
      "Epoch 51/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 0.0054 - acc: 0.0347 - val_loss: 0.0202 - val_acc: 0.0240\n",
      "Epoch 52/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0053 - acc: 0.0413 - val_loss: 0.0200 - val_acc: 0.0240\n",
      "Epoch 53/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0052 - acc: 0.0453 - val_loss: 0.0201 - val_acc: 0.0320\n",
      "Epoch 54/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 0.0051 - acc: 0.0373 - val_loss: 0.0204 - val_acc: 0.0200\n",
      "Epoch 55/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0050 - acc: 0.0467 - val_loss: 0.0208 - val_acc: 0.0240\n",
      "Epoch 56/1000\n",
      "750/750 [==============================] - 0s 621us/step - loss: 0.0049 - acc: 0.0360 - val_loss: 0.0207 - val_acc: 0.0240\n",
      "Epoch 57/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 0.0049 - acc: 0.0360 - val_loss: 0.0203 - val_acc: 0.0280\n",
      "Epoch 58/1000\n",
      "750/750 [==============================] - 0s 612us/step - loss: 0.0047 - acc: 0.0427 - val_loss: 0.0208 - val_acc: 0.0280\n",
      "Epoch 59/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 0.0045 - acc: 0.0347 - val_loss: 0.0206 - val_acc: 0.0280\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 586us/step - loss: 0.0044 - acc: 0.0373 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 61/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 0.0044 - acc: 0.0413 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 62/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 0.0042 - acc: 0.0480 - val_loss: 0.0206 - val_acc: 0.0280\n",
      "Epoch 63/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 0.0040 - acc: 0.0320 - val_loss: 0.0212 - val_acc: 0.0200\n",
      "Epoch 64/1000\n",
      "750/750 [==============================] - 0s 608us/step - loss: 0.0040 - acc: 0.0413 - val_loss: 0.0213 - val_acc: 0.0200\n",
      "Epoch 65/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 0.0039 - acc: 0.0413 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 66/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 0.0038 - acc: 0.0413 - val_loss: 0.0209 - val_acc: 0.0200\n",
      "Epoch 67/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 0.0037 - acc: 0.0400 - val_loss: 0.0210 - val_acc: 0.0200\n",
      "Epoch 68/1000\n",
      "750/750 [==============================] - 0s 615us/step - loss: 0.0036 - acc: 0.0400 - val_loss: 0.0211 - val_acc: 0.0240\n",
      "Epoch 69/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 0.0035 - acc: 0.0320 - val_loss: 0.0213 - val_acc: 0.0240\n",
      "Epoch 70/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 0.0034 - acc: 0.0387 - val_loss: 0.0215 - val_acc: 0.0240\n",
      "Epoch 71/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0033 - acc: 0.0440 - val_loss: 0.0213 - val_acc: 0.0240\n",
      "Epoch 72/1000\n",
      "750/750 [==============================] - 0s 618us/step - loss: 0.0033 - acc: 0.0360 - val_loss: 0.0215 - val_acc: 0.0160\n",
      "Epoch 73/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0033 - acc: 0.0360 - val_loss: 0.0218 - val_acc: 0.0200\n",
      "Epoch 74/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 0.0032 - acc: 0.0480 - val_loss: 0.0213 - val_acc: 0.0240\n",
      "Epoch 75/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0032 - acc: 0.0400 - val_loss: 0.0216 - val_acc: 0.0280\n",
      "Epoch 76/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0031 - acc: 0.0373 - val_loss: 0.0214 - val_acc: 0.0200\n",
      "Epoch 77/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 0.0030 - acc: 0.0400 - val_loss: 0.0219 - val_acc: 0.0240\n",
      "Epoch 78/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 0.0029 - acc: 0.0400 - val_loss: 0.0217 - val_acc: 0.0320\n",
      "Epoch 79/1000\n",
      "750/750 [==============================] - 0s 620us/step - loss: 0.0029 - acc: 0.0373 - val_loss: 0.0218 - val_acc: 0.0160\n",
      "Epoch 80/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 0.0030 - acc: 0.0360 - val_loss: 0.0220 - val_acc: 0.0320\n",
      "Epoch 81/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 0.0030 - acc: 0.0493 - val_loss: 0.0217 - val_acc: 0.0320\n",
      "Epoch 82/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0029 - acc: 0.0373 - val_loss: 0.0223 - val_acc: 0.0280\n",
      "Epoch 83/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0028 - acc: 0.0453 - val_loss: 0.0217 - val_acc: 0.0440\n",
      "Epoch 84/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 0.0028 - acc: 0.0387 - val_loss: 0.0224 - val_acc: 0.0240\n",
      "Epoch 85/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0027 - acc: 0.0373 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 86/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0027 - acc: 0.0320 - val_loss: 0.0221 - val_acc: 0.0280\n",
      "Epoch 87/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 0.0026 - acc: 0.0333 - val_loss: 0.0218 - val_acc: 0.0240\n",
      "Epoch 88/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 0.0025 - acc: 0.0373 - val_loss: 0.0222 - val_acc: 0.0400\n",
      "Epoch 89/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 0.0024 - acc: 0.0387 - val_loss: 0.0224 - val_acc: 0.0200\n",
      "Epoch 90/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 0.0024 - acc: 0.0360 - val_loss: 0.0221 - val_acc: 0.0200\n",
      "Epoch 91/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 0.0023 - acc: 0.0347 - val_loss: 0.0225 - val_acc: 0.0240\n",
      "Epoch 92/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0023 - acc: 0.0333 - val_loss: 0.0223 - val_acc: 0.0280\n",
      "Epoch 93/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 0.0022 - acc: 0.0427 - val_loss: 0.0224 - val_acc: 0.0200\n",
      "Epoch 94/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0022 - acc: 0.0373 - val_loss: 0.0222 - val_acc: 0.0200\n",
      "Epoch 95/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 0.0021 - acc: 0.0373 - val_loss: 0.0224 - val_acc: 0.0440\n",
      "Epoch 96/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 0.0021 - acc: 0.0387 - val_loss: 0.0226 - val_acc: 0.0360\n",
      "Epoch 97/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0021 - acc: 0.0373 - val_loss: 0.0221 - val_acc: 0.0280\n",
      "Epoch 98/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 0.0021 - acc: 0.0373 - val_loss: 0.0226 - val_acc: 0.0280\n",
      "Epoch 99/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0020 - acc: 0.0347 - val_loss: 0.0224 - val_acc: 0.0200\n",
      "Epoch 100/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 0.0020 - acc: 0.0387 - val_loss: 0.0225 - val_acc: 0.0320\n",
      "Epoch 101/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 0.0019 - acc: 0.0347 - val_loss: 0.0224 - val_acc: 0.0280\n",
      "Epoch 102/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0018 - acc: 0.0427 - val_loss: 0.0227 - val_acc: 0.0320\n",
      "Epoch 103/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0018 - acc: 0.0347 - val_loss: 0.0225 - val_acc: 0.0440\n",
      "Epoch 104/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0018 - acc: 0.0360 - val_loss: 0.0224 - val_acc: 0.0240\n",
      "Epoch 105/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0017 - acc: 0.0467 - val_loss: 0.0229 - val_acc: 0.0360\n",
      "Epoch 106/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 0.0017 - acc: 0.0453 - val_loss: 0.0226 - val_acc: 0.0320\n",
      "Epoch 107/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 0.0016 - acc: 0.0387 - val_loss: 0.0228 - val_acc: 0.0160\n",
      "Epoch 108/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 0.0016 - acc: 0.0427 - val_loss: 0.0225 - val_acc: 0.0200\n",
      "Epoch 109/1000\n",
      "750/750 [==============================] - 0s 618us/step - loss: 0.0016 - acc: 0.0360 - val_loss: 0.0228 - val_acc: 0.0160\n",
      "Epoch 110/1000\n",
      "750/750 [==============================] - 0s 630us/step - loss: 0.0016 - acc: 0.0333 - val_loss: 0.0228 - val_acc: 0.0360\n",
      "Epoch 111/1000\n",
      "750/750 [==============================] - 0s 624us/step - loss: 0.0016 - acc: 0.0440 - val_loss: 0.0230 - val_acc: 0.0280\n",
      "Epoch 112/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 0.0016 - acc: 0.0373 - val_loss: 0.0229 - val_acc: 0.0200\n",
      "Epoch 113/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 0.0016 - acc: 0.0440 - val_loss: 0.0230 - val_acc: 0.0280\n",
      "Epoch 114/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0016 - acc: 0.0440 - val_loss: 0.0232 - val_acc: 0.0280\n",
      "Epoch 115/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0016 - acc: 0.0440 - val_loss: 0.0229 - val_acc: 0.0200\n",
      "Epoch 116/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 0.0015 - acc: 0.0453 - val_loss: 0.0230 - val_acc: 0.0280\n",
      "Epoch 117/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 0.0015 - acc: 0.0467 - val_loss: 0.0230 - val_acc: 0.0200\n",
      "Epoch 118/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0014 - acc: 0.0373 - val_loss: 0.0232 - val_acc: 0.0240\n",
      "Epoch 119/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 0.0014 - acc: 0.0507 - val_loss: 0.0229 - val_acc: 0.0240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 0.0014 - acc: 0.0480 - val_loss: 0.0228 - val_acc: 0.0160\n",
      "Epoch 121/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 0.0013 - acc: 0.0427 - val_loss: 0.0231 - val_acc: 0.0400\n",
      "Epoch 122/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 0.0013 - acc: 0.0413 - val_loss: 0.0231 - val_acc: 0.0200\n",
      "Epoch 123/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 0.0013 - acc: 0.0453 - val_loss: 0.0233 - val_acc: 0.0400\n",
      "Epoch 124/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 0.0013 - acc: 0.0480 - val_loss: 0.0234 - val_acc: 0.0240\n",
      "Epoch 125/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 0.0013 - acc: 0.0427 - val_loss: 0.0230 - val_acc: 0.0280\n",
      "Epoch 126/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 0.0013 - acc: 0.0480 - val_loss: 0.0233 - val_acc: 0.0360\n",
      "Epoch 127/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 0.0013 - acc: 0.0440 - val_loss: 0.0232 - val_acc: 0.0280\n",
      "Epoch 128/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 0.0012 - acc: 0.0467 - val_loss: 0.0234 - val_acc: 0.0200\n",
      "Epoch 129/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 0.0012 - acc: 0.0493 - val_loss: 0.0228 - val_acc: 0.0240\n",
      "Epoch 130/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 0.0012 - acc: 0.0413 - val_loss: 0.0234 - val_acc: 0.0320\n",
      "Epoch 131/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 0.0012 - acc: 0.0440 - val_loss: 0.0230 - val_acc: 0.0240\n",
      "Epoch 132/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 0.0012 - acc: 0.0480 - val_loss: 0.0232 - val_acc: 0.0400\n",
      "Epoch 133/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 0.0011 - acc: 0.0453 - val_loss: 0.0235 - val_acc: 0.0320\n",
      "Epoch 134/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 0.0011 - acc: 0.0493 - val_loss: 0.0232 - val_acc: 0.0480\n",
      "Epoch 135/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 0.0011 - acc: 0.0493 - val_loss: 0.0234 - val_acc: 0.0280\n",
      "Epoch 136/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 0.0011 - acc: 0.0440 - val_loss: 0.0234 - val_acc: 0.0400\n",
      "Epoch 137/1000\n",
      "750/750 [==============================] - 0s 606us/step - loss: 0.0011 - acc: 0.0427 - val_loss: 0.0233 - val_acc: 0.0360\n",
      "Epoch 138/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 0.0011 - acc: 0.0440 - val_loss: 0.0234 - val_acc: 0.0280\n",
      "Epoch 139/1000\n",
      "750/750 [==============================] - 0s 623us/step - loss: 0.0011 - acc: 0.0493 - val_loss: 0.0233 - val_acc: 0.0320\n",
      "Epoch 140/1000\n",
      "750/750 [==============================] - 0s 615us/step - loss: 0.0010 - acc: 0.0400 - val_loss: 0.0229 - val_acc: 0.0360\n",
      "Epoch 141/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 0.0010 - acc: 0.0347 - val_loss: 0.0237 - val_acc: 0.0360\n",
      "Epoch 142/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 9.7856e-04 - acc: 0.0440 - val_loss: 0.0233 - val_acc: 0.0400\n",
      "Epoch 143/1000\n",
      "750/750 [==============================] - 0s 608us/step - loss: 9.5871e-04 - acc: 0.0467 - val_loss: 0.0233 - val_acc: 0.0320\n",
      "Epoch 144/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 9.6473e-04 - acc: 0.0413 - val_loss: 0.0235 - val_acc: 0.0320\n",
      "Epoch 145/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 9.5294e-04 - acc: 0.0520 - val_loss: 0.0234 - val_acc: 0.0320\n",
      "Epoch 146/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 9.2098e-04 - acc: 0.0400 - val_loss: 0.0231 - val_acc: 0.0320\n",
      "Epoch 147/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 9.3636e-04 - acc: 0.0373 - val_loss: 0.0236 - val_acc: 0.0360\n",
      "Epoch 148/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 9.0976e-04 - acc: 0.0453 - val_loss: 0.0235 - val_acc: 0.0280\n",
      "Epoch 149/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 8.9004e-04 - acc: 0.0413 - val_loss: 0.0234 - val_acc: 0.0280\n",
      "Epoch 150/1000\n",
      "750/750 [==============================] - 0s 601us/step - loss: 8.8813e-04 - acc: 0.0427 - val_loss: 0.0233 - val_acc: 0.0360\n",
      "Epoch 151/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 8.9039e-04 - acc: 0.0387 - val_loss: 0.0237 - val_acc: 0.0440\n",
      "Epoch 152/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 8.6076e-04 - acc: 0.0440 - val_loss: 0.0233 - val_acc: 0.0320\n",
      "Epoch 153/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 8.6938e-04 - acc: 0.0453 - val_loss: 0.0235 - val_acc: 0.0360\n",
      "Epoch 154/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 8.2186e-04 - acc: 0.0400 - val_loss: 0.0234 - val_acc: 0.0400\n",
      "Epoch 155/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 8.0495e-04 - acc: 0.0413 - val_loss: 0.0233 - val_acc: 0.0400\n",
      "Epoch 156/1000\n",
      "750/750 [==============================] - 0s 601us/step - loss: 8.3182e-04 - acc: 0.0400 - val_loss: 0.0234 - val_acc: 0.0440\n",
      "Epoch 157/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 8.2875e-04 - acc: 0.0400 - val_loss: 0.0234 - val_acc: 0.0320\n",
      "Epoch 158/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 8.1210e-04 - acc: 0.0453 - val_loss: 0.0236 - val_acc: 0.0280\n",
      "Epoch 159/1000\n",
      "750/750 [==============================] - 0s 601us/step - loss: 7.7254e-04 - acc: 0.0453 - val_loss: 0.0233 - val_acc: 0.0400\n",
      "Epoch 160/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 7.6270e-04 - acc: 0.0400 - val_loss: 0.0238 - val_acc: 0.0240\n",
      "Epoch 161/1000\n",
      "750/750 [==============================] - 0s 636us/step - loss: 7.5808e-04 - acc: 0.0467 - val_loss: 0.0233 - val_acc: 0.0320\n",
      "Epoch 162/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 7.3385e-04 - acc: 0.0453 - val_loss: 0.0236 - val_acc: 0.0400\n",
      "Epoch 163/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 7.2091e-04 - acc: 0.0413 - val_loss: 0.0236 - val_acc: 0.0320\n",
      "Epoch 164/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 7.0670e-04 - acc: 0.0453 - val_loss: 0.0234 - val_acc: 0.0360\n",
      "Epoch 165/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 6.8726e-04 - acc: 0.0440 - val_loss: 0.0236 - val_acc: 0.0280\n",
      "Epoch 166/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 6.8521e-04 - acc: 0.0440 - val_loss: 0.0234 - val_acc: 0.0280\n",
      "Epoch 167/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 6.9656e-04 - acc: 0.0373 - val_loss: 0.0234 - val_acc: 0.0400\n",
      "Epoch 168/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 7.3435e-04 - acc: 0.0427 - val_loss: 0.0235 - val_acc: 0.0320\n",
      "Epoch 169/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 7.0441e-04 - acc: 0.0400 - val_loss: 0.0234 - val_acc: 0.0280\n",
      "Epoch 170/1000\n",
      "750/750 [==============================] - 0s 616us/step - loss: 6.8756e-04 - acc: 0.0373 - val_loss: 0.0236 - val_acc: 0.0240\n",
      "Epoch 171/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 6.9324e-04 - acc: 0.0333 - val_loss: 0.0236 - val_acc: 0.0360\n",
      "Epoch 172/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 6.7523e-04 - acc: 0.0440 - val_loss: 0.0238 - val_acc: 0.0280\n",
      "Epoch 173/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 7.1092e-04 - acc: 0.0333 - val_loss: 0.0232 - val_acc: 0.0320\n",
      "Epoch 174/1000\n",
      "750/750 [==============================] - 0s 609us/step - loss: 6.8998e-04 - acc: 0.0480 - val_loss: 0.0237 - val_acc: 0.0400\n",
      "Epoch 175/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 6.6551e-04 - acc: 0.0507 - val_loss: 0.0235 - val_acc: 0.0320\n",
      "Epoch 176/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 6.5105e-04 - acc: 0.0400 - val_loss: 0.0237 - val_acc: 0.0280\n",
      "Epoch 177/1000\n",
      "750/750 [==============================] - 0s 604us/step - loss: 6.4600e-04 - acc: 0.0333 - val_loss: 0.0235 - val_acc: 0.0280\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 599us/step - loss: 6.5621e-04 - acc: 0.0427 - val_loss: 0.0236 - val_acc: 0.0320\n",
      "Epoch 179/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 6.6960e-04 - acc: 0.0320 - val_loss: 0.0233 - val_acc: 0.0480\n",
      "Epoch 180/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 6.8233e-04 - acc: 0.0373 - val_loss: 0.0236 - val_acc: 0.0240\n",
      "Epoch 181/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 6.6858e-04 - acc: 0.0440 - val_loss: 0.0234 - val_acc: 0.0200\n",
      "Epoch 182/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 6.2683e-04 - acc: 0.0333 - val_loss: 0.0235 - val_acc: 0.0200\n",
      "Epoch 183/1000\n",
      "750/750 [==============================] - 0s 610us/step - loss: 6.0092e-04 - acc: 0.0467 - val_loss: 0.0235 - val_acc: 0.0360\n",
      "Epoch 184/1000\n",
      "750/750 [==============================] - 0s 601us/step - loss: 5.8147e-04 - acc: 0.0373 - val_loss: 0.0235 - val_acc: 0.0320\n",
      "Epoch 185/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 5.7090e-04 - acc: 0.0520 - val_loss: 0.0235 - val_acc: 0.0240\n",
      "Epoch 186/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 5.5665e-04 - acc: 0.0373 - val_loss: 0.0233 - val_acc: 0.0440\n",
      "Epoch 187/1000\n",
      "750/750 [==============================] - 0s 626us/step - loss: 5.4376e-04 - acc: 0.0520 - val_loss: 0.0237 - val_acc: 0.0280\n",
      "Epoch 188/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 5.5074e-04 - acc: 0.0453 - val_loss: 0.0234 - val_acc: 0.0320\n",
      "Epoch 189/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 5.2002e-04 - acc: 0.0440 - val_loss: 0.0235 - val_acc: 0.0320\n",
      "Epoch 190/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 5.0237e-04 - acc: 0.0307 - val_loss: 0.0237 - val_acc: 0.0320\n",
      "Epoch 191/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 4.9507e-04 - acc: 0.0493 - val_loss: 0.0235 - val_acc: 0.0280\n",
      "Epoch 192/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 4.8169e-04 - acc: 0.0480 - val_loss: 0.0235 - val_acc: 0.0240\n",
      "Epoch 193/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 4.6855e-04 - acc: 0.0400 - val_loss: 0.0234 - val_acc: 0.0360\n",
      "Epoch 194/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 4.7201e-04 - acc: 0.0427 - val_loss: 0.0236 - val_acc: 0.0280\n",
      "Epoch 195/1000\n",
      "750/750 [==============================] - 0s 604us/step - loss: 4.6296e-04 - acc: 0.0347 - val_loss: 0.0236 - val_acc: 0.0240\n",
      "Epoch 196/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 4.5788e-04 - acc: 0.0320 - val_loss: 0.0236 - val_acc: 0.0280\n",
      "Epoch 197/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 4.4804e-04 - acc: 0.0560 - val_loss: 0.0235 - val_acc: 0.0320\n",
      "Epoch 198/1000\n",
      "750/750 [==============================] - 0s 603us/step - loss: 4.3532e-04 - acc: 0.0347 - val_loss: 0.0237 - val_acc: 0.0280\n",
      "Epoch 199/1000\n",
      "750/750 [==============================] - 0s 607us/step - loss: 4.1030e-04 - acc: 0.0387 - val_loss: 0.0234 - val_acc: 0.0280\n",
      "Epoch 200/1000\n",
      "750/750 [==============================] - 0s 604us/step - loss: 4.1412e-04 - acc: 0.0480 - val_loss: 0.0236 - val_acc: 0.0240\n",
      "Epoch 201/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 4.1953e-04 - acc: 0.0373 - val_loss: 0.0235 - val_acc: 0.0280\n",
      "Epoch 202/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 4.4011e-04 - acc: 0.0533 - val_loss: 0.0236 - val_acc: 0.0280\n",
      "Epoch 203/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 4.2801e-04 - acc: 0.0440 - val_loss: 0.0237 - val_acc: 0.0280\n",
      "Epoch 204/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 4.4659e-04 - acc: 0.0387 - val_loss: 0.0235 - val_acc: 0.0440\n",
      "Epoch 205/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 4.7853e-04 - acc: 0.0333 - val_loss: 0.0238 - val_acc: 0.0320\n",
      "Epoch 206/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 5.1631e-04 - acc: 0.0427 - val_loss: 0.0237 - val_acc: 0.0320\n",
      "Epoch 207/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 5.2733e-04 - acc: 0.0333 - val_loss: 0.0235 - val_acc: 0.0360\n",
      "Epoch 208/1000\n",
      "750/750 [==============================] - 0s 608us/step - loss: 5.0886e-04 - acc: 0.0427 - val_loss: 0.0235 - val_acc: 0.0360\n",
      "Epoch 209/1000\n",
      "750/750 [==============================] - 0s 609us/step - loss: 4.8976e-04 - acc: 0.0453 - val_loss: 0.0236 - val_acc: 0.0200\n",
      "Epoch 210/1000\n",
      "750/750 [==============================] - 0s 610us/step - loss: 4.8426e-04 - acc: 0.0507 - val_loss: 0.0235 - val_acc: 0.0200\n",
      "Epoch 211/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 4.5446e-04 - acc: 0.0413 - val_loss: 0.0236 - val_acc: 0.0480\n",
      "Epoch 212/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 4.2720e-04 - acc: 0.0333 - val_loss: 0.0237 - val_acc: 0.0480\n",
      "Epoch 213/1000\n",
      "750/750 [==============================] - 0s 635us/step - loss: 4.1035e-04 - acc: 0.0573 - val_loss: 0.0233 - val_acc: 0.0200\n",
      "Epoch 214/1000\n",
      "750/750 [==============================] - 0s 628us/step - loss: 3.9092e-04 - acc: 0.0480 - val_loss: 0.0237 - val_acc: 0.0320\n",
      "Epoch 215/1000\n",
      "750/750 [==============================] - 0s 626us/step - loss: 4.0109e-04 - acc: 0.0320 - val_loss: 0.0235 - val_acc: 0.0360\n",
      "Epoch 216/1000\n",
      "750/750 [==============================] - 0s 625us/step - loss: 4.1083e-04 - acc: 0.0347 - val_loss: 0.0234 - val_acc: 0.0400\n",
      "Epoch 217/1000\n",
      "750/750 [==============================] - 0s 628us/step - loss: 4.0324e-04 - acc: 0.0480 - val_loss: 0.0234 - val_acc: 0.0320\n",
      "Epoch 218/1000\n",
      "750/750 [==============================] - 0s 629us/step - loss: 3.9678e-04 - acc: 0.0507 - val_loss: 0.0235 - val_acc: 0.0440\n",
      "Epoch 219/1000\n",
      "750/750 [==============================] - 0s 625us/step - loss: 3.8417e-04 - acc: 0.0333 - val_loss: 0.0236 - val_acc: 0.0360\n",
      "Epoch 220/1000\n",
      "750/750 [==============================] - 0s 632us/step - loss: 3.6851e-04 - acc: 0.0347 - val_loss: 0.0235 - val_acc: 0.0400\n",
      "Epoch 221/1000\n",
      "750/750 [==============================] - 0s 636us/step - loss: 3.3583e-04 - acc: 0.0453 - val_loss: 0.0236 - val_acc: 0.0360\n",
      "Epoch 222/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 3.3005e-04 - acc: 0.0453 - val_loss: 0.0235 - val_acc: 0.0360\n",
      "Epoch 223/1000\n",
      "750/750 [==============================] - 0s 638us/step - loss: 3.3174e-04 - acc: 0.0427 - val_loss: 0.0234 - val_acc: 0.0440\n",
      "Epoch 224/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 3.2191e-04 - acc: 0.0493 - val_loss: 0.0237 - val_acc: 0.0320\n",
      "Epoch 225/1000\n",
      "750/750 [==============================] - 0s 613us/step - loss: 3.4637e-04 - acc: 0.0373 - val_loss: 0.0234 - val_acc: 0.0400\n",
      "Epoch 226/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 3.3277e-04 - acc: 0.0427 - val_loss: 0.0236 - val_acc: 0.0320\n",
      "Epoch 227/1000\n",
      "750/750 [==============================] - 0s 601us/step - loss: 3.6123e-04 - acc: 0.0480 - val_loss: 0.0233 - val_acc: 0.0360\n",
      "Epoch 228/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 3.4373e-04 - acc: 0.0467 - val_loss: 0.0234 - val_acc: 0.0320\n",
      "Epoch 229/1000\n",
      "750/750 [==============================] - 0s 600us/step - loss: 3.2107e-04 - acc: 0.0373 - val_loss: 0.0236 - val_acc: 0.0400\n",
      "Epoch 230/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 3.0349e-04 - acc: 0.0493 - val_loss: 0.0234 - val_acc: 0.0240\n",
      "Epoch 231/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 2.8238e-04 - acc: 0.0533 - val_loss: 0.0234 - val_acc: 0.0400\n",
      "Epoch 232/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 2.6674e-04 - acc: 0.0507 - val_loss: 0.0235 - val_acc: 0.0400\n",
      "Epoch 233/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 2.6597e-04 - acc: 0.0440 - val_loss: 0.0235 - val_acc: 0.0280\n",
      "Epoch 234/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 2.6381e-04 - acc: 0.0373 - val_loss: 0.0236 - val_acc: 0.0400\n",
      "Epoch 235/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 2.6308e-04 - acc: 0.0547 - val_loss: 0.0233 - val_acc: 0.0400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 2.6409e-04 - acc: 0.0413 - val_loss: 0.0236 - val_acc: 0.0360\n",
      "Epoch 237/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 2.6299e-04 - acc: 0.0467 - val_loss: 0.0234 - val_acc: 0.0440\n",
      "Epoch 238/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 2.6342e-04 - acc: 0.0427 - val_loss: 0.0236 - val_acc: 0.0400\n",
      "Epoch 239/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 2.6417e-04 - acc: 0.0360 - val_loss: 0.0236 - val_acc: 0.0320\n",
      "Epoch 240/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 2.7192e-04 - acc: 0.0467 - val_loss: 0.0236 - val_acc: 0.0400\n",
      "Epoch 241/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 2.6897e-04 - acc: 0.0467 - val_loss: 0.0236 - val_acc: 0.0360\n",
      "Epoch 242/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 2.5562e-04 - acc: 0.0360 - val_loss: 0.0236 - val_acc: 0.0360\n",
      "Epoch 243/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 2.4608e-04 - acc: 0.0347 - val_loss: 0.0236 - val_acc: 0.0400\n",
      "Epoch 244/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 2.4558e-04 - acc: 0.0440 - val_loss: 0.0237 - val_acc: 0.0360\n",
      "Epoch 245/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 2.2817e-04 - acc: 0.0387 - val_loss: 0.0235 - val_acc: 0.0360\n",
      "Epoch 246/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 2.3270e-04 - acc: 0.0507 - val_loss: 0.0236 - val_acc: 0.0360\n",
      "Epoch 247/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 2.1965e-04 - acc: 0.0453 - val_loss: 0.0235 - val_acc: 0.0360\n",
      "Epoch 248/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 2.2087e-04 - acc: 0.0440 - val_loss: 0.0235 - val_acc: 0.0320\n",
      "Epoch 249/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 2.2396e-04 - acc: 0.0400 - val_loss: 0.0235 - val_acc: 0.0440\n",
      "Epoch 250/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 2.3834e-04 - acc: 0.0533 - val_loss: 0.0235 - val_acc: 0.0320\n",
      "Epoch 251/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 2.6185e-04 - acc: 0.0320 - val_loss: 0.0236 - val_acc: 0.0360\n",
      "Epoch 252/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 2.6639e-04 - acc: 0.0520 - val_loss: 0.0234 - val_acc: 0.0440\n",
      "Epoch 253/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 2.8569e-04 - acc: 0.0413 - val_loss: 0.0234 - val_acc: 0.0360\n",
      "Epoch 254/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 3.0697e-04 - acc: 0.0427 - val_loss: 0.0236 - val_acc: 0.0400\n",
      "Epoch 255/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 3.2664e-04 - acc: 0.0467 - val_loss: 0.0235 - val_acc: 0.0480\n",
      "Epoch 256/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 3.3527e-04 - acc: 0.0413 - val_loss: 0.0234 - val_acc: 0.0320\n",
      "Epoch 257/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 3.3038e-04 - acc: 0.0440 - val_loss: 0.0233 - val_acc: 0.0320\n",
      "Epoch 258/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 3.5187e-04 - acc: 0.0373 - val_loss: 0.0238 - val_acc: 0.0480\n",
      "Epoch 259/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 4.0761e-04 - acc: 0.0440 - val_loss: 0.0234 - val_acc: 0.0400\n",
      "Epoch 260/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 3.8750e-04 - acc: 0.0587 - val_loss: 0.0234 - val_acc: 0.0360\n",
      "Epoch 261/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 3.4550e-04 - acc: 0.0520 - val_loss: 0.0232 - val_acc: 0.0480\n",
      "Epoch 262/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 3.2451e-04 - acc: 0.0453 - val_loss: 0.0233 - val_acc: 0.0320\n",
      "Epoch 263/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 3.1823e-04 - acc: 0.0480 - val_loss: 0.0235 - val_acc: 0.0440\n",
      "Epoch 264/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 2.9522e-04 - acc: 0.0547 - val_loss: 0.0233 - val_acc: 0.0440\n",
      "Epoch 265/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 3.0434e-04 - acc: 0.0453 - val_loss: 0.0233 - val_acc: 0.0360\n",
      "Epoch 266/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 2.9911e-04 - acc: 0.0333 - val_loss: 0.0233 - val_acc: 0.0400\n",
      "Epoch 267/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 3.0775e-04 - acc: 0.0427 - val_loss: 0.0235 - val_acc: 0.0520\n",
      "Epoch 268/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 3.2421e-04 - acc: 0.0480 - val_loss: 0.0234 - val_acc: 0.0400\n",
      "Epoch 269/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 3.2332e-04 - acc: 0.0373 - val_loss: 0.0235 - val_acc: 0.0360\n",
      "Epoch 270/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 3.1573e-04 - acc: 0.0400 - val_loss: 0.0234 - val_acc: 0.0480\n",
      "Epoch 271/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 2.9456e-04 - acc: 0.0387 - val_loss: 0.0235 - val_acc: 0.0400\n",
      "Epoch 272/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 2.7818e-04 - acc: 0.0493 - val_loss: 0.0232 - val_acc: 0.0320\n",
      "Epoch 273/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 2.5890e-04 - acc: 0.0413 - val_loss: 0.0234 - val_acc: 0.0400\n",
      "Epoch 274/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 2.4307e-04 - acc: 0.0413 - val_loss: 0.0232 - val_acc: 0.0400\n",
      "Epoch 275/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 2.3566e-04 - acc: 0.0480 - val_loss: 0.0234 - val_acc: 0.0280\n",
      "Epoch 276/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 2.3900e-04 - acc: 0.0507 - val_loss: 0.0233 - val_acc: 0.0360\n",
      "Epoch 277/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 2.3896e-04 - acc: 0.0480 - val_loss: 0.0231 - val_acc: 0.0240\n",
      "Epoch 278/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 2.2551e-04 - acc: 0.0467 - val_loss: 0.0232 - val_acc: 0.0400\n",
      "Epoch 279/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 2.0712e-04 - acc: 0.0507 - val_loss: 0.0235 - val_acc: 0.0400\n",
      "Epoch 280/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 1.9907e-04 - acc: 0.0440 - val_loss: 0.0233 - val_acc: 0.0440\n",
      "Epoch 281/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.9284e-04 - acc: 0.0467 - val_loss: 0.0234 - val_acc: 0.0400\n",
      "Epoch 282/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.7780e-04 - acc: 0.0400 - val_loss: 0.0233 - val_acc: 0.0320\n",
      "Epoch 283/1000\n",
      "750/750 [==============================] - 0s 580us/step - loss: 1.7726e-04 - acc: 0.0480 - val_loss: 0.0233 - val_acc: 0.0400\n",
      "Epoch 284/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.7227e-04 - acc: 0.0533 - val_loss: 0.0232 - val_acc: 0.0320\n",
      "Epoch 285/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.7081e-04 - acc: 0.0533 - val_loss: 0.0233 - val_acc: 0.0320\n",
      "Epoch 286/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.7239e-04 - acc: 0.0440 - val_loss: 0.0233 - val_acc: 0.0360\n",
      "Epoch 287/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 1.7237e-04 - acc: 0.0520 - val_loss: 0.0232 - val_acc: 0.0320\n",
      "Epoch 288/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 1.7020e-04 - acc: 0.0440 - val_loss: 0.0232 - val_acc: 0.0240\n",
      "Epoch 289/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.7747e-04 - acc: 0.0560 - val_loss: 0.0234 - val_acc: 0.0320\n",
      "Epoch 290/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 1.9955e-04 - acc: 0.0440 - val_loss: 0.0232 - val_acc: 0.0360\n",
      "Epoch 291/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 2.1523e-04 - acc: 0.0533 - val_loss: 0.0234 - val_acc: 0.0240\n",
      "Epoch 292/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 2.1145e-04 - acc: 0.0400 - val_loss: 0.0232 - val_acc: 0.0320\n",
      "Epoch 293/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 2.2331e-04 - acc: 0.0493 - val_loss: 0.0233 - val_acc: 0.0400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 2.2841e-04 - acc: 0.0453 - val_loss: 0.0232 - val_acc: 0.0280\n",
      "Epoch 295/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 2.0972e-04 - acc: 0.0560 - val_loss: 0.0233 - val_acc: 0.0360\n",
      "Epoch 296/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 1.9196e-04 - acc: 0.0427 - val_loss: 0.0233 - val_acc: 0.0280\n",
      "Epoch 297/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.9873e-04 - acc: 0.0387 - val_loss: 0.0231 - val_acc: 0.0320\n",
      "Epoch 298/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 1.9014e-04 - acc: 0.0560 - val_loss: 0.0232 - val_acc: 0.0360\n",
      "Epoch 299/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.9480e-04 - acc: 0.0507 - val_loss: 0.0234 - val_acc: 0.0360\n",
      "Epoch 300/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 2.0329e-04 - acc: 0.0387 - val_loss: 0.0231 - val_acc: 0.0320\n",
      "Epoch 301/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 2.1748e-04 - acc: 0.0600 - val_loss: 0.0230 - val_acc: 0.0360\n",
      "Epoch 302/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 2.1373e-04 - acc: 0.0480 - val_loss: 0.0232 - val_acc: 0.0320\n",
      "Epoch 303/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 2.3225e-04 - acc: 0.0480 - val_loss: 0.0232 - val_acc: 0.0360\n",
      "Epoch 304/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 2.1389e-04 - acc: 0.0493 - val_loss: 0.0230 - val_acc: 0.0440\n",
      "Epoch 305/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 2.1938e-04 - acc: 0.0440 - val_loss: 0.0232 - val_acc: 0.0240\n",
      "Epoch 306/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 2.0361e-04 - acc: 0.0400 - val_loss: 0.0232 - val_acc: 0.0320\n",
      "Epoch 307/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 1.8673e-04 - acc: 0.0573 - val_loss: 0.0232 - val_acc: 0.0360\n",
      "Epoch 308/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 1.8511e-04 - acc: 0.0507 - val_loss: 0.0231 - val_acc: 0.0320\n",
      "Epoch 309/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.9591e-04 - acc: 0.0533 - val_loss: 0.0232 - val_acc: 0.0280\n",
      "Epoch 310/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 2.4754e-04 - acc: 0.0493 - val_loss: 0.0230 - val_acc: 0.0400\n",
      "Epoch 311/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 2.4559e-04 - acc: 0.0467 - val_loss: 0.0230 - val_acc: 0.0360\n",
      "Epoch 312/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 2.3366e-04 - acc: 0.0547 - val_loss: 0.0233 - val_acc: 0.0400\n",
      "Epoch 313/1000\n",
      "750/750 [==============================] - 0s 637us/step - loss: 2.0662e-04 - acc: 0.0413 - val_loss: 0.0231 - val_acc: 0.0280\n",
      "Epoch 314/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 1.9930e-04 - acc: 0.0627 - val_loss: 0.0232 - val_acc: 0.0360\n",
      "Epoch 315/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 1.8968e-04 - acc: 0.0507 - val_loss: 0.0231 - val_acc: 0.0320\n",
      "Epoch 316/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 1.8137e-04 - acc: 0.0507 - val_loss: 0.0231 - val_acc: 0.0320\n",
      "Epoch 317/1000\n",
      "750/750 [==============================] - 0s 600us/step - loss: 1.7011e-04 - acc: 0.0627 - val_loss: 0.0231 - val_acc: 0.0400\n",
      "Epoch 318/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 1.6651e-04 - acc: 0.0533 - val_loss: 0.0231 - val_acc: 0.0280\n",
      "Epoch 319/1000\n",
      "750/750 [==============================] - 0s 610us/step - loss: 1.5895e-04 - acc: 0.0493 - val_loss: 0.0232 - val_acc: 0.0320\n",
      "Epoch 320/1000\n",
      "750/750 [==============================] - 0s 622us/step - loss: 1.6522e-04 - acc: 0.0600 - val_loss: 0.0229 - val_acc: 0.0320\n",
      "Epoch 321/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 1.6545e-04 - acc: 0.0547 - val_loss: 0.0230 - val_acc: 0.0360\n",
      "Epoch 322/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 1.6833e-04 - acc: 0.0520 - val_loss: 0.0231 - val_acc: 0.0320\n",
      "Epoch 323/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 1.8199e-04 - acc: 0.0427 - val_loss: 0.0230 - val_acc: 0.0320\n",
      "Epoch 324/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 2.0030e-04 - acc: 0.0453 - val_loss: 0.0230 - val_acc: 0.0280\n",
      "Epoch 325/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 2.1600e-04 - acc: 0.0400 - val_loss: 0.0232 - val_acc: 0.0360\n",
      "Epoch 326/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 2.3657e-04 - acc: 0.0493 - val_loss: 0.0230 - val_acc: 0.0320\n",
      "Epoch 327/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 2.4962e-04 - acc: 0.0547 - val_loss: 0.0228 - val_acc: 0.0360\n",
      "Epoch 328/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 2.3541e-04 - acc: 0.0400 - val_loss: 0.0233 - val_acc: 0.0280\n",
      "Epoch 329/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 2.3202e-04 - acc: 0.0547 - val_loss: 0.0228 - val_acc: 0.0320\n",
      "Epoch 330/1000\n",
      "750/750 [==============================] - 0s 611us/step - loss: 2.2815e-04 - acc: 0.0560 - val_loss: 0.0230 - val_acc: 0.0280\n",
      "Epoch 331/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 2.1536e-04 - acc: 0.0467 - val_loss: 0.0230 - val_acc: 0.0400\n",
      "Epoch 332/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 2.0754e-04 - acc: 0.0427 - val_loss: 0.0228 - val_acc: 0.0320\n",
      "Epoch 333/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 1.8833e-04 - acc: 0.0493 - val_loss: 0.0231 - val_acc: 0.0280\n",
      "Epoch 334/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.7051e-04 - acc: 0.0467 - val_loss: 0.0230 - val_acc: 0.0240\n",
      "Epoch 335/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.6471e-04 - acc: 0.0413 - val_loss: 0.0230 - val_acc: 0.0360\n",
      "Epoch 336/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.6085e-04 - acc: 0.0520 - val_loss: 0.0229 - val_acc: 0.0280\n",
      "Epoch 337/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 1.5958e-04 - acc: 0.0387 - val_loss: 0.0231 - val_acc: 0.0360\n",
      "Epoch 338/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.5851e-04 - acc: 0.0493 - val_loss: 0.0229 - val_acc: 0.0280\n",
      "Epoch 339/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.6500e-04 - acc: 0.0493 - val_loss: 0.0229 - val_acc: 0.0280\n",
      "Epoch 340/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.5823e-04 - acc: 0.0387 - val_loss: 0.0229 - val_acc: 0.0240\n",
      "Epoch 341/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.5350e-04 - acc: 0.0560 - val_loss: 0.0230 - val_acc: 0.0360\n",
      "Epoch 342/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.5346e-04 - acc: 0.0440 - val_loss: 0.0228 - val_acc: 0.0240\n",
      "Epoch 343/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.5749e-04 - acc: 0.0560 - val_loss: 0.0229 - val_acc: 0.0240\n",
      "Epoch 344/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.5017e-04 - acc: 0.0373 - val_loss: 0.0230 - val_acc: 0.0280\n",
      "Epoch 345/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 1.3814e-04 - acc: 0.0600 - val_loss: 0.0230 - val_acc: 0.0360\n",
      "Epoch 346/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 1.3675e-04 - acc: 0.0440 - val_loss: 0.0229 - val_acc: 0.0400\n",
      "Epoch 347/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 1.4225e-04 - acc: 0.0493 - val_loss: 0.0229 - val_acc: 0.0280\n",
      "Epoch 348/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 1.5091e-04 - acc: 0.0533 - val_loss: 0.0228 - val_acc: 0.0280\n",
      "Epoch 349/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 1.5640e-04 - acc: 0.0507 - val_loss: 0.0229 - val_acc: 0.0280\n",
      "Epoch 350/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.5880e-04 - acc: 0.0493 - val_loss: 0.0226 - val_acc: 0.0320\n",
      "Epoch 351/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.6861e-04 - acc: 0.0547 - val_loss: 0.0230 - val_acc: 0.0360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.6781e-04 - acc: 0.0533 - val_loss: 0.0227 - val_acc: 0.0320\n",
      "Epoch 353/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 1.7591e-04 - acc: 0.0533 - val_loss: 0.0230 - val_acc: 0.0320\n",
      "Epoch 354/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.7671e-04 - acc: 0.0587 - val_loss: 0.0228 - val_acc: 0.0360\n",
      "Epoch 355/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 1.6790e-04 - acc: 0.0600 - val_loss: 0.0229 - val_acc: 0.0360\n",
      "Epoch 356/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.4895e-04 - acc: 0.0387 - val_loss: 0.0228 - val_acc: 0.0360\n",
      "Epoch 357/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.4469e-04 - acc: 0.0680 - val_loss: 0.0228 - val_acc: 0.0320\n",
      "Epoch 358/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.3936e-04 - acc: 0.0480 - val_loss: 0.0227 - val_acc: 0.0360\n",
      "Epoch 359/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.4140e-04 - acc: 0.0413 - val_loss: 0.0230 - val_acc: 0.0360\n",
      "Epoch 360/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 1.3596e-04 - acc: 0.0453 - val_loss: 0.0228 - val_acc: 0.0360\n",
      "Epoch 361/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.2844e-04 - acc: 0.0587 - val_loss: 0.0229 - val_acc: 0.0360\n",
      "Epoch 362/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 1.2590e-04 - acc: 0.0560 - val_loss: 0.0228 - val_acc: 0.0360\n",
      "Epoch 363/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 1.2716e-04 - acc: 0.0427 - val_loss: 0.0228 - val_acc: 0.0400\n",
      "Epoch 364/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.1955e-04 - acc: 0.0667 - val_loss: 0.0229 - val_acc: 0.0400\n",
      "Epoch 365/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.1715e-04 - acc: 0.0480 - val_loss: 0.0228 - val_acc: 0.0360\n",
      "Epoch 366/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 1.0549e-04 - acc: 0.0533 - val_loss: 0.0228 - val_acc: 0.0280\n",
      "Epoch 367/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 9.7768e-05 - acc: 0.0533 - val_loss: 0.0229 - val_acc: 0.0440\n",
      "Epoch 368/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 9.8058e-05 - acc: 0.0613 - val_loss: 0.0227 - val_acc: 0.0320\n",
      "Epoch 369/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 9.7196e-05 - acc: 0.0493 - val_loss: 0.0229 - val_acc: 0.0360\n",
      "Epoch 370/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 9.2977e-05 - acc: 0.0480 - val_loss: 0.0227 - val_acc: 0.0360\n",
      "Epoch 371/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 9.4838e-05 - acc: 0.0533 - val_loss: 0.0228 - val_acc: 0.0440\n",
      "Epoch 372/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 9.4366e-05 - acc: 0.0387 - val_loss: 0.0228 - val_acc: 0.0400\n",
      "Epoch 373/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 9.4489e-05 - acc: 0.0600 - val_loss: 0.0227 - val_acc: 0.0320\n",
      "Epoch 374/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 9.2617e-05 - acc: 0.0693 - val_loss: 0.0227 - val_acc: 0.0320\n",
      "Epoch 375/1000\n",
      "750/750 [==============================] - 0s 601us/step - loss: 1.0283e-04 - acc: 0.0440 - val_loss: 0.0228 - val_acc: 0.0320\n",
      "Epoch 376/1000\n",
      "750/750 [==============================] - 0s 622us/step - loss: 1.0591e-04 - acc: 0.0547 - val_loss: 0.0228 - val_acc: 0.0320\n",
      "Epoch 377/1000\n",
      "750/750 [==============================] - 0s 627us/step - loss: 1.1639e-04 - acc: 0.0520 - val_loss: 0.0229 - val_acc: 0.0360\n",
      "Epoch 378/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 1.3608e-04 - acc: 0.0493 - val_loss: 0.0228 - val_acc: 0.0320\n",
      "Epoch 379/1000\n",
      "750/750 [==============================] - 0s 621us/step - loss: 1.6542e-04 - acc: 0.0467 - val_loss: 0.0227 - val_acc: 0.0400\n",
      "Epoch 380/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 1.8435e-04 - acc: 0.0520 - val_loss: 0.0228 - val_acc: 0.0360\n",
      "Epoch 381/1000\n",
      "750/750 [==============================] - 0s 613us/step - loss: 1.9365e-04 - acc: 0.0467 - val_loss: 0.0228 - val_acc: 0.0400\n",
      "Epoch 382/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 1.9704e-04 - acc: 0.0507 - val_loss: 0.0227 - val_acc: 0.0320\n",
      "Epoch 383/1000\n",
      "750/750 [==============================] - 0s 622us/step - loss: 2.0205e-04 - acc: 0.0493 - val_loss: 0.0226 - val_acc: 0.0320\n",
      "Epoch 384/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 2.1193e-04 - acc: 0.0413 - val_loss: 0.0228 - val_acc: 0.0280\n",
      "Epoch 385/1000\n",
      "750/750 [==============================] - 0s 632us/step - loss: 2.1998e-04 - acc: 0.0520 - val_loss: 0.0225 - val_acc: 0.0360\n",
      "Epoch 386/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 2.4190e-04 - acc: 0.0493 - val_loss: 0.0227 - val_acc: 0.0320\n",
      "Epoch 387/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 2.4416e-04 - acc: 0.0413 - val_loss: 0.0226 - val_acc: 0.0280\n",
      "Epoch 388/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 2.5045e-04 - acc: 0.0547 - val_loss: 0.0226 - val_acc: 0.0320\n",
      "Epoch 389/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 2.5128e-04 - acc: 0.0480 - val_loss: 0.0226 - val_acc: 0.0400\n",
      "Epoch 390/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 2.2345e-04 - acc: 0.0440 - val_loss: 0.0225 - val_acc: 0.0360\n",
      "Epoch 391/1000\n",
      "750/750 [==============================] - 0s 625us/step - loss: 2.0180e-04 - acc: 0.0467 - val_loss: 0.0226 - val_acc: 0.0280\n",
      "Epoch 392/1000\n",
      "750/750 [==============================] - 0s 609us/step - loss: 1.9373e-04 - acc: 0.0440 - val_loss: 0.0225 - val_acc: 0.0360\n",
      "Epoch 393/1000\n",
      "750/750 [==============================] - 0s 617us/step - loss: 1.8340e-04 - acc: 0.0427 - val_loss: 0.0227 - val_acc: 0.0360\n",
      "Epoch 394/1000\n",
      "750/750 [==============================] - 0s 631us/step - loss: 1.7304e-04 - acc: 0.0440 - val_loss: 0.0224 - val_acc: 0.0440\n",
      "Epoch 395/1000\n",
      "750/750 [==============================] - 0s 616us/step - loss: 1.7310e-04 - acc: 0.0680 - val_loss: 0.0226 - val_acc: 0.0320\n",
      "Epoch 396/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 1.7267e-04 - acc: 0.0427 - val_loss: 0.0225 - val_acc: 0.0360\n",
      "Epoch 397/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.7103e-04 - acc: 0.0493 - val_loss: 0.0226 - val_acc: 0.0320\n",
      "Epoch 398/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 1.7600e-04 - acc: 0.0467 - val_loss: 0.0225 - val_acc: 0.0360\n",
      "Epoch 399/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 1.7744e-04 - acc: 0.0413 - val_loss: 0.0225 - val_acc: 0.0320\n",
      "Epoch 400/1000\n",
      "750/750 [==============================] - 0s 606us/step - loss: 1.6927e-04 - acc: 0.0573 - val_loss: 0.0225 - val_acc: 0.0400\n",
      "Epoch 401/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 1.7859e-04 - acc: 0.0520 - val_loss: 0.0224 - val_acc: 0.0360\n",
      "Epoch 402/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 1.6620e-04 - acc: 0.0413 - val_loss: 0.0228 - val_acc: 0.0280\n",
      "Epoch 403/1000\n",
      "750/750 [==============================] - 0s 617us/step - loss: 1.6567e-04 - acc: 0.0533 - val_loss: 0.0224 - val_acc: 0.0400\n",
      "Epoch 404/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 1.7923e-04 - acc: 0.0467 - val_loss: 0.0228 - val_acc: 0.0360\n",
      "Epoch 405/1000\n",
      "750/750 [==============================] - 0s 617us/step - loss: 1.8554e-04 - acc: 0.0480 - val_loss: 0.0225 - val_acc: 0.0320\n",
      "Epoch 406/1000\n",
      "750/750 [==============================] - 0s 613us/step - loss: 1.7658e-04 - acc: 0.0587 - val_loss: 0.0226 - val_acc: 0.0320\n",
      "Epoch 407/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.6225e-04 - acc: 0.0520 - val_loss: 0.0224 - val_acc: 0.0360\n",
      "Epoch 408/1000\n",
      "750/750 [==============================] - 0s 618us/step - loss: 1.6749e-04 - acc: 0.0520 - val_loss: 0.0226 - val_acc: 0.0280\n",
      "Epoch 409/1000\n",
      "750/750 [==============================] - 0s 615us/step - loss: 1.6283e-04 - acc: 0.0640 - val_loss: 0.0225 - val_acc: 0.0400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 1.5511e-04 - acc: 0.0453 - val_loss: 0.0227 - val_acc: 0.0320\n",
      "Epoch 411/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 1.5097e-04 - acc: 0.0400 - val_loss: 0.0222 - val_acc: 0.0360\n",
      "Epoch 412/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 1.5278e-04 - acc: 0.0507 - val_loss: 0.0226 - val_acc: 0.0320\n",
      "Epoch 413/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 1.3923e-04 - acc: 0.0600 - val_loss: 0.0224 - val_acc: 0.0440\n",
      "Epoch 414/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 1.2883e-04 - acc: 0.0587 - val_loss: 0.0227 - val_acc: 0.0400\n",
      "Epoch 415/1000\n",
      "750/750 [==============================] - 0s 619us/step - loss: 1.2252e-04 - acc: 0.0453 - val_loss: 0.0223 - val_acc: 0.0400\n",
      "Epoch 416/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 1.1416e-04 - acc: 0.0493 - val_loss: 0.0226 - val_acc: 0.0400\n",
      "Epoch 417/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 1.0424e-04 - acc: 0.0520 - val_loss: 0.0223 - val_acc: 0.0440\n",
      "Epoch 418/1000\n",
      "750/750 [==============================] - 0s 616us/step - loss: 9.8259e-05 - acc: 0.0453 - val_loss: 0.0226 - val_acc: 0.0360\n",
      "Epoch 419/1000\n",
      "750/750 [==============================] - 0s 616us/step - loss: 8.4025e-05 - acc: 0.0440 - val_loss: 0.0224 - val_acc: 0.0440\n",
      "Epoch 420/1000\n",
      "750/750 [==============================] - 0s 608us/step - loss: 7.8279e-05 - acc: 0.0613 - val_loss: 0.0225 - val_acc: 0.0360\n",
      "Epoch 421/1000\n",
      "750/750 [==============================] - 0s 618us/step - loss: 6.6622e-05 - acc: 0.0640 - val_loss: 0.0224 - val_acc: 0.0320\n",
      "Epoch 422/1000\n",
      "750/750 [==============================] - 0s 623us/step - loss: 6.3875e-05 - acc: 0.0533 - val_loss: 0.0225 - val_acc: 0.0400\n",
      "Epoch 423/1000\n",
      "750/750 [==============================] - 0s 615us/step - loss: 5.9056e-05 - acc: 0.0427 - val_loss: 0.0225 - val_acc: 0.0400\n",
      "Epoch 424/1000\n",
      "750/750 [==============================] - 0s 612us/step - loss: 5.7301e-05 - acc: 0.0547 - val_loss: 0.0225 - val_acc: 0.0360\n",
      "Epoch 425/1000\n",
      "750/750 [==============================] - 0s 615us/step - loss: 5.4960e-05 - acc: 0.0640 - val_loss: 0.0224 - val_acc: 0.0440\n",
      "Epoch 426/1000\n",
      "750/750 [==============================] - 0s 619us/step - loss: 5.5048e-05 - acc: 0.0547 - val_loss: 0.0226 - val_acc: 0.0400\n",
      "Epoch 427/1000\n",
      "750/750 [==============================] - 0s 610us/step - loss: 5.4846e-05 - acc: 0.0520 - val_loss: 0.0224 - val_acc: 0.0280\n",
      "Epoch 428/1000\n",
      "750/750 [==============================] - 0s 618us/step - loss: 5.7267e-05 - acc: 0.0453 - val_loss: 0.0225 - val_acc: 0.0440\n",
      "Epoch 429/1000\n",
      "750/750 [==============================] - 0s 618us/step - loss: 6.5200e-05 - acc: 0.0707 - val_loss: 0.0225 - val_acc: 0.0360\n",
      "Epoch 430/1000\n",
      "750/750 [==============================] - 0s 627us/step - loss: 7.0240e-05 - acc: 0.0560 - val_loss: 0.0225 - val_acc: 0.0400\n",
      "Epoch 431/1000\n",
      "750/750 [==============================] - 0s 622us/step - loss: 7.3965e-05 - acc: 0.0453 - val_loss: 0.0224 - val_acc: 0.0360\n",
      "Epoch 432/1000\n",
      "750/750 [==============================] - 0s 628us/step - loss: 7.9152e-05 - acc: 0.0467 - val_loss: 0.0225 - val_acc: 0.0280\n",
      "Epoch 433/1000\n",
      "750/750 [==============================] - 0s 622us/step - loss: 8.3581e-05 - acc: 0.0547 - val_loss: 0.0224 - val_acc: 0.0480\n",
      "Epoch 434/1000\n",
      "750/750 [==============================] - 0s 603us/step - loss: 8.3490e-05 - acc: 0.0573 - val_loss: 0.0225 - val_acc: 0.0440\n",
      "Epoch 435/1000\n",
      "750/750 [==============================] - 0s 617us/step - loss: 8.1505e-05 - acc: 0.0493 - val_loss: 0.0224 - val_acc: 0.0400\n",
      "Epoch 436/1000\n",
      "750/750 [==============================] - 0s 605us/step - loss: 8.5182e-05 - acc: 0.0613 - val_loss: 0.0226 - val_acc: 0.0360\n",
      "Epoch 437/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 9.1405e-05 - acc: 0.0573 - val_loss: 0.0224 - val_acc: 0.0320\n",
      "Epoch 438/1000\n",
      "750/750 [==============================] - 0s 616us/step - loss: 8.8797e-05 - acc: 0.0627 - val_loss: 0.0224 - val_acc: 0.0440\n",
      "Epoch 439/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 9.5226e-05 - acc: 0.0587 - val_loss: 0.0225 - val_acc: 0.0400\n",
      "Epoch 440/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 1.0592e-04 - acc: 0.0427 - val_loss: 0.0224 - val_acc: 0.0360\n",
      "Epoch 441/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 1.1859e-04 - acc: 0.0480 - val_loss: 0.0224 - val_acc: 0.0320\n",
      "Epoch 442/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 1.2296e-04 - acc: 0.0427 - val_loss: 0.0223 - val_acc: 0.0320\n",
      "Epoch 443/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 1.1875e-04 - acc: 0.0600 - val_loss: 0.0226 - val_acc: 0.0440\n",
      "Epoch 444/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 1.3558e-04 - acc: 0.0400 - val_loss: 0.0222 - val_acc: 0.0320\n",
      "Epoch 445/1000\n",
      "750/750 [==============================] - 0s 615us/step - loss: 1.3920e-04 - acc: 0.0520 - val_loss: 0.0225 - val_acc: 0.0360\n",
      "Epoch 446/1000\n",
      "750/750 [==============================] - 0s 629us/step - loss: 1.5525e-04 - acc: 0.0493 - val_loss: 0.0224 - val_acc: 0.0360\n",
      "Epoch 447/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 1.7015e-04 - acc: 0.0587 - val_loss: 0.0224 - val_acc: 0.0280\n",
      "Epoch 448/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.8550e-04 - acc: 0.0573 - val_loss: 0.0224 - val_acc: 0.0320\n",
      "Epoch 449/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 1.9260e-04 - acc: 0.0653 - val_loss: 0.0224 - val_acc: 0.0360\n",
      "Epoch 450/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 2.1259e-04 - acc: 0.0373 - val_loss: 0.0224 - val_acc: 0.0440\n",
      "Epoch 451/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 2.3879e-04 - acc: 0.0507 - val_loss: 0.0225 - val_acc: 0.0480\n",
      "Epoch 452/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 2.1700e-04 - acc: 0.0533 - val_loss: 0.0221 - val_acc: 0.0360\n",
      "Epoch 453/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.9349e-04 - acc: 0.0453 - val_loss: 0.0224 - val_acc: 0.0400\n",
      "Epoch 454/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 1.8221e-04 - acc: 0.0480 - val_loss: 0.0222 - val_acc: 0.0360\n",
      "Epoch 455/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 1.7444e-04 - acc: 0.0547 - val_loss: 0.0223 - val_acc: 0.0400\n",
      "Epoch 456/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.6342e-04 - acc: 0.0507 - val_loss: 0.0223 - val_acc: 0.0360\n",
      "Epoch 457/1000\n",
      "750/750 [==============================] - 0s 600us/step - loss: 1.7602e-04 - acc: 0.0440 - val_loss: 0.0221 - val_acc: 0.0360\n",
      "Epoch 458/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 1.8262e-04 - acc: 0.0493 - val_loss: 0.0224 - val_acc: 0.0400\n",
      "Epoch 459/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 2.0171e-04 - acc: 0.0440 - val_loss: 0.0221 - val_acc: 0.0400\n",
      "Epoch 460/1000\n",
      "750/750 [==============================] - 0s 607us/step - loss: 2.1146e-04 - acc: 0.0627 - val_loss: 0.0223 - val_acc: 0.0480\n",
      "Epoch 461/1000\n",
      "750/750 [==============================] - 0s 638us/step - loss: 2.0169e-04 - acc: 0.0600 - val_loss: 0.0220 - val_acc: 0.0360\n",
      "Epoch 462/1000\n",
      "750/750 [==============================] - 0s 612us/step - loss: 1.9220e-04 - acc: 0.0400 - val_loss: 0.0224 - val_acc: 0.0360\n",
      "Epoch 463/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.8053e-04 - acc: 0.0533 - val_loss: 0.0221 - val_acc: 0.0400\n",
      "Epoch 464/1000\n",
      "750/750 [==============================] - 0s 620us/step - loss: 1.7032e-04 - acc: 0.0427 - val_loss: 0.0224 - val_acc: 0.0360\n",
      "Epoch 465/1000\n",
      "750/750 [==============================] - 0s 603us/step - loss: 1.6786e-04 - acc: 0.0533 - val_loss: 0.0219 - val_acc: 0.0400\n",
      "Epoch 466/1000\n",
      "750/750 [==============================] - 0s 629us/step - loss: 1.6363e-04 - acc: 0.0453 - val_loss: 0.0223 - val_acc: 0.0480\n",
      "Epoch 467/1000\n",
      "750/750 [==============================] - 0s 621us/step - loss: 1.4752e-04 - acc: 0.0533 - val_loss: 0.0220 - val_acc: 0.0400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/1000\n",
      "750/750 [==============================] - 0s 622us/step - loss: 1.3488e-04 - acc: 0.0440 - val_loss: 0.0222 - val_acc: 0.0400\n",
      "Epoch 469/1000\n",
      "750/750 [==============================] - 0s 622us/step - loss: 1.1324e-04 - acc: 0.0560 - val_loss: 0.0222 - val_acc: 0.0440\n",
      "Epoch 470/1000\n",
      "750/750 [==============================] - 0s 613us/step - loss: 1.0428e-04 - acc: 0.0507 - val_loss: 0.0221 - val_acc: 0.0440\n",
      "Epoch 471/1000\n",
      "750/750 [==============================] - 0s 611us/step - loss: 9.6063e-05 - acc: 0.0440 - val_loss: 0.0219 - val_acc: 0.0400\n",
      "Epoch 472/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 9.2876e-05 - acc: 0.0480 - val_loss: 0.0226 - val_acc: 0.0400\n",
      "Epoch 473/1000\n",
      "750/750 [==============================] - 0s 611us/step - loss: 9.8848e-05 - acc: 0.0520 - val_loss: 0.0220 - val_acc: 0.0400\n",
      "Epoch 474/1000\n",
      "750/750 [==============================] - 0s 620us/step - loss: 1.1040e-04 - acc: 0.0573 - val_loss: 0.0222 - val_acc: 0.0360\n",
      "Epoch 475/1000\n",
      "750/750 [==============================] - 0s 609us/step - loss: 1.2036e-04 - acc: 0.0533 - val_loss: 0.0220 - val_acc: 0.0400\n",
      "Epoch 476/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 1.2795e-04 - acc: 0.0520 - val_loss: 0.0223 - val_acc: 0.0440\n",
      "Epoch 477/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 1.2269e-04 - acc: 0.0560 - val_loss: 0.0221 - val_acc: 0.0360\n",
      "Epoch 478/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 1.2321e-04 - acc: 0.0587 - val_loss: 0.0221 - val_acc: 0.0440\n",
      "Epoch 479/1000\n",
      "750/750 [==============================] - 0s 611us/step - loss: 1.2492e-04 - acc: 0.0453 - val_loss: 0.0220 - val_acc: 0.0400\n",
      "Epoch 480/1000\n",
      "750/750 [==============================] - 0s 631us/step - loss: 1.2471e-04 - acc: 0.0467 - val_loss: 0.0224 - val_acc: 0.0440\n",
      "Epoch 481/1000\n",
      "750/750 [==============================] - 0s 609us/step - loss: 1.2389e-04 - acc: 0.0613 - val_loss: 0.0220 - val_acc: 0.0320\n",
      "Epoch 482/1000\n",
      "750/750 [==============================] - 0s 608us/step - loss: 1.2131e-04 - acc: 0.0613 - val_loss: 0.0222 - val_acc: 0.0400\n",
      "Epoch 483/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 1.3061e-04 - acc: 0.0507 - val_loss: 0.0220 - val_acc: 0.0320\n",
      "Epoch 484/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 1.2834e-04 - acc: 0.0440 - val_loss: 0.0223 - val_acc: 0.0400\n",
      "Epoch 485/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 1.2417e-04 - acc: 0.0440 - val_loss: 0.0220 - val_acc: 0.0520\n",
      "Epoch 486/1000\n",
      "750/750 [==============================] - 0s 603us/step - loss: 1.2483e-04 - acc: 0.0547 - val_loss: 0.0222 - val_acc: 0.0360\n",
      "Epoch 487/1000\n",
      "750/750 [==============================] - 0s 611us/step - loss: 1.1847e-04 - acc: 0.0440 - val_loss: 0.0219 - val_acc: 0.0360\n",
      "Epoch 488/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.1057e-04 - acc: 0.0547 - val_loss: 0.0223 - val_acc: 0.0480\n",
      "Epoch 489/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.0676e-04 - acc: 0.0667 - val_loss: 0.0219 - val_acc: 0.0320\n",
      "Epoch 490/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.0022e-04 - acc: 0.0560 - val_loss: 0.0223 - val_acc: 0.0480\n",
      "Epoch 491/1000\n",
      "750/750 [==============================] - 0s 620us/step - loss: 1.0442e-04 - acc: 0.0373 - val_loss: 0.0219 - val_acc: 0.0360\n",
      "Epoch 492/1000\n",
      "750/750 [==============================] - 0s 610us/step - loss: 1.0180e-04 - acc: 0.0653 - val_loss: 0.0221 - val_acc: 0.0440\n",
      "Epoch 493/1000\n",
      "750/750 [==============================] - 0s 604us/step - loss: 1.0122e-04 - acc: 0.0493 - val_loss: 0.0220 - val_acc: 0.0400\n",
      "Epoch 494/1000\n",
      "750/750 [==============================] - 0s 626us/step - loss: 1.0091e-04 - acc: 0.0627 - val_loss: 0.0223 - val_acc: 0.0440\n",
      "Epoch 495/1000\n",
      "750/750 [==============================] - 0s 646us/step - loss: 1.0769e-04 - acc: 0.0467 - val_loss: 0.0220 - val_acc: 0.0440\n",
      "Epoch 496/1000\n",
      "750/750 [==============================] - 0s 642us/step - loss: 1.0491e-04 - acc: 0.0547 - val_loss: 0.0223 - val_acc: 0.0400\n",
      "Epoch 497/1000\n",
      "750/750 [==============================] - 0s 626us/step - loss: 1.1873e-04 - acc: 0.0600 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 498/1000\n",
      "750/750 [==============================] - 0s 628us/step - loss: 1.2770e-04 - acc: 0.0467 - val_loss: 0.0223 - val_acc: 0.0400\n",
      "Epoch 499/1000\n",
      "750/750 [==============================] - 0s 647us/step - loss: 1.2741e-04 - acc: 0.0560 - val_loss: 0.0220 - val_acc: 0.0400\n",
      "Epoch 500/1000\n",
      "750/750 [==============================] - 0s 622us/step - loss: 1.3470e-04 - acc: 0.0520 - val_loss: 0.0223 - val_acc: 0.0400\n",
      "Epoch 501/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.3821e-04 - acc: 0.0520 - val_loss: 0.0219 - val_acc: 0.0400\n",
      "Epoch 502/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 1.3767e-04 - acc: 0.0480 - val_loss: 0.0222 - val_acc: 0.0480\n",
      "Epoch 503/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 1.2438e-04 - acc: 0.0653 - val_loss: 0.0220 - val_acc: 0.0360\n",
      "Epoch 504/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 1.2983e-04 - acc: 0.0400 - val_loss: 0.0222 - val_acc: 0.0360\n",
      "Epoch 505/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.1886e-04 - acc: 0.0413 - val_loss: 0.0219 - val_acc: 0.0400\n",
      "Epoch 506/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.1288e-04 - acc: 0.0560 - val_loss: 0.0221 - val_acc: 0.0400\n",
      "Epoch 507/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.0018e-04 - acc: 0.0453 - val_loss: 0.0219 - val_acc: 0.0320\n",
      "Epoch 508/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 9.5289e-05 - acc: 0.0453 - val_loss: 0.0221 - val_acc: 0.0520\n",
      "Epoch 509/1000\n",
      "750/750 [==============================] - 0s 620us/step - loss: 9.1178e-05 - acc: 0.0667 - val_loss: 0.0220 - val_acc: 0.0440\n",
      "Epoch 510/1000\n",
      "750/750 [==============================] - 0s 639us/step - loss: 8.2451e-05 - acc: 0.0547 - val_loss: 0.0220 - val_acc: 0.0440\n",
      "Epoch 511/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 7.8538e-05 - acc: 0.0453 - val_loss: 0.0221 - val_acc: 0.0400\n",
      "Epoch 512/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 7.6342e-05 - acc: 0.0520 - val_loss: 0.0220 - val_acc: 0.0360\n",
      "Epoch 513/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 7.0453e-05 - acc: 0.0480 - val_loss: 0.0220 - val_acc: 0.0520\n",
      "Epoch 514/1000\n",
      "750/750 [==============================] - 0s 625us/step - loss: 6.8337e-05 - acc: 0.0520 - val_loss: 0.0221 - val_acc: 0.0400\n",
      "Epoch 515/1000\n",
      "750/750 [==============================] - 0s 620us/step - loss: 6.7868e-05 - acc: 0.0520 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 516/1000\n",
      "750/750 [==============================] - 0s 616us/step - loss: 6.7460e-05 - acc: 0.0493 - val_loss: 0.0220 - val_acc: 0.0440\n",
      "Epoch 517/1000\n",
      "750/750 [==============================] - 0s 644us/step - loss: 6.0018e-05 - acc: 0.0680 - val_loss: 0.0219 - val_acc: 0.0400\n",
      "Epoch 518/1000\n",
      "750/750 [==============================] - 0s 635us/step - loss: 5.7074e-05 - acc: 0.0533 - val_loss: 0.0220 - val_acc: 0.0480\n",
      "Epoch 519/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 5.5680e-05 - acc: 0.0640 - val_loss: 0.0219 - val_acc: 0.0400\n",
      "Epoch 520/1000\n",
      "750/750 [==============================] - 0s 610us/step - loss: 5.4951e-05 - acc: 0.0480 - val_loss: 0.0221 - val_acc: 0.0480\n",
      "Epoch 521/1000\n",
      "750/750 [==============================] - 0s 625us/step - loss: 4.9653e-05 - acc: 0.0533 - val_loss: 0.0218 - val_acc: 0.0440\n",
      "Epoch 522/1000\n",
      "750/750 [==============================] - 0s 601us/step - loss: 4.8220e-05 - acc: 0.0480 - val_loss: 0.0221 - val_acc: 0.0440\n",
      "Epoch 523/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 4.7932e-05 - acc: 0.0467 - val_loss: 0.0220 - val_acc: 0.0400\n",
      "Epoch 524/1000\n",
      "750/750 [==============================] - 0s 609us/step - loss: 5.2426e-05 - acc: 0.0533 - val_loss: 0.0221 - val_acc: 0.0480\n",
      "Epoch 525/1000\n",
      "750/750 [==============================] - 0s 613us/step - loss: 5.2090e-05 - acc: 0.0613 - val_loss: 0.0220 - val_acc: 0.0400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 526/1000\n",
      "750/750 [==============================] - 0s 603us/step - loss: 5.7287e-05 - acc: 0.0627 - val_loss: 0.0221 - val_acc: 0.0480\n",
      "Epoch 527/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 5.9480e-05 - acc: 0.0600 - val_loss: 0.0219 - val_acc: 0.0400\n",
      "Epoch 528/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 6.4969e-05 - acc: 0.0480 - val_loss: 0.0221 - val_acc: 0.0480\n",
      "Epoch 529/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 6.5450e-05 - acc: 0.0507 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 530/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 6.7803e-05 - acc: 0.0547 - val_loss: 0.0221 - val_acc: 0.0480\n",
      "Epoch 531/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 8.1258e-05 - acc: 0.0360 - val_loss: 0.0220 - val_acc: 0.0480\n",
      "Epoch 532/1000\n",
      "750/750 [==============================] - 0s 580us/step - loss: 9.5189e-05 - acc: 0.0533 - val_loss: 0.0220 - val_acc: 0.0520\n",
      "Epoch 533/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 1.0635e-04 - acc: 0.0720 - val_loss: 0.0221 - val_acc: 0.0400\n",
      "Epoch 534/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 1.1895e-04 - acc: 0.0560 - val_loss: 0.0220 - val_acc: 0.0400\n",
      "Epoch 535/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 1.1487e-04 - acc: 0.0480 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 536/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 1.1981e-04 - acc: 0.0533 - val_loss: 0.0221 - val_acc: 0.0280\n",
      "Epoch 537/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 1.1640e-04 - acc: 0.0600 - val_loss: 0.0218 - val_acc: 0.0440\n",
      "Epoch 538/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.1078e-04 - acc: 0.0440 - val_loss: 0.0221 - val_acc: 0.0400\n",
      "Epoch 539/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.0427e-04 - acc: 0.0600 - val_loss: 0.0219 - val_acc: 0.0360\n",
      "Epoch 540/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 1.0482e-04 - acc: 0.0453 - val_loss: 0.0221 - val_acc: 0.0440\n",
      "Epoch 541/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 1.1070e-04 - acc: 0.0453 - val_loss: 0.0218 - val_acc: 0.0360\n",
      "Epoch 542/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 1.2277e-04 - acc: 0.0453 - val_loss: 0.0220 - val_acc: 0.0400\n",
      "Epoch 543/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.4198e-04 - acc: 0.0493 - val_loss: 0.0218 - val_acc: 0.0360\n",
      "Epoch 544/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.5248e-04 - acc: 0.0453 - val_loss: 0.0220 - val_acc: 0.0360\n",
      "Epoch 545/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.4730e-04 - acc: 0.0547 - val_loss: 0.0219 - val_acc: 0.0360\n",
      "Epoch 546/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 1.3985e-04 - acc: 0.0520 - val_loss: 0.0220 - val_acc: 0.0480\n",
      "Epoch 547/1000\n",
      "750/750 [==============================] - 0s 606us/step - loss: 1.3246e-04 - acc: 0.0520 - val_loss: 0.0218 - val_acc: 0.0360\n",
      "Epoch 548/1000\n",
      "750/750 [==============================] - 0s 613us/step - loss: 1.3615e-04 - acc: 0.0453 - val_loss: 0.0221 - val_acc: 0.0360\n",
      "Epoch 549/1000\n",
      "750/750 [==============================] - 0s 616us/step - loss: 1.3327e-04 - acc: 0.0680 - val_loss: 0.0218 - val_acc: 0.0280\n",
      "Epoch 550/1000\n",
      "750/750 [==============================] - 0s 637us/step - loss: 1.2395e-04 - acc: 0.0533 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 551/1000\n",
      "750/750 [==============================] - 1s 689us/step - loss: 1.2410e-04 - acc: 0.0667 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 552/1000\n",
      "750/750 [==============================] - 1s 682us/step - loss: 1.2699e-04 - acc: 0.0493 - val_loss: 0.0220 - val_acc: 0.0400\n",
      "Epoch 553/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.2869e-04 - acc: 0.0640 - val_loss: 0.0216 - val_acc: 0.0400\n",
      "Epoch 554/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.2711e-04 - acc: 0.0573 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 555/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 1.3754e-04 - acc: 0.0560 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 556/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 1.3797e-04 - acc: 0.0427 - val_loss: 0.0218 - val_acc: 0.0440\n",
      "Epoch 557/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 1.2364e-04 - acc: 0.0653 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 558/1000\n",
      "750/750 [==============================] - 0s 610us/step - loss: 1.1080e-04 - acc: 0.0587 - val_loss: 0.0218 - val_acc: 0.0480\n",
      "Epoch 559/1000\n",
      "750/750 [==============================] - 0s 637us/step - loss: 9.9943e-05 - acc: 0.0573 - val_loss: 0.0218 - val_acc: 0.0440\n",
      "Epoch 560/1000\n",
      "750/750 [==============================] - 0s 636us/step - loss: 9.3100e-05 - acc: 0.0467 - val_loss: 0.0220 - val_acc: 0.0400\n",
      "Epoch 561/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 8.7866e-05 - acc: 0.0520 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 562/1000\n",
      "750/750 [==============================] - 0s 618us/step - loss: 8.7055e-05 - acc: 0.0533 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 563/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 9.4268e-05 - acc: 0.0547 - val_loss: 0.0217 - val_acc: 0.0400\n",
      "Epoch 564/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 8.5783e-05 - acc: 0.0560 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 565/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 8.8221e-05 - acc: 0.0533 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 566/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 8.6540e-05 - acc: 0.0547 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 567/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 8.7344e-05 - acc: 0.0600 - val_loss: 0.0217 - val_acc: 0.0360\n",
      "Epoch 568/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 8.3135e-05 - acc: 0.0520 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 569/1000\n",
      "750/750 [==============================] - 0s 617us/step - loss: 8.1431e-05 - acc: 0.0467 - val_loss: 0.0218 - val_acc: 0.0440\n",
      "Epoch 570/1000\n",
      "750/750 [==============================] - 0s 616us/step - loss: 7.9110e-05 - acc: 0.0373 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 571/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 6.9539e-05 - acc: 0.0520 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 572/1000\n",
      "750/750 [==============================] - 0s 632us/step - loss: 6.4382e-05 - acc: 0.0547 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 573/1000\n",
      "750/750 [==============================] - 0s 643us/step - loss: 6.5558e-05 - acc: 0.0507 - val_loss: 0.0218 - val_acc: 0.0320\n",
      "Epoch 574/1000\n",
      "750/750 [==============================] - 0s 647us/step - loss: 6.9644e-05 - acc: 0.0627 - val_loss: 0.0218 - val_acc: 0.0440\n",
      "Epoch 575/1000\n",
      "750/750 [==============================] - 0s 627us/step - loss: 6.7728e-05 - acc: 0.0613 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 576/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 6.6360e-05 - acc: 0.0733 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 577/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 6.2819e-05 - acc: 0.0507 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 578/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 6.5346e-05 - acc: 0.0547 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 579/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 6.5069e-05 - acc: 0.0533 - val_loss: 0.0218 - val_acc: 0.0440\n",
      "Epoch 580/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 6.4732e-05 - acc: 0.0507 - val_loss: 0.0218 - val_acc: 0.0440\n",
      "Epoch 581/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 6.1516e-05 - acc: 0.0600 - val_loss: 0.0218 - val_acc: 0.0440\n",
      "Epoch 582/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 5.7511e-05 - acc: 0.0480 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 583/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 582us/step - loss: 6.4377e-05 - acc: 0.0467 - val_loss: 0.0217 - val_acc: 0.0440\n",
      "Epoch 584/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 6.7119e-05 - acc: 0.0573 - val_loss: 0.0219 - val_acc: 0.0400\n",
      "Epoch 585/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 7.0252e-05 - acc: 0.0413 - val_loss: 0.0217 - val_acc: 0.0320\n",
      "Epoch 586/1000\n",
      "750/750 [==============================] - 0s 610us/step - loss: 8.2613e-05 - acc: 0.0507 - val_loss: 0.0219 - val_acc: 0.0400\n",
      "Epoch 587/1000\n",
      "750/750 [==============================] - 0s 611us/step - loss: 8.1604e-05 - acc: 0.0627 - val_loss: 0.0216 - val_acc: 0.0200\n",
      "Epoch 588/1000\n",
      "750/750 [==============================] - 0s 615us/step - loss: 8.9929e-05 - acc: 0.0453 - val_loss: 0.0219 - val_acc: 0.0440\n",
      "Epoch 589/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 1.0743e-04 - acc: 0.0387 - val_loss: 0.0216 - val_acc: 0.0440\n",
      "Epoch 590/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 1.0244e-04 - acc: 0.0680 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 591/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 9.8650e-05 - acc: 0.0640 - val_loss: 0.0218 - val_acc: 0.0320\n",
      "Epoch 592/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.0281e-04 - acc: 0.0440 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 593/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 1.0169e-04 - acc: 0.0520 - val_loss: 0.0216 - val_acc: 0.0400\n",
      "Epoch 594/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 9.1529e-05 - acc: 0.0507 - val_loss: 0.0218 - val_acc: 0.0280\n",
      "Epoch 595/1000\n",
      "750/750 [==============================] - 0s 629us/step - loss: 8.8245e-05 - acc: 0.0533 - val_loss: 0.0216 - val_acc: 0.0440\n",
      "Epoch 596/1000\n",
      "750/750 [==============================] - 0s 628us/step - loss: 9.2534e-05 - acc: 0.0547 - val_loss: 0.0217 - val_acc: 0.0440\n",
      "Epoch 597/1000\n",
      "750/750 [==============================] - 0s 633us/step - loss: 8.8907e-05 - acc: 0.0387 - val_loss: 0.0217 - val_acc: 0.0400\n",
      "Epoch 598/1000\n",
      "750/750 [==============================] - 0s 625us/step - loss: 8.8361e-05 - acc: 0.0453 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 599/1000\n",
      "750/750 [==============================] - 0s 628us/step - loss: 8.8468e-05 - acc: 0.0453 - val_loss: 0.0217 - val_acc: 0.0400\n",
      "Epoch 600/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 8.9549e-05 - acc: 0.0600 - val_loss: 0.0217 - val_acc: 0.0320\n",
      "Epoch 601/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 8.5395e-05 - acc: 0.0467 - val_loss: 0.0216 - val_acc: 0.0440\n",
      "Epoch 602/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 8.5737e-05 - acc: 0.0493 - val_loss: 0.0218 - val_acc: 0.0320\n",
      "Epoch 603/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 8.5345e-05 - acc: 0.0480 - val_loss: 0.0216 - val_acc: 0.0520\n",
      "Epoch 604/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 8.2796e-05 - acc: 0.0413 - val_loss: 0.0218 - val_acc: 0.0360\n",
      "Epoch 605/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 7.5428e-05 - acc: 0.0573 - val_loss: 0.0217 - val_acc: 0.0400\n",
      "Epoch 606/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 7.4865e-05 - acc: 0.0493 - val_loss: 0.0218 - val_acc: 0.0360\n",
      "Epoch 607/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 7.2818e-05 - acc: 0.0560 - val_loss: 0.0216 - val_acc: 0.0400\n",
      "Epoch 608/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 7.1719e-05 - acc: 0.0520 - val_loss: 0.0217 - val_acc: 0.0400\n",
      "Epoch 609/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 7.1952e-05 - acc: 0.0547 - val_loss: 0.0217 - val_acc: 0.0440\n",
      "Epoch 610/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 7.7135e-05 - acc: 0.0413 - val_loss: 0.0217 - val_acc: 0.0440\n",
      "Epoch 611/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 8.2577e-05 - acc: 0.0600 - val_loss: 0.0217 - val_acc: 0.0360\n",
      "Epoch 612/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 8.1525e-05 - acc: 0.0520 - val_loss: 0.0218 - val_acc: 0.0400\n",
      "Epoch 613/1000\n",
      "750/750 [==============================] - 0s 619us/step - loss: 7.7815e-05 - acc: 0.0533 - val_loss: 0.0216 - val_acc: 0.0320\n",
      "Epoch 614/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 8.1813e-05 - acc: 0.0587 - val_loss: 0.0216 - val_acc: 0.0440\n",
      "Epoch 615/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 8.0295e-05 - acc: 0.0493 - val_loss: 0.0216 - val_acc: 0.0400\n",
      "Epoch 616/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 7.7370e-05 - acc: 0.0507 - val_loss: 0.0217 - val_acc: 0.0360\n",
      "Epoch 617/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 8.1192e-05 - acc: 0.0480 - val_loss: 0.0216 - val_acc: 0.0400\n",
      "Epoch 618/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 7.9926e-05 - acc: 0.0440 - val_loss: 0.0216 - val_acc: 0.0440\n",
      "Epoch 619/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 7.3736e-05 - acc: 0.0520 - val_loss: 0.0217 - val_acc: 0.0440\n",
      "Epoch 620/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 7.1437e-05 - acc: 0.0333 - val_loss: 0.0217 - val_acc: 0.0480\n",
      "Epoch 621/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 7.1492e-05 - acc: 0.0520 - val_loss: 0.0216 - val_acc: 0.0400\n",
      "Epoch 622/1000\n",
      "750/750 [==============================] - 0s 640us/step - loss: 8.2588e-05 - acc: 0.0533 - val_loss: 0.0217 - val_acc: 0.0320\n",
      "Epoch 623/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 9.5770e-05 - acc: 0.0453 - val_loss: 0.0216 - val_acc: 0.0400\n",
      "Epoch 624/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.0227e-04 - acc: 0.0533 - val_loss: 0.0217 - val_acc: 0.0400\n",
      "Epoch 625/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 9.5018e-05 - acc: 0.0547 - val_loss: 0.0215 - val_acc: 0.0400\n",
      "Epoch 626/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 9.3491e-05 - acc: 0.0533 - val_loss: 0.0218 - val_acc: 0.0440\n",
      "Epoch 627/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 8.6071e-05 - acc: 0.0587 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 628/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 8.2585e-05 - acc: 0.0600 - val_loss: 0.0219 - val_acc: 0.0360\n",
      "Epoch 629/1000\n",
      "750/750 [==============================] - 0s 604us/step - loss: 8.1457e-05 - acc: 0.0387 - val_loss: 0.0215 - val_acc: 0.0320\n",
      "Epoch 630/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 8.8787e-05 - acc: 0.0440 - val_loss: 0.0218 - val_acc: 0.0440\n",
      "Epoch 631/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 9.5599e-05 - acc: 0.0360 - val_loss: 0.0216 - val_acc: 0.0320\n",
      "Epoch 632/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 9.9846e-05 - acc: 0.0533 - val_loss: 0.0218 - val_acc: 0.0280\n",
      "Epoch 633/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.0404e-04 - acc: 0.0453 - val_loss: 0.0216 - val_acc: 0.0280\n",
      "Epoch 634/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.0274e-04 - acc: 0.0400 - val_loss: 0.0217 - val_acc: 0.0360\n",
      "Epoch 635/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 9.8585e-05 - acc: 0.0507 - val_loss: 0.0215 - val_acc: 0.0360\n",
      "Epoch 636/1000\n",
      "750/750 [==============================] - 0s 632us/step - loss: 9.7598e-05 - acc: 0.0507 - val_loss: 0.0216 - val_acc: 0.0320\n",
      "Epoch 637/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 1.0213e-04 - acc: 0.0373 - val_loss: 0.0216 - val_acc: 0.0320\n",
      "Epoch 638/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.0224e-04 - acc: 0.0667 - val_loss: 0.0216 - val_acc: 0.0360\n",
      "Epoch 639/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 1.0397e-04 - acc: 0.0507 - val_loss: 0.0216 - val_acc: 0.0280\n",
      "Epoch 640/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 1.0624e-04 - acc: 0.0453 - val_loss: 0.0215 - val_acc: 0.0360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 9.9963e-05 - acc: 0.0653 - val_loss: 0.0217 - val_acc: 0.0320\n",
      "Epoch 642/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 1.0018e-04 - acc: 0.0520 - val_loss: 0.0215 - val_acc: 0.0280\n",
      "Epoch 643/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 9.3194e-05 - acc: 0.0480 - val_loss: 0.0216 - val_acc: 0.0360\n",
      "Epoch 644/1000\n",
      "750/750 [==============================] - 0s 621us/step - loss: 9.9950e-05 - acc: 0.0507 - val_loss: 0.0215 - val_acc: 0.0360\n",
      "Epoch 645/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.0187e-04 - acc: 0.0413 - val_loss: 0.0216 - val_acc: 0.0440\n",
      "Epoch 646/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 9.9862e-05 - acc: 0.0600 - val_loss: 0.0216 - val_acc: 0.0360\n",
      "Epoch 647/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 9.2635e-05 - acc: 0.0507 - val_loss: 0.0216 - val_acc: 0.0360\n",
      "Epoch 648/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 8.1732e-05 - acc: 0.0613 - val_loss: 0.0215 - val_acc: 0.0360\n",
      "Epoch 649/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 7.1318e-05 - acc: 0.0480 - val_loss: 0.0217 - val_acc: 0.0320\n",
      "Epoch 650/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 6.5770e-05 - acc: 0.0480 - val_loss: 0.0215 - val_acc: 0.0320\n",
      "Epoch 651/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 5.9098e-05 - acc: 0.0667 - val_loss: 0.0215 - val_acc: 0.0360\n",
      "Epoch 652/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 5.6649e-05 - acc: 0.0413 - val_loss: 0.0215 - val_acc: 0.0320\n",
      "Epoch 653/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 5.1671e-05 - acc: 0.0733 - val_loss: 0.0215 - val_acc: 0.0280\n",
      "Epoch 654/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 4.9888e-05 - acc: 0.0747 - val_loss: 0.0216 - val_acc: 0.0400\n",
      "Epoch 655/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 4.8606e-05 - acc: 0.0680 - val_loss: 0.0215 - val_acc: 0.0320\n",
      "Epoch 656/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 4.8608e-05 - acc: 0.0480 - val_loss: 0.0216 - val_acc: 0.0320\n",
      "Epoch 657/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 5.2347e-05 - acc: 0.0507 - val_loss: 0.0214 - val_acc: 0.0320\n",
      "Epoch 658/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 5.5892e-05 - acc: 0.0693 - val_loss: 0.0216 - val_acc: 0.0320\n",
      "Epoch 659/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 6.5573e-05 - acc: 0.0547 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 660/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 6.9569e-05 - acc: 0.0520 - val_loss: 0.0215 - val_acc: 0.0360\n",
      "Epoch 661/1000\n",
      "750/750 [==============================] - 0s 607us/step - loss: 7.7811e-05 - acc: 0.0720 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 662/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 8.6170e-05 - acc: 0.0493 - val_loss: 0.0216 - val_acc: 0.0360\n",
      "Epoch 663/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 8.1121e-05 - acc: 0.0400 - val_loss: 0.0216 - val_acc: 0.0320\n",
      "Epoch 664/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 8.9469e-05 - acc: 0.0427 - val_loss: 0.0215 - val_acc: 0.0400\n",
      "Epoch 665/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 9.0999e-05 - acc: 0.0653 - val_loss: 0.0214 - val_acc: 0.0440\n",
      "Epoch 666/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 9.7205e-05 - acc: 0.0533 - val_loss: 0.0213 - val_acc: 0.0360\n",
      "Epoch 667/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 9.2070e-05 - acc: 0.0453 - val_loss: 0.0215 - val_acc: 0.0360\n",
      "Epoch 668/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 8.8436e-05 - acc: 0.0427 - val_loss: 0.0215 - val_acc: 0.0360\n",
      "Epoch 669/1000\n",
      "750/750 [==============================] - 0s 605us/step - loss: 8.7188e-05 - acc: 0.0480 - val_loss: 0.0214 - val_acc: 0.0400\n",
      "Epoch 670/1000\n",
      "750/750 [==============================] - 0s 620us/step - loss: 9.0089e-05 - acc: 0.0520 - val_loss: 0.0216 - val_acc: 0.0320\n",
      "Epoch 671/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 9.5057e-05 - acc: 0.0413 - val_loss: 0.0213 - val_acc: 0.0360\n",
      "Epoch 672/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 1.0505e-04 - acc: 0.0493 - val_loss: 0.0215 - val_acc: 0.0320\n",
      "Epoch 673/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 1.1734e-04 - acc: 0.0587 - val_loss: 0.0216 - val_acc: 0.0280\n",
      "Epoch 674/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.2976e-04 - acc: 0.0453 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 675/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 1.2538e-04 - acc: 0.0640 - val_loss: 0.0214 - val_acc: 0.0400\n",
      "Epoch 676/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 1.2099e-04 - acc: 0.0533 - val_loss: 0.0215 - val_acc: 0.0320\n",
      "Epoch 677/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 1.1032e-04 - acc: 0.0387 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 678/1000\n",
      "750/750 [==============================] - 0s 643us/step - loss: 1.0049e-04 - acc: 0.0653 - val_loss: 0.0215 - val_acc: 0.0360\n",
      "Epoch 679/1000\n",
      "750/750 [==============================] - 0s 618us/step - loss: 8.8844e-05 - acc: 0.0533 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 680/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 8.2454e-05 - acc: 0.0547 - val_loss: 0.0215 - val_acc: 0.0280\n",
      "Epoch 681/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 8.7910e-05 - acc: 0.0467 - val_loss: 0.0214 - val_acc: 0.0320\n",
      "Epoch 682/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 8.2491e-05 - acc: 0.0507 - val_loss: 0.0215 - val_acc: 0.0400\n",
      "Epoch 683/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 7.7794e-05 - acc: 0.0587 - val_loss: 0.0213 - val_acc: 0.0360\n",
      "Epoch 684/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 8.6206e-05 - acc: 0.0533 - val_loss: 0.0216 - val_acc: 0.0320\n",
      "Epoch 685/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 8.6002e-05 - acc: 0.0613 - val_loss: 0.0213 - val_acc: 0.0360\n",
      "Epoch 686/1000\n",
      "750/750 [==============================] - 0s 603us/step - loss: 7.2303e-05 - acc: 0.0360 - val_loss: 0.0215 - val_acc: 0.0400\n",
      "Epoch 687/1000\n",
      "750/750 [==============================] - 0s 620us/step - loss: 6.8135e-05 - acc: 0.0600 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 688/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 7.3783e-05 - acc: 0.0373 - val_loss: 0.0215 - val_acc: 0.0400\n",
      "Epoch 689/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 6.9395e-05 - acc: 0.0547 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 690/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 6.8403e-05 - acc: 0.0440 - val_loss: 0.0215 - val_acc: 0.0360\n",
      "Epoch 691/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 7.2264e-05 - acc: 0.0547 - val_loss: 0.0214 - val_acc: 0.0400\n",
      "Epoch 692/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 7.6137e-05 - acc: 0.0560 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 693/1000\n",
      "750/750 [==============================] - 0s 612us/step - loss: 6.8094e-05 - acc: 0.0547 - val_loss: 0.0214 - val_acc: 0.0320\n",
      "Epoch 694/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 6.6220e-05 - acc: 0.0533 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 695/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 6.1966e-05 - acc: 0.0507 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 696/1000\n",
      "750/750 [==============================] - 0s 600us/step - loss: 5.9370e-05 - acc: 0.0480 - val_loss: 0.0215 - val_acc: 0.0360\n",
      "Epoch 697/1000\n",
      "750/750 [==============================] - 0s 617us/step - loss: 5.2618e-05 - acc: 0.0493 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 698/1000\n",
      "750/750 [==============================] - 0s 626us/step - loss: 5.0198e-05 - acc: 0.0427 - val_loss: 0.0215 - val_acc: 0.0320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 6.3223e-05 - acc: 0.0627 - val_loss: 0.0214 - val_acc: 0.0160\n",
      "Epoch 700/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 6.4132e-05 - acc: 0.0467 - val_loss: 0.0214 - val_acc: 0.0320\n",
      "Epoch 701/1000\n",
      "750/750 [==============================] - 0s 600us/step - loss: 6.6458e-05 - acc: 0.0600 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 702/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 6.6778e-05 - acc: 0.0453 - val_loss: 0.0215 - val_acc: 0.0320\n",
      "Epoch 703/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 7.0140e-05 - acc: 0.0413 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 704/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 6.9880e-05 - acc: 0.0427 - val_loss: 0.0214 - val_acc: 0.0320\n",
      "Epoch 705/1000\n",
      "750/750 [==============================] - 0s 602us/step - loss: 6.8768e-05 - acc: 0.0493 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 706/1000\n",
      "750/750 [==============================] - 0s 619us/step - loss: 6.8934e-05 - acc: 0.0560 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 707/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 6.8821e-05 - acc: 0.0480 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 708/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 6.6260e-05 - acc: 0.0653 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 709/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 6.8861e-05 - acc: 0.0373 - val_loss: 0.0214 - val_acc: 0.0320\n",
      "Epoch 710/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 7.3387e-05 - acc: 0.0640 - val_loss: 0.0215 - val_acc: 0.0280\n",
      "Epoch 711/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 7.4648e-05 - acc: 0.0507 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 712/1000\n",
      "750/750 [==============================] - 0s 603us/step - loss: 7.7935e-05 - acc: 0.0587 - val_loss: 0.0212 - val_acc: 0.0360\n",
      "Epoch 713/1000\n",
      "750/750 [==============================] - 0s 617us/step - loss: 9.0143e-05 - acc: 0.0573 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 714/1000\n",
      "750/750 [==============================] - 0s 611us/step - loss: 9.7269e-05 - acc: 0.0493 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 715/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 9.2231e-05 - acc: 0.0440 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 716/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 8.4215e-05 - acc: 0.0507 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 717/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 7.9203e-05 - acc: 0.0453 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 718/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 7.9364e-05 - acc: 0.0493 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 719/1000\n",
      "750/750 [==============================] - 0s 623us/step - loss: 7.8773e-05 - acc: 0.0427 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 720/1000\n",
      "750/750 [==============================] - 0s 654us/step - loss: 7.9482e-05 - acc: 0.0613 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 721/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 7.4501e-05 - acc: 0.0440 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 722/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 6.9797e-05 - acc: 0.0587 - val_loss: 0.0213 - val_acc: 0.0360\n",
      "Epoch 723/1000\n",
      "750/750 [==============================] - 0s 605us/step - loss: 6.4001e-05 - acc: 0.0467 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 724/1000\n",
      "750/750 [==============================] - 0s 610us/step - loss: 6.0731e-05 - acc: 0.0653 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 725/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 5.4540e-05 - acc: 0.0467 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 726/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 5.4322e-05 - acc: 0.0520 - val_loss: 0.0213 - val_acc: 0.0360\n",
      "Epoch 727/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 5.2574e-05 - acc: 0.0387 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 728/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 5.4076e-05 - acc: 0.0760 - val_loss: 0.0214 - val_acc: 0.0320\n",
      "Epoch 729/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 5.0627e-05 - acc: 0.0547 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 730/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 4.9023e-05 - acc: 0.0560 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 731/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 4.7364e-05 - acc: 0.0400 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 732/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 4.4604e-05 - acc: 0.0720 - val_loss: 0.0213 - val_acc: 0.0360\n",
      "Epoch 733/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 4.7951e-05 - acc: 0.0493 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 734/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 5.1279e-05 - acc: 0.0507 - val_loss: 0.0213 - val_acc: 0.0440\n",
      "Epoch 735/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 5.0048e-05 - acc: 0.0600 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 736/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 5.1122e-05 - acc: 0.0667 - val_loss: 0.0214 - val_acc: 0.0320\n",
      "Epoch 737/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 5.7445e-05 - acc: 0.0333 - val_loss: 0.0212 - val_acc: 0.0360\n",
      "Epoch 738/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 5.9793e-05 - acc: 0.0453 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 739/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 5.9578e-05 - acc: 0.0520 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 740/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 6.0431e-05 - acc: 0.0520 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 741/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 6.2210e-05 - acc: 0.0507 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 742/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 6.2915e-05 - acc: 0.0613 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 743/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 7.0297e-05 - acc: 0.0507 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 744/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 7.1226e-05 - acc: 0.0347 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 745/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 7.1557e-05 - acc: 0.0573 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 746/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 8.0309e-05 - acc: 0.0440 - val_loss: 0.0213 - val_acc: 0.0360\n",
      "Epoch 747/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 9.6233e-05 - acc: 0.0560 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 748/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 1.0793e-04 - acc: 0.0413 - val_loss: 0.0214 - val_acc: 0.0320\n",
      "Epoch 749/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 1.1564e-04 - acc: 0.0493 - val_loss: 0.0212 - val_acc: 0.0240\n",
      "Epoch 750/1000\n",
      "750/750 [==============================] - 0s 631us/step - loss: 1.1420e-04 - acc: 0.0387 - val_loss: 0.0213 - val_acc: 0.0440\n",
      "Epoch 751/1000\n",
      "750/750 [==============================] - 0s 617us/step - loss: 1.2291e-04 - acc: 0.0613 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 752/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 1.2456e-04 - acc: 0.0307 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 753/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 1.2753e-04 - acc: 0.0480 - val_loss: 0.0212 - val_acc: 0.0400\n",
      "Epoch 754/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 1.3041e-04 - acc: 0.0493 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 755/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 1.2596e-04 - acc: 0.0507 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 756/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 1.2188e-04 - acc: 0.0640 - val_loss: 0.0213 - val_acc: 0.0280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 757/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 1.0541e-04 - acc: 0.0347 - val_loss: 0.0212 - val_acc: 0.0400\n",
      "Epoch 758/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 8.7291e-05 - acc: 0.0587 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 759/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 7.2952e-05 - acc: 0.0507 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 760/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 7.2605e-05 - acc: 0.0573 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 761/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 6.8212e-05 - acc: 0.0467 - val_loss: 0.0213 - val_acc: 0.0240\n",
      "Epoch 762/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 6.3861e-05 - acc: 0.0507 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 763/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 5.7142e-05 - acc: 0.0507 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 764/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 5.2858e-05 - acc: 0.0533 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 765/1000\n",
      "750/750 [==============================] - 0s 626us/step - loss: 4.9065e-05 - acc: 0.0413 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 766/1000\n",
      "750/750 [==============================] - 0s 610us/step - loss: 4.8219e-05 - acc: 0.0467 - val_loss: 0.0212 - val_acc: 0.0360\n",
      "Epoch 767/1000\n",
      "750/750 [==============================] - 0s 610us/step - loss: 4.5054e-05 - acc: 0.0587 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 768/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 4.1577e-05 - acc: 0.0360 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 769/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 3.8383e-05 - acc: 0.0560 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 770/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 3.6900e-05 - acc: 0.0587 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 771/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 3.7215e-05 - acc: 0.0547 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 772/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 3.8631e-05 - acc: 0.0547 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 773/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 3.8024e-05 - acc: 0.0507 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 774/1000\n",
      "750/750 [==============================] - 0s 634us/step - loss: 3.5648e-05 - acc: 0.0560 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 775/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 3.5962e-05 - acc: 0.0467 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 776/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 3.1965e-05 - acc: 0.0507 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 777/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 3.3776e-05 - acc: 0.0333 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 778/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 3.6969e-05 - acc: 0.0587 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 779/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 3.7956e-05 - acc: 0.0453 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 780/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 4.0940e-05 - acc: 0.0480 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 781/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 4.2700e-05 - acc: 0.0467 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 782/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 4.4019e-05 - acc: 0.0533 - val_loss: 0.0213 - val_acc: 0.0360\n",
      "Epoch 783/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 5.3778e-05 - acc: 0.0453 - val_loss: 0.0212 - val_acc: 0.0360\n",
      "Epoch 784/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 5.5728e-05 - acc: 0.0413 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 785/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 5.5141e-05 - acc: 0.0467 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 786/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 7.3176e-05 - acc: 0.0467 - val_loss: 0.0212 - val_acc: 0.0360\n",
      "Epoch 787/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 8.2561e-05 - acc: 0.0640 - val_loss: 0.0214 - val_acc: 0.0280\n",
      "Epoch 788/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 7.5354e-05 - acc: 0.0373 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 789/1000\n",
      "750/750 [==============================] - 0s 609us/step - loss: 7.4925e-05 - acc: 0.0480 - val_loss: 0.0214 - val_acc: 0.0360\n",
      "Epoch 790/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 8.0031e-05 - acc: 0.0467 - val_loss: 0.0212 - val_acc: 0.0360\n",
      "Epoch 791/1000\n",
      "750/750 [==============================] - 0s 604us/step - loss: 8.8149e-05 - acc: 0.0387 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 792/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 9.3056e-05 - acc: 0.0493 - val_loss: 0.0212 - val_acc: 0.0360\n",
      "Epoch 793/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 1.0368e-04 - acc: 0.0453 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 794/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 9.5133e-05 - acc: 0.0587 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 795/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 9.6485e-05 - acc: 0.0533 - val_loss: 0.0213 - val_acc: 0.0280\n",
      "Epoch 796/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 9.7732e-05 - acc: 0.0347 - val_loss: 0.0213 - val_acc: 0.0320\n",
      "Epoch 797/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 9.0216e-05 - acc: 0.0493 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 798/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 9.6982e-05 - acc: 0.0453 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 799/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 1.0244e-04 - acc: 0.0533 - val_loss: 0.0214 - val_acc: 0.0320\n",
      "Epoch 800/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 9.6702e-05 - acc: 0.0387 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 801/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 9.1131e-05 - acc: 0.0427 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 802/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 8.3582e-05 - acc: 0.0507 - val_loss: 0.0213 - val_acc: 0.0360\n",
      "Epoch 803/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 9.0707e-05 - acc: 0.0427 - val_loss: 0.0212 - val_acc: 0.0360\n",
      "Epoch 804/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 9.0454e-05 - acc: 0.0493 - val_loss: 0.0213 - val_acc: 0.0400\n",
      "Epoch 805/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 8.4833e-05 - acc: 0.0507 - val_loss: 0.0212 - val_acc: 0.0360\n",
      "Epoch 806/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 7.9115e-05 - acc: 0.0813 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 807/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 7.0369e-05 - acc: 0.0520 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 808/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 6.2758e-05 - acc: 0.0413 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 809/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 6.1369e-05 - acc: 0.0453 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 810/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 5.9636e-05 - acc: 0.0507 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 811/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 6.3175e-05 - acc: 0.0587 - val_loss: 0.0212 - val_acc: 0.0240\n",
      "Epoch 812/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 7.1539e-05 - acc: 0.0413 - val_loss: 0.0212 - val_acc: 0.0360\n",
      "Epoch 813/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 8.1012e-05 - acc: 0.0427 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 814/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 8.1581e-05 - acc: 0.0387 - val_loss: 0.0212 - val_acc: 0.0240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 815/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 7.9386e-05 - acc: 0.0427 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 816/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 7.9982e-05 - acc: 0.0627 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 817/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 7.6153e-05 - acc: 0.0533 - val_loss: 0.0212 - val_acc: 0.0240\n",
      "Epoch 818/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 7.9537e-05 - acc: 0.0560 - val_loss: 0.0212 - val_acc: 0.0240\n",
      "Epoch 819/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 7.3893e-05 - acc: 0.0413 - val_loss: 0.0212 - val_acc: 0.0240\n",
      "Epoch 820/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 7.7926e-05 - acc: 0.0387 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 821/1000\n",
      "750/750 [==============================] - 0s 613us/step - loss: 7.7630e-05 - acc: 0.0533 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 822/1000\n",
      "750/750 [==============================] - 0s 620us/step - loss: 7.1412e-05 - acc: 0.0467 - val_loss: 0.0212 - val_acc: 0.0240\n",
      "Epoch 823/1000\n",
      "750/750 [==============================] - 0s 616us/step - loss: 6.8963e-05 - acc: 0.0480 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 824/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 6.3863e-05 - acc: 0.0653 - val_loss: 0.0212 - val_acc: 0.0240\n",
      "Epoch 825/1000\n",
      "750/750 [==============================] - 0s 632us/step - loss: 5.7141e-05 - acc: 0.0507 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 826/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 5.6047e-05 - acc: 0.0587 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 827/1000\n",
      "750/750 [==============================] - 0s 637us/step - loss: 5.1086e-05 - acc: 0.0440 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 828/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 4.8681e-05 - acc: 0.0627 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 829/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 4.3119e-05 - acc: 0.0387 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 830/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 4.2641e-05 - acc: 0.0547 - val_loss: 0.0211 - val_acc: 0.0360\n",
      "Epoch 831/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 4.0778e-05 - acc: 0.0547 - val_loss: 0.0211 - val_acc: 0.0240\n",
      "Epoch 832/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 4.2047e-05 - acc: 0.0493 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 833/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 4.0355e-05 - acc: 0.0573 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 834/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 4.2812e-05 - acc: 0.0480 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 835/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 4.7765e-05 - acc: 0.0440 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 836/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 5.2696e-05 - acc: 0.0400 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 837/1000\n",
      "750/750 [==============================] - 0s 600us/step - loss: 5.3867e-05 - acc: 0.0333 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 838/1000\n",
      "750/750 [==============================] - 0s 626us/step - loss: 5.0639e-05 - acc: 0.0467 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 839/1000\n",
      "750/750 [==============================] - 0s 624us/step - loss: 5.4679e-05 - acc: 0.0480 - val_loss: 0.0211 - val_acc: 0.0240\n",
      "Epoch 840/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 5.7784e-05 - acc: 0.0427 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 841/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 5.8317e-05 - acc: 0.0400 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 842/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 5.9435e-05 - acc: 0.0560 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 843/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 6.1304e-05 - acc: 0.0467 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 844/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 6.0968e-05 - acc: 0.0413 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 845/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 5.9829e-05 - acc: 0.0573 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 846/1000\n",
      "750/750 [==============================] - 0s 598us/step - loss: 6.2065e-05 - acc: 0.0453 - val_loss: 0.0211 - val_acc: 0.0240\n",
      "Epoch 847/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 6.0072e-05 - acc: 0.0467 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 848/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 6.1386e-05 - acc: 0.0440 - val_loss: 0.0212 - val_acc: 0.0240\n",
      "Epoch 849/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 5.9515e-05 - acc: 0.0440 - val_loss: 0.0211 - val_acc: 0.0240\n",
      "Epoch 850/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 6.5697e-05 - acc: 0.0600 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 851/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 6.7042e-05 - acc: 0.0493 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 852/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 6.7542e-05 - acc: 0.0440 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 853/1000\n",
      "750/750 [==============================] - 0s 609us/step - loss: 6.4183e-05 - acc: 0.0520 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 854/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 6.0376e-05 - acc: 0.0547 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 855/1000\n",
      "750/750 [==============================] - 0s 603us/step - loss: 5.7164e-05 - acc: 0.0493 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 856/1000\n",
      "750/750 [==============================] - 0s 618us/step - loss: 5.6386e-05 - acc: 0.0427 - val_loss: 0.0212 - val_acc: 0.0240\n",
      "Epoch 857/1000\n",
      "750/750 [==============================] - 0s 605us/step - loss: 5.6477e-05 - acc: 0.0427 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 858/1000\n",
      "750/750 [==============================] - 0s 603us/step - loss: 5.5713e-05 - acc: 0.0453 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 859/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 5.7697e-05 - acc: 0.0453 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 860/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 6.1366e-05 - acc: 0.0507 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 861/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 6.7345e-05 - acc: 0.0480 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 862/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 6.5635e-05 - acc: 0.0520 - val_loss: 0.0211 - val_acc: 0.0360\n",
      "Epoch 863/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 6.5435e-05 - acc: 0.0360 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 864/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 6.5276e-05 - acc: 0.0480 - val_loss: 0.0211 - val_acc: 0.0240\n",
      "Epoch 865/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 6.5475e-05 - acc: 0.0453 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 866/1000\n",
      "750/750 [==============================] - 0s 599us/step - loss: 5.8927e-05 - acc: 0.0560 - val_loss: 0.0211 - val_acc: 0.0240\n",
      "Epoch 867/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 5.0998e-05 - acc: 0.0573 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 868/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 4.6924e-05 - acc: 0.0387 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 869/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 4.1380e-05 - acc: 0.0573 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 870/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 3.9484e-05 - acc: 0.0480 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 871/1000\n",
      "750/750 [==============================] - 0s 594us/step - loss: 4.0030e-05 - acc: 0.0560 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 872/1000\n",
      "750/750 [==============================] - 0s 595us/step - loss: 4.4172e-05 - acc: 0.0453 - val_loss: 0.0211 - val_acc: 0.0280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 873/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 4.2213e-05 - acc: 0.0480 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 874/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 4.4031e-05 - acc: 0.0400 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 875/1000\n",
      "750/750 [==============================] - 0s 597us/step - loss: 4.5486e-05 - acc: 0.0773 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 876/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 4.6674e-05 - acc: 0.0387 - val_loss: 0.0212 - val_acc: 0.0320\n",
      "Epoch 877/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 4.5624e-05 - acc: 0.0467 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 878/1000\n",
      "750/750 [==============================] - 0s 593us/step - loss: 4.6233e-05 - acc: 0.0373 - val_loss: 0.0212 - val_acc: 0.0280\n",
      "Epoch 879/1000\n",
      "750/750 [==============================] - 0s 596us/step - loss: 4.5910e-05 - acc: 0.0480 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 880/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 5.0413e-05 - acc: 0.0480 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 881/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 4.9666e-05 - acc: 0.0520 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 882/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 5.4232e-05 - acc: 0.0587 - val_loss: 0.0211 - val_acc: 0.0240\n",
      "Epoch 883/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 5.7741e-05 - acc: 0.0360 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 884/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 6.3675e-05 - acc: 0.0587 - val_loss: 0.0211 - val_acc: 0.0240\n",
      "Epoch 885/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 5.7043e-05 - acc: 0.0547 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 886/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 5.7207e-05 - acc: 0.0680 - val_loss: 0.0211 - val_acc: 0.0360\n",
      "Epoch 887/1000\n",
      "750/750 [==============================] - 0s 592us/step - loss: 5.8691e-05 - acc: 0.0453 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 888/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 6.2911e-05 - acc: 0.0573 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 889/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 6.8539e-05 - acc: 0.0467 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 890/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 7.4018e-05 - acc: 0.0533 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 891/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 7.9383e-05 - acc: 0.0467 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 892/1000\n",
      "750/750 [==============================] - 0s 614us/step - loss: 7.6353e-05 - acc: 0.0453 - val_loss: 0.0211 - val_acc: 0.0200\n",
      "Epoch 893/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 7.1374e-05 - acc: 0.0587 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 894/1000\n",
      "750/750 [==============================] - 0s 604us/step - loss: 6.9458e-05 - acc: 0.0520 - val_loss: 0.0211 - val_acc: 0.0360\n",
      "Epoch 895/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 6.7302e-05 - acc: 0.0467 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 896/1000\n",
      "750/750 [==============================] - 0s 609us/step - loss: 6.2318e-05 - acc: 0.0493 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 897/1000\n",
      "750/750 [==============================] - 0s 606us/step - loss: 6.2148e-05 - acc: 0.0507 - val_loss: 0.0209 - val_acc: 0.0320\n",
      "Epoch 898/1000\n",
      "750/750 [==============================] - 0s 622us/step - loss: 5.7905e-05 - acc: 0.0560 - val_loss: 0.0211 - val_acc: 0.0360\n",
      "Epoch 899/1000\n",
      "750/750 [==============================] - 0s 623us/step - loss: 5.5864e-05 - acc: 0.0587 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 900/1000\n",
      "750/750 [==============================] - 0s 591us/step - loss: 5.5639e-05 - acc: 0.0293 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 901/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 5.0558e-05 - acc: 0.0467 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 902/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 5.4273e-05 - acc: 0.0507 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 903/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 5.2375e-05 - acc: 0.0533 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 904/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 4.8013e-05 - acc: 0.0520 - val_loss: 0.0211 - val_acc: 0.0280\n",
      "Epoch 905/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 4.6846e-05 - acc: 0.0387 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 906/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 4.7536e-05 - acc: 0.0480 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 907/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 4.9820e-05 - acc: 0.0480 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 908/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 5.1009e-05 - acc: 0.0493 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 909/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 4.7862e-05 - acc: 0.0373 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 910/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 4.6330e-05 - acc: 0.0440 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 911/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 4.7001e-05 - acc: 0.0507 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 912/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 4.9548e-05 - acc: 0.0400 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 913/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 5.2541e-05 - acc: 0.0547 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 914/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 5.7283e-05 - acc: 0.0400 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 915/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 5.2996e-05 - acc: 0.0533 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 916/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 5.2022e-05 - acc: 0.0453 - val_loss: 0.0211 - val_acc: 0.0240\n",
      "Epoch 917/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 5.1422e-05 - acc: 0.0533 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 918/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 5.1774e-05 - acc: 0.0467 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 919/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 5.3506e-05 - acc: 0.0587 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 920/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 4.9286e-05 - acc: 0.0413 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 921/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 4.9327e-05 - acc: 0.0493 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 922/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 4.6283e-05 - acc: 0.0387 - val_loss: 0.0209 - val_acc: 0.0320\n",
      "Epoch 923/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 4.3777e-05 - acc: 0.0320 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 924/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 4.4063e-05 - acc: 0.0387 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 925/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 4.2710e-05 - acc: 0.0400 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 926/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 4.4340e-05 - acc: 0.0453 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 927/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 4.8568e-05 - acc: 0.0467 - val_loss: 0.0211 - val_acc: 0.0240\n",
      "Epoch 928/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 5.7296e-05 - acc: 0.0533 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 929/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 6.3116e-05 - acc: 0.0467 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 930/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 585us/step - loss: 6.6784e-05 - acc: 0.0440 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 931/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 7.0192e-05 - acc: 0.0467 - val_loss: 0.0211 - val_acc: 0.0320\n",
      "Epoch 932/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 6.9221e-05 - acc: 0.0413 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 933/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 6.9953e-05 - acc: 0.0400 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 934/1000\n",
      "750/750 [==============================] - 0s 580us/step - loss: 6.7973e-05 - acc: 0.0493 - val_loss: 0.0210 - val_acc: 0.0360\n",
      "Epoch 935/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 6.4792e-05 - acc: 0.0587 - val_loss: 0.0209 - val_acc: 0.0320\n",
      "Epoch 936/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 6.3075e-05 - acc: 0.0360 - val_loss: 0.0210 - val_acc: 0.0360\n",
      "Epoch 937/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 5.9592e-05 - acc: 0.0533 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 938/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 5.8843e-05 - acc: 0.0613 - val_loss: 0.0210 - val_acc: 0.0360\n",
      "Epoch 939/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 6.1779e-05 - acc: 0.0387 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 940/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 6.6061e-05 - acc: 0.0453 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 941/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 6.4161e-05 - acc: 0.0520 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 942/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 6.4816e-05 - acc: 0.0373 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 943/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 6.1741e-05 - acc: 0.0493 - val_loss: 0.0211 - val_acc: 0.0240\n",
      "Epoch 944/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 6.0831e-05 - acc: 0.0587 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 945/1000\n",
      "750/750 [==============================] - 0s 590us/step - loss: 6.0699e-05 - acc: 0.0373 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 946/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 6.1637e-05 - acc: 0.0520 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 947/1000\n",
      "750/750 [==============================] - 0s 589us/step - loss: 5.9942e-05 - acc: 0.0467 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 948/1000\n",
      "750/750 [==============================] - 0s 588us/step - loss: 5.7566e-05 - acc: 0.0627 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 949/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 5.6857e-05 - acc: 0.0320 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 950/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 6.0476e-05 - acc: 0.0533 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 951/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 6.5472e-05 - acc: 0.0480 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 952/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 6.6808e-05 - acc: 0.0560 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 953/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 5.7159e-05 - acc: 0.0427 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 954/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 4.8723e-05 - acc: 0.0560 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 955/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 4.3452e-05 - acc: 0.0600 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 956/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 4.1502e-05 - acc: 0.0520 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 957/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 3.9431e-05 - acc: 0.0533 - val_loss: 0.0209 - val_acc: 0.0320\n",
      "Epoch 958/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 4.0664e-05 - acc: 0.0493 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 959/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 4.0587e-05 - acc: 0.0520 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 960/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 4.0650e-05 - acc: 0.0493 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 961/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 4.0447e-05 - acc: 0.0373 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 962/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 3.7776e-05 - acc: 0.0693 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 963/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 3.5492e-05 - acc: 0.0493 - val_loss: 0.0208 - val_acc: 0.0240\n",
      "Epoch 964/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 3.3750e-05 - acc: 0.0333 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 965/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 3.3735e-05 - acc: 0.0493 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 966/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 2.9660e-05 - acc: 0.0480 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 967/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 2.8601e-05 - acc: 0.0493 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 968/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 3.0409e-05 - acc: 0.0493 - val_loss: 0.0210 - val_acc: 0.0240\n",
      "Epoch 969/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 3.3882e-05 - acc: 0.0413 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 970/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 3.9761e-05 - acc: 0.0493 - val_loss: 0.0209 - val_acc: 0.0320\n",
      "Epoch 971/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 4.0660e-05 - acc: 0.0413 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 972/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 4.0969e-05 - acc: 0.0520 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 973/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 4.3608e-05 - acc: 0.0480 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 974/1000\n",
      "750/750 [==============================] - 0s 586us/step - loss: 4.6980e-05 - acc: 0.0480 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 975/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 4.7689e-05 - acc: 0.0373 - val_loss: 0.0208 - val_acc: 0.0280\n",
      "Epoch 976/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 4.7872e-05 - acc: 0.0560 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 977/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 4.9991e-05 - acc: 0.0427 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 978/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 5.3634e-05 - acc: 0.0360 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 979/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 6.0239e-05 - acc: 0.0400 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 980/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 5.8395e-05 - acc: 0.0520 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 981/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 5.2531e-05 - acc: 0.0573 - val_loss: 0.0209 - val_acc: 0.0200\n",
      "Epoch 982/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 5.2473e-05 - acc: 0.0320 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 983/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 5.1743e-05 - acc: 0.0413 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 984/1000\n",
      "750/750 [==============================] - 0s 582us/step - loss: 5.0924e-05 - acc: 0.0493 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 985/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 5.3076e-05 - acc: 0.0413 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 986/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 5.4740e-05 - acc: 0.0520 - val_loss: 0.0209 - val_acc: 0.0320\n",
      "Epoch 987/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 5.3881e-05 - acc: 0.0493 - val_loss: 0.0208 - val_acc: 0.0320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 4.7401e-05 - acc: 0.0373 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 989/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 4.3082e-05 - acc: 0.0387 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 990/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 4.3307e-05 - acc: 0.0520 - val_loss: 0.0208 - val_acc: 0.0280\n",
      "Epoch 991/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 3.9792e-05 - acc: 0.0547 - val_loss: 0.0210 - val_acc: 0.0320\n",
      "Epoch 992/1000\n",
      "750/750 [==============================] - 0s 587us/step - loss: 3.9382e-05 - acc: 0.0427 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 993/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 4.1336e-05 - acc: 0.0387 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 994/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 4.3356e-05 - acc: 0.0400 - val_loss: 0.0209 - val_acc: 0.0240\n",
      "Epoch 995/1000\n",
      "750/750 [==============================] - 0s 581us/step - loss: 4.2388e-05 - acc: 0.0520 - val_loss: 0.0210 - val_acc: 0.0280\n",
      "Epoch 996/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 4.0588e-05 - acc: 0.0533 - val_loss: 0.0209 - val_acc: 0.0200\n",
      "Epoch 997/1000\n",
      "750/750 [==============================] - 0s 585us/step - loss: 4.2228e-05 - acc: 0.0547 - val_loss: 0.0209 - val_acc: 0.0320\n",
      "Epoch 998/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 4.2945e-05 - acc: 0.0467 - val_loss: 0.0209 - val_acc: 0.0200\n",
      "Epoch 999/1000\n",
      "750/750 [==============================] - 0s 584us/step - loss: 3.8608e-05 - acc: 0.0347 - val_loss: 0.0209 - val_acc: 0.0280\n",
      "Epoch 1000/1000\n",
      "750/750 [==============================] - 0s 583us/step - loss: 3.3972e-05 - acc: 0.0667 - val_loss: 0.0208 - val_acc: 0.0200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense, Flatten,LSTM, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TIME_STEPS = 3\n",
    "INPUT_SIZE = 512\n",
    "BATCH_SIZE = 50\n",
    "BATCH_INDEX = 0\n",
    "OUTPUT_SIZE = 1536\n",
    "#CELL_SIZE = 800\n",
    "LR = 0.001\n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "# loading data\n",
    "X_train = np.loadtxt(\"0126_spec_train_1000.txt\")\n",
    "y_train = np.loadtxt(\"0126_mask_train_1000.txt\")\n",
    "\n",
    "X_test = np.loadtxt(\"0126_spec_test_1000.txt\")\n",
    "y_test = np.loadtxt(\"0126_mask_test_1000.txt\")\n",
    "\n",
    "# batch_size=y_test.shape[0]\n",
    "\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 3, 512)\n",
    "#y_train = y_train.reshape(-1, 3, 512)\n",
    "X_test = X_test.reshape(-1, 3, 512)\n",
    "#y_test = y_test.reshape(-1, 3, 512)\n",
    "\n",
    "#  build RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# RNN cell\n",
    "\n",
    "model.add(LSTM(\n",
    "    units =1000,\n",
    "    batch_input_shape=( BATCH_SIZE, TIME_STEPS, INPUT_SIZE),\n",
    "    #input_dim=INPUT_SIZE,\n",
    "    #input_length=TIME_STEPS,\n",
    "    #output_dim=CELL_SIZE,\n",
    "    #return_sequences=True,\n",
    "    #stateful=True \n",
    "    unroll=True\n",
    "))\n",
    "\n",
    "# output layer\n",
    "#model.add(Flatten())\n",
    "model.add((Dense(OUTPUT_SIZE)))  #TimeDistributed\n",
    "#model.add(Activation('hard_sigmoid'))\n",
    "\n",
    "# # optimizer\n",
    "#\n",
    "adam = Adam(LR)\n",
    "\n",
    "#optimizer\n",
    "#rmsprop = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=adam,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # training\n",
    "#\n",
    "\n",
    "# for step in range(51):\n",
    "#     # data shape = (batch_num, steps, inputs/outputs)\n",
    "#     X_batch = X_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :, :]\n",
    "#     Y_batch = y_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :]\n",
    "#     cost = model.train_on_batch(X_batch, Y_batch)\n",
    "#     BATCH_INDEX += BATCH_SIZE\n",
    "#     BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "\n",
    "#     if step % 50 == 0:\n",
    "#         print('Next_Train----------: step = ', step)\n",
    "#         train_cost, train_accuracy = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('train_cost: ', train_cost, 'train_accuracy: ', train_accuracy)\n",
    "#         cost, accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "        \n",
    "       \n",
    "\n",
    "print('Train-------------------------')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.25, epochs=1000, shuffle=True, batch_size=50, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "#                                   [model.layers[1].output])\n",
    "# layer_output1 = get_3rd_layer_output([X_train])[0]\n",
    "\n",
    "# print(layer_output1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_mask = y_train.reshape(1000,1536)\n",
    "plt.imshow(abs(y_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [32,1000] vs. [50,1000]\n\t [[Node: lstm_1/add_6 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/BiasAdd_3, lstm_1/MatMul_7)]]\n\t [[Node: dense_1/BiasAdd/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_263_dense_1/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f84d36abc125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#[0:1000])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print('prediction of the model', x_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print('prediction size', x_pred.size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1536\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[0;32m-> 1454\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [32,1000] vs. [50,1000]\n\t [[Node: lstm_1/add_6 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/BiasAdd_3, lstm_1/MatMul_7)]]\n\t [[Node: dense_1/BiasAdd/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_263_dense_1/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "x_pred = model.predict(X_train[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1536)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Predicted_Training_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_mask = y_test.reshape(1000,1536)\n",
    "plt.imshow(abs(y_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [32,1000] vs. [50,1000]\n\t [[Node: lstm_1/add_6 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/BiasAdd_3, lstm_1/MatMul_7)]]\n\t [[Node: dense_1/BiasAdd/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_263_dense_1/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4758c6d7303e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction of the model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1536\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[0;32m-> 1454\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [32,1000] vs. [50,1000]\n\t [[Node: lstm_1/add_6 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_1/BiasAdd_3, lstm_1/MatMul_7)]]\n\t [[Node: dense_1/BiasAdd/_73 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_263_dense_1/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "x_pred = model.predict(X_test[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1536)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Predicted_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear_spec_input_250.txt\n",
    "#clear_mask_generated_from_threshold_250.txt\n",
    "\n",
    "y_c = np.loadtxt(\"clear_mask_generated_from_threshold_250.txt\")\n",
    "\n",
    "y_c = y_c.reshape(250,1024)\n",
    "plt.imshow(abs(y_c[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c = np.loadtxt(\"clear_spec_input_250.txt\")\n",
    "\n",
    "\n",
    "x_c = model.predict(x_c)\n",
    "print('prediction of the model', x_c)\n",
    "print('prediction size', x_c.size)\n",
    "\n",
    "x_c = x_c.reshape(250,1024)\n",
    "plt.imshow(abs(x_c[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Predicted_Mask_for_checking\", fontsize = 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
