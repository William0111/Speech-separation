{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM test by data-10*512 to 1*512\n",
    "# 5000 steps with lr = 0.0005\n",
    "# batch size = 500\n",
    "# no dropout\n",
    "# units = 512\n",
    "# This one is using test_dataset\n",
    "# This one is using lower lr = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are better than\n",
    "best run: \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-------------------------\n",
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/1000\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2365 - acc: 0.0027 - val_loss: 0.1499 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0879 - acc: 0.0000e+00 - val_loss: 0.0367 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0408 - acc: 0.0147 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0397 - acc: 0.0147 - val_loss: 0.0327 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0394 - acc: 0.0093 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0392 - acc: 0.0173 - val_loss: 0.0319 - val_acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0390 - acc: 0.0160 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0388 - acc: 0.0187 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0387 - acc: 0.0187 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0386 - acc: 0.0187 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0384 - acc: 0.0080 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0383 - acc: 0.0160 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0383 - acc: 0.0200 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0378 - acc: 0.0093 - val_loss: 0.0307 - val_acc: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0376 - acc: 0.0173 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0375 - acc: 0.0080 - val_loss: 0.0312 - val_acc: 0.0400\n",
      "Epoch 17/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0381 - acc: 0.0253 - val_loss: 0.0302 - val_acc: 0.0080\n",
      "Epoch 18/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0367 - acc: 0.0120 - val_loss: 0.0299 - val_acc: 0.0320\n",
      "Epoch 19/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0362 - acc: 0.0267 - val_loss: 0.0298 - val_acc: 0.0040\n",
      "Epoch 20/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0367 - acc: 0.0107 - val_loss: 0.0320 - val_acc: 0.0360\n",
      "Epoch 21/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0373 - acc: 0.0227 - val_loss: 0.0293 - val_acc: 0.0200\n",
      "Epoch 22/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0355 - acc: 0.0120 - val_loss: 0.0298 - val_acc: 0.0360\n",
      "Epoch 23/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0353 - acc: 0.0173 - val_loss: 0.0293 - val_acc: 0.0080\n",
      "Epoch 24/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0353 - acc: 0.0187 - val_loss: 0.0310 - val_acc: 0.0280\n",
      "Epoch 25/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0355 - acc: 0.0147 - val_loss: 0.0290 - val_acc: 0.0280\n",
      "Epoch 26/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0344 - acc: 0.0120 - val_loss: 0.0296 - val_acc: 0.0360\n",
      "Epoch 27/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0341 - acc: 0.0187 - val_loss: 0.0290 - val_acc: 0.0240\n",
      "Epoch 28/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0343 - acc: 0.0213 - val_loss: 0.0307 - val_acc: 0.0400\n",
      "Epoch 29/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0342 - acc: 0.0147 - val_loss: 0.0285 - val_acc: 0.0400\n",
      "Epoch 30/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0332 - acc: 0.0253 - val_loss: 0.0300 - val_acc: 0.0400\n",
      "Epoch 31/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0331 - acc: 0.0160 - val_loss: 0.0287 - val_acc: 0.0200\n",
      "Epoch 32/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0336 - acc: 0.0293 - val_loss: 0.0308 - val_acc: 0.0320\n",
      "Epoch 33/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0335 - acc: 0.0213 - val_loss: 0.0283 - val_acc: 0.0480\n",
      "Epoch 34/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0325 - acc: 0.0293 - val_loss: 0.0294 - val_acc: 0.0560\n",
      "Epoch 35/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0320 - acc: 0.0227 - val_loss: 0.0289 - val_acc: 0.0280\n",
      "Epoch 36/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0321 - acc: 0.0280 - val_loss: 0.0315 - val_acc: 0.0480\n",
      "Epoch 37/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0331 - acc: 0.0227 - val_loss: 0.0289 - val_acc: 0.0280\n",
      "Epoch 38/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0328 - acc: 0.0267 - val_loss: 0.0298 - val_acc: 0.0640\n",
      "Epoch 39/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0313 - acc: 0.0253 - val_loss: 0.0285 - val_acc: 0.0520\n",
      "Epoch 40/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0322 - acc: 0.0267 - val_loss: 0.0312 - val_acc: 0.0720\n",
      "Epoch 41/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0320 - acc: 0.0307 - val_loss: 0.0281 - val_acc: 0.0600\n",
      "Epoch 42/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0315 - acc: 0.0360 - val_loss: 0.0302 - val_acc: 0.0760\n",
      "Epoch 43/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0310 - acc: 0.0253 - val_loss: 0.0281 - val_acc: 0.0560\n",
      "Epoch 44/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0322 - acc: 0.0333 - val_loss: 0.0307 - val_acc: 0.0640\n",
      "Epoch 45/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0313 - acc: 0.0427 - val_loss: 0.0282 - val_acc: 0.0400\n",
      "Epoch 46/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0310 - acc: 0.0320 - val_loss: 0.0302 - val_acc: 0.0640\n",
      "Epoch 47/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0305 - acc: 0.0307 - val_loss: 0.0280 - val_acc: 0.0680\n",
      "Epoch 48/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0313 - acc: 0.0333 - val_loss: 0.0308 - val_acc: 0.0520\n",
      "Epoch 49/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0309 - acc: 0.0453 - val_loss: 0.0279 - val_acc: 0.0520\n",
      "Epoch 50/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0309 - acc: 0.0347 - val_loss: 0.0299 - val_acc: 0.0600\n",
      "Epoch 51/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0301 - acc: 0.0493 - val_loss: 0.0287 - val_acc: 0.0800\n",
      "Epoch 52/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0302 - acc: 0.0507 - val_loss: 0.0315 - val_acc: 0.0520\n",
      "Epoch 53/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0316 - acc: 0.0253 - val_loss: 0.0283 - val_acc: 0.0400\n",
      "Epoch 54/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0307 - acc: 0.0360 - val_loss: 0.0292 - val_acc: 0.0720\n",
      "Epoch 55/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0297 - acc: 0.0427 - val_loss: 0.0290 - val_acc: 0.0840\n",
      "Epoch 56/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0296 - acc: 0.0453 - val_loss: 0.0302 - val_acc: 0.0560\n",
      "Epoch 57/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0299 - acc: 0.0573 - val_loss: 0.0278 - val_acc: 0.0640\n",
      "Epoch 58/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0314 - acc: 0.0613 - val_loss: 0.0298 - val_acc: 0.0760\n",
      "Epoch 59/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0298 - acc: 0.0440 - val_loss: 0.0278 - val_acc: 0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0296 - acc: 0.0413 - val_loss: 0.0291 - val_acc: 0.0680\n",
      "Epoch 61/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0296 - acc: 0.0440 - val_loss: 0.0278 - val_acc: 0.0520\n",
      "Epoch 62/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0301 - acc: 0.0560 - val_loss: 0.0304 - val_acc: 0.0600\n",
      "Epoch 63/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0295 - acc: 0.0547 - val_loss: 0.0276 - val_acc: 0.0640\n",
      "Epoch 64/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0298 - acc: 0.0773 - val_loss: 0.0296 - val_acc: 0.0560\n",
      "Epoch 65/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0289 - acc: 0.0467 - val_loss: 0.0281 - val_acc: 0.1200\n",
      "Epoch 66/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0294 - acc: 0.0733 - val_loss: 0.0308 - val_acc: 0.0760\n",
      "Epoch 67/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0303 - acc: 0.0360 - val_loss: 0.0278 - val_acc: 0.0240\n",
      "Epoch 68/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0299 - acc: 0.0720 - val_loss: 0.0289 - val_acc: 0.0680\n",
      "Epoch 69/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0288 - acc: 0.0573 - val_loss: 0.0281 - val_acc: 0.1400\n",
      "Epoch 70/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0288 - acc: 0.0947 - val_loss: 0.0300 - val_acc: 0.0720\n",
      "Epoch 71/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0289 - acc: 0.0627 - val_loss: 0.0275 - val_acc: 0.0800\n",
      "Epoch 72/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0295 - acc: 0.0840 - val_loss: 0.0295 - val_acc: 0.0960\n",
      "Epoch 73/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0287 - acc: 0.0600 - val_loss: 0.0275 - val_acc: 0.0720\n",
      "Epoch 74/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0286 - acc: 0.0760 - val_loss: 0.0294 - val_acc: 0.1080\n",
      "Epoch 75/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0285 - acc: 0.0680 - val_loss: 0.0275 - val_acc: 0.1440\n",
      "Epoch 76/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0289 - acc: 0.1013 - val_loss: 0.0294 - val_acc: 0.0640\n",
      "Epoch 77/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0282 - acc: 0.0693 - val_loss: 0.0278 - val_acc: 0.1520\n",
      "Epoch 78/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0282 - acc: 0.1120 - val_loss: 0.0298 - val_acc: 0.1160\n",
      "Epoch 79/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0292 - acc: 0.0667 - val_loss: 0.0278 - val_acc: 0.0600\n",
      "Epoch 80/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0291 - acc: 0.0853 - val_loss: 0.0288 - val_acc: 0.0960\n",
      "Epoch 81/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0277 - acc: 0.0667 - val_loss: 0.0277 - val_acc: 0.1720\n",
      "Epoch 82/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0279 - acc: 0.1120 - val_loss: 0.0296 - val_acc: 0.0920\n",
      "Epoch 83/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0279 - acc: 0.0680 - val_loss: 0.0273 - val_acc: 0.1200\n",
      "Epoch 84/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0282 - acc: 0.0933 - val_loss: 0.0292 - val_acc: 0.1240\n",
      "Epoch 85/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0276 - acc: 0.0827 - val_loss: 0.0273 - val_acc: 0.0720\n",
      "Epoch 86/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0276 - acc: 0.0853 - val_loss: 0.0293 - val_acc: 0.1320\n",
      "Epoch 87/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0274 - acc: 0.1000 - val_loss: 0.0273 - val_acc: 0.1040\n",
      "Epoch 88/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0279 - acc: 0.0987 - val_loss: 0.0296 - val_acc: 0.0480\n",
      "Epoch 89/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0275 - acc: 0.0800 - val_loss: 0.0274 - val_acc: 0.1440\n",
      "Epoch 90/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0272 - acc: 0.1107 - val_loss: 0.0291 - val_acc: 0.0880\n",
      "Epoch 91/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0274 - acc: 0.0800 - val_loss: 0.0273 - val_acc: 0.0600\n",
      "Epoch 92/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0278 - acc: 0.0853 - val_loss: 0.0291 - val_acc: 0.0760\n",
      "Epoch 93/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0265 - acc: 0.0907 - val_loss: 0.0273 - val_acc: 0.0840\n",
      "Epoch 94/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0270 - acc: 0.1027 - val_loss: 0.0296 - val_acc: 0.0640\n",
      "Epoch 95/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0271 - acc: 0.0840 - val_loss: 0.0268 - val_acc: 0.0680\n",
      "Epoch 96/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0268 - acc: 0.0893 - val_loss: 0.0289 - val_acc: 0.0880\n",
      "Epoch 97/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0262 - acc: 0.0827 - val_loss: 0.0270 - val_acc: 0.0800\n",
      "Epoch 98/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0268 - acc: 0.0933 - val_loss: 0.0292 - val_acc: 0.0920\n",
      "Epoch 99/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0265 - acc: 0.0800 - val_loss: 0.0273 - val_acc: 0.0560\n",
      "Epoch 100/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0265 - acc: 0.0853 - val_loss: 0.0291 - val_acc: 0.0920\n",
      "Epoch 101/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0260 - acc: 0.0920 - val_loss: 0.0272 - val_acc: 0.0920\n",
      "Epoch 102/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0273 - acc: 0.1293 - val_loss: 0.0289 - val_acc: 0.0680\n",
      "Epoch 103/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0262 - acc: 0.0907 - val_loss: 0.0268 - val_acc: 0.0560\n",
      "Epoch 104/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0258 - acc: 0.0987 - val_loss: 0.0286 - val_acc: 0.1000\n",
      "Epoch 105/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0254 - acc: 0.0893 - val_loss: 0.0270 - val_acc: 0.0680\n",
      "Epoch 106/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0260 - acc: 0.1000 - val_loss: 0.0297 - val_acc: 0.1120\n",
      "Epoch 107/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0261 - acc: 0.1080 - val_loss: 0.0270 - val_acc: 0.0640\n",
      "Epoch 108/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0258 - acc: 0.0987 - val_loss: 0.0291 - val_acc: 0.0920\n",
      "Epoch 109/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0253 - acc: 0.0960 - val_loss: 0.0273 - val_acc: 0.1240\n",
      "Epoch 110/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0258 - acc: 0.1320 - val_loss: 0.0286 - val_acc: 0.1080\n",
      "Epoch 111/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0252 - acc: 0.0933 - val_loss: 0.0268 - val_acc: 0.0880\n",
      "Epoch 112/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0253 - acc: 0.1107 - val_loss: 0.0295 - val_acc: 0.1040\n",
      "Epoch 113/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0251 - acc: 0.0920 - val_loss: 0.0269 - val_acc: 0.0800\n",
      "Epoch 114/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0252 - acc: 0.1000 - val_loss: 0.0292 - val_acc: 0.0720\n",
      "Epoch 115/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0249 - acc: 0.0920 - val_loss: 0.0267 - val_acc: 0.1240\n",
      "Epoch 116/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0251 - acc: 0.1133 - val_loss: 0.0298 - val_acc: 0.0960\n",
      "Epoch 117/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0251 - acc: 0.0880 - val_loss: 0.0271 - val_acc: 0.1200\n",
      "Epoch 118/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0245 - acc: 0.1147 - val_loss: 0.0287 - val_acc: 0.0840\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 169us/step - loss: 0.0245 - acc: 0.1000 - val_loss: 0.0268 - val_acc: 0.1360\n",
      "Epoch 120/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0250 - acc: 0.1080 - val_loss: 0.0295 - val_acc: 0.0800\n",
      "Epoch 121/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0241 - acc: 0.0947 - val_loss: 0.0273 - val_acc: 0.0720\n",
      "Epoch 122/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0241 - acc: 0.1013 - val_loss: 0.0294 - val_acc: 0.1280\n",
      "Epoch 123/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0245 - acc: 0.1040 - val_loss: 0.0266 - val_acc: 0.1400\n",
      "Epoch 124/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0249 - acc: 0.1253 - val_loss: 0.0292 - val_acc: 0.1160\n",
      "Epoch 125/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0240 - acc: 0.0880 - val_loss: 0.0270 - val_acc: 0.1440\n",
      "Epoch 126/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0236 - acc: 0.1200 - val_loss: 0.0286 - val_acc: 0.1360\n",
      "Epoch 127/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0236 - acc: 0.1080 - val_loss: 0.0268 - val_acc: 0.1400\n",
      "Epoch 128/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0242 - acc: 0.0933 - val_loss: 0.0295 - val_acc: 0.0680\n",
      "Epoch 129/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0233 - acc: 0.0867 - val_loss: 0.0271 - val_acc: 0.0960\n",
      "Epoch 130/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0235 - acc: 0.1067 - val_loss: 0.0306 - val_acc: 0.1120\n",
      "Epoch 131/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0241 - acc: 0.0813 - val_loss: 0.0267 - val_acc: 0.1240\n",
      "Epoch 132/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0236 - acc: 0.1200 - val_loss: 0.0283 - val_acc: 0.0720\n",
      "Epoch 133/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0229 - acc: 0.0827 - val_loss: 0.0269 - val_acc: 0.1360\n",
      "Epoch 134/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0229 - acc: 0.1120 - val_loss: 0.0295 - val_acc: 0.1000\n",
      "Epoch 135/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0235 - acc: 0.0973 - val_loss: 0.0270 - val_acc: 0.0960\n",
      "Epoch 136/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0230 - acc: 0.0853 - val_loss: 0.0289 - val_acc: 0.0760\n",
      "Epoch 137/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0223 - acc: 0.0880 - val_loss: 0.0276 - val_acc: 0.0760\n",
      "Epoch 138/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0229 - acc: 0.1200 - val_loss: 0.0306 - val_acc: 0.1160\n",
      "Epoch 139/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0232 - acc: 0.0880 - val_loss: 0.0267 - val_acc: 0.1000\n",
      "Epoch 140/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0229 - acc: 0.1067 - val_loss: 0.0284 - val_acc: 0.0800\n",
      "Epoch 141/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0223 - acc: 0.0893 - val_loss: 0.0267 - val_acc: 0.1080\n",
      "Epoch 142/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0223 - acc: 0.1053 - val_loss: 0.0297 - val_acc: 0.0720\n",
      "Epoch 143/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0222 - acc: 0.0947 - val_loss: 0.0269 - val_acc: 0.0960\n",
      "Epoch 144/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0219 - acc: 0.0947 - val_loss: 0.0293 - val_acc: 0.0800\n",
      "Epoch 145/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0224 - acc: 0.0893 - val_loss: 0.0268 - val_acc: 0.0520\n",
      "Epoch 146/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0228 - acc: 0.1067 - val_loss: 0.0287 - val_acc: 0.0800\n",
      "Epoch 147/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0218 - acc: 0.0880 - val_loss: 0.0269 - val_acc: 0.0840\n",
      "Epoch 148/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0214 - acc: 0.1107 - val_loss: 0.0287 - val_acc: 0.0880\n",
      "Epoch 149/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0216 - acc: 0.0973 - val_loss: 0.0268 - val_acc: 0.1360\n",
      "Epoch 150/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0218 - acc: 0.1107 - val_loss: 0.0291 - val_acc: 0.0640\n",
      "Epoch 151/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0212 - acc: 0.0947 - val_loss: 0.0270 - val_acc: 0.0920\n",
      "Epoch 152/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0220 - acc: 0.1240 - val_loss: 0.0308 - val_acc: 0.1320\n",
      "Epoch 153/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0220 - acc: 0.0880 - val_loss: 0.0271 - val_acc: 0.0680\n",
      "Epoch 154/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0209 - acc: 0.1107 - val_loss: 0.0285 - val_acc: 0.0960\n",
      "Epoch 155/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0208 - acc: 0.1040 - val_loss: 0.0268 - val_acc: 0.1360\n",
      "Epoch 156/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0212 - acc: 0.1173 - val_loss: 0.0286 - val_acc: 0.0880\n",
      "Epoch 157/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0212 - acc: 0.1120 - val_loss: 0.0267 - val_acc: 0.1000\n",
      "Epoch 158/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0210 - acc: 0.1107 - val_loss: 0.0303 - val_acc: 0.0920\n",
      "Epoch 159/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0208 - acc: 0.0907 - val_loss: 0.0274 - val_acc: 0.0880\n",
      "Epoch 160/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0210 - acc: 0.1467 - val_loss: 0.0299 - val_acc: 0.1120\n",
      "Epoch 161/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0207 - acc: 0.0987 - val_loss: 0.0270 - val_acc: 0.0840\n",
      "Epoch 162/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0202 - acc: 0.1160 - val_loss: 0.0283 - val_acc: 0.1040\n",
      "Epoch 163/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0202 - acc: 0.1160 - val_loss: 0.0272 - val_acc: 0.1120\n",
      "Epoch 164/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0202 - acc: 0.1053 - val_loss: 0.0281 - val_acc: 0.0640\n",
      "Epoch 165/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0201 - acc: 0.1133 - val_loss: 0.0287 - val_acc: 0.1520\n",
      "Epoch 166/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0200 - acc: 0.1120 - val_loss: 0.0272 - val_acc: 0.0960\n",
      "Epoch 167/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0208 - acc: 0.1240 - val_loss: 0.0313 - val_acc: 0.1000\n",
      "Epoch 168/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0208 - acc: 0.1293 - val_loss: 0.0266 - val_acc: 0.1240\n",
      "Epoch 169/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0197 - acc: 0.1280 - val_loss: 0.0282 - val_acc: 0.1000\n",
      "Epoch 170/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0192 - acc: 0.1013 - val_loss: 0.0279 - val_acc: 0.0840\n",
      "Epoch 171/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0194 - acc: 0.1267 - val_loss: 0.0285 - val_acc: 0.1080\n",
      "Epoch 172/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0195 - acc: 0.1160 - val_loss: 0.0270 - val_acc: 0.0880\n",
      "Epoch 173/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0197 - acc: 0.1307 - val_loss: 0.0297 - val_acc: 0.1120\n",
      "Epoch 174/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0197 - acc: 0.1093 - val_loss: 0.0265 - val_acc: 0.0960\n",
      "Epoch 175/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0194 - acc: 0.1307 - val_loss: 0.0305 - val_acc: 0.0880\n",
      "Epoch 176/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0195 - acc: 0.1160 - val_loss: 0.0270 - val_acc: 0.1040\n",
      "Epoch 177/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0187 - acc: 0.1360 - val_loss: 0.0287 - val_acc: 0.0960\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0187 - acc: 0.1173 - val_loss: 0.0270 - val_acc: 0.1560\n",
      "Epoch 179/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0192 - acc: 0.1333 - val_loss: 0.0291 - val_acc: 0.0920\n",
      "Epoch 180/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0194 - acc: 0.1507 - val_loss: 0.0286 - val_acc: 0.1280\n",
      "Epoch 181/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0187 - acc: 0.1080 - val_loss: 0.0277 - val_acc: 0.1040\n",
      "Epoch 182/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0188 - acc: 0.1467 - val_loss: 0.0305 - val_acc: 0.1240\n",
      "Epoch 183/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0188 - acc: 0.1307 - val_loss: 0.0269 - val_acc: 0.1080\n",
      "Epoch 184/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0184 - acc: 0.1373 - val_loss: 0.0289 - val_acc: 0.1200\n",
      "Epoch 185/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0180 - acc: 0.1360 - val_loss: 0.0273 - val_acc: 0.1040\n",
      "Epoch 186/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0181 - acc: 0.1333 - val_loss: 0.0304 - val_acc: 0.1120\n",
      "Epoch 187/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0184 - acc: 0.1187 - val_loss: 0.0271 - val_acc: 0.1320\n",
      "Epoch 188/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0180 - acc: 0.1640 - val_loss: 0.0301 - val_acc: 0.1040\n",
      "Epoch 189/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0184 - acc: 0.1307 - val_loss: 0.0272 - val_acc: 0.1160\n",
      "Epoch 190/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0181 - acc: 0.1573 - val_loss: 0.0285 - val_acc: 0.1520\n",
      "Epoch 191/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0178 - acc: 0.1267 - val_loss: 0.0286 - val_acc: 0.0880\n",
      "Epoch 192/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0176 - acc: 0.1387 - val_loss: 0.0280 - val_acc: 0.1080\n",
      "Epoch 193/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0175 - acc: 0.1333 - val_loss: 0.0287 - val_acc: 0.1080\n",
      "Epoch 194/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0175 - acc: 0.1453 - val_loss: 0.0279 - val_acc: 0.1080\n",
      "Epoch 195/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0169 - acc: 0.1453 - val_loss: 0.0296 - val_acc: 0.1240\n",
      "Epoch 196/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0176 - acc: 0.1387 - val_loss: 0.0267 - val_acc: 0.1120\n",
      "Epoch 197/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0188 - acc: 0.1480 - val_loss: 0.0307 - val_acc: 0.1200\n",
      "Epoch 198/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0174 - acc: 0.1493 - val_loss: 0.0274 - val_acc: 0.1240\n",
      "Epoch 199/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0168 - acc: 0.1680 - val_loss: 0.0284 - val_acc: 0.1240\n",
      "Epoch 200/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0166 - acc: 0.1413 - val_loss: 0.0287 - val_acc: 0.1000\n",
      "Epoch 201/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0167 - acc: 0.1533 - val_loss: 0.0285 - val_acc: 0.1480\n",
      "Epoch 202/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0165 - acc: 0.1707 - val_loss: 0.0277 - val_acc: 0.1200\n",
      "Epoch 203/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0167 - acc: 0.1547 - val_loss: 0.0299 - val_acc: 0.1200\n",
      "Epoch 204/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0172 - acc: 0.1507 - val_loss: 0.0270 - val_acc: 0.1160\n",
      "Epoch 205/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0170 - acc: 0.1813 - val_loss: 0.0310 - val_acc: 0.1440\n",
      "Epoch 206/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0168 - acc: 0.1467 - val_loss: 0.0280 - val_acc: 0.1280\n",
      "Epoch 207/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0160 - acc: 0.1653 - val_loss: 0.0285 - val_acc: 0.1480\n",
      "Epoch 208/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0160 - acc: 0.1507 - val_loss: 0.0287 - val_acc: 0.1160\n",
      "Epoch 209/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0158 - acc: 0.1573 - val_loss: 0.0283 - val_acc: 0.1120\n",
      "Epoch 210/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0159 - acc: 0.1560 - val_loss: 0.0288 - val_acc: 0.1480\n",
      "Epoch 211/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0157 - acc: 0.1507 - val_loss: 0.0293 - val_acc: 0.1080\n",
      "Epoch 212/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0169 - acc: 0.1720 - val_loss: 0.0273 - val_acc: 0.1680\n",
      "Epoch 213/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0162 - acc: 0.1680 - val_loss: 0.0304 - val_acc: 0.1160\n",
      "Epoch 214/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0156 - acc: 0.1613 - val_loss: 0.0283 - val_acc: 0.1160\n",
      "Epoch 215/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0161 - acc: 0.1893 - val_loss: 0.0306 - val_acc: 0.1560\n",
      "Epoch 216/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0159 - acc: 0.1640 - val_loss: 0.0280 - val_acc: 0.1240\n",
      "Epoch 217/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0153 - acc: 0.1827 - val_loss: 0.0288 - val_acc: 0.1920\n",
      "Epoch 218/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0151 - acc: 0.1840 - val_loss: 0.0283 - val_acc: 0.1280\n",
      "Epoch 219/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0149 - acc: 0.1747 - val_loss: 0.0296 - val_acc: 0.1800\n",
      "Epoch 220/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0151 - acc: 0.1693 - val_loss: 0.0277 - val_acc: 0.1360\n",
      "Epoch 221/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0153 - acc: 0.1600 - val_loss: 0.0308 - val_acc: 0.1320\n",
      "Epoch 222/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0153 - acc: 0.1760 - val_loss: 0.0276 - val_acc: 0.1920\n",
      "Epoch 223/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0154 - acc: 0.2040 - val_loss: 0.0308 - val_acc: 0.1560\n",
      "Epoch 224/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0153 - acc: 0.1880 - val_loss: 0.0280 - val_acc: 0.1480\n",
      "Epoch 225/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0147 - acc: 0.2040 - val_loss: 0.0288 - val_acc: 0.1640\n",
      "Epoch 226/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0143 - acc: 0.1760 - val_loss: 0.0288 - val_acc: 0.1400\n",
      "Epoch 227/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0142 - acc: 0.1653 - val_loss: 0.0290 - val_acc: 0.1400\n",
      "Epoch 228/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0142 - acc: 0.1720 - val_loss: 0.0290 - val_acc: 0.1720\n",
      "Epoch 229/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0143 - acc: 0.1787 - val_loss: 0.0291 - val_acc: 0.1440\n",
      "Epoch 230/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0140 - acc: 0.1787 - val_loss: 0.0291 - val_acc: 0.1880\n",
      "Epoch 231/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0143 - acc: 0.1933 - val_loss: 0.0297 - val_acc: 0.1480\n",
      "Epoch 232/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0146 - acc: 0.2173 - val_loss: 0.0308 - val_acc: 0.1800\n",
      "Epoch 233/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0153 - acc: 0.1947 - val_loss: 0.0269 - val_acc: 0.1640\n",
      "Epoch 234/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0146 - acc: 0.2227 - val_loss: 0.0301 - val_acc: 0.1560\n",
      "Epoch 235/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0133 - acc: 0.1907 - val_loss: 0.0289 - val_acc: 0.1800\n",
      "Epoch 236/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0132 - acc: 0.1933 - val_loss: 0.0298 - val_acc: 0.1560\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0135 - acc: 0.1867 - val_loss: 0.0290 - val_acc: 0.1560\n",
      "Epoch 238/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0136 - acc: 0.1800 - val_loss: 0.0298 - val_acc: 0.1720\n",
      "Epoch 239/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0135 - acc: 0.1933 - val_loss: 0.0293 - val_acc: 0.1400\n",
      "Epoch 240/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0135 - acc: 0.2080 - val_loss: 0.0290 - val_acc: 0.1840\n",
      "Epoch 241/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0134 - acc: 0.2187 - val_loss: 0.0298 - val_acc: 0.1960\n",
      "Epoch 242/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0135 - acc: 0.2107 - val_loss: 0.0282 - val_acc: 0.1840\n",
      "Epoch 243/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0137 - acc: 0.2267 - val_loss: 0.0317 - val_acc: 0.1880\n",
      "Epoch 244/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0138 - acc: 0.2067 - val_loss: 0.0278 - val_acc: 0.1480\n",
      "Epoch 245/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0128 - acc: 0.2360 - val_loss: 0.0297 - val_acc: 0.2000\n",
      "Epoch 246/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0125 - acc: 0.2040 - val_loss: 0.0294 - val_acc: 0.1800\n",
      "Epoch 247/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0128 - acc: 0.2080 - val_loss: 0.0293 - val_acc: 0.1760\n",
      "Epoch 248/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0127 - acc: 0.2053 - val_loss: 0.0300 - val_acc: 0.1720\n",
      "Epoch 249/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0128 - acc: 0.2120 - val_loss: 0.0278 - val_acc: 0.2000\n",
      "Epoch 250/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0134 - acc: 0.2213 - val_loss: 0.0312 - val_acc: 0.1600\n",
      "Epoch 251/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0129 - acc: 0.2200 - val_loss: 0.0282 - val_acc: 0.2120\n",
      "Epoch 252/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0127 - acc: 0.2320 - val_loss: 0.0302 - val_acc: 0.1720\n",
      "Epoch 253/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0119 - acc: 0.2080 - val_loss: 0.0290 - val_acc: 0.1920\n",
      "Epoch 254/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0118 - acc: 0.2293 - val_loss: 0.0297 - val_acc: 0.1840\n",
      "Epoch 255/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0119 - acc: 0.2200 - val_loss: 0.0295 - val_acc: 0.1840\n",
      "Epoch 256/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0122 - acc: 0.2227 - val_loss: 0.0302 - val_acc: 0.1960\n",
      "Epoch 257/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0126 - acc: 0.2373 - val_loss: 0.0280 - val_acc: 0.1880\n",
      "Epoch 258/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0129 - acc: 0.2667 - val_loss: 0.0324 - val_acc: 0.2280\n",
      "Epoch 259/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0125 - acc: 0.2280 - val_loss: 0.0294 - val_acc: 0.1720\n",
      "Epoch 260/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0115 - acc: 0.2440 - val_loss: 0.0301 - val_acc: 0.1920\n",
      "Epoch 261/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0113 - acc: 0.2160 - val_loss: 0.0301 - val_acc: 0.1880\n",
      "Epoch 262/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0115 - acc: 0.2347 - val_loss: 0.0302 - val_acc: 0.1920\n",
      "Epoch 263/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0114 - acc: 0.2173 - val_loss: 0.0296 - val_acc: 0.2080\n",
      "Epoch 264/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0113 - acc: 0.2387 - val_loss: 0.0312 - val_acc: 0.1560\n",
      "Epoch 265/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0119 - acc: 0.2240 - val_loss: 0.0280 - val_acc: 0.2320\n",
      "Epoch 266/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0125 - acc: 0.2573 - val_loss: 0.0323 - val_acc: 0.2000\n",
      "Epoch 267/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0117 - acc: 0.2427 - val_loss: 0.0289 - val_acc: 0.2160\n",
      "Epoch 268/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0110 - acc: 0.2587 - val_loss: 0.0305 - val_acc: 0.2000\n",
      "Epoch 269/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0107 - acc: 0.2373 - val_loss: 0.0299 - val_acc: 0.1920\n",
      "Epoch 270/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0110 - acc: 0.2480 - val_loss: 0.0298 - val_acc: 0.2200\n",
      "Epoch 271/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0109 - acc: 0.2413 - val_loss: 0.0304 - val_acc: 0.1720\n",
      "Epoch 272/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0109 - acc: 0.2733 - val_loss: 0.0301 - val_acc: 0.2160\n",
      "Epoch 273/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0108 - acc: 0.2573 - val_loss: 0.0293 - val_acc: 0.2240\n",
      "Epoch 274/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0110 - acc: 0.2693 - val_loss: 0.0317 - val_acc: 0.2120\n",
      "Epoch 275/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0111 - acc: 0.2520 - val_loss: 0.0284 - val_acc: 0.2400\n",
      "Epoch 276/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0110 - acc: 0.2853 - val_loss: 0.0322 - val_acc: 0.2040\n",
      "Epoch 277/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0106 - acc: 0.2493 - val_loss: 0.0295 - val_acc: 0.2040\n",
      "Epoch 278/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0103 - acc: 0.2787 - val_loss: 0.0307 - val_acc: 0.2040\n",
      "Epoch 279/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0102 - acc: 0.2520 - val_loss: 0.0298 - val_acc: 0.1960\n",
      "Epoch 280/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0101 - acc: 0.2680 - val_loss: 0.0307 - val_acc: 0.2040\n",
      "Epoch 281/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0100 - acc: 0.2547 - val_loss: 0.0295 - val_acc: 0.2200\n",
      "Epoch 282/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0105 - acc: 0.2613 - val_loss: 0.0311 - val_acc: 0.2000\n",
      "Epoch 283/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0104 - acc: 0.2573 - val_loss: 0.0290 - val_acc: 0.2200\n",
      "Epoch 284/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0104 - acc: 0.2600 - val_loss: 0.0308 - val_acc: 0.2040\n",
      "Epoch 285/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0098 - acc: 0.2733 - val_loss: 0.0308 - val_acc: 0.2040\n",
      "Epoch 286/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0099 - acc: 0.2787 - val_loss: 0.0289 - val_acc: 0.2160\n",
      "Epoch 287/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0102 - acc: 0.2907 - val_loss: 0.0323 - val_acc: 0.2120\n",
      "Epoch 288/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0104 - acc: 0.2853 - val_loss: 0.0292 - val_acc: 0.2360\n",
      "Epoch 289/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0095 - acc: 0.3040 - val_loss: 0.0309 - val_acc: 0.2040\n",
      "Epoch 290/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0094 - acc: 0.2520 - val_loss: 0.0303 - val_acc: 0.2080\n",
      "Epoch 291/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0093 - acc: 0.2947 - val_loss: 0.0308 - val_acc: 0.2280\n",
      "Epoch 292/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0090 - acc: 0.2800 - val_loss: 0.0301 - val_acc: 0.2200\n",
      "Epoch 293/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0092 - acc: 0.2880 - val_loss: 0.0329 - val_acc: 0.1880\n",
      "Epoch 294/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0103 - acc: 0.2773 - val_loss: 0.0287 - val_acc: 0.2200\n",
      "Epoch 295/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0096 - acc: 0.3067 - val_loss: 0.0319 - val_acc: 0.2080\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 164us/step - loss: 0.0090 - acc: 0.2867 - val_loss: 0.0299 - val_acc: 0.2280\n",
      "Epoch 297/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0090 - acc: 0.3320 - val_loss: 0.0319 - val_acc: 0.2120\n",
      "Epoch 298/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0089 - acc: 0.2947 - val_loss: 0.0295 - val_acc: 0.2240\n",
      "Epoch 299/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0090 - acc: 0.3120 - val_loss: 0.0313 - val_acc: 0.2080\n",
      "Epoch 300/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0089 - acc: 0.3013 - val_loss: 0.0298 - val_acc: 0.2400\n",
      "Epoch 301/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0086 - acc: 0.2987 - val_loss: 0.0304 - val_acc: 0.2160\n",
      "Epoch 302/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0086 - acc: 0.2973 - val_loss: 0.0306 - val_acc: 0.2200\n",
      "Epoch 303/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0082 - acc: 0.3027 - val_loss: 0.0308 - val_acc: 0.2360\n",
      "Epoch 304/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0083 - acc: 0.2867 - val_loss: 0.0309 - val_acc: 0.2000\n",
      "Epoch 305/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0085 - acc: 0.2960 - val_loss: 0.0307 - val_acc: 0.2440\n",
      "Epoch 306/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0086 - acc: 0.3147 - val_loss: 0.0317 - val_acc: 0.2400\n",
      "Epoch 307/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0080 - acc: 0.3067 - val_loss: 0.0306 - val_acc: 0.2160\n",
      "Epoch 308/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0079 - acc: 0.3227 - val_loss: 0.0316 - val_acc: 0.2360\n",
      "Epoch 309/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0086 - acc: 0.3293 - val_loss: 0.0292 - val_acc: 0.2440\n",
      "Epoch 310/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0089 - acc: 0.3347 - val_loss: 0.0343 - val_acc: 0.1920\n",
      "Epoch 311/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0082 - acc: 0.3067 - val_loss: 0.0299 - val_acc: 0.2480\n",
      "Epoch 312/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0074 - acc: 0.3373 - val_loss: 0.0313 - val_acc: 0.2320\n",
      "Epoch 313/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0072 - acc: 0.3133 - val_loss: 0.0312 - val_acc: 0.2320\n",
      "Epoch 314/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0075 - acc: 0.3253 - val_loss: 0.0317 - val_acc: 0.2120\n",
      "Epoch 315/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0076 - acc: 0.3053 - val_loss: 0.0307 - val_acc: 0.1960\n",
      "Epoch 316/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0079 - acc: 0.3040 - val_loss: 0.0336 - val_acc: 0.2200\n",
      "Epoch 317/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0081 - acc: 0.3427 - val_loss: 0.0294 - val_acc: 0.2480\n",
      "Epoch 318/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0075 - acc: 0.3827 - val_loss: 0.0329 - val_acc: 0.2360\n",
      "Epoch 319/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0072 - acc: 0.3240 - val_loss: 0.0304 - val_acc: 0.2320\n",
      "Epoch 320/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0073 - acc: 0.3707 - val_loss: 0.0326 - val_acc: 0.2160\n",
      "Epoch 321/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0075 - acc: 0.3187 - val_loss: 0.0301 - val_acc: 0.2400\n",
      "Epoch 322/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0071 - acc: 0.3400 - val_loss: 0.0322 - val_acc: 0.2240\n",
      "Epoch 323/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0069 - acc: 0.3160 - val_loss: 0.0301 - val_acc: 0.2480\n",
      "Epoch 324/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0071 - acc: 0.3307 - val_loss: 0.0325 - val_acc: 0.2240\n",
      "Epoch 325/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0068 - acc: 0.3333 - val_loss: 0.0302 - val_acc: 0.2360\n",
      "Epoch 326/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0067 - acc: 0.3333 - val_loss: 0.0334 - val_acc: 0.2160\n",
      "Epoch 327/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0073 - acc: 0.3387 - val_loss: 0.0301 - val_acc: 0.2480\n",
      "Epoch 328/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0075 - acc: 0.3573 - val_loss: 0.0332 - val_acc: 0.2360\n",
      "Epoch 329/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0066 - acc: 0.3427 - val_loss: 0.0313 - val_acc: 0.2360\n",
      "Epoch 330/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0064 - acc: 0.3773 - val_loss: 0.0306 - val_acc: 0.2440\n",
      "Epoch 331/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0067 - acc: 0.3707 - val_loss: 0.0331 - val_acc: 0.2160\n",
      "Epoch 332/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0068 - acc: 0.3573 - val_loss: 0.0296 - val_acc: 0.2320\n",
      "Epoch 333/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0065 - acc: 0.3733 - val_loss: 0.0327 - val_acc: 0.2280\n",
      "Epoch 334/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0062 - acc: 0.3427 - val_loss: 0.0302 - val_acc: 0.2480\n",
      "Epoch 335/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0062 - acc: 0.3707 - val_loss: 0.0329 - val_acc: 0.2120\n",
      "Epoch 336/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0061 - acc: 0.3480 - val_loss: 0.0310 - val_acc: 0.2400\n",
      "Epoch 337/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0062 - acc: 0.3640 - val_loss: 0.0333 - val_acc: 0.2240\n",
      "Epoch 338/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0069 - acc: 0.3480 - val_loss: 0.0305 - val_acc: 0.2240\n",
      "Epoch 339/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0063 - acc: 0.3720 - val_loss: 0.0334 - val_acc: 0.2280\n",
      "Epoch 340/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0059 - acc: 0.3373 - val_loss: 0.0305 - val_acc: 0.2480\n",
      "Epoch 341/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0058 - acc: 0.3867 - val_loss: 0.0329 - val_acc: 0.2520\n",
      "Epoch 342/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0057 - acc: 0.3707 - val_loss: 0.0309 - val_acc: 0.2320\n",
      "Epoch 343/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0060 - acc: 0.3667 - val_loss: 0.0334 - val_acc: 0.1920\n",
      "Epoch 344/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0061 - acc: 0.3533 - val_loss: 0.0300 - val_acc: 0.2560\n",
      "Epoch 345/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0058 - acc: 0.3600 - val_loss: 0.0333 - val_acc: 0.2360\n",
      "Epoch 346/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0056 - acc: 0.4027 - val_loss: 0.0308 - val_acc: 0.2560\n",
      "Epoch 347/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0057 - acc: 0.3960 - val_loss: 0.0333 - val_acc: 0.2240\n",
      "Epoch 348/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0060 - acc: 0.3893 - val_loss: 0.0306 - val_acc: 0.2600\n",
      "Epoch 349/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0057 - acc: 0.4267 - val_loss: 0.0325 - val_acc: 0.2400\n",
      "Epoch 350/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0053 - acc: 0.3773 - val_loss: 0.0312 - val_acc: 0.2480\n",
      "Epoch 351/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0053 - acc: 0.3960 - val_loss: 0.0314 - val_acc: 0.2480\n",
      "Epoch 352/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0056 - acc: 0.3733 - val_loss: 0.0342 - val_acc: 0.2080\n",
      "Epoch 353/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0058 - acc: 0.3733 - val_loss: 0.0299 - val_acc: 0.2320\n",
      "Epoch 354/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0055 - acc: 0.4120 - val_loss: 0.0340 - val_acc: 0.2480\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0051 - acc: 0.3933 - val_loss: 0.0313 - val_acc: 0.2480\n",
      "Epoch 356/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0050 - acc: 0.4307 - val_loss: 0.0332 - val_acc: 0.2440\n",
      "Epoch 357/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0050 - acc: 0.3920 - val_loss: 0.0319 - val_acc: 0.2440\n",
      "Epoch 358/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0055 - acc: 0.4107 - val_loss: 0.0329 - val_acc: 0.2680\n",
      "Epoch 359/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0050 - acc: 0.3987 - val_loss: 0.0320 - val_acc: 0.2400\n",
      "Epoch 360/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0048 - acc: 0.4133 - val_loss: 0.0321 - val_acc: 0.2720\n",
      "Epoch 361/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0048 - acc: 0.4240 - val_loss: 0.0327 - val_acc: 0.2320\n",
      "Epoch 362/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0049 - acc: 0.4013 - val_loss: 0.0322 - val_acc: 0.2480\n",
      "Epoch 363/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0048 - acc: 0.4240 - val_loss: 0.0317 - val_acc: 0.2480\n",
      "Epoch 364/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0053 - acc: 0.4373 - val_loss: 0.0372 - val_acc: 0.2680\n",
      "Epoch 365/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0061 - acc: 0.4067 - val_loss: 0.0299 - val_acc: 0.2400\n",
      "Epoch 366/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0049 - acc: 0.4573 - val_loss: 0.0329 - val_acc: 0.2520\n",
      "Epoch 367/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0044 - acc: 0.4693 - val_loss: 0.0321 - val_acc: 0.2520\n",
      "Epoch 368/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 0.4680 - val_loss: 0.0322 - val_acc: 0.2520\n",
      "Epoch 369/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0044 - acc: 0.4307 - val_loss: 0.0323 - val_acc: 0.2480\n",
      "Epoch 370/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0047 - acc: 0.4320 - val_loss: 0.0320 - val_acc: 0.2560\n",
      "Epoch 371/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0044 - acc: 0.3960 - val_loss: 0.0330 - val_acc: 0.2320\n",
      "Epoch 372/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0046 - acc: 0.4307 - val_loss: 0.0306 - val_acc: 0.2520\n",
      "Epoch 373/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0051 - acc: 0.4267 - val_loss: 0.0335 - val_acc: 0.2360\n",
      "Epoch 374/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0045 - acc: 0.4120 - val_loss: 0.0311 - val_acc: 0.2720\n",
      "Epoch 375/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0042 - acc: 0.4907 - val_loss: 0.0319 - val_acc: 0.2560\n",
      "Epoch 376/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0043 - acc: 0.4533 - val_loss: 0.0329 - val_acc: 0.2560\n",
      "Epoch 377/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0047 - acc: 0.4227 - val_loss: 0.0309 - val_acc: 0.2360\n",
      "Epoch 378/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0045 - acc: 0.4493 - val_loss: 0.0332 - val_acc: 0.2680\n",
      "Epoch 379/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0043 - acc: 0.4613 - val_loss: 0.0312 - val_acc: 0.2520\n",
      "Epoch 380/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0042 - acc: 0.4773 - val_loss: 0.0334 - val_acc: 0.2600\n",
      "Epoch 381/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0041 - acc: 0.4600 - val_loss: 0.0320 - val_acc: 0.2680\n",
      "Epoch 382/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0043 - acc: 0.4867 - val_loss: 0.0336 - val_acc: 0.2560\n",
      "Epoch 383/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0042 - acc: 0.4440 - val_loss: 0.0335 - val_acc: 0.2560\n",
      "Epoch 384/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0042 - acc: 0.4227 - val_loss: 0.0323 - val_acc: 0.2880\n",
      "Epoch 385/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0041 - acc: 0.4893 - val_loss: 0.0336 - val_acc: 0.2680\n",
      "Epoch 386/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0041 - acc: 0.4747 - val_loss: 0.0334 - val_acc: 0.2360\n",
      "Epoch 387/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0048 - acc: 0.4493 - val_loss: 0.0307 - val_acc: 0.2640\n",
      "Epoch 388/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0045 - acc: 0.4693 - val_loss: 0.0340 - val_acc: 0.2680\n",
      "Epoch 389/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0038 - acc: 0.5213 - val_loss: 0.0318 - val_acc: 0.2720\n",
      "Epoch 390/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0037 - acc: 0.5267 - val_loss: 0.0327 - val_acc: 0.2800\n",
      "Epoch 391/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0037 - acc: 0.5253 - val_loss: 0.0328 - val_acc: 0.2720\n",
      "Epoch 392/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0038 - acc: 0.4747 - val_loss: 0.0332 - val_acc: 0.2520\n",
      "Epoch 393/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0040 - acc: 0.4987 - val_loss: 0.0325 - val_acc: 0.2680\n",
      "Epoch 394/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0039 - acc: 0.4867 - val_loss: 0.0344 - val_acc: 0.2360\n",
      "Epoch 395/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0039 - acc: 0.5160 - val_loss: 0.0313 - val_acc: 0.2800\n",
      "Epoch 396/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0039 - acc: 0.5013 - val_loss: 0.0359 - val_acc: 0.2640\n",
      "Epoch 397/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0046 - acc: 0.4600 - val_loss: 0.0309 - val_acc: 0.2480\n",
      "Epoch 398/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0038 - acc: 0.5160 - val_loss: 0.0338 - val_acc: 0.2560\n",
      "Epoch 399/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0035 - acc: 0.5427 - val_loss: 0.0326 - val_acc: 0.2960\n",
      "Epoch 400/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0035 - acc: 0.5360 - val_loss: 0.0329 - val_acc: 0.2600\n",
      "Epoch 401/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0035 - acc: 0.5253 - val_loss: 0.0324 - val_acc: 0.2840\n",
      "Epoch 402/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0037 - acc: 0.5173 - val_loss: 0.0337 - val_acc: 0.2320\n",
      "Epoch 403/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0039 - acc: 0.4827 - val_loss: 0.0335 - val_acc: 0.2360\n",
      "Epoch 404/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 0.4960 - val_loss: 0.0323 - val_acc: 0.2720\n",
      "Epoch 405/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0038 - acc: 0.5147 - val_loss: 0.0331 - val_acc: 0.2720\n",
      "Epoch 406/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0033 - acc: 0.5893 - val_loss: 0.0323 - val_acc: 0.2720\n",
      "Epoch 407/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0034 - acc: 0.5587 - val_loss: 0.0343 - val_acc: 0.2720\n",
      "Epoch 408/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0036 - acc: 0.5440 - val_loss: 0.0312 - val_acc: 0.2680\n",
      "Epoch 409/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0049 - acc: 0.4907 - val_loss: 0.0366 - val_acc: 0.2480\n",
      "Epoch 410/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0038 - acc: 0.4800 - val_loss: 0.0320 - val_acc: 0.2600\n",
      "Epoch 411/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0033 - acc: 0.5760 - val_loss: 0.0323 - val_acc: 0.2880\n",
      "Epoch 412/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0032 - acc: 0.5733 - val_loss: 0.0325 - val_acc: 0.2880\n",
      "Epoch 413/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0031 - acc: 0.5933 - val_loss: 0.0327 - val_acc: 0.2920\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 165us/step - loss: 0.0031 - acc: 0.5800 - val_loss: 0.0327 - val_acc: 0.2920\n",
      "Epoch 415/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0033 - acc: 0.5600 - val_loss: 0.0337 - val_acc: 0.2560\n",
      "Epoch 416/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0034 - acc: 0.5573 - val_loss: 0.0326 - val_acc: 0.2880\n",
      "Epoch 417/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0032 - acc: 0.5853 - val_loss: 0.0344 - val_acc: 0.2840\n",
      "Epoch 418/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0032 - acc: 0.5480 - val_loss: 0.0325 - val_acc: 0.2640\n",
      "Epoch 419/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0031 - acc: 0.6093 - val_loss: 0.0332 - val_acc: 0.2840\n",
      "Epoch 420/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0031 - acc: 0.5467 - val_loss: 0.0337 - val_acc: 0.2880\n",
      "Epoch 421/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0033 - acc: 0.5253 - val_loss: 0.0325 - val_acc: 0.2360\n",
      "Epoch 422/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0035 - acc: 0.5373 - val_loss: 0.0353 - val_acc: 0.2480\n",
      "Epoch 423/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0033 - acc: 0.5280 - val_loss: 0.0331 - val_acc: 0.2720\n",
      "Epoch 424/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0030 - acc: 0.6160 - val_loss: 0.0324 - val_acc: 0.2920\n",
      "Epoch 425/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0029 - acc: 0.6307 - val_loss: 0.0346 - val_acc: 0.2960\n",
      "Epoch 426/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0028 - acc: 0.6347 - val_loss: 0.0330 - val_acc: 0.3080\n",
      "Epoch 427/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0028 - acc: 0.6427 - val_loss: 0.0341 - val_acc: 0.2880\n",
      "Epoch 428/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0029 - acc: 0.6213 - val_loss: 0.0330 - val_acc: 0.3000\n",
      "Epoch 429/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0033 - acc: 0.5507 - val_loss: 0.0368 - val_acc: 0.2440\n",
      "Epoch 430/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0037 - acc: 0.5453 - val_loss: 0.0314 - val_acc: 0.2640\n",
      "Epoch 431/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0055 - acc: 0.5600 - val_loss: 0.0333 - val_acc: 0.2880\n",
      "Epoch 432/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0030 - acc: 0.5787 - val_loss: 0.0331 - val_acc: 0.2840\n",
      "Epoch 433/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0028 - acc: 0.6400 - val_loss: 0.0331 - val_acc: 0.2840\n",
      "Epoch 434/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0028 - acc: 0.6560 - val_loss: 0.0331 - val_acc: 0.2840\n",
      "Epoch 435/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 0.6480 - val_loss: 0.0332 - val_acc: 0.2880\n",
      "Epoch 436/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0027 - acc: 0.6520 - val_loss: 0.0332 - val_acc: 0.2920\n",
      "Epoch 437/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0027 - acc: 0.6520 - val_loss: 0.0332 - val_acc: 0.2920\n",
      "Epoch 438/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0027 - acc: 0.6507 - val_loss: 0.0333 - val_acc: 0.3040\n",
      "Epoch 439/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0027 - acc: 0.6533 - val_loss: 0.0332 - val_acc: 0.3040\n",
      "Epoch 440/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0027 - acc: 0.6413 - val_loss: 0.0341 - val_acc: 0.2560\n",
      "Epoch 441/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0036 - acc: 0.5680 - val_loss: 0.0325 - val_acc: 0.2840\n",
      "Epoch 442/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0032 - acc: 0.5720 - val_loss: 0.0348 - val_acc: 0.2480\n",
      "Epoch 443/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0028 - acc: 0.6507 - val_loss: 0.0334 - val_acc: 0.2800\n",
      "Epoch 444/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0027 - acc: 0.7000 - val_loss: 0.0336 - val_acc: 0.2880\n",
      "Epoch 445/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0027 - acc: 0.6800 - val_loss: 0.0332 - val_acc: 0.3160\n",
      "Epoch 446/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0027 - acc: 0.6787 - val_loss: 0.0339 - val_acc: 0.2320\n",
      "Epoch 447/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0029 - acc: 0.6147 - val_loss: 0.0336 - val_acc: 0.2720\n",
      "Epoch 448/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0034 - acc: 0.5493 - val_loss: 0.0354 - val_acc: 0.2720\n",
      "Epoch 449/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0029 - acc: 0.6227 - val_loss: 0.0327 - val_acc: 0.2720\n",
      "Epoch 450/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0027 - acc: 0.7080 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 451/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7160 - val_loss: 0.0335 - val_acc: 0.3000\n",
      "Epoch 452/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7107 - val_loss: 0.0335 - val_acc: 0.3000\n",
      "Epoch 453/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7107 - val_loss: 0.0334 - val_acc: 0.2920\n",
      "Epoch 454/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 0.6640 - val_loss: 0.0344 - val_acc: 0.2640\n",
      "Epoch 455/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0037 - acc: 0.5933 - val_loss: 0.0330 - val_acc: 0.2440\n",
      "Epoch 456/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0033 - acc: 0.5867 - val_loss: 0.0332 - val_acc: 0.2920\n",
      "Epoch 457/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0028 - acc: 0.6720 - val_loss: 0.0331 - val_acc: 0.2840\n",
      "Epoch 458/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7227 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 459/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7427 - val_loss: 0.0333 - val_acc: 0.3000\n",
      "Epoch 460/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7373 - val_loss: 0.0333 - val_acc: 0.3000\n",
      "Epoch 461/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.7240 - val_loss: 0.0336 - val_acc: 0.3080\n",
      "Epoch 462/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7107 - val_loss: 0.0331 - val_acc: 0.2760\n",
      "Epoch 463/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0032 - acc: 0.6493 - val_loss: 0.0393 - val_acc: 0.2680\n",
      "Epoch 464/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0044 - acc: 0.5627 - val_loss: 0.0328 - val_acc: 0.2800\n",
      "Epoch 465/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0028 - acc: 0.7600 - val_loss: 0.0343 - val_acc: 0.2880\n",
      "Epoch 466/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7573 - val_loss: 0.0337 - val_acc: 0.2920\n",
      "Epoch 467/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.7573 - val_loss: 0.0336 - val_acc: 0.2960\n",
      "Epoch 468/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7467 - val_loss: 0.0336 - val_acc: 0.3000\n",
      "Epoch 469/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7467 - val_loss: 0.0336 - val_acc: 0.2960\n",
      "Epoch 470/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.7453 - val_loss: 0.0336 - val_acc: 0.3000\n",
      "Epoch 471/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.7427 - val_loss: 0.0336 - val_acc: 0.3040\n",
      "Epoch 472/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7480 - val_loss: 0.0336 - val_acc: 0.2960\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 164us/step - loss: 0.0025 - acc: 0.7480 - val_loss: 0.0336 - val_acc: 0.2920\n",
      "Epoch 474/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.7467 - val_loss: 0.0334 - val_acc: 0.2760\n",
      "Epoch 475/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0028 - acc: 0.6707 - val_loss: 0.0384 - val_acc: 0.2440\n",
      "Epoch 476/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0042 - acc: 0.5720 - val_loss: 0.0328 - val_acc: 0.2840\n",
      "Epoch 477/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0028 - acc: 0.6587 - val_loss: 0.0343 - val_acc: 0.3000\n",
      "Epoch 478/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7347 - val_loss: 0.0336 - val_acc: 0.2960\n",
      "Epoch 479/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7693 - val_loss: 0.0336 - val_acc: 0.2920\n",
      "Epoch 480/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.7733 - val_loss: 0.0336 - val_acc: 0.2880\n",
      "Epoch 481/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.7853 - val_loss: 0.0336 - val_acc: 0.2880\n",
      "Epoch 482/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0025 - acc: 0.7867 - val_loss: 0.0336 - val_acc: 0.2920\n",
      "Epoch 483/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.7840 - val_loss: 0.0336 - val_acc: 0.2960\n",
      "Epoch 484/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.7840 - val_loss: 0.0337 - val_acc: 0.2920\n",
      "Epoch 485/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.7920 - val_loss: 0.0336 - val_acc: 0.3120\n",
      "Epoch 486/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0028 - acc: 0.6560 - val_loss: 0.0364 - val_acc: 0.2520\n",
      "Epoch 487/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0043 - acc: 0.5600 - val_loss: 0.0336 - val_acc: 0.2920\n",
      "Epoch 488/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 0.7267 - val_loss: 0.0330 - val_acc: 0.3200\n",
      "Epoch 489/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.7853 - val_loss: 0.0333 - val_acc: 0.3120\n",
      "Epoch 490/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.7933 - val_loss: 0.0334 - val_acc: 0.3040\n",
      "Epoch 491/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.7987 - val_loss: 0.0335 - val_acc: 0.2960\n",
      "Epoch 492/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.7947 - val_loss: 0.0335 - val_acc: 0.2960\n",
      "Epoch 493/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.7880 - val_loss: 0.0336 - val_acc: 0.3000\n",
      "Epoch 494/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.7907 - val_loss: 0.0336 - val_acc: 0.3040\n",
      "Epoch 495/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.7960 - val_loss: 0.0336 - val_acc: 0.3000\n",
      "Epoch 496/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8027 - val_loss: 0.0335 - val_acc: 0.3080\n",
      "Epoch 497/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.7893 - val_loss: 0.0349 - val_acc: 0.2720\n",
      "Epoch 498/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0037 - acc: 0.6027 - val_loss: 0.0351 - val_acc: 0.2760\n",
      "Epoch 499/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0033 - acc: 0.6400 - val_loss: 0.0343 - val_acc: 0.2760\n",
      "Epoch 500/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.7787 - val_loss: 0.0338 - val_acc: 0.2880\n",
      "Epoch 501/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8053 - val_loss: 0.0336 - val_acc: 0.2760\n",
      "Epoch 502/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8080 - val_loss: 0.0336 - val_acc: 0.2760\n",
      "Epoch 503/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8133 - val_loss: 0.0336 - val_acc: 0.2760\n",
      "Epoch 504/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8107 - val_loss: 0.0336 - val_acc: 0.2720\n",
      "Epoch 505/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8213 - val_loss: 0.0336 - val_acc: 0.2720\n",
      "Epoch 506/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8253 - val_loss: 0.0336 - val_acc: 0.2720\n",
      "Epoch 507/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8240 - val_loss: 0.0336 - val_acc: 0.2640\n",
      "Epoch 508/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8227 - val_loss: 0.0336 - val_acc: 0.2680\n",
      "Epoch 509/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8293 - val_loss: 0.0336 - val_acc: 0.2680\n",
      "Epoch 510/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8253 - val_loss: 0.0337 - val_acc: 0.2840\n",
      "Epoch 511/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8067 - val_loss: 0.0338 - val_acc: 0.2280\n",
      "Epoch 512/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0040 - acc: 0.5280 - val_loss: 0.0386 - val_acc: 0.2640\n",
      "Epoch 513/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0031 - acc: 0.6747 - val_loss: 0.0326 - val_acc: 0.2680\n",
      "Epoch 514/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.8160 - val_loss: 0.0331 - val_acc: 0.2840\n",
      "Epoch 515/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8227 - val_loss: 0.0332 - val_acc: 0.2800\n",
      "Epoch 516/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0025 - acc: 0.8227 - val_loss: 0.0333 - val_acc: 0.2800\n",
      "Epoch 517/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8280 - val_loss: 0.0333 - val_acc: 0.2800\n",
      "Epoch 518/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8253 - val_loss: 0.0333 - val_acc: 0.2800\n",
      "Epoch 519/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0025 - acc: 0.8280 - val_loss: 0.0333 - val_acc: 0.2880\n",
      "Epoch 520/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8320 - val_loss: 0.0333 - val_acc: 0.2920\n",
      "Epoch 521/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0025 - acc: 0.8373 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 522/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0025 - acc: 0.8427 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 523/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8440 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 524/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8440 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 525/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8640 - val_loss: 0.0333 - val_acc: 0.2800\n",
      "Epoch 526/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7427 - val_loss: 0.0360 - val_acc: 0.2600\n",
      "Epoch 527/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0036 - acc: 0.6027 - val_loss: 0.0361 - val_acc: 0.2520\n",
      "Epoch 528/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 0.7453 - val_loss: 0.0329 - val_acc: 0.3000\n",
      "Epoch 529/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8160 - val_loss: 0.0337 - val_acc: 0.3080\n",
      "Epoch 530/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8333 - val_loss: 0.0338 - val_acc: 0.3080\n",
      "Epoch 531/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8493 - val_loss: 0.0338 - val_acc: 0.3040\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8587 - val_loss: 0.0338 - val_acc: 0.3000\n",
      "Epoch 533/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.8613 - val_loss: 0.0338 - val_acc: 0.3040\n",
      "Epoch 534/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0024 - acc: 0.8587 - val_loss: 0.0338 - val_acc: 0.3040\n",
      "Epoch 535/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8573 - val_loss: 0.0338 - val_acc: 0.3000\n",
      "Epoch 536/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8573 - val_loss: 0.0337 - val_acc: 0.3040\n",
      "Epoch 537/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8587 - val_loss: 0.0338 - val_acc: 0.3000\n",
      "Epoch 538/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8680 - val_loss: 0.0337 - val_acc: 0.3040\n",
      "Epoch 539/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8867 - val_loss: 0.0338 - val_acc: 0.3120\n",
      "Epoch 540/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.7720 - val_loss: 0.0342 - val_acc: 0.2360\n",
      "Epoch 541/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0037 - acc: 0.5853 - val_loss: 0.0347 - val_acc: 0.2880\n",
      "Epoch 542/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7667 - val_loss: 0.0341 - val_acc: 0.3080\n",
      "Epoch 543/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8267 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 544/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8493 - val_loss: 0.0340 - val_acc: 0.2800\n",
      "Epoch 545/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8627 - val_loss: 0.0339 - val_acc: 0.2880\n",
      "Epoch 546/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8680 - val_loss: 0.0340 - val_acc: 0.2840\n",
      "Epoch 547/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0024 - acc: 0.8693 - val_loss: 0.0339 - val_acc: 0.2960\n",
      "Epoch 548/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8787 - val_loss: 0.0339 - val_acc: 0.2960\n",
      "Epoch 549/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8773 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 550/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8800 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 551/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8947 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 552/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.9067 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 553/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0023 - acc: 0.9013 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 554/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8813 - val_loss: 0.0357 - val_acc: 0.2560\n",
      "Epoch 555/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0039 - acc: 0.6320 - val_loss: 0.0331 - val_acc: 0.2640\n",
      "Epoch 556/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 0.7000 - val_loss: 0.0339 - val_acc: 0.3120\n",
      "Epoch 557/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0024 - acc: 0.8333 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 558/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8733 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 559/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.8907 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 560/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.8907 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 561/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.8933 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 562/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8933 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 563/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.8947 - val_loss: 0.0340 - val_acc: 0.3040\n",
      "Epoch 564/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.8973 - val_loss: 0.0340 - val_acc: 0.3040\n",
      "Epoch 565/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0023 - acc: 0.8987 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 566/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.9053 - val_loss: 0.0340 - val_acc: 0.3040\n",
      "Epoch 567/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9107 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 568/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9133 - val_loss: 0.0340 - val_acc: 0.2960\n",
      "Epoch 569/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9133 - val_loss: 0.0340 - val_acc: 0.2960\n",
      "Epoch 570/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.9227 - val_loss: 0.0340 - val_acc: 0.2960\n",
      "Epoch 571/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9040 - val_loss: 0.0341 - val_acc: 0.2960\n",
      "Epoch 572/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.9027 - val_loss: 0.0341 - val_acc: 0.3080\n",
      "Epoch 573/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0036 - acc: 0.6173 - val_loss: 0.0363 - val_acc: 0.2920\n",
      "Epoch 574/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.7347 - val_loss: 0.0337 - val_acc: 0.3080\n",
      "Epoch 575/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8480 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 576/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8720 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 577/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.8813 - val_loss: 0.0341 - val_acc: 0.3040\n",
      "Epoch 578/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8867 - val_loss: 0.0341 - val_acc: 0.3040\n",
      "Epoch 579/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8880 - val_loss: 0.0341 - val_acc: 0.3040\n",
      "Epoch 580/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.8880 - val_loss: 0.0341 - val_acc: 0.3040\n",
      "Epoch 581/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8987 - val_loss: 0.0340 - val_acc: 0.3040\n",
      "Epoch 582/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9040 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 583/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0023 - acc: 0.9053 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 584/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0023 - acc: 0.9080 - val_loss: 0.0341 - val_acc: 0.2920\n",
      "Epoch 585/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0023 - acc: 0.9160 - val_loss: 0.0338 - val_acc: 0.3120\n",
      "Epoch 586/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.9200 - val_loss: 0.0340 - val_acc: 0.2880\n",
      "Epoch 587/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.9200 - val_loss: 0.0340 - val_acc: 0.3120\n",
      "Epoch 588/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9240 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 589/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0031 - acc: 0.7107 - val_loss: 0.0348 - val_acc: 0.2640\n",
      "Epoch 590/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 0.6800 - val_loss: 0.0346 - val_acc: 0.3000\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8720 - val_loss: 0.0339 - val_acc: 0.2880\n",
      "Epoch 592/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.8853 - val_loss: 0.0340 - val_acc: 0.2920\n",
      "Epoch 593/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9067 - val_loss: 0.0340 - val_acc: 0.2960\n",
      "Epoch 594/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9093 - val_loss: 0.0340 - val_acc: 0.2960\n",
      "Epoch 595/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9133 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 596/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9147 - val_loss: 0.0340 - val_acc: 0.3040\n",
      "Epoch 597/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9227 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 598/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9227 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 599/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9200 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 600/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9213 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 601/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9227 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 602/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9280 - val_loss: 0.0340 - val_acc: 0.3040\n",
      "Epoch 603/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9267 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 604/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9347 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 605/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9307 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 606/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9400 - val_loss: 0.0339 - val_acc: 0.3080\n",
      "Epoch 607/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9267 - val_loss: 0.0340 - val_acc: 0.3040\n",
      "Epoch 608/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8667 - val_loss: 0.0350 - val_acc: 0.1960\n",
      "Epoch 609/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0049 - acc: 0.5920 - val_loss: 0.0324 - val_acc: 0.3040\n",
      "Epoch 610/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.7387 - val_loss: 0.0331 - val_acc: 0.3000\n",
      "Epoch 611/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.8427 - val_loss: 0.0331 - val_acc: 0.3080\n",
      "Epoch 612/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.8573 - val_loss: 0.0332 - val_acc: 0.3080\n",
      "Epoch 613/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.8720 - val_loss: 0.0332 - val_acc: 0.3080\n",
      "Epoch 614/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.8827 - val_loss: 0.0332 - val_acc: 0.3080\n",
      "Epoch 615/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.8840 - val_loss: 0.0332 - val_acc: 0.3040\n",
      "Epoch 616/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.8920 - val_loss: 0.0332 - val_acc: 0.3040\n",
      "Epoch 617/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.8973 - val_loss: 0.0332 - val_acc: 0.3040\n",
      "Epoch 618/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9053 - val_loss: 0.0332 - val_acc: 0.3080\n",
      "Epoch 619/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9093 - val_loss: 0.0332 - val_acc: 0.3120\n",
      "Epoch 620/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9120 - val_loss: 0.0331 - val_acc: 0.3120\n",
      "Epoch 621/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9160 - val_loss: 0.0331 - val_acc: 0.3120\n",
      "Epoch 622/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9133 - val_loss: 0.0331 - val_acc: 0.3120\n",
      "Epoch 623/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9147 - val_loss: 0.0331 - val_acc: 0.3080\n",
      "Epoch 624/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9147 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 625/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9000 - val_loss: 0.0325 - val_acc: 0.3240\n",
      "Epoch 626/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0028 - acc: 0.7800 - val_loss: 0.0386 - val_acc: 0.2480\n",
      "Epoch 627/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0029 - acc: 0.6640 - val_loss: 0.0344 - val_acc: 0.2880\n",
      "Epoch 628/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.8560 - val_loss: 0.0337 - val_acc: 0.3080\n",
      "Epoch 629/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9080 - val_loss: 0.0339 - val_acc: 0.2960\n",
      "Epoch 630/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9200 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 631/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9240 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 632/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9227 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 633/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9253 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 634/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9253 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 635/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9307 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 636/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9267 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 637/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9267 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 638/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9347 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 639/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9360 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 640/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9360 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 641/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9480 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 642/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9520 - val_loss: 0.0339 - val_acc: 0.2960\n",
      "Epoch 643/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9493 - val_loss: 0.0338 - val_acc: 0.2880\n",
      "Epoch 644/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9440 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 645/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9400 - val_loss: 0.0338 - val_acc: 0.3040\n",
      "Epoch 646/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9027 - val_loss: 0.0372 - val_acc: 0.2720\n",
      "Epoch 647/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0035 - acc: 0.6480 - val_loss: 0.0333 - val_acc: 0.3040\n",
      "Epoch 648/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0023 - acc: 0.7987 - val_loss: 0.0347 - val_acc: 0.2960\n",
      "Epoch 649/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.8840 - val_loss: 0.0343 - val_acc: 0.3080\n",
      "Epoch 650/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9107 - val_loss: 0.0343 - val_acc: 0.3120\n",
      "Epoch 651/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9107 - val_loss: 0.0343 - val_acc: 0.3120\n",
      "Epoch 652/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9147 - val_loss: 0.0343 - val_acc: 0.3120\n",
      "Epoch 653/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9187 - val_loss: 0.0343 - val_acc: 0.3120\n",
      "Epoch 654/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9240 - val_loss: 0.0343 - val_acc: 0.3120\n",
      "Epoch 655/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9253 - val_loss: 0.0343 - val_acc: 0.3120\n",
      "Epoch 656/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9333 - val_loss: 0.0342 - val_acc: 0.3080\n",
      "Epoch 657/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9373 - val_loss: 0.0342 - val_acc: 0.3080\n",
      "Epoch 658/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9387 - val_loss: 0.0343 - val_acc: 0.3080\n",
      "Epoch 659/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9440 - val_loss: 0.0342 - val_acc: 0.3040\n",
      "Epoch 660/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9400 - val_loss: 0.0343 - val_acc: 0.3080\n",
      "Epoch 661/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9440 - val_loss: 0.0342 - val_acc: 0.3040\n",
      "Epoch 662/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9373 - val_loss: 0.0342 - val_acc: 0.3000\n",
      "Epoch 663/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9480 - val_loss: 0.0342 - val_acc: 0.3000\n",
      "Epoch 664/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9587 - val_loss: 0.0342 - val_acc: 0.3000\n",
      "Epoch 665/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9547 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 666/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9587 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 667/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9600 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 668/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9600 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 669/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 670/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9613 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 671/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 672/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9613 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 673/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9627 - val_loss: 0.0342 - val_acc: 0.2920\n",
      "Epoch 674/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9627 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 675/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9653 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 676/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 677/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 678/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 679/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 680/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 681/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 682/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 683/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 684/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 685/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 686/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 687/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 688/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 689/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 690/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 691/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 692/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 693/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 694/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 695/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 696/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 697/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 698/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 699/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 700/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 701/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 702/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 703/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 704/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 705/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 706/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 707/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 708/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 709/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 710/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 711/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 712/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 713/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 714/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 715/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 716/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 717/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 718/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 719/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 720/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 721/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 722/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 723/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 724/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 725/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 726/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 727/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 728/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 729/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 730/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 731/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 732/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 733/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 734/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 735/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 736/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 737/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 738/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 739/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 740/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 741/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 742/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 743/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 744/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 745/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 746/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 747/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 748/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 749/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 750/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 751/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 752/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 753/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 754/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 755/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 756/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 757/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 758/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 759/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 760/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 761/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 762/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 763/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 764/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 765/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 766/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 767/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 769/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 770/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 771/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 772/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 773/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 774/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 775/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 776/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 777/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 778/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 779/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 780/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 781/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 782/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 783/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 784/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 785/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 786/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 787/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 788/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 789/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 790/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 791/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 792/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 793/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 794/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 795/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 796/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 797/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 798/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 799/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 800/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 801/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 802/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 803/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 804/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 805/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 806/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 807/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 808/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 809/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 810/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 811/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 812/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 813/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 814/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 815/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 816/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 817/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 818/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 819/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 820/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 821/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 822/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 823/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 824/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 825/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 826/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 828/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 829/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 830/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 831/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 832/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 833/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 834/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 835/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 836/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 837/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 838/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 839/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 840/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 841/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 842/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 843/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 844/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 845/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 846/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 847/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 848/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 849/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 850/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 851/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 852/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 853/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 854/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 855/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 856/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 857/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 858/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 859/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 860/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 861/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 862/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 863/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 864/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 865/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 866/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 867/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 868/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 869/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 870/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 871/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 872/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 873/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 874/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 875/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 876/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 877/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 878/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 879/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 880/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 881/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 882/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 883/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 884/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 885/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 887/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 888/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 889/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 890/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 891/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 892/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 893/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 894/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 895/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 896/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 897/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 898/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 899/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 900/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 901/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 902/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 903/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 904/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 905/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 906/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 907/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 908/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 909/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 910/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 911/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 912/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 913/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 914/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 915/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 916/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 917/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 918/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 919/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 920/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 921/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 922/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 923/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 924/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 925/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 926/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 927/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 928/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 929/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 930/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 931/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 932/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 933/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 934/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 935/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 936/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 937/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 938/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 939/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 940/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 941/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 942/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 943/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 944/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 945/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 946/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 947/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 948/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 949/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 950/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 951/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 952/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 953/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 954/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 955/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 956/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 957/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 958/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 959/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 960/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 961/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 962/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 963/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 964/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 965/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 966/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 967/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 968/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 969/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 970/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 971/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 972/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 973/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 974/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 975/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 976/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 977/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 978/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 979/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 980/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 981/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 982/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 983/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 984/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 985/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 986/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 987/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 988/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 989/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 990/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 991/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 992/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 993/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 994/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 995/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 996/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 997/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 998/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 999/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 1000/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9667 - val_loss: 0.0342 - val_acc: 0.2960\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense, Flatten,LSTM, TimeDistributed, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TIME_STEPS = 10\n",
    "INPUT_SIZE = 512\n",
    "BATCH_SIZE = 250\n",
    "BATCH_INDEX = 0\n",
    "OUTPUT_SIZE = 512\n",
    "#CELL_SIZE = 800\n",
    "LR = 0.0005\n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "# loading data\n",
    "X_train = np.loadtxt(\"0220_spec_train_1000*5120.txt\")\n",
    "y_train = np.loadtxt(\"0220_mask_train_1000*512.txt\")\n",
    "\n",
    "X_test = np.loadtxt(\"0220_spec_test_1000*5120.txt\")\n",
    "y_test = np.loadtxt(\"0220_mask_test_1000*512.txt\")\n",
    "\n",
    "# batch_size=y_test.shape[0]\n",
    "\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 10, 512)\n",
    "#y_train = y_train.reshape(-1, 3, 512)\n",
    "X_test = X_test.reshape(-1, 10, 512)\n",
    "#y_test = y_test.reshape(-1, 3, 512)\n",
    "\n",
    "\n",
    "#  build RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# RNN cell\n",
    "\n",
    "model.add(LSTM(\n",
    "    units =512,\n",
    "    batch_input_shape=( BATCH_SIZE, TIME_STEPS, INPUT_SIZE),\n",
    "    #input_dim=INPUT_SIZE,\n",
    "    #input_length=TIME_STEPS,\n",
    "    #output_dim=CELL_SIZE,\n",
    "    #return_sequences=True,\n",
    "    #stateful=True \n",
    "    unroll=True\n",
    "))\n",
    "\n",
    "# output layer\n",
    "#model.add(Flatten())\n",
    "model.add((Dense(OUTPUT_SIZE)))  #TimeDistributed\n",
    "model.add(Activation('hard_sigmoid'))\n",
    "#model.add(Dropout(rate = 0.2)) \n",
    "\n",
    "# # optimizer\n",
    "#\n",
    "# optimizer\n",
    "\n",
    "rmsprop = RMSprop(lr=LR, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # training\n",
    "#\n",
    "\n",
    "# for step in range(51):\n",
    "#     # data shape = (batch_num, steps, inputs/outputs)\n",
    "#     X_batch = X_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :, :]\n",
    "#     Y_batch = y_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :]\n",
    "#     cost = model.train_on_batch(X_batch, Y_batch)\n",
    "#     BATCH_INDEX += BATCH_SIZE\n",
    "#     BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "\n",
    "#     if step % 50 == 0:\n",
    "#         print('Next_Train----------: step = ', step)\n",
    "#         train_cost, train_accuracy = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('train_cost: ', train_cost, 'train_accuracy: ', train_accuracy)\n",
    "#         cost, accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "        \n",
    "       \n",
    "\n",
    "print('Train-------------------------')\n",
    "\n",
    "history = model.fit(X_test, y_test, validation_split=0.25, epochs=1000, shuffle=False, batch_size=250, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "#                                   [model.layers[1].output])\n",
    "# layer_output1 = get_3rd_layer_output([X_train])[0]\n",
    "\n",
    "# print(layer_output1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-------------------------\n",
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/1000\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2372 - acc: 0.0013 - val_loss: 0.1471 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0840 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0920\n",
      "Epoch 3/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0405 - acc: 0.0120 - val_loss: 0.0335 - val_acc: 0.0320\n",
      "Epoch 4/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0398 - acc: 0.0240 - val_loss: 0.0325 - val_acc: 0.0160\n",
      "Epoch 5/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0392 - acc: 0.0187 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0390 - acc: 0.0067 - val_loss: 0.0317 - val_acc: 0.0240\n",
      "Epoch 7/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0388 - acc: 0.0413 - val_loss: 0.0320 - val_acc: 0.0040\n",
      "Epoch 8/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0386 - acc: 0.0173 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0388 - acc: 0.0120 - val_loss: 0.0320 - val_acc: 0.0120\n",
      "Epoch 10/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0384 - acc: 0.0133 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0384 - acc: 0.0107 - val_loss: 0.0320 - val_acc: 0.0360\n",
      "Epoch 12/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0381 - acc: 0.0187 - val_loss: 0.0307 - val_acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0378 - acc: 0.0160 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0381 - acc: 0.0173 - val_loss: 0.0303 - val_acc: 0.0720\n",
      "Epoch 15/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0376 - acc: 0.0320 - val_loss: 0.0324 - val_acc: 0.0360\n",
      "Epoch 16/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0374 - acc: 0.0213 - val_loss: 0.0299 - val_acc: 0.0080\n",
      "Epoch 17/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0372 - acc: 0.0093 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0365 - acc: 0.0093 - val_loss: 0.0296 - val_acc: 0.0160\n",
      "Epoch 19/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0357 - acc: 0.0200 - val_loss: 0.0321 - val_acc: 0.0080\n",
      "Epoch 20/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0372 - acc: 0.0200 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0353 - acc: 0.0080 - val_loss: 0.0326 - val_acc: 0.0320\n",
      "Epoch 22/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0353 - acc: 0.0187 - val_loss: 0.0290 - val_acc: 0.0120\n",
      "Epoch 23/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0342 - acc: 0.0160 - val_loss: 0.0311 - val_acc: 0.0040\n",
      "Epoch 24/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0351 - acc: 0.0147 - val_loss: 0.0291 - val_acc: 0.0040\n",
      "Epoch 25/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0353 - acc: 0.0107 - val_loss: 0.0296 - val_acc: 0.0120\n",
      "Epoch 26/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0335 - acc: 0.0133 - val_loss: 0.0286 - val_acc: 0.0040\n",
      "Epoch 27/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0338 - acc: 0.0187 - val_loss: 0.0303 - val_acc: 0.0360\n",
      "Epoch 28/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0331 - acc: 0.0173 - val_loss: 0.0283 - val_acc: 0.0280\n",
      "Epoch 29/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0333 - acc: 0.0240 - val_loss: 0.0318 - val_acc: 0.0440\n",
      "Epoch 30/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0335 - acc: 0.0160 - val_loss: 0.0284 - val_acc: 0.0280\n",
      "Epoch 31/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0327 - acc: 0.0147 - val_loss: 0.0302 - val_acc: 0.0760\n",
      "Epoch 32/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0327 - acc: 0.0280 - val_loss: 0.0287 - val_acc: 0.0160\n",
      "Epoch 33/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0340 - acc: 0.0227 - val_loss: 0.0305 - val_acc: 0.0400\n",
      "Epoch 34/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0319 - acc: 0.0293 - val_loss: 0.0283 - val_acc: 0.0360\n",
      "Epoch 35/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0314 - acc: 0.0280 - val_loss: 0.0305 - val_acc: 0.0440\n",
      "Epoch 36/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0318 - acc: 0.0253 - val_loss: 0.0282 - val_acc: 0.0280\n",
      "Epoch 37/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0329 - acc: 0.0227 - val_loss: 0.0317 - val_acc: 0.0400\n",
      "Epoch 38/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0314 - acc: 0.0307 - val_loss: 0.0280 - val_acc: 0.0320\n",
      "Epoch 39/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0309 - acc: 0.0240 - val_loss: 0.0282 - val_acc: 0.0600\n",
      "Epoch 40/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0327 - acc: 0.0293 - val_loss: 0.0328 - val_acc: 0.0320\n",
      "Epoch 41/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0332 - acc: 0.0187 - val_loss: 0.0279 - val_acc: 0.0560\n",
      "Epoch 42/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0306 - acc: 0.0280 - val_loss: 0.0302 - val_acc: 0.0560\n",
      "Epoch 43/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0308 - acc: 0.0227 - val_loss: 0.0278 - val_acc: 0.0600\n",
      "Epoch 44/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0313 - acc: 0.0413 - val_loss: 0.0310 - val_acc: 0.0400\n",
      "Epoch 45/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0308 - acc: 0.0320 - val_loss: 0.0279 - val_acc: 0.0160\n",
      "Epoch 46/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0319 - acc: 0.0173 - val_loss: 0.0309 - val_acc: 0.0560\n",
      "Epoch 47/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0308 - acc: 0.0373 - val_loss: 0.0287 - val_acc: 0.0200\n",
      "Epoch 48/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0312 - acc: 0.0640 - val_loss: 0.0294 - val_acc: 0.0400\n",
      "Epoch 49/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0299 - acc: 0.0240 - val_loss: 0.0293 - val_acc: 0.0520\n",
      "Epoch 50/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0298 - acc: 0.0427 - val_loss: 0.0280 - val_acc: 0.0240\n",
      "Epoch 51/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0312 - acc: 0.0667 - val_loss: 0.0324 - val_acc: 0.0360\n",
      "Epoch 52/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0307 - acc: 0.0400 - val_loss: 0.0285 - val_acc: 0.1640\n",
      "Epoch 53/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0299 - acc: 0.0533 - val_loss: 0.0294 - val_acc: 0.0600\n",
      "Epoch 54/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0298 - acc: 0.0360 - val_loss: 0.0275 - val_acc: 0.1880\n",
      "Epoch 55/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0296 - acc: 0.0693 - val_loss: 0.0307 - val_acc: 0.0440\n",
      "Epoch 56/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0301 - acc: 0.0400 - val_loss: 0.0275 - val_acc: 0.1280\n",
      "Epoch 57/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0303 - acc: 0.1000 - val_loss: 0.0319 - val_acc: 0.0520\n",
      "Epoch 58/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0310 - acc: 0.0293 - val_loss: 0.0277 - val_acc: 0.0600\n",
      "Epoch 59/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0292 - acc: 0.0507 - val_loss: 0.0283 - val_acc: 0.0520\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0291 - acc: 0.0560 - val_loss: 0.0301 - val_acc: 0.1200\n",
      "Epoch 61/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0293 - acc: 0.0720 - val_loss: 0.0280 - val_acc: 0.1440\n",
      "Epoch 62/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0285 - acc: 0.1013 - val_loss: 0.0296 - val_acc: 0.0320\n",
      "Epoch 63/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0300 - acc: 0.0800 - val_loss: 0.0283 - val_acc: 0.1120\n",
      "Epoch 64/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0303 - acc: 0.0653 - val_loss: 0.0285 - val_acc: 0.0320\n",
      "Epoch 65/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0291 - acc: 0.0560 - val_loss: 0.0286 - val_acc: 0.1840\n",
      "Epoch 66/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0285 - acc: 0.0733 - val_loss: 0.0277 - val_acc: 0.0320\n",
      "Epoch 67/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0286 - acc: 0.0600 - val_loss: 0.0296 - val_acc: 0.1600\n",
      "Epoch 68/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0281 - acc: 0.0960 - val_loss: 0.0291 - val_acc: 0.0320\n",
      "Epoch 69/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0294 - acc: 0.0533 - val_loss: 0.0282 - val_acc: 0.2280\n",
      "Epoch 70/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0298 - acc: 0.1160 - val_loss: 0.0299 - val_acc: 0.1520\n",
      "Epoch 71/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0287 - acc: 0.0573 - val_loss: 0.0273 - val_acc: 0.0800\n",
      "Epoch 72/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0287 - acc: 0.0787 - val_loss: 0.0298 - val_acc: 0.0240\n",
      "Epoch 73/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0281 - acc: 0.0627 - val_loss: 0.0273 - val_acc: 0.1040\n",
      "Epoch 74/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0286 - acc: 0.0547 - val_loss: 0.0288 - val_acc: 0.1760\n",
      "Epoch 75/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0283 - acc: 0.0707 - val_loss: 0.0279 - val_acc: 0.1000\n",
      "Epoch 76/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0277 - acc: 0.0880 - val_loss: 0.0277 - val_acc: 0.1640\n",
      "Epoch 77/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0282 - acc: 0.1293 - val_loss: 0.0322 - val_acc: 0.0440\n",
      "Epoch 78/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0291 - acc: 0.0520 - val_loss: 0.0272 - val_acc: 0.1600\n",
      "Epoch 79/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0277 - acc: 0.0707 - val_loss: 0.0292 - val_acc: 0.1040\n",
      "Epoch 80/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0273 - acc: 0.0613 - val_loss: 0.0277 - val_acc: 0.0760\n",
      "Epoch 81/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0273 - acc: 0.0547 - val_loss: 0.0295 - val_acc: 0.1920\n",
      "Epoch 82/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0272 - acc: 0.0800 - val_loss: 0.0295 - val_acc: 0.0360\n",
      "Epoch 83/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0277 - acc: 0.0573 - val_loss: 0.0276 - val_acc: 0.0920\n",
      "Epoch 84/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0292 - acc: 0.0680 - val_loss: 0.0298 - val_acc: 0.0560\n",
      "Epoch 85/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0269 - acc: 0.0560 - val_loss: 0.0273 - val_acc: 0.1280\n",
      "Epoch 86/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0267 - acc: 0.0840 - val_loss: 0.0288 - val_acc: 0.0440\n",
      "Epoch 87/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0267 - acc: 0.0413 - val_loss: 0.0270 - val_acc: 0.0840\n",
      "Epoch 88/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0277 - acc: 0.0573 - val_loss: 0.0324 - val_acc: 0.0640\n",
      "Epoch 89/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0278 - acc: 0.0867 - val_loss: 0.0277 - val_acc: 0.1400\n",
      "Epoch 90/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0267 - acc: 0.0667 - val_loss: 0.0279 - val_acc: 0.0480\n",
      "Epoch 91/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0264 - acc: 0.0733 - val_loss: 0.0306 - val_acc: 0.0680\n",
      "Epoch 92/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0272 - acc: 0.0680 - val_loss: 0.0271 - val_acc: 0.0720\n",
      "Epoch 93/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0265 - acc: 0.0520 - val_loss: 0.0289 - val_acc: 0.0600\n",
      "Epoch 94/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0263 - acc: 0.0587 - val_loss: 0.0270 - val_acc: 0.0600\n",
      "Epoch 95/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0265 - acc: 0.1027 - val_loss: 0.0298 - val_acc: 0.0320\n",
      "Epoch 96/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0263 - acc: 0.0613 - val_loss: 0.0270 - val_acc: 0.0120\n",
      "Epoch 97/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0261 - acc: 0.0720 - val_loss: 0.0294 - val_acc: 0.0360\n",
      "Epoch 98/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0265 - acc: 0.0453 - val_loss: 0.0270 - val_acc: 0.1160\n",
      "Epoch 99/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0270 - acc: 0.0653 - val_loss: 0.0297 - val_acc: 0.1440\n",
      "Epoch 100/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0261 - acc: 0.0827 - val_loss: 0.0274 - val_acc: 0.0800\n",
      "Epoch 101/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0254 - acc: 0.0800 - val_loss: 0.0286 - val_acc: 0.0480\n",
      "Epoch 102/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0254 - acc: 0.0467 - val_loss: 0.0283 - val_acc: 0.1480\n",
      "Epoch 103/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0251 - acc: 0.0907 - val_loss: 0.0290 - val_acc: 0.0880\n",
      "Epoch 104/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0254 - acc: 0.0707 - val_loss: 0.0269 - val_acc: 0.0600\n",
      "Epoch 105/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0273 - acc: 0.0827 - val_loss: 0.0288 - val_acc: 0.0320\n",
      "Epoch 106/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0254 - acc: 0.0533 - val_loss: 0.0267 - val_acc: 0.1400\n",
      "Epoch 107/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0248 - acc: 0.0960 - val_loss: 0.0283 - val_acc: 0.0280\n",
      "Epoch 108/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0248 - acc: 0.0747 - val_loss: 0.0276 - val_acc: 0.0440\n",
      "Epoch 109/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0251 - acc: 0.0733 - val_loss: 0.0311 - val_acc: 0.0520\n",
      "Epoch 110/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0266 - acc: 0.0653 - val_loss: 0.0276 - val_acc: 0.0680\n",
      "Epoch 111/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0246 - acc: 0.0987 - val_loss: 0.0289 - val_acc: 0.0400\n",
      "Epoch 112/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0244 - acc: 0.0547 - val_loss: 0.0273 - val_acc: 0.1400\n",
      "Epoch 113/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0245 - acc: 0.1173 - val_loss: 0.0306 - val_acc: 0.1080\n",
      "Epoch 114/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0250 - acc: 0.0733 - val_loss: 0.0273 - val_acc: 0.0360\n",
      "Epoch 115/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0247 - acc: 0.0800 - val_loss: 0.0287 - val_acc: 0.1360\n",
      "Epoch 116/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0244 - acc: 0.0907 - val_loss: 0.0267 - val_acc: 0.0880\n",
      "Epoch 117/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0249 - acc: 0.0747 - val_loss: 0.0288 - val_acc: 0.0480\n",
      "Epoch 118/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0239 - acc: 0.0547 - val_loss: 0.0271 - val_acc: 0.1240\n",
      "Epoch 119/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0237 - acc: 0.0960 - val_loss: 0.0296 - val_acc: 0.0760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0249 - acc: 0.0613 - val_loss: 0.0266 - val_acc: 0.0440\n",
      "Epoch 121/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0248 - acc: 0.0973 - val_loss: 0.0285 - val_acc: 0.0640\n",
      "Epoch 122/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0232 - acc: 0.0680 - val_loss: 0.0273 - val_acc: 0.0560\n",
      "Epoch 123/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0232 - acc: 0.0933 - val_loss: 0.0295 - val_acc: 0.0600\n",
      "Epoch 124/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0245 - acc: 0.1040 - val_loss: 0.0268 - val_acc: 0.0640\n",
      "Epoch 125/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0234 - acc: 0.0827 - val_loss: 0.0302 - val_acc: 0.0920\n",
      "Epoch 126/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0242 - acc: 0.0973 - val_loss: 0.0262 - val_acc: 0.0600\n",
      "Epoch 127/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0237 - acc: 0.0813 - val_loss: 0.0286 - val_acc: 0.1200\n",
      "Epoch 128/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0229 - acc: 0.1187 - val_loss: 0.0273 - val_acc: 0.0480\n",
      "Epoch 129/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0230 - acc: 0.1080 - val_loss: 0.0302 - val_acc: 0.0440\n",
      "Epoch 130/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0240 - acc: 0.0920 - val_loss: 0.0267 - val_acc: 0.0360\n",
      "Epoch 131/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0231 - acc: 0.0827 - val_loss: 0.0289 - val_acc: 0.0600\n",
      "Epoch 132/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0230 - acc: 0.0987 - val_loss: 0.0283 - val_acc: 0.1320\n",
      "Epoch 133/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0231 - acc: 0.1013 - val_loss: 0.0268 - val_acc: 0.1120\n",
      "Epoch 134/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0225 - acc: 0.1027 - val_loss: 0.0282 - val_acc: 0.1400\n",
      "Epoch 135/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0224 - acc: 0.1333 - val_loss: 0.0265 - val_acc: 0.0880\n",
      "Epoch 136/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0240 - acc: 0.1280 - val_loss: 0.0296 - val_acc: 0.0520\n",
      "Epoch 137/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0226 - acc: 0.0987 - val_loss: 0.0270 - val_acc: 0.0840\n",
      "Epoch 138/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0220 - acc: 0.0947 - val_loss: 0.0287 - val_acc: 0.1360\n",
      "Epoch 139/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0222 - acc: 0.1093 - val_loss: 0.0263 - val_acc: 0.1960\n",
      "Epoch 140/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0234 - acc: 0.1227 - val_loss: 0.0290 - val_acc: 0.0960\n",
      "Epoch 141/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0222 - acc: 0.1213 - val_loss: 0.0269 - val_acc: 0.1080\n",
      "Epoch 142/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0220 - acc: 0.1027 - val_loss: 0.0286 - val_acc: 0.0960\n",
      "Epoch 143/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0217 - acc: 0.1133 - val_loss: 0.0268 - val_acc: 0.1120\n",
      "Epoch 144/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0223 - acc: 0.1333 - val_loss: 0.0303 - val_acc: 0.0920\n",
      "Epoch 145/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0223 - acc: 0.0920 - val_loss: 0.0264 - val_acc: 0.1280\n",
      "Epoch 146/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0218 - acc: 0.1173 - val_loss: 0.0284 - val_acc: 0.1160\n",
      "Epoch 147/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0213 - acc: 0.1133 - val_loss: 0.0269 - val_acc: 0.1480\n",
      "Epoch 148/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0212 - acc: 0.1173 - val_loss: 0.0288 - val_acc: 0.1400\n",
      "Epoch 149/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0212 - acc: 0.1293 - val_loss: 0.0269 - val_acc: 0.1120\n",
      "Epoch 150/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0218 - acc: 0.1040 - val_loss: 0.0287 - val_acc: 0.1720\n",
      "Epoch 151/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0221 - acc: 0.1333 - val_loss: 0.0264 - val_acc: 0.1080\n",
      "Epoch 152/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0214 - acc: 0.1373 - val_loss: 0.0284 - val_acc: 0.0880\n",
      "Epoch 153/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0211 - acc: 0.1133 - val_loss: 0.0263 - val_acc: 0.0760\n",
      "Epoch 154/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0212 - acc: 0.1173 - val_loss: 0.0283 - val_acc: 0.1080\n",
      "Epoch 155/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0206 - acc: 0.1120 - val_loss: 0.0268 - val_acc: 0.1280\n",
      "Epoch 156/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0214 - acc: 0.1373 - val_loss: 0.0295 - val_acc: 0.1040\n",
      "Epoch 157/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0211 - acc: 0.1373 - val_loss: 0.0266 - val_acc: 0.0760\n",
      "Epoch 158/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0202 - acc: 0.1200 - val_loss: 0.0285 - val_acc: 0.1400\n",
      "Epoch 159/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0207 - acc: 0.1613 - val_loss: 0.0276 - val_acc: 0.0440\n",
      "Epoch 160/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0203 - acc: 0.1093 - val_loss: 0.0284 - val_acc: 0.1680\n",
      "Epoch 161/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0204 - acc: 0.1440 - val_loss: 0.0264 - val_acc: 0.1240\n",
      "Epoch 162/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0209 - acc: 0.1507 - val_loss: 0.0322 - val_acc: 0.1080\n",
      "Epoch 163/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0211 - acc: 0.1453 - val_loss: 0.0268 - val_acc: 0.1200\n",
      "Epoch 164/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0198 - acc: 0.1240 - val_loss: 0.0280 - val_acc: 0.1000\n",
      "Epoch 165/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0195 - acc: 0.1360 - val_loss: 0.0280 - val_acc: 0.1680\n",
      "Epoch 166/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0196 - acc: 0.1547 - val_loss: 0.0278 - val_acc: 0.1160\n",
      "Epoch 167/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0199 - acc: 0.1613 - val_loss: 0.0307 - val_acc: 0.1280\n",
      "Epoch 168/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0213 - acc: 0.1413 - val_loss: 0.0262 - val_acc: 0.1800\n",
      "Epoch 169/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0201 - acc: 0.1200 - val_loss: 0.0283 - val_acc: 0.1320\n",
      "Epoch 170/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0190 - acc: 0.1360 - val_loss: 0.0276 - val_acc: 0.1480\n",
      "Epoch 171/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0190 - acc: 0.1307 - val_loss: 0.0281 - val_acc: 0.1840\n",
      "Epoch 172/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0192 - acc: 0.1707 - val_loss: 0.0287 - val_acc: 0.1320\n",
      "Epoch 173/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0193 - acc: 0.1267 - val_loss: 0.0263 - val_acc: 0.1560\n",
      "Epoch 174/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0200 - acc: 0.1560 - val_loss: 0.0309 - val_acc: 0.1520\n",
      "Epoch 175/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0197 - acc: 0.1240 - val_loss: 0.0268 - val_acc: 0.1800\n",
      "Epoch 176/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0190 - acc: 0.1493 - val_loss: 0.0283 - val_acc: 0.1080\n",
      "Epoch 177/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0186 - acc: 0.1227 - val_loss: 0.0279 - val_acc: 0.1560\n",
      "Epoch 178/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0188 - acc: 0.1373 - val_loss: 0.0309 - val_acc: 0.1680\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 164us/step - loss: 0.0191 - acc: 0.1680 - val_loss: 0.0271 - val_acc: 0.1040\n",
      "Epoch 180/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0182 - acc: 0.1360 - val_loss: 0.0313 - val_acc: 0.1320\n",
      "Epoch 181/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0189 - acc: 0.1600 - val_loss: 0.0267 - val_acc: 0.1720\n",
      "Epoch 182/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0185 - acc: 0.1587 - val_loss: 0.0298 - val_acc: 0.1240\n",
      "Epoch 183/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0184 - acc: 0.1400 - val_loss: 0.0273 - val_acc: 0.1440\n",
      "Epoch 184/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0181 - acc: 0.1493 - val_loss: 0.0287 - val_acc: 0.1640\n",
      "Epoch 185/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0181 - acc: 0.1453 - val_loss: 0.0267 - val_acc: 0.1800\n",
      "Epoch 186/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0184 - acc: 0.1840 - val_loss: 0.0335 - val_acc: 0.1200\n",
      "Epoch 187/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0187 - acc: 0.1227 - val_loss: 0.0268 - val_acc: 0.1840\n",
      "Epoch 188/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0179 - acc: 0.1667 - val_loss: 0.0293 - val_acc: 0.1640\n",
      "Epoch 189/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0183 - acc: 0.1720 - val_loss: 0.0268 - val_acc: 0.0960\n",
      "Epoch 190/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0180 - acc: 0.1587 - val_loss: 0.0277 - val_acc: 0.1920\n",
      "Epoch 191/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0173 - acc: 0.1640 - val_loss: 0.0279 - val_acc: 0.1440\n",
      "Epoch 192/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0172 - acc: 0.1467 - val_loss: 0.0291 - val_acc: 0.1800\n",
      "Epoch 193/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0172 - acc: 0.1733 - val_loss: 0.0274 - val_acc: 0.1720\n",
      "Epoch 194/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0174 - acc: 0.1760 - val_loss: 0.0300 - val_acc: 0.1120\n",
      "Epoch 195/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0177 - acc: 0.1667 - val_loss: 0.0269 - val_acc: 0.2000\n",
      "Epoch 196/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0181 - acc: 0.2013 - val_loss: 0.0305 - val_acc: 0.1560\n",
      "Epoch 197/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0173 - acc: 0.1707 - val_loss: 0.0269 - val_acc: 0.1960\n",
      "Epoch 198/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0170 - acc: 0.1653 - val_loss: 0.0295 - val_acc: 0.1600\n",
      "Epoch 199/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0167 - acc: 0.1693 - val_loss: 0.0277 - val_acc: 0.1720\n",
      "Epoch 200/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0168 - acc: 0.1493 - val_loss: 0.0282 - val_acc: 0.2040\n",
      "Epoch 201/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0163 - acc: 0.1787 - val_loss: 0.0287 - val_acc: 0.1520\n",
      "Epoch 202/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0164 - acc: 0.1893 - val_loss: 0.0268 - val_acc: 0.1840\n",
      "Epoch 203/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0172 - acc: 0.1747 - val_loss: 0.0337 - val_acc: 0.1360\n",
      "Epoch 204/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0178 - acc: 0.1747 - val_loss: 0.0277 - val_acc: 0.1360\n",
      "Epoch 205/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0160 - acc: 0.1640 - val_loss: 0.0273 - val_acc: 0.1800\n",
      "Epoch 206/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0160 - acc: 0.1840 - val_loss: 0.0302 - val_acc: 0.1480\n",
      "Epoch 207/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0162 - acc: 0.1627 - val_loss: 0.0273 - val_acc: 0.2000\n",
      "Epoch 208/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0162 - acc: 0.1920 - val_loss: 0.0302 - val_acc: 0.1520\n",
      "Epoch 209/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0160 - acc: 0.1693 - val_loss: 0.0272 - val_acc: 0.1680\n",
      "Epoch 210/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0163 - acc: 0.1853 - val_loss: 0.0294 - val_acc: 0.1960\n",
      "Epoch 211/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0155 - acc: 0.1800 - val_loss: 0.0275 - val_acc: 0.1560\n",
      "Epoch 212/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0156 - acc: 0.1800 - val_loss: 0.0322 - val_acc: 0.1760\n",
      "Epoch 213/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0166 - acc: 0.2013 - val_loss: 0.0265 - val_acc: 0.1720\n",
      "Epoch 214/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0157 - acc: 0.1893 - val_loss: 0.0287 - val_acc: 0.1840\n",
      "Epoch 215/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0150 - acc: 0.1893 - val_loss: 0.0280 - val_acc: 0.2120\n",
      "Epoch 216/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0153 - acc: 0.1960 - val_loss: 0.0296 - val_acc: 0.1760\n",
      "Epoch 217/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0148 - acc: 0.1800 - val_loss: 0.0274 - val_acc: 0.2240\n",
      "Epoch 218/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0152 - acc: 0.2067 - val_loss: 0.0326 - val_acc: 0.1680\n",
      "Epoch 219/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0165 - acc: 0.1920 - val_loss: 0.0275 - val_acc: 0.1680\n",
      "Epoch 220/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0157 - acc: 0.2147 - val_loss: 0.0295 - val_acc: 0.2040\n",
      "Epoch 221/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0147 - acc: 0.2013 - val_loss: 0.0282 - val_acc: 0.1760\n",
      "Epoch 222/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0145 - acc: 0.1800 - val_loss: 0.0287 - val_acc: 0.2040\n",
      "Epoch 223/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0144 - acc: 0.1920 - val_loss: 0.0276 - val_acc: 0.2160\n",
      "Epoch 224/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0148 - acc: 0.1973 - val_loss: 0.0302 - val_acc: 0.1800\n",
      "Epoch 225/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0145 - acc: 0.1827 - val_loss: 0.0276 - val_acc: 0.2080\n",
      "Epoch 226/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0144 - acc: 0.1987 - val_loss: 0.0307 - val_acc: 0.1760\n",
      "Epoch 227/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0145 - acc: 0.1973 - val_loss: 0.0274 - val_acc: 0.2320\n",
      "Epoch 228/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0147 - acc: 0.2200 - val_loss: 0.0305 - val_acc: 0.1880\n",
      "Epoch 229/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0143 - acc: 0.2027 - val_loss: 0.0286 - val_acc: 0.1760\n",
      "Epoch 230/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0138 - acc: 0.2120 - val_loss: 0.0294 - val_acc: 0.2040\n",
      "Epoch 231/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0140 - acc: 0.2240 - val_loss: 0.0278 - val_acc: 0.2120\n",
      "Epoch 232/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0143 - acc: 0.2307 - val_loss: 0.0304 - val_acc: 0.1960\n",
      "Epoch 233/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0140 - acc: 0.2173 - val_loss: 0.0279 - val_acc: 0.1920\n",
      "Epoch 234/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0134 - acc: 0.2080 - val_loss: 0.0282 - val_acc: 0.2240\n",
      "Epoch 235/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0138 - acc: 0.2093 - val_loss: 0.0309 - val_acc: 0.1960\n",
      "Epoch 236/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0137 - acc: 0.2187 - val_loss: 0.0274 - val_acc: 0.2080\n",
      "Epoch 237/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0137 - acc: 0.2387 - val_loss: 0.0316 - val_acc: 0.1880\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 165us/step - loss: 0.0138 - acc: 0.2253 - val_loss: 0.0272 - val_acc: 0.2360\n",
      "Epoch 239/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0139 - acc: 0.2213 - val_loss: 0.0300 - val_acc: 0.1720\n",
      "Epoch 240/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0130 - acc: 0.2053 - val_loss: 0.0295 - val_acc: 0.2120\n",
      "Epoch 241/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0128 - acc: 0.2333 - val_loss: 0.0285 - val_acc: 0.1880\n",
      "Epoch 242/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0129 - acc: 0.2213 - val_loss: 0.0311 - val_acc: 0.2000\n",
      "Epoch 243/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0133 - acc: 0.2240 - val_loss: 0.0271 - val_acc: 0.2440\n",
      "Epoch 244/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0133 - acc: 0.2387 - val_loss: 0.0319 - val_acc: 0.1920\n",
      "Epoch 245/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0131 - acc: 0.2333 - val_loss: 0.0283 - val_acc: 0.1640\n",
      "Epoch 246/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0127 - acc: 0.2240 - val_loss: 0.0304 - val_acc: 0.2000\n",
      "Epoch 247/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0124 - acc: 0.2120 - val_loss: 0.0285 - val_acc: 0.2200\n",
      "Epoch 248/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0123 - acc: 0.2200 - val_loss: 0.0302 - val_acc: 0.1880\n",
      "Epoch 249/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0122 - acc: 0.2307 - val_loss: 0.0293 - val_acc: 0.2160\n",
      "Epoch 250/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0119 - acc: 0.2413 - val_loss: 0.0282 - val_acc: 0.2240\n",
      "Epoch 251/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0128 - acc: 0.2347 - val_loss: 0.0316 - val_acc: 0.2200\n",
      "Epoch 252/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0125 - acc: 0.2320 - val_loss: 0.0278 - val_acc: 0.2080\n",
      "Epoch 253/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0124 - acc: 0.2440 - val_loss: 0.0301 - val_acc: 0.2040\n",
      "Epoch 254/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0115 - acc: 0.2453 - val_loss: 0.0291 - val_acc: 0.2240\n",
      "Epoch 255/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0118 - acc: 0.2360 - val_loss: 0.0314 - val_acc: 0.2160\n",
      "Epoch 256/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0122 - acc: 0.2707 - val_loss: 0.0275 - val_acc: 0.2640\n",
      "Epoch 257/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0126 - acc: 0.2507 - val_loss: 0.0307 - val_acc: 0.2000\n",
      "Epoch 258/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0114 - acc: 0.2347 - val_loss: 0.0293 - val_acc: 0.2240\n",
      "Epoch 259/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0113 - acc: 0.2360 - val_loss: 0.0300 - val_acc: 0.2120\n",
      "Epoch 260/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0116 - acc: 0.2600 - val_loss: 0.0297 - val_acc: 0.1880\n",
      "Epoch 261/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0115 - acc: 0.2707 - val_loss: 0.0302 - val_acc: 0.2000\n",
      "Epoch 262/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0110 - acc: 0.2440 - val_loss: 0.0287 - val_acc: 0.2240\n",
      "Epoch 263/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0118 - acc: 0.2440 - val_loss: 0.0323 - val_acc: 0.1920\n",
      "Epoch 264/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0112 - acc: 0.2573 - val_loss: 0.0285 - val_acc: 0.2240\n",
      "Epoch 265/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0109 - acc: 0.2573 - val_loss: 0.0313 - val_acc: 0.2120\n",
      "Epoch 266/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0114 - acc: 0.2693 - val_loss: 0.0283 - val_acc: 0.1720\n",
      "Epoch 267/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0112 - acc: 0.2573 - val_loss: 0.0321 - val_acc: 0.1880\n",
      "Epoch 268/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0109 - acc: 0.2427 - val_loss: 0.0284 - val_acc: 0.2400\n",
      "Epoch 269/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0107 - acc: 0.3013 - val_loss: 0.0308 - val_acc: 0.2160\n",
      "Epoch 270/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0107 - acc: 0.2560 - val_loss: 0.0292 - val_acc: 0.2120\n",
      "Epoch 271/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0105 - acc: 0.2640 - val_loss: 0.0300 - val_acc: 0.2360\n",
      "Epoch 272/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0105 - acc: 0.2747 - val_loss: 0.0290 - val_acc: 0.2120\n",
      "Epoch 273/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0108 - acc: 0.2653 - val_loss: 0.0336 - val_acc: 0.2240\n",
      "Epoch 274/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0115 - acc: 0.2560 - val_loss: 0.0284 - val_acc: 0.2320\n",
      "Epoch 275/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0100 - acc: 0.2680 - val_loss: 0.0298 - val_acc: 0.2160\n",
      "Epoch 276/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0097 - acc: 0.2720 - val_loss: 0.0301 - val_acc: 0.2440\n",
      "Epoch 277/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0097 - acc: 0.2760 - val_loss: 0.0300 - val_acc: 0.2000\n",
      "Epoch 278/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0105 - acc: 0.2440 - val_loss: 0.0325 - val_acc: 0.2200\n",
      "Epoch 279/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0105 - acc: 0.2747 - val_loss: 0.0278 - val_acc: 0.2320\n",
      "Epoch 280/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0104 - acc: 0.3053 - val_loss: 0.0314 - val_acc: 0.2200\n",
      "Epoch 281/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0097 - acc: 0.2720 - val_loss: 0.0297 - val_acc: 0.2360\n",
      "Epoch 282/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0094 - acc: 0.3000 - val_loss: 0.0300 - val_acc: 0.2000\n",
      "Epoch 283/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0095 - acc: 0.2653 - val_loss: 0.0318 - val_acc: 0.2160\n",
      "Epoch 284/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0095 - acc: 0.3080 - val_loss: 0.0285 - val_acc: 0.2160\n",
      "Epoch 285/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0102 - acc: 0.3147 - val_loss: 0.0347 - val_acc: 0.1960\n",
      "Epoch 286/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0100 - acc: 0.2667 - val_loss: 0.0289 - val_acc: 0.2440\n",
      "Epoch 287/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0093 - acc: 0.3067 - val_loss: 0.0313 - val_acc: 0.2120\n",
      "Epoch 288/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0090 - acc: 0.2787 - val_loss: 0.0300 - val_acc: 0.2360\n",
      "Epoch 289/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0090 - acc: 0.3053 - val_loss: 0.0307 - val_acc: 0.2040\n",
      "Epoch 290/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0097 - acc: 0.2907 - val_loss: 0.0305 - val_acc: 0.2160\n",
      "Epoch 291/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0091 - acc: 0.2893 - val_loss: 0.0305 - val_acc: 0.2200\n",
      "Epoch 292/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0087 - acc: 0.2867 - val_loss: 0.0301 - val_acc: 0.2360\n",
      "Epoch 293/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0086 - acc: 0.3013 - val_loss: 0.0300 - val_acc: 0.2000\n",
      "Epoch 294/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0093 - acc: 0.2947 - val_loss: 0.0364 - val_acc: 0.2360\n",
      "Epoch 295/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0109 - acc: 0.3253 - val_loss: 0.0287 - val_acc: 0.2360\n",
      "Epoch 296/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0087 - acc: 0.3333 - val_loss: 0.0305 - val_acc: 0.2160\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0083 - acc: 0.3240 - val_loss: 0.0300 - val_acc: 0.2080\n",
      "Epoch 298/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0081 - acc: 0.2893 - val_loss: 0.0303 - val_acc: 0.2240\n",
      "Epoch 299/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0083 - acc: 0.3093 - val_loss: 0.0309 - val_acc: 0.2080\n",
      "Epoch 300/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0085 - acc: 0.2773 - val_loss: 0.0305 - val_acc: 0.2160\n",
      "Epoch 301/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0086 - acc: 0.2933 - val_loss: 0.0318 - val_acc: 0.2320\n",
      "Epoch 302/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0085 - acc: 0.3133 - val_loss: 0.0293 - val_acc: 0.2400\n",
      "Epoch 303/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0083 - acc: 0.3427 - val_loss: 0.0335 - val_acc: 0.2120\n",
      "Epoch 304/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0087 - acc: 0.3107 - val_loss: 0.0282 - val_acc: 0.2200\n",
      "Epoch 305/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0089 - acc: 0.3107 - val_loss: 0.0330 - val_acc: 0.2040\n",
      "Epoch 306/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0084 - acc: 0.3307 - val_loss: 0.0300 - val_acc: 0.2080\n",
      "Epoch 307/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0078 - acc: 0.3173 - val_loss: 0.0307 - val_acc: 0.2440\n",
      "Epoch 308/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0076 - acc: 0.3467 - val_loss: 0.0300 - val_acc: 0.2120\n",
      "Epoch 309/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0077 - acc: 0.3120 - val_loss: 0.0311 - val_acc: 0.2160\n",
      "Epoch 310/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0076 - acc: 0.3467 - val_loss: 0.0288 - val_acc: 0.2440\n",
      "Epoch 311/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0084 - acc: 0.3387 - val_loss: 0.0383 - val_acc: 0.2000\n",
      "Epoch 312/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0089 - acc: 0.3133 - val_loss: 0.0295 - val_acc: 0.2280\n",
      "Epoch 313/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0074 - acc: 0.3547 - val_loss: 0.0308 - val_acc: 0.2320\n",
      "Epoch 314/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0073 - acc: 0.3307 - val_loss: 0.0306 - val_acc: 0.2280\n",
      "Epoch 315/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0077 - acc: 0.3427 - val_loss: 0.0306 - val_acc: 0.2000\n",
      "Epoch 316/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0076 - acc: 0.3307 - val_loss: 0.0317 - val_acc: 0.2200\n",
      "Epoch 317/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0075 - acc: 0.3467 - val_loss: 0.0319 - val_acc: 0.2440\n",
      "Epoch 318/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0074 - acc: 0.3347 - val_loss: 0.0292 - val_acc: 0.2200\n",
      "Epoch 319/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0073 - acc: 0.3560 - val_loss: 0.0327 - val_acc: 0.2200\n",
      "Epoch 320/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0075 - acc: 0.3747 - val_loss: 0.0295 - val_acc: 0.2120\n",
      "Epoch 321/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0083 - acc: 0.3440 - val_loss: 0.0326 - val_acc: 0.2360\n",
      "Epoch 322/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0073 - acc: 0.3507 - val_loss: 0.0306 - val_acc: 0.2320\n",
      "Epoch 323/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0068 - acc: 0.3600 - val_loss: 0.0312 - val_acc: 0.2200\n",
      "Epoch 324/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0068 - acc: 0.3520 - val_loss: 0.0301 - val_acc: 0.2320\n",
      "Epoch 325/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0072 - acc: 0.3200 - val_loss: 0.0326 - val_acc: 0.2120\n",
      "Epoch 326/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0074 - acc: 0.3347 - val_loss: 0.0296 - val_acc: 0.2480\n",
      "Epoch 327/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0074 - acc: 0.4040 - val_loss: 0.0315 - val_acc: 0.2160\n",
      "Epoch 328/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0067 - acc: 0.3760 - val_loss: 0.0314 - val_acc: 0.2400\n",
      "Epoch 329/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0067 - acc: 0.3547 - val_loss: 0.0301 - val_acc: 0.2240\n",
      "Epoch 330/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0069 - acc: 0.3627 - val_loss: 0.0327 - val_acc: 0.2000\n",
      "Epoch 331/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0067 - acc: 0.3760 - val_loss: 0.0297 - val_acc: 0.2400\n",
      "Epoch 332/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0070 - acc: 0.3840 - val_loss: 0.0336 - val_acc: 0.2640\n",
      "Epoch 333/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0069 - acc: 0.3920 - val_loss: 0.0303 - val_acc: 0.2320\n",
      "Epoch 334/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0063 - acc: 0.3827 - val_loss: 0.0323 - val_acc: 0.2240\n",
      "Epoch 335/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0063 - acc: 0.3733 - val_loss: 0.0303 - val_acc: 0.2400\n",
      "Epoch 336/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0066 - acc: 0.4093 - val_loss: 0.0340 - val_acc: 0.2040\n",
      "Epoch 337/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 0.3573 - val_loss: 0.0300 - val_acc: 0.2520\n",
      "Epoch 338/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0066 - acc: 0.4040 - val_loss: 0.0325 - val_acc: 0.2320\n",
      "Epoch 339/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0062 - acc: 0.4133 - val_loss: 0.0302 - val_acc: 0.2200\n",
      "Epoch 340/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0061 - acc: 0.4093 - val_loss: 0.0329 - val_acc: 0.2320\n",
      "Epoch 341/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0070 - acc: 0.4240 - val_loss: 0.0305 - val_acc: 0.2280\n",
      "Epoch 342/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0065 - acc: 0.3680 - val_loss: 0.0327 - val_acc: 0.2600\n",
      "Epoch 343/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0061 - acc: 0.4080 - val_loss: 0.0301 - val_acc: 0.2440\n",
      "Epoch 344/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0059 - acc: 0.3960 - val_loss: 0.0317 - val_acc: 0.2200\n",
      "Epoch 345/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0058 - acc: 0.3947 - val_loss: 0.0311 - val_acc: 0.2520\n",
      "Epoch 346/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0059 - acc: 0.4147 - val_loss: 0.0325 - val_acc: 0.2400\n",
      "Epoch 347/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0062 - acc: 0.3893 - val_loss: 0.0294 - val_acc: 0.2560\n",
      "Epoch 348/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0066 - acc: 0.4080 - val_loss: 0.0331 - val_acc: 0.2360\n",
      "Epoch 349/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0059 - acc: 0.4147 - val_loss: 0.0305 - val_acc: 0.2240\n",
      "Epoch 350/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0058 - acc: 0.3987 - val_loss: 0.0325 - val_acc: 0.2280\n",
      "Epoch 351/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0059 - acc: 0.4120 - val_loss: 0.0311 - val_acc: 0.2600\n",
      "Epoch 352/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0061 - acc: 0.3893 - val_loss: 0.0320 - val_acc: 0.2280\n",
      "Epoch 353/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0056 - acc: 0.4240 - val_loss: 0.0314 - val_acc: 0.2200\n",
      "Epoch 354/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0055 - acc: 0.4053 - val_loss: 0.0324 - val_acc: 0.2400\n",
      "Epoch 355/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0055 - acc: 0.4480 - val_loss: 0.0320 - val_acc: 0.2360\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 165us/step - loss: 0.0055 - acc: 0.4267 - val_loss: 0.0316 - val_acc: 0.2400\n",
      "Epoch 357/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0061 - acc: 0.4280 - val_loss: 0.0367 - val_acc: 0.2240\n",
      "Epoch 358/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0063 - acc: 0.4080 - val_loss: 0.0302 - val_acc: 0.2400\n",
      "Epoch 359/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0057 - acc: 0.4600 - val_loss: 0.0326 - val_acc: 0.2440\n",
      "Epoch 360/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0054 - acc: 0.4587 - val_loss: 0.0312 - val_acc: 0.2440\n",
      "Epoch 361/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0053 - acc: 0.4507 - val_loss: 0.0323 - val_acc: 0.2320\n",
      "Epoch 362/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0053 - acc: 0.4680 - val_loss: 0.0314 - val_acc: 0.2320\n",
      "Epoch 363/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0051 - acc: 0.4587 - val_loss: 0.0321 - val_acc: 0.2360\n",
      "Epoch 364/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0052 - acc: 0.4547 - val_loss: 0.0318 - val_acc: 0.2880\n",
      "Epoch 365/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0057 - acc: 0.4280 - val_loss: 0.0347 - val_acc: 0.2240\n",
      "Epoch 366/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0058 - acc: 0.4680 - val_loss: 0.0294 - val_acc: 0.2480\n",
      "Epoch 367/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0056 - acc: 0.4493 - val_loss: 0.0331 - val_acc: 0.2440\n",
      "Epoch 368/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0050 - acc: 0.4653 - val_loss: 0.0314 - val_acc: 0.2400\n",
      "Epoch 369/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 0.5013 - val_loss: 0.0319 - val_acc: 0.2320\n",
      "Epoch 370/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0048 - acc: 0.4947 - val_loss: 0.0318 - val_acc: 0.2400\n",
      "Epoch 371/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0053 - acc: 0.4453 - val_loss: 0.0331 - val_acc: 0.2520\n",
      "Epoch 372/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0056 - acc: 0.4507 - val_loss: 0.0321 - val_acc: 0.2440\n",
      "Epoch 373/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0052 - acc: 0.4600 - val_loss: 0.0332 - val_acc: 0.2240\n",
      "Epoch 374/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0049 - acc: 0.4813 - val_loss: 0.0308 - val_acc: 0.2560\n",
      "Epoch 375/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0051 - acc: 0.4960 - val_loss: 0.0364 - val_acc: 0.2280\n",
      "Epoch 376/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0054 - acc: 0.4800 - val_loss: 0.0308 - val_acc: 0.2680\n",
      "Epoch 377/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0050 - acc: 0.4827 - val_loss: 0.0326 - val_acc: 0.2200\n",
      "Epoch 378/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0047 - acc: 0.5280 - val_loss: 0.0316 - val_acc: 0.2760\n",
      "Epoch 379/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0047 - acc: 0.4973 - val_loss: 0.0329 - val_acc: 0.2280\n",
      "Epoch 380/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0052 - acc: 0.4920 - val_loss: 0.0310 - val_acc: 0.2160\n",
      "Epoch 381/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0051 - acc: 0.4773 - val_loss: 0.0344 - val_acc: 0.2960\n",
      "Epoch 382/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0048 - acc: 0.5107 - val_loss: 0.0314 - val_acc: 0.2400\n",
      "Epoch 383/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0045 - acc: 0.5213 - val_loss: 0.0327 - val_acc: 0.2560\n",
      "Epoch 384/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0047 - acc: 0.5160 - val_loss: 0.0320 - val_acc: 0.2360\n",
      "Epoch 385/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0049 - acc: 0.4880 - val_loss: 0.0330 - val_acc: 0.2520\n",
      "Epoch 386/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0049 - acc: 0.4773 - val_loss: 0.0316 - val_acc: 0.2520\n",
      "Epoch 387/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0046 - acc: 0.5080 - val_loss: 0.0325 - val_acc: 0.2600\n",
      "Epoch 388/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0046 - acc: 0.5440 - val_loss: 0.0323 - val_acc: 0.2360\n",
      "Epoch 389/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0047 - acc: 0.5080 - val_loss: 0.0350 - val_acc: 0.2440\n",
      "Epoch 390/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0056 - acc: 0.4827 - val_loss: 0.0297 - val_acc: 0.2440\n",
      "Epoch 391/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0050 - acc: 0.4893 - val_loss: 0.0325 - val_acc: 0.2520\n",
      "Epoch 392/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0044 - acc: 0.5747 - val_loss: 0.0322 - val_acc: 0.2560\n",
      "Epoch 393/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0043 - acc: 0.5707 - val_loss: 0.0323 - val_acc: 0.2480\n",
      "Epoch 394/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0042 - acc: 0.5573 - val_loss: 0.0324 - val_acc: 0.2600\n",
      "Epoch 395/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0043 - acc: 0.5773 - val_loss: 0.0332 - val_acc: 0.2600\n",
      "Epoch 396/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0046 - acc: 0.5120 - val_loss: 0.0320 - val_acc: 0.2520\n",
      "Epoch 397/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0044 - acc: 0.5480 - val_loss: 0.0341 - val_acc: 0.2640\n",
      "Epoch 398/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0047 - acc: 0.5267 - val_loss: 0.0322 - val_acc: 0.2600\n",
      "Epoch 399/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0047 - acc: 0.5053 - val_loss: 0.0332 - val_acc: 0.2560\n",
      "Epoch 400/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0042 - acc: 0.6013 - val_loss: 0.0319 - val_acc: 0.2560\n",
      "Epoch 401/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0042 - acc: 0.5960 - val_loss: 0.0341 - val_acc: 0.2520\n",
      "Epoch 402/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0044 - acc: 0.5507 - val_loss: 0.0311 - val_acc: 0.2800\n",
      "Epoch 403/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0055 - acc: 0.5173 - val_loss: 0.0393 - val_acc: 0.2080\n",
      "Epoch 404/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0060 - acc: 0.4867 - val_loss: 0.0333 - val_acc: 0.2840\n",
      "Epoch 405/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 0.6040 - val_loss: 0.0322 - val_acc: 0.2800\n",
      "Epoch 406/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0041 - acc: 0.5960 - val_loss: 0.0321 - val_acc: 0.2560\n",
      "Epoch 407/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0040 - acc: 0.5987 - val_loss: 0.0323 - val_acc: 0.2720\n",
      "Epoch 408/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0040 - acc: 0.6013 - val_loss: 0.0324 - val_acc: 0.2760\n",
      "Epoch 409/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0040 - acc: 0.6093 - val_loss: 0.0322 - val_acc: 0.2600\n",
      "Epoch 410/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0042 - acc: 0.5547 - val_loss: 0.0342 - val_acc: 0.2320\n",
      "Epoch 411/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0049 - acc: 0.5400 - val_loss: 0.0320 - val_acc: 0.2800\n",
      "Epoch 412/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0042 - acc: 0.5813 - val_loss: 0.0326 - val_acc: 0.2640\n",
      "Epoch 413/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0040 - acc: 0.6360 - val_loss: 0.0327 - val_acc: 0.2480\n",
      "Epoch 414/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0040 - acc: 0.6133 - val_loss: 0.0327 - val_acc: 0.2720\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 165us/step - loss: 0.0040 - acc: 0.6533 - val_loss: 0.0327 - val_acc: 0.2600\n",
      "Epoch 416/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 0.5253 - val_loss: 0.0342 - val_acc: 0.2600\n",
      "Epoch 417/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0042 - acc: 0.6080 - val_loss: 0.0323 - val_acc: 0.2680\n",
      "Epoch 418/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0041 - acc: 0.6187 - val_loss: 0.0339 - val_acc: 0.2640\n",
      "Epoch 419/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0040 - acc: 0.6120 - val_loss: 0.0326 - val_acc: 0.2800\n",
      "Epoch 420/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0039 - acc: 0.6493 - val_loss: 0.0340 - val_acc: 0.2800\n",
      "Epoch 421/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0042 - acc: 0.5707 - val_loss: 0.0336 - val_acc: 0.2920\n",
      "Epoch 422/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0047 - acc: 0.5387 - val_loss: 0.0339 - val_acc: 0.2600\n",
      "Epoch 423/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0039 - acc: 0.6653 - val_loss: 0.0323 - val_acc: 0.2720\n",
      "Epoch 424/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0038 - acc: 0.6507 - val_loss: 0.0329 - val_acc: 0.2920\n",
      "Epoch 425/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0037 - acc: 0.6707 - val_loss: 0.0327 - val_acc: 0.3000\n",
      "Epoch 426/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0037 - acc: 0.6360 - val_loss: 0.0330 - val_acc: 0.2760\n",
      "Epoch 427/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0041 - acc: 0.6280 - val_loss: 0.0318 - val_acc: 0.2440\n",
      "Epoch 428/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0048 - acc: 0.4973 - val_loss: 0.0343 - val_acc: 0.2720\n",
      "Epoch 429/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0039 - acc: 0.6467 - val_loss: 0.0326 - val_acc: 0.2760\n",
      "Epoch 430/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0036 - acc: 0.6747 - val_loss: 0.0326 - val_acc: 0.2720\n",
      "Epoch 431/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0036 - acc: 0.6707 - val_loss: 0.0327 - val_acc: 0.2960\n",
      "Epoch 432/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0035 - acc: 0.6987 - val_loss: 0.0328 - val_acc: 0.2800\n",
      "Epoch 433/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0036 - acc: 0.6680 - val_loss: 0.0330 - val_acc: 0.2840\n",
      "Epoch 434/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0038 - acc: 0.5907 - val_loss: 0.0331 - val_acc: 0.2800\n",
      "Epoch 435/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0037 - acc: 0.6080 - val_loss: 0.0324 - val_acc: 0.3000\n",
      "Epoch 436/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0036 - acc: 0.6547 - val_loss: 0.0348 - val_acc: 0.2760\n",
      "Epoch 437/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0039 - acc: 0.6293 - val_loss: 0.0306 - val_acc: 0.2720\n",
      "Epoch 438/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0049 - acc: 0.5773 - val_loss: 0.0342 - val_acc: 0.2840\n",
      "Epoch 439/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0036 - acc: 0.6520 - val_loss: 0.0327 - val_acc: 0.2840\n",
      "Epoch 440/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0034 - acc: 0.7120 - val_loss: 0.0327 - val_acc: 0.2840\n",
      "Epoch 441/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0033 - acc: 0.7160 - val_loss: 0.0326 - val_acc: 0.2840\n",
      "Epoch 442/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0033 - acc: 0.7173 - val_loss: 0.0327 - val_acc: 0.2840\n",
      "Epoch 443/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0033 - acc: 0.7133 - val_loss: 0.0326 - val_acc: 0.2960\n",
      "Epoch 444/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0033 - acc: 0.6973 - val_loss: 0.0332 - val_acc: 0.2760\n",
      "Epoch 445/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0036 - acc: 0.6440 - val_loss: 0.0330 - val_acc: 0.2840\n",
      "Epoch 446/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0039 - acc: 0.5960 - val_loss: 0.0329 - val_acc: 0.3000\n",
      "Epoch 447/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0032 - acc: 0.7200 - val_loss: 0.0329 - val_acc: 0.2880\n",
      "Epoch 448/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0032 - acc: 0.7387 - val_loss: 0.0328 - val_acc: 0.2880\n",
      "Epoch 449/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0032 - acc: 0.7280 - val_loss: 0.0329 - val_acc: 0.3000\n",
      "Epoch 450/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0031 - acc: 0.7333 - val_loss: 0.0326 - val_acc: 0.2800\n",
      "Epoch 451/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0033 - acc: 0.6827 - val_loss: 0.0318 - val_acc: 0.3000\n",
      "Epoch 452/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0041 - acc: 0.5720 - val_loss: 0.0352 - val_acc: 0.2480\n",
      "Epoch 453/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0034 - acc: 0.6587 - val_loss: 0.0324 - val_acc: 0.3040\n",
      "Epoch 454/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0031 - acc: 0.7440 - val_loss: 0.0326 - val_acc: 0.3000\n",
      "Epoch 455/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0031 - acc: 0.7587 - val_loss: 0.0327 - val_acc: 0.2920\n",
      "Epoch 456/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0031 - acc: 0.7547 - val_loss: 0.0330 - val_acc: 0.2760\n",
      "Epoch 457/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0030 - acc: 0.7613 - val_loss: 0.0328 - val_acc: 0.2960\n",
      "Epoch 458/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0030 - acc: 0.6920 - val_loss: 0.0334 - val_acc: 0.2680\n",
      "Epoch 459/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0034 - acc: 0.6640 - val_loss: 0.0336 - val_acc: 0.1880\n",
      "Epoch 460/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0042 - acc: 0.5107 - val_loss: 0.0340 - val_acc: 0.2520\n",
      "Epoch 461/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0028 - acc: 0.7640 - val_loss: 0.0327 - val_acc: 0.2760\n",
      "Epoch 462/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0028 - acc: 0.7867 - val_loss: 0.0328 - val_acc: 0.2880\n",
      "Epoch 463/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0027 - acc: 0.7960 - val_loss: 0.0327 - val_acc: 0.2920\n",
      "Epoch 464/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0027 - acc: 0.7933 - val_loss: 0.0327 - val_acc: 0.3000\n",
      "Epoch 465/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0027 - acc: 0.7987 - val_loss: 0.0328 - val_acc: 0.2920\n",
      "Epoch 466/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0027 - acc: 0.7947 - val_loss: 0.0328 - val_acc: 0.2880\n",
      "Epoch 467/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0027 - acc: 0.7853 - val_loss: 0.0323 - val_acc: 0.2760\n",
      "Epoch 468/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0027 - acc: 0.7733 - val_loss: 0.0354 - val_acc: 0.2520\n",
      "Epoch 469/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0034 - acc: 0.6480 - val_loss: 0.0304 - val_acc: 0.2840\n",
      "Epoch 470/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0038 - acc: 0.6280 - val_loss: 0.0340 - val_acc: 0.2720\n",
      "Epoch 471/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0027 - acc: 0.7680 - val_loss: 0.0330 - val_acc: 0.2920\n",
      "Epoch 472/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0026 - acc: 0.8040 - val_loss: 0.0330 - val_acc: 0.2920\n",
      "Epoch 473/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0026 - acc: 0.7987 - val_loss: 0.0330 - val_acc: 0.2960\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 167us/step - loss: 0.0026 - acc: 0.8093 - val_loss: 0.0331 - val_acc: 0.2840\n",
      "Epoch 475/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0026 - acc: 0.8027 - val_loss: 0.0330 - val_acc: 0.2880\n",
      "Epoch 476/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.7947 - val_loss: 0.0330 - val_acc: 0.2920\n",
      "Epoch 477/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0025 - acc: 0.7947 - val_loss: 0.0330 - val_acc: 0.3000\n",
      "Epoch 478/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.7600 - val_loss: 0.0334 - val_acc: 0.2520\n",
      "Epoch 479/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0030 - acc: 0.6667 - val_loss: 0.0319 - val_acc: 0.2920\n",
      "Epoch 480/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0033 - acc: 0.6227 - val_loss: 0.0354 - val_acc: 0.2920\n",
      "Epoch 481/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0030 - acc: 0.7067 - val_loss: 0.0327 - val_acc: 0.2960\n",
      "Epoch 482/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8133 - val_loss: 0.0328 - val_acc: 0.3000\n",
      "Epoch 483/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0025 - acc: 0.8200 - val_loss: 0.0329 - val_acc: 0.2960\n",
      "Epoch 484/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8253 - val_loss: 0.0330 - val_acc: 0.3000\n",
      "Epoch 485/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8293 - val_loss: 0.0330 - val_acc: 0.3000\n",
      "Epoch 486/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0025 - acc: 0.8187 - val_loss: 0.0329 - val_acc: 0.3040\n",
      "Epoch 487/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0025 - acc: 0.8360 - val_loss: 0.0331 - val_acc: 0.3000\n",
      "Epoch 488/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0025 - acc: 0.8187 - val_loss: 0.0328 - val_acc: 0.2920\n",
      "Epoch 489/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0025 - acc: 0.7627 - val_loss: 0.0353 - val_acc: 0.2960\n",
      "Epoch 490/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 0.5520 - val_loss: 0.0305 - val_acc: 0.2960\n",
      "Epoch 491/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0029 - acc: 0.7027 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 492/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0025 - acc: 0.8027 - val_loss: 0.0329 - val_acc: 0.2960\n",
      "Epoch 493/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0025 - acc: 0.8227 - val_loss: 0.0329 - val_acc: 0.3000\n",
      "Epoch 494/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8227 - val_loss: 0.0329 - val_acc: 0.3000\n",
      "Epoch 495/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8280 - val_loss: 0.0329 - val_acc: 0.3040\n",
      "Epoch 496/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.8333 - val_loss: 0.0329 - val_acc: 0.3080\n",
      "Epoch 497/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0024 - acc: 0.8440 - val_loss: 0.0329 - val_acc: 0.2960\n",
      "Epoch 498/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0024 - acc: 0.8400 - val_loss: 0.0328 - val_acc: 0.2960\n",
      "Epoch 499/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.8467 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 500/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0024 - acc: 0.8373 - val_loss: 0.0330 - val_acc: 0.3080\n",
      "Epoch 501/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0027 - acc: 0.7653 - val_loss: 0.0341 - val_acc: 0.3000\n",
      "Epoch 502/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0033 - acc: 0.5827 - val_loss: 0.0319 - val_acc: 0.2920\n",
      "Epoch 503/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0025 - acc: 0.8067 - val_loss: 0.0330 - val_acc: 0.2920\n",
      "Epoch 504/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0024 - acc: 0.8480 - val_loss: 0.0331 - val_acc: 0.2880\n",
      "Epoch 505/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0024 - acc: 0.8560 - val_loss: 0.0329 - val_acc: 0.2880\n",
      "Epoch 506/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.8573 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 507/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.8667 - val_loss: 0.0328 - val_acc: 0.2960\n",
      "Epoch 508/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0024 - acc: 0.8627 - val_loss: 0.0329 - val_acc: 0.2920\n",
      "Epoch 509/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0024 - acc: 0.8613 - val_loss: 0.0334 - val_acc: 0.3000\n",
      "Epoch 510/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0024 - acc: 0.8573 - val_loss: 0.0327 - val_acc: 0.2880\n",
      "Epoch 511/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0029 - acc: 0.7307 - val_loss: 0.0386 - val_acc: 0.2720\n",
      "Epoch 512/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0035 - acc: 0.6013 - val_loss: 0.0318 - val_acc: 0.2840\n",
      "Epoch 513/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0025 - acc: 0.7933 - val_loss: 0.0328 - val_acc: 0.3040\n",
      "Epoch 514/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.8600 - val_loss: 0.0328 - val_acc: 0.3040\n",
      "Epoch 515/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0024 - acc: 0.8720 - val_loss: 0.0328 - val_acc: 0.3000\n",
      "Epoch 516/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0024 - acc: 0.8707 - val_loss: 0.0329 - val_acc: 0.3040\n",
      "Epoch 517/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0024 - acc: 0.8787 - val_loss: 0.0329 - val_acc: 0.3000\n",
      "Epoch 518/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.8693 - val_loss: 0.0329 - val_acc: 0.2960\n",
      "Epoch 519/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0024 - acc: 0.8720 - val_loss: 0.0328 - val_acc: 0.2960\n",
      "Epoch 520/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0024 - acc: 0.8813 - val_loss: 0.0329 - val_acc: 0.3000\n",
      "Epoch 521/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8773 - val_loss: 0.0329 - val_acc: 0.3000\n",
      "Epoch 522/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8893 - val_loss: 0.0328 - val_acc: 0.2960\n",
      "Epoch 523/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8733 - val_loss: 0.0329 - val_acc: 0.2920\n",
      "Epoch 524/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0023 - acc: 0.8933 - val_loss: 0.0329 - val_acc: 0.3040\n",
      "Epoch 525/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0023 - acc: 0.8733 - val_loss: 0.0331 - val_acc: 0.2880\n",
      "Epoch 526/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0028 - acc: 0.7533 - val_loss: 0.0326 - val_acc: 0.2400\n",
      "Epoch 527/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0034 - acc: 0.6013 - val_loss: 0.0340 - val_acc: 0.3120\n",
      "Epoch 528/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0024 - acc: 0.8293 - val_loss: 0.0333 - val_acc: 0.2920\n",
      "Epoch 529/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0023 - acc: 0.8640 - val_loss: 0.0333 - val_acc: 0.2920\n",
      "Epoch 530/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8627 - val_loss: 0.0333 - val_acc: 0.2880\n",
      "Epoch 531/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8720 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 532/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8707 - val_loss: 0.0332 - val_acc: 0.2960\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 182us/step - loss: 0.0023 - acc: 0.8800 - val_loss: 0.0332 - val_acc: 0.2880\n",
      "Epoch 534/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0023 - acc: 0.8867 - val_loss: 0.0333 - val_acc: 0.2920\n",
      "Epoch 535/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.8880 - val_loss: 0.0332 - val_acc: 0.2960\n",
      "Epoch 536/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8960 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 537/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0023 - acc: 0.8880 - val_loss: 0.0330 - val_acc: 0.3000\n",
      "Epoch 538/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8947 - val_loss: 0.0332 - val_acc: 0.2680\n",
      "Epoch 539/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0033 - acc: 0.6400 - val_loss: 0.0360 - val_acc: 0.2640\n",
      "Epoch 540/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.7653 - val_loss: 0.0328 - val_acc: 0.2760\n",
      "Epoch 541/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.8787 - val_loss: 0.0331 - val_acc: 0.2840\n",
      "Epoch 542/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.8933 - val_loss: 0.0330 - val_acc: 0.2840\n",
      "Epoch 543/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8880 - val_loss: 0.0330 - val_acc: 0.2880\n",
      "Epoch 544/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8933 - val_loss: 0.0330 - val_acc: 0.2840\n",
      "Epoch 545/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9013 - val_loss: 0.0330 - val_acc: 0.2880\n",
      "Epoch 546/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0023 - acc: 0.9013 - val_loss: 0.0330 - val_acc: 0.2880\n",
      "Epoch 547/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0023 - acc: 0.8933 - val_loss: 0.0330 - val_acc: 0.2800\n",
      "Epoch 548/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9053 - val_loss: 0.0330 - val_acc: 0.2840\n",
      "Epoch 549/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.9013 - val_loss: 0.0330 - val_acc: 0.2760\n",
      "Epoch 550/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9120 - val_loss: 0.0329 - val_acc: 0.2880\n",
      "Epoch 551/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.9000 - val_loss: 0.0330 - val_acc: 0.3000\n",
      "Epoch 552/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 0.7653 - val_loss: 0.0352 - val_acc: 0.2360\n",
      "Epoch 553/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0035 - acc: 0.5880 - val_loss: 0.0345 - val_acc: 0.2680\n",
      "Epoch 554/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8493 - val_loss: 0.0331 - val_acc: 0.2880\n",
      "Epoch 555/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.8867 - val_loss: 0.0330 - val_acc: 0.2880\n",
      "Epoch 556/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0023 - acc: 0.8947 - val_loss: 0.0330 - val_acc: 0.2840\n",
      "Epoch 557/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0023 - acc: 0.9027 - val_loss: 0.0330 - val_acc: 0.2880\n",
      "Epoch 558/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0023 - acc: 0.9053 - val_loss: 0.0330 - val_acc: 0.2880\n",
      "Epoch 559/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.9093 - val_loss: 0.0330 - val_acc: 0.2880\n",
      "Epoch 560/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.9093 - val_loss: 0.0330 - val_acc: 0.2880\n",
      "Epoch 561/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.9093 - val_loss: 0.0330 - val_acc: 0.2800\n",
      "Epoch 562/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0023 - acc: 0.9120 - val_loss: 0.0330 - val_acc: 0.2800\n",
      "Epoch 563/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0023 - acc: 0.9147 - val_loss: 0.0329 - val_acc: 0.2800\n",
      "Epoch 564/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0023 - acc: 0.9173 - val_loss: 0.0330 - val_acc: 0.2800\n",
      "Epoch 565/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.9293 - val_loss: 0.0329 - val_acc: 0.2840\n",
      "Epoch 566/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.9307 - val_loss: 0.0330 - val_acc: 0.2800\n",
      "Epoch 567/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0023 - acc: 0.9227 - val_loss: 0.0330 - val_acc: 0.2840\n",
      "Epoch 568/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0023 - acc: 0.9333 - val_loss: 0.0329 - val_acc: 0.2800\n",
      "Epoch 569/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0023 - acc: 0.9133 - val_loss: 0.0327 - val_acc: 0.2840\n",
      "Epoch 570/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0036 - acc: 0.6640 - val_loss: 0.0345 - val_acc: 0.2800\n",
      "Epoch 571/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.8160 - val_loss: 0.0330 - val_acc: 0.2920\n",
      "Epoch 572/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0023 - acc: 0.8973 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 573/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0023 - acc: 0.8987 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 574/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9013 - val_loss: 0.0331 - val_acc: 0.3000\n",
      "Epoch 575/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.9093 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 576/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0023 - acc: 0.9187 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 577/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0023 - acc: 0.9173 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 578/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0023 - acc: 0.9253 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 579/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9253 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 580/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0023 - acc: 0.9267 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 581/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0023 - acc: 0.9293 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 582/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0023 - acc: 0.9280 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 583/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.9360 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 584/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.9373 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 585/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.9453 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 586/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.9493 - val_loss: 0.0330 - val_acc: 0.2920\n",
      "Epoch 587/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.8800 - val_loss: 0.0339 - val_acc: 0.2920\n",
      "Epoch 588/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0033 - acc: 0.6693 - val_loss: 0.0349 - val_acc: 0.3040\n",
      "Epoch 589/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8693 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 590/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8947 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 591/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9027 - val_loss: 0.0333 - val_acc: 0.3000\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 169us/step - loss: 0.0023 - acc: 0.9040 - val_loss: 0.0333 - val_acc: 0.3000\n",
      "Epoch 593/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0023 - acc: 0.9093 - val_loss: 0.0333 - val_acc: 0.3000\n",
      "Epoch 594/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9160 - val_loss: 0.0333 - val_acc: 0.3000\n",
      "Epoch 595/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.9160 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 596/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9173 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 597/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.9173 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 598/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9267 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 599/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.9253 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 600/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9320 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 601/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.9347 - val_loss: 0.0332 - val_acc: 0.2960\n",
      "Epoch 602/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0023 - acc: 0.9320 - val_loss: 0.0333 - val_acc: 0.2920\n",
      "Epoch 603/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.9320 - val_loss: 0.0333 - val_acc: 0.2960\n",
      "Epoch 604/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9440 - val_loss: 0.0332 - val_acc: 0.2960\n",
      "Epoch 605/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9507 - val_loss: 0.0333 - val_acc: 0.2920\n",
      "Epoch 606/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0023 - acc: 0.9373 - val_loss: 0.0321 - val_acc: 0.2960\n",
      "Epoch 607/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0038 - acc: 0.6973 - val_loss: 0.0374 - val_acc: 0.3160\n",
      "Epoch 608/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.7960 - val_loss: 0.0329 - val_acc: 0.2840\n",
      "Epoch 609/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8867 - val_loss: 0.0330 - val_acc: 0.2960\n",
      "Epoch 610/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0023 - acc: 0.9040 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 611/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0023 - acc: 0.9093 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 612/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0023 - acc: 0.9160 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 613/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0023 - acc: 0.9120 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 614/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0023 - acc: 0.9200 - val_loss: 0.0331 - val_acc: 0.3000\n",
      "Epoch 615/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0023 - acc: 0.9307 - val_loss: 0.0331 - val_acc: 0.3000\n",
      "Epoch 616/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0023 - acc: 0.9320 - val_loss: 0.0331 - val_acc: 0.3000\n",
      "Epoch 617/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0023 - acc: 0.9360 - val_loss: 0.0331 - val_acc: 0.3000\n",
      "Epoch 618/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9333 - val_loss: 0.0331 - val_acc: 0.3000\n",
      "Epoch 619/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9400 - val_loss: 0.0331 - val_acc: 0.3000\n",
      "Epoch 620/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9373 - val_loss: 0.0331 - val_acc: 0.3000\n",
      "Epoch 621/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9387 - val_loss: 0.0331 - val_acc: 0.3000\n",
      "Epoch 622/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.9373 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 623/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9307 - val_loss: 0.0330 - val_acc: 0.2960\n",
      "Epoch 624/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9333 - val_loss: 0.0332 - val_acc: 0.2960\n",
      "Epoch 625/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9187 - val_loss: 0.0329 - val_acc: 0.2960\n",
      "Epoch 626/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9053 - val_loss: 0.0328 - val_acc: 0.3200\n",
      "Epoch 627/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0039 - acc: 0.6813 - val_loss: 0.0340 - val_acc: 0.2920\n",
      "Epoch 628/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0023 - acc: 0.8467 - val_loss: 0.0328 - val_acc: 0.3120\n",
      "Epoch 629/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9040 - val_loss: 0.0328 - val_acc: 0.3120\n",
      "Epoch 630/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9107 - val_loss: 0.0328 - val_acc: 0.3080\n",
      "Epoch 631/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9187 - val_loss: 0.0328 - val_acc: 0.3080\n",
      "Epoch 632/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9147 - val_loss: 0.0328 - val_acc: 0.3120\n",
      "Epoch 633/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9173 - val_loss: 0.0328 - val_acc: 0.3160\n",
      "Epoch 634/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9200 - val_loss: 0.0328 - val_acc: 0.3160\n",
      "Epoch 635/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9267 - val_loss: 0.0328 - val_acc: 0.3120\n",
      "Epoch 636/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9280 - val_loss: 0.0328 - val_acc: 0.3080\n",
      "Epoch 637/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9293 - val_loss: 0.0327 - val_acc: 0.3080\n",
      "Epoch 638/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9360 - val_loss: 0.0328 - val_acc: 0.3040\n",
      "Epoch 639/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9373 - val_loss: 0.0327 - val_acc: 0.3040\n",
      "Epoch 640/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9400 - val_loss: 0.0327 - val_acc: 0.3040\n",
      "Epoch 641/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9427 - val_loss: 0.0327 - val_acc: 0.3040\n",
      "Epoch 642/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9480 - val_loss: 0.0327 - val_acc: 0.3040\n",
      "Epoch 643/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9480 - val_loss: 0.0327 - val_acc: 0.3040\n",
      "Epoch 644/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9467 - val_loss: 0.0327 - val_acc: 0.3040\n",
      "Epoch 645/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9467 - val_loss: 0.0327 - val_acc: 0.3120\n",
      "Epoch 646/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9467 - val_loss: 0.0327 - val_acc: 0.3000\n",
      "Epoch 647/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9507 - val_loss: 0.0327 - val_acc: 0.3080\n",
      "Epoch 648/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9280 - val_loss: 0.0351 - val_acc: 0.2680\n",
      "Epoch 649/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0038 - acc: 0.5720 - val_loss: 0.0388 - val_acc: 0.3000\n",
      "Epoch 650/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0031 - acc: 0.8013 - val_loss: 0.0329 - val_acc: 0.3240\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.8707 - val_loss: 0.0329 - val_acc: 0.3280\n",
      "Epoch 652/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.8813 - val_loss: 0.0329 - val_acc: 0.3280\n",
      "Epoch 653/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.8920 - val_loss: 0.0329 - val_acc: 0.3280\n",
      "Epoch 654/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9000 - val_loss: 0.0329 - val_acc: 0.3240\n",
      "Epoch 655/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9093 - val_loss: 0.0329 - val_acc: 0.3240\n",
      "Epoch 656/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9107 - val_loss: 0.0329 - val_acc: 0.3240\n",
      "Epoch 657/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9133 - val_loss: 0.0329 - val_acc: 0.3200\n",
      "Epoch 658/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9160 - val_loss: 0.0329 - val_acc: 0.3200\n",
      "Epoch 659/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9187 - val_loss: 0.0329 - val_acc: 0.3200\n",
      "Epoch 660/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9240 - val_loss: 0.0329 - val_acc: 0.3200\n",
      "Epoch 661/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9293 - val_loss: 0.0329 - val_acc: 0.3200\n",
      "Epoch 662/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9253 - val_loss: 0.0329 - val_acc: 0.3200\n",
      "Epoch 663/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9333 - val_loss: 0.0329 - val_acc: 0.3200\n",
      "Epoch 664/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9333 - val_loss: 0.0329 - val_acc: 0.3200\n",
      "Epoch 665/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9360 - val_loss: 0.0329 - val_acc: 0.3200\n",
      "Epoch 666/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9360 - val_loss: 0.0329 - val_acc: 0.3200\n",
      "Epoch 667/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9080 - val_loss: 0.0329 - val_acc: 0.3120\n",
      "Epoch 668/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0024 - acc: 0.8333 - val_loss: 0.0336 - val_acc: 0.2880\n",
      "Epoch 669/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0028 - acc: 0.6613 - val_loss: 0.0348 - val_acc: 0.3240\n",
      "Epoch 670/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.8840 - val_loss: 0.0332 - val_acc: 0.2880\n",
      "Epoch 671/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9280 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 672/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9307 - val_loss: 0.0332 - val_acc: 0.2960\n",
      "Epoch 673/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9320 - val_loss: 0.0332 - val_acc: 0.2960\n",
      "Epoch 674/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9400 - val_loss: 0.0332 - val_acc: 0.2960\n",
      "Epoch 675/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9387 - val_loss: 0.0332 - val_acc: 0.2960\n",
      "Epoch 676/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9453 - val_loss: 0.0332 - val_acc: 0.2960\n",
      "Epoch 677/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9467 - val_loss: 0.0332 - val_acc: 0.2960\n",
      "Epoch 678/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9507 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 679/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9493 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 680/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9560 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 681/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9547 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 682/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9560 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 683/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9587 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 684/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9600 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 685/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9627 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 686/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9627 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 687/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9627 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 688/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9600 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 689/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 690/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 691/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 692/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 693/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 694/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 695/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 696/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 697/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 698/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 699/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 700/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 701/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 702/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 703/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 704/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 705/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 706/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 707/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 708/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 709/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 711/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 712/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 713/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 714/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 715/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 716/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 717/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 718/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 719/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 720/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 721/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 722/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 723/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 724/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 725/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 726/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 727/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 728/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 729/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 730/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 731/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 732/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 733/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 734/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 735/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 736/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 737/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 738/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 739/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 740/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 741/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 742/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 743/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 744/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 745/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 746/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 747/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 748/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 749/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 750/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 751/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 752/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 753/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 754/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 755/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 756/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 757/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 758/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 759/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 760/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 761/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 762/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 763/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 764/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 765/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 766/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 767/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 768/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 770/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 771/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 772/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 773/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 774/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 775/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 776/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 777/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 778/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 779/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 780/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 781/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 782/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 783/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 784/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 785/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 786/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 787/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 788/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 789/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 790/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 791/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 792/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 793/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 794/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 795/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 796/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 797/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 798/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 799/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 800/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 801/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 802/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 803/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 804/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 805/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 806/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 807/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 808/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 809/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 810/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 811/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 812/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 813/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 814/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 815/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 816/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 817/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 818/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 819/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 820/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 821/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 822/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 823/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 824/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 825/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 826/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 827/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 829/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 830/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 831/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 832/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 833/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 834/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 835/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 836/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 837/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 838/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 839/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 840/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 841/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 842/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 843/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 844/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 845/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 846/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 847/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 848/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 849/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 850/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 851/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 852/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 853/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 854/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 855/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 856/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 857/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 858/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 859/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 860/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 861/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 862/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 863/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 864/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 865/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 866/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 867/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 868/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 869/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 870/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 871/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 872/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 873/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 874/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 875/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 876/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 877/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 878/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 879/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 880/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 881/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 882/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 883/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 884/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 885/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 886/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 888/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 889/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 890/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 891/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 892/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 893/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 894/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 895/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 896/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 897/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 898/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 899/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 900/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 901/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 902/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 903/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 904/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 905/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 906/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 907/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 908/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 909/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 910/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 911/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 912/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 913/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 914/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 915/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 916/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 917/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 918/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 919/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 920/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 921/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 922/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 923/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 924/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 925/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 926/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 927/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 928/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 929/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 930/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 931/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 932/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 933/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 934/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 935/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 936/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 937/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 938/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 939/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 940/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 941/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 942/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 943/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 944/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 945/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 947/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 948/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 949/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 950/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 951/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 952/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 953/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 954/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 955/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 956/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 957/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 958/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 959/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 960/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 961/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 962/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 963/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 964/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 965/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 966/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 967/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 968/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 969/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 970/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 971/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 972/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 973/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 974/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 975/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 976/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 977/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 978/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 979/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 980/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 981/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 982/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 983/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 984/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 985/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 986/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 987/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 988/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 989/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 990/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 991/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 992/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 993/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 994/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 995/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 996/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 997/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 998/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 999/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n",
      "Epoch 1000/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9640 - val_loss: 0.0332 - val_acc: 0.3000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense, Flatten,LSTM, TimeDistributed, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TIME_STEPS = 10\n",
    "INPUT_SIZE = 512\n",
    "BATCH_SIZE = 250\n",
    "BATCH_INDEX = 0\n",
    "OUTPUT_SIZE = 512\n",
    "#CELL_SIZE = 800\n",
    "LR = 0.0005\n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "# loading data\n",
    "X_train = np.loadtxt(\"0220_spec_train_1000*5120.txt\")\n",
    "y_train = np.loadtxt(\"0220_mask_train_1000*512.txt\")\n",
    "\n",
    "X_test = np.loadtxt(\"0220_spec_test_1000*5120.txt\")\n",
    "y_test = np.loadtxt(\"0220_mask_test_1000*512.txt\")\n",
    "\n",
    "# batch_size=y_test.shape[0]\n",
    "\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 10, 512)\n",
    "#y_train = y_train.reshape(-1, 3, 512)\n",
    "X_test = X_test.reshape(-1, 10, 512)\n",
    "#y_test = y_test.reshape(-1, 3, 512)\n",
    "\n",
    "\n",
    "#  build RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# RNN cell\n",
    "\n",
    "model.add(LSTM(\n",
    "    units =512,\n",
    "    batch_input_shape=( BATCH_SIZE, TIME_STEPS, INPUT_SIZE),\n",
    "    #input_dim=INPUT_SIZE,\n",
    "    #input_length=TIME_STEPS,\n",
    "    #output_dim=CELL_SIZE,\n",
    "    #return_sequences=True,\n",
    "    #stateful=True \n",
    "    unroll=True\n",
    "))\n",
    "\n",
    "# output layer\n",
    "#model.add(Flatten())\n",
    "model.add((Dense(OUTPUT_SIZE)))  #TimeDistributed\n",
    "model.add(Activation('hard_sigmoid'))\n",
    "#model.add(Dropout(rate = 0.2)) \n",
    "\n",
    "# # optimizer\n",
    "#\n",
    "# optimizer\n",
    "\n",
    "rmsprop = RMSprop(lr=LR, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # training\n",
    "#\n",
    "\n",
    "# for step in range(51):\n",
    "#     # data shape = (batch_num, steps, inputs/outputs)\n",
    "#     X_batch = X_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :, :]\n",
    "#     Y_batch = y_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :]\n",
    "#     cost = model.train_on_batch(X_batch, Y_batch)\n",
    "#     BATCH_INDEX += BATCH_SIZE\n",
    "#     BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "\n",
    "#     if step % 50 == 0:\n",
    "#         print('Next_Train----------: step = ', step)\n",
    "#         train_cost, train_accuracy = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('train_cost: ', train_cost, 'train_accuracy: ', train_accuracy)\n",
    "#         cost, accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "        \n",
    "       \n",
    "\n",
    "print('Train-------------------------')\n",
    "\n",
    "history = model.fit(X_test, y_test, validation_split=0.25, epochs=1000, shuffle=True, batch_size=250, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "#                                   [model.layers[1].output])\n",
    "# layer_output1 = get_3rd_layer_output([X_train])[0]\n",
    "\n",
    "# print(layer_output1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = model.predict(X_train[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1536)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Predicted_Training_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mask = y_test.reshape(1000,1536)\n",
    "plt.imshow(abs(y_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = model.predict(X_test[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1536)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Predicted_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear_spec_input_250.txt\n",
    "#clear_mask_generated_from_threshold_250.txt\n",
    "\n",
    "y_c = np.loadtxt(\"clear_mask_generated_from_threshold_250.txt\")\n",
    "\n",
    "y_c = y_c.reshape(250,1024)\n",
    "plt.imshow(abs(y_c[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c = np.loadtxt(\"clear_spec_input_250.txt\")\n",
    "\n",
    "\n",
    "x_c = model.predict(x_c)\n",
    "print('prediction of the model', x_c)\n",
    "print('prediction size', x_c.size)\n",
    "\n",
    "x_c = x_c.reshape(250,1024)\n",
    "plt.imshow(abs(x_c[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Predicted_Mask_for_checking\", fontsize = 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
