{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM test by data-10*512 to 1*512\n",
    "# 5000 steps with lr = 0.001\n",
    "# batch size = 500\n",
    "# no dropout\n",
    "# units = 512\n",
    "# This one is using test_dataset\n",
    "# This one is using roll = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are better than\n",
    "best run: \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-------------------------\n",
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/1000\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2019 - acc: 0.0053 - val_loss: 0.0412 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "750/750 [==============================] - 0s 228us/step - loss: 0.0431 - acc: 0.0013 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0396 - acc: 0.0253 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0394 - acc: 0.0227 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0390 - acc: 0.0120 - val_loss: 0.0315 - val_acc: 0.0240\n",
      "Epoch 6/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0388 - acc: 0.0240 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0386 - acc: 0.0107 - val_loss: 0.0312 - val_acc: 0.0320\n",
      "Epoch 8/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0389 - acc: 0.0240 - val_loss: 0.0308 - val_acc: 0.0280\n",
      "Epoch 9/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0379 - acc: 0.0187 - val_loss: 0.0306 - val_acc: 0.0360\n",
      "Epoch 10/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0378 - acc: 0.0453 - val_loss: 0.0315 - val_acc: 0.0080\n",
      "Epoch 11/1000\n",
      "750/750 [==============================] - 0s 222us/step - loss: 0.0393 - acc: 0.0027 - val_loss: 0.0299 - val_acc: 0.0360\n",
      "Epoch 12/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0364 - acc: 0.0320 - val_loss: 0.0318 - val_acc: 0.0040\n",
      "Epoch 13/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0383 - acc: 0.0400 - val_loss: 0.0297 - val_acc: 0.0120\n",
      "Epoch 14/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0351 - acc: 0.0120 - val_loss: 0.0294 - val_acc: 0.0280\n",
      "Epoch 15/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0348 - acc: 0.0173 - val_loss: 0.0314 - val_acc: 0.0480\n",
      "Epoch 16/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0357 - acc: 0.0373 - val_loss: 0.0312 - val_acc: 0.0280\n",
      "Epoch 17/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0356 - acc: 0.0200 - val_loss: 0.0289 - val_acc: 0.0400\n",
      "Epoch 18/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0345 - acc: 0.0387 - val_loss: 0.0307 - val_acc: 0.0280\n",
      "Epoch 19/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0338 - acc: 0.0253 - val_loss: 0.0283 - val_acc: 0.0560\n",
      "Epoch 20/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0352 - acc: 0.0280 - val_loss: 0.0299 - val_acc: 0.0400\n",
      "Epoch 21/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0339 - acc: 0.0360 - val_loss: 0.0280 - val_acc: 0.0840\n",
      "Epoch 22/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0325 - acc: 0.0320 - val_loss: 0.0303 - val_acc: 0.0600\n",
      "Epoch 23/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0345 - acc: 0.0187 - val_loss: 0.0297 - val_acc: 0.0160\n",
      "Epoch 24/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0346 - acc: 0.0333 - val_loss: 0.0322 - val_acc: 0.0360\n",
      "Epoch 25/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0342 - acc: 0.0293 - val_loss: 0.0277 - val_acc: 0.0720\n",
      "Epoch 26/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0316 - acc: 0.0267 - val_loss: 0.0289 - val_acc: 0.0240\n",
      "Epoch 27/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0311 - acc: 0.0240 - val_loss: 0.0281 - val_acc: 0.0160\n",
      "Epoch 28/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0321 - acc: 0.0227 - val_loss: 0.0318 - val_acc: 0.0280\n",
      "Epoch 29/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0322 - acc: 0.0293 - val_loss: 0.0281 - val_acc: 0.0960\n",
      "Epoch 30/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0313 - acc: 0.0320 - val_loss: 0.0300 - val_acc: 0.0440\n",
      "Epoch 31/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0314 - acc: 0.0560 - val_loss: 0.0275 - val_acc: 0.0640\n",
      "Epoch 32/1000\n",
      "750/750 [==============================] - 0s 222us/step - loss: 0.0320 - acc: 0.0387 - val_loss: 0.0295 - val_acc: 0.0080\n",
      "Epoch 33/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0308 - acc: 0.0093 - val_loss: 0.0278 - val_acc: 0.0440\n",
      "Epoch 34/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0303 - acc: 0.0413 - val_loss: 0.0289 - val_acc: 0.0280\n",
      "Epoch 35/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0296 - acc: 0.0347 - val_loss: 0.0291 - val_acc: 0.0080\n",
      "Epoch 36/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0314 - acc: 0.0547 - val_loss: 0.0296 - val_acc: 0.0680\n",
      "Epoch 37/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0312 - acc: 0.0200 - val_loss: 0.0288 - val_acc: 0.0520\n",
      "Epoch 38/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0323 - acc: 0.0573 - val_loss: 0.0292 - val_acc: 0.0280\n",
      "Epoch 39/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0292 - acc: 0.0147 - val_loss: 0.0270 - val_acc: 0.0680\n",
      "Epoch 40/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0303 - acc: 0.0253 - val_loss: 0.0293 - val_acc: 0.0240\n",
      "Epoch 41/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0301 - acc: 0.0347 - val_loss: 0.0269 - val_acc: 0.0360\n",
      "Epoch 42/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0294 - acc: 0.0360 - val_loss: 0.0284 - val_acc: 0.0240\n",
      "Epoch 43/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0284 - acc: 0.0240 - val_loss: 0.0269 - val_acc: 0.0560\n",
      "Epoch 44/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0301 - acc: 0.0547 - val_loss: 0.0304 - val_acc: 0.0280\n",
      "Epoch 45/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0295 - acc: 0.0267 - val_loss: 0.0269 - val_acc: 0.0680\n",
      "Epoch 46/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0285 - acc: 0.0400 - val_loss: 0.0284 - val_acc: 0.0360\n",
      "Epoch 47/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0281 - acc: 0.0400 - val_loss: 0.0270 - val_acc: 0.1240\n",
      "Epoch 48/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0292 - acc: 0.0600 - val_loss: 0.0282 - val_acc: 0.0360\n",
      "Epoch 49/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0283 - acc: 0.0307 - val_loss: 0.0276 - val_acc: 0.0560\n",
      "Epoch 50/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0289 - acc: 0.0480 - val_loss: 0.0298 - val_acc: 0.0040\n",
      "Epoch 51/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0276 - acc: 0.0293 - val_loss: 0.0268 - val_acc: 0.1320\n",
      "Epoch 52/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0287 - acc: 0.0920 - val_loss: 0.0286 - val_acc: 0.0120\n",
      "Epoch 53/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0272 - acc: 0.0320 - val_loss: 0.0267 - val_acc: 0.0920\n",
      "Epoch 54/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0276 - acc: 0.0640 - val_loss: 0.0286 - val_acc: 0.0640\n",
      "Epoch 55/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0269 - acc: 0.0453 - val_loss: 0.0266 - val_acc: 0.1120\n",
      "Epoch 56/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0277 - acc: 0.0760 - val_loss: 0.0294 - val_acc: 0.0360\n",
      "Epoch 57/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0276 - acc: 0.0827 - val_loss: 0.0263 - val_acc: 0.0920\n",
      "Epoch 58/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0269 - acc: 0.0840 - val_loss: 0.0286 - val_acc: 0.0760\n",
      "Epoch 59/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0262 - acc: 0.0600 - val_loss: 0.0266 - val_acc: 0.0920\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 187us/step - loss: 0.0261 - acc: 0.0787 - val_loss: 0.0294 - val_acc: 0.1040\n",
      "Epoch 61/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0262 - acc: 0.0627 - val_loss: 0.0266 - val_acc: 0.1040\n",
      "Epoch 62/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0267 - acc: 0.1000 - val_loss: 0.0293 - val_acc: 0.0480\n",
      "Epoch 63/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0262 - acc: 0.0427 - val_loss: 0.0279 - val_acc: 0.0440\n",
      "Epoch 64/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0256 - acc: 0.0680 - val_loss: 0.0281 - val_acc: 0.1000\n",
      "Epoch 65/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0258 - acc: 0.0853 - val_loss: 0.0268 - val_acc: 0.1080\n",
      "Epoch 66/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0259 - acc: 0.1013 - val_loss: 0.0293 - val_acc: 0.1160\n",
      "Epoch 67/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0247 - acc: 0.0813 - val_loss: 0.0271 - val_acc: 0.1520\n",
      "Epoch 68/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0251 - acc: 0.1240 - val_loss: 0.0285 - val_acc: 0.0680\n",
      "Epoch 69/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0255 - acc: 0.0773 - val_loss: 0.0262 - val_acc: 0.0600\n",
      "Epoch 70/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0248 - acc: 0.0880 - val_loss: 0.0289 - val_acc: 0.1400\n",
      "Epoch 71/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0241 - acc: 0.0840 - val_loss: 0.0285 - val_acc: 0.1400\n",
      "Epoch 72/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0237 - acc: 0.1147 - val_loss: 0.0279 - val_acc: 0.1280\n",
      "Epoch 73/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0242 - acc: 0.0747 - val_loss: 0.0297 - val_acc: 0.0560\n",
      "Epoch 74/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0260 - acc: 0.0933 - val_loss: 0.0266 - val_acc: 0.0800\n",
      "Epoch 75/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0244 - acc: 0.1053 - val_loss: 0.0297 - val_acc: 0.1280\n",
      "Epoch 76/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0242 - acc: 0.1053 - val_loss: 0.0268 - val_acc: 0.1520\n",
      "Epoch 77/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0231 - acc: 0.1227 - val_loss: 0.0281 - val_acc: 0.1320\n",
      "Epoch 78/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0228 - acc: 0.0973 - val_loss: 0.0270 - val_acc: 0.1120\n",
      "Epoch 79/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0230 - acc: 0.1267 - val_loss: 0.0299 - val_acc: 0.1440\n",
      "Epoch 80/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0238 - acc: 0.1053 - val_loss: 0.0266 - val_acc: 0.1440\n",
      "Epoch 81/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0234 - acc: 0.1013 - val_loss: 0.0295 - val_acc: 0.1560\n",
      "Epoch 82/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0222 - acc: 0.1040 - val_loss: 0.0278 - val_acc: 0.1640\n",
      "Epoch 83/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0220 - acc: 0.1227 - val_loss: 0.0289 - val_acc: 0.1000\n",
      "Epoch 84/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0231 - acc: 0.1240 - val_loss: 0.0278 - val_acc: 0.1520\n",
      "Epoch 85/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0227 - acc: 0.1467 - val_loss: 0.0288 - val_acc: 0.1360\n",
      "Epoch 86/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0217 - acc: 0.1053 - val_loss: 0.0272 - val_acc: 0.1280\n",
      "Epoch 87/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0211 - acc: 0.1280 - val_loss: 0.0287 - val_acc: 0.1600\n",
      "Epoch 88/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0217 - acc: 0.1253 - val_loss: 0.0264 - val_acc: 0.1680\n",
      "Epoch 89/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0222 - acc: 0.1347 - val_loss: 0.0293 - val_acc: 0.1200\n",
      "Epoch 90/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0211 - acc: 0.1480 - val_loss: 0.0273 - val_acc: 0.1960\n",
      "Epoch 91/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0211 - acc: 0.1467 - val_loss: 0.0292 - val_acc: 0.1440\n",
      "Epoch 92/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0223 - acc: 0.1040 - val_loss: 0.0274 - val_acc: 0.2160\n",
      "Epoch 93/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0216 - acc: 0.1667 - val_loss: 0.0300 - val_acc: 0.1640\n",
      "Epoch 94/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0210 - acc: 0.1413 - val_loss: 0.0277 - val_acc: 0.1600\n",
      "Epoch 95/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0202 - acc: 0.1187 - val_loss: 0.0283 - val_acc: 0.1080\n",
      "Epoch 96/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0198 - acc: 0.1227 - val_loss: 0.0279 - val_acc: 0.2040\n",
      "Epoch 97/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0200 - acc: 0.1547 - val_loss: 0.0285 - val_acc: 0.1240\n",
      "Epoch 98/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0208 - acc: 0.1507 - val_loss: 0.0276 - val_acc: 0.1960\n",
      "Epoch 99/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0206 - acc: 0.1827 - val_loss: 0.0286 - val_acc: 0.1480\n",
      "Epoch 100/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0199 - acc: 0.1320 - val_loss: 0.0289 - val_acc: 0.1560\n",
      "Epoch 101/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0195 - acc: 0.1613 - val_loss: 0.0274 - val_acc: 0.2320\n",
      "Epoch 102/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0193 - acc: 0.1600 - val_loss: 0.0283 - val_acc: 0.1400\n",
      "Epoch 103/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0195 - acc: 0.1627 - val_loss: 0.0276 - val_acc: 0.2320\n",
      "Epoch 104/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0189 - acc: 0.1827 - val_loss: 0.0308 - val_acc: 0.1600\n",
      "Epoch 105/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0193 - acc: 0.1680 - val_loss: 0.0276 - val_acc: 0.2440\n",
      "Epoch 106/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0187 - acc: 0.1720 - val_loss: 0.0295 - val_acc: 0.1640\n",
      "Epoch 107/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0188 - acc: 0.1640 - val_loss: 0.0291 - val_acc: 0.2720\n",
      "Epoch 108/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0180 - acc: 0.2280 - val_loss: 0.0292 - val_acc: 0.1680\n",
      "Epoch 109/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0178 - acc: 0.1640 - val_loss: 0.0292 - val_acc: 0.2320\n",
      "Epoch 110/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0181 - acc: 0.1933 - val_loss: 0.0298 - val_acc: 0.2600\n",
      "Epoch 111/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0180 - acc: 0.1680 - val_loss: 0.0278 - val_acc: 0.1360\n",
      "Epoch 112/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0185 - acc: 0.1653 - val_loss: 0.0305 - val_acc: 0.2360\n",
      "Epoch 113/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0184 - acc: 0.1853 - val_loss: 0.0292 - val_acc: 0.1160\n",
      "Epoch 114/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0170 - acc: 0.1720 - val_loss: 0.0297 - val_acc: 0.1600\n",
      "Epoch 115/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0165 - acc: 0.1907 - val_loss: 0.0288 - val_acc: 0.2640\n",
      "Epoch 116/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0174 - acc: 0.2133 - val_loss: 0.0330 - val_acc: 0.1440\n",
      "Epoch 117/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0186 - acc: 0.1800 - val_loss: 0.0276 - val_acc: 0.1840\n",
      "Epoch 118/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0168 - acc: 0.2040 - val_loss: 0.0297 - val_acc: 0.1840\n",
      "Epoch 119/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0166 - acc: 0.1960 - val_loss: 0.0295 - val_acc: 0.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0160 - acc: 0.2453 - val_loss: 0.0296 - val_acc: 0.1880\n",
      "Epoch 121/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0159 - acc: 0.1947 - val_loss: 0.0306 - val_acc: 0.2480\n",
      "Epoch 122/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0157 - acc: 0.2373 - val_loss: 0.0284 - val_acc: 0.1840\n",
      "Epoch 123/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0155 - acc: 0.2040 - val_loss: 0.0302 - val_acc: 0.1880\n",
      "Epoch 124/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0158 - acc: 0.2040 - val_loss: 0.0288 - val_acc: 0.2640\n",
      "Epoch 125/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0162 - acc: 0.2373 - val_loss: 0.0314 - val_acc: 0.1400\n",
      "Epoch 126/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0161 - acc: 0.2067 - val_loss: 0.0284 - val_acc: 0.2400\n",
      "Epoch 127/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0149 - acc: 0.2347 - val_loss: 0.0304 - val_acc: 0.1800\n",
      "Epoch 128/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0146 - acc: 0.2213 - val_loss: 0.0296 - val_acc: 0.1800\n",
      "Epoch 129/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0149 - acc: 0.2267 - val_loss: 0.0304 - val_acc: 0.1880\n",
      "Epoch 130/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0148 - acc: 0.2027 - val_loss: 0.0292 - val_acc: 0.2240\n",
      "Epoch 131/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0139 - acc: 0.2440 - val_loss: 0.0294 - val_acc: 0.2360\n",
      "Epoch 132/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0139 - acc: 0.2387 - val_loss: 0.0316 - val_acc: 0.1760\n",
      "Epoch 133/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0146 - acc: 0.2147 - val_loss: 0.0289 - val_acc: 0.2400\n",
      "Epoch 134/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0144 - acc: 0.2547 - val_loss: 0.0319 - val_acc: 0.1760\n",
      "Epoch 135/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0158 - acc: 0.1960 - val_loss: 0.0301 - val_acc: 0.2200\n",
      "Epoch 136/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0141 - acc: 0.2507 - val_loss: 0.0305 - val_acc: 0.1840\n",
      "Epoch 137/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0128 - acc: 0.2200 - val_loss: 0.0288 - val_acc: 0.2200\n",
      "Epoch 138/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0126 - acc: 0.2480 - val_loss: 0.0309 - val_acc: 0.1800\n",
      "Epoch 139/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0125 - acc: 0.2387 - val_loss: 0.0295 - val_acc: 0.2160\n",
      "Epoch 140/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0127 - acc: 0.2640 - val_loss: 0.0323 - val_acc: 0.2000\n",
      "Epoch 141/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0134 - acc: 0.2533 - val_loss: 0.0326 - val_acc: 0.1960\n",
      "Epoch 142/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0130 - acc: 0.2600 - val_loss: 0.0328 - val_acc: 0.1640\n",
      "Epoch 143/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0123 - acc: 0.2373 - val_loss: 0.0297 - val_acc: 0.2200\n",
      "Epoch 144/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0119 - acc: 0.2813 - val_loss: 0.0310 - val_acc: 0.1920\n",
      "Epoch 145/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0116 - acc: 0.2333 - val_loss: 0.0308 - val_acc: 0.1960\n",
      "Epoch 146/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0119 - acc: 0.2373 - val_loss: 0.0315 - val_acc: 0.2160\n",
      "Epoch 147/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0117 - acc: 0.2707 - val_loss: 0.0317 - val_acc: 0.2120\n",
      "Epoch 148/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0114 - acc: 0.2493 - val_loss: 0.0314 - val_acc: 0.2200\n",
      "Epoch 149/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0109 - acc: 0.2693 - val_loss: 0.0325 - val_acc: 0.2240\n",
      "Epoch 150/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0111 - acc: 0.2653 - val_loss: 0.0309 - val_acc: 0.2000\n",
      "Epoch 151/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0116 - acc: 0.2640 - val_loss: 0.0313 - val_acc: 0.2280\n",
      "Epoch 152/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0115 - acc: 0.2907 - val_loss: 0.0341 - val_acc: 0.2120\n",
      "Epoch 153/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0116 - acc: 0.2693 - val_loss: 0.0294 - val_acc: 0.2360\n",
      "Epoch 154/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0105 - acc: 0.3160 - val_loss: 0.0322 - val_acc: 0.1880\n",
      "Epoch 155/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0103 - acc: 0.2800 - val_loss: 0.0295 - val_acc: 0.2160\n",
      "Epoch 156/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0098 - acc: 0.2853 - val_loss: 0.0322 - val_acc: 0.2000\n",
      "Epoch 157/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0099 - acc: 0.2627 - val_loss: 0.0319 - val_acc: 0.2160\n",
      "Epoch 158/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0095 - acc: 0.3133 - val_loss: 0.0316 - val_acc: 0.2040\n",
      "Epoch 159/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0098 - acc: 0.2973 - val_loss: 0.0322 - val_acc: 0.1760\n",
      "Epoch 160/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0097 - acc: 0.2920 - val_loss: 0.0329 - val_acc: 0.2200\n",
      "Epoch 161/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0091 - acc: 0.2853 - val_loss: 0.0303 - val_acc: 0.2240\n",
      "Epoch 162/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0096 - acc: 0.3147 - val_loss: 0.0341 - val_acc: 0.1680\n",
      "Epoch 163/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0105 - acc: 0.2840 - val_loss: 0.0306 - val_acc: 0.2280\n",
      "Epoch 164/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0101 - acc: 0.3080 - val_loss: 0.0339 - val_acc: 0.2120\n",
      "Epoch 165/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0087 - acc: 0.3027 - val_loss: 0.0313 - val_acc: 0.2360\n",
      "Epoch 166/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0082 - acc: 0.3267 - val_loss: 0.0315 - val_acc: 0.2240\n",
      "Epoch 167/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0079 - acc: 0.3013 - val_loss: 0.0315 - val_acc: 0.2520\n",
      "Epoch 168/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0081 - acc: 0.3160 - val_loss: 0.0328 - val_acc: 0.2000\n",
      "Epoch 169/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0082 - acc: 0.3000 - val_loss: 0.0307 - val_acc: 0.2280\n",
      "Epoch 170/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0087 - acc: 0.3027 - val_loss: 0.0346 - val_acc: 0.2520\n",
      "Epoch 171/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0089 - acc: 0.3053 - val_loss: 0.0305 - val_acc: 0.2280\n",
      "Epoch 172/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0079 - acc: 0.3360 - val_loss: 0.0346 - val_acc: 0.2400\n",
      "Epoch 173/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0083 - acc: 0.2973 - val_loss: 0.0332 - val_acc: 0.2720\n",
      "Epoch 174/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0078 - acc: 0.3333 - val_loss: 0.0331 - val_acc: 0.2320\n",
      "Epoch 175/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0074 - acc: 0.3240 - val_loss: 0.0318 - val_acc: 0.2600\n",
      "Epoch 176/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0075 - acc: 0.3440 - val_loss: 0.0344 - val_acc: 0.2320\n",
      "Epoch 177/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0073 - acc: 0.3227 - val_loss: 0.0336 - val_acc: 0.2480\n",
      "Epoch 178/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0070 - acc: 0.3587 - val_loss: 0.0354 - val_acc: 0.2240\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 186us/step - loss: 0.0073 - acc: 0.3360 - val_loss: 0.0327 - val_acc: 0.2480\n",
      "Epoch 180/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0072 - acc: 0.3360 - val_loss: 0.0333 - val_acc: 0.2280\n",
      "Epoch 181/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0067 - acc: 0.3507 - val_loss: 0.0336 - val_acc: 0.2240\n",
      "Epoch 182/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0067 - acc: 0.3440 - val_loss: 0.0328 - val_acc: 0.2440\n",
      "Epoch 183/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0072 - acc: 0.3533 - val_loss: 0.0341 - val_acc: 0.2760\n",
      "Epoch 184/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0074 - acc: 0.3480 - val_loss: 0.0347 - val_acc: 0.2080\n",
      "Epoch 185/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0064 - acc: 0.3533 - val_loss: 0.0303 - val_acc: 0.2480\n",
      "Epoch 186/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0061 - acc: 0.3773 - val_loss: 0.0337 - val_acc: 0.2040\n",
      "Epoch 187/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0059 - acc: 0.3627 - val_loss: 0.0321 - val_acc: 0.2400\n",
      "Epoch 188/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0060 - acc: 0.3653 - val_loss: 0.0344 - val_acc: 0.2320\n",
      "Epoch 189/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0061 - acc: 0.3667 - val_loss: 0.0320 - val_acc: 0.2400\n",
      "Epoch 190/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0064 - acc: 0.3627 - val_loss: 0.0336 - val_acc: 0.2400\n",
      "Epoch 191/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0060 - acc: 0.3747 - val_loss: 0.0328 - val_acc: 0.2800\n",
      "Epoch 192/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0057 - acc: 0.3787 - val_loss: 0.0324 - val_acc: 0.2360\n",
      "Epoch 193/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0058 - acc: 0.3787 - val_loss: 0.0347 - val_acc: 0.2240\n",
      "Epoch 194/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0058 - acc: 0.4000 - val_loss: 0.0331 - val_acc: 0.2480\n",
      "Epoch 195/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0054 - acc: 0.4080 - val_loss: 0.0317 - val_acc: 0.2680\n",
      "Epoch 196/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0058 - acc: 0.4253 - val_loss: 0.0358 - val_acc: 0.2480\n",
      "Epoch 197/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0060 - acc: 0.4080 - val_loss: 0.0304 - val_acc: 0.2720\n",
      "Epoch 198/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0053 - acc: 0.4080 - val_loss: 0.0352 - val_acc: 0.2520\n",
      "Epoch 199/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0050 - acc: 0.3867 - val_loss: 0.0346 - val_acc: 0.2680\n",
      "Epoch 200/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0050 - acc: 0.4200 - val_loss: 0.0339 - val_acc: 0.2640\n",
      "Epoch 201/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0049 - acc: 0.4027 - val_loss: 0.0344 - val_acc: 0.2960\n",
      "Epoch 202/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0047 - acc: 0.4533 - val_loss: 0.0344 - val_acc: 0.2680\n",
      "Epoch 203/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0049 - acc: 0.4360 - val_loss: 0.0350 - val_acc: 0.2840\n",
      "Epoch 204/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0054 - acc: 0.4280 - val_loss: 0.0348 - val_acc: 0.2520\n",
      "Epoch 205/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0049 - acc: 0.4200 - val_loss: 0.0334 - val_acc: 0.2720\n",
      "Epoch 206/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0044 - acc: 0.4773 - val_loss: 0.0341 - val_acc: 0.2800\n",
      "Epoch 207/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0043 - acc: 0.4440 - val_loss: 0.0337 - val_acc: 0.2880\n",
      "Epoch 208/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0043 - acc: 0.4653 - val_loss: 0.0365 - val_acc: 0.3040\n",
      "Epoch 209/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0052 - acc: 0.4267 - val_loss: 0.0304 - val_acc: 0.3080\n",
      "Epoch 210/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0065 - acc: 0.4467 - val_loss: 0.0344 - val_acc: 0.2520\n",
      "Epoch 211/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0053 - acc: 0.4333 - val_loss: 0.0334 - val_acc: 0.2840\n",
      "Epoch 212/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0041 - acc: 0.4600 - val_loss: 0.0336 - val_acc: 0.2840\n",
      "Epoch 213/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0038 - acc: 0.5133 - val_loss: 0.0334 - val_acc: 0.2760\n",
      "Epoch 214/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0037 - acc: 0.4987 - val_loss: 0.0336 - val_acc: 0.2920\n",
      "Epoch 215/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0037 - acc: 0.4973 - val_loss: 0.0338 - val_acc: 0.2760\n",
      "Epoch 216/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0042 - acc: 0.4640 - val_loss: 0.0362 - val_acc: 0.2640\n",
      "Epoch 217/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0050 - acc: 0.4187 - val_loss: 0.0362 - val_acc: 0.3040\n",
      "Epoch 218/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0041 - acc: 0.5080 - val_loss: 0.0340 - val_acc: 0.2640\n",
      "Epoch 219/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0036 - acc: 0.5133 - val_loss: 0.0335 - val_acc: 0.2800\n",
      "Epoch 220/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0035 - acc: 0.5173 - val_loss: 0.0343 - val_acc: 0.2600\n",
      "Epoch 221/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0035 - acc: 0.5133 - val_loss: 0.0344 - val_acc: 0.3000\n",
      "Epoch 222/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0038 - acc: 0.5160 - val_loss: 0.0368 - val_acc: 0.2520\n",
      "Epoch 223/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0046 - acc: 0.4467 - val_loss: 0.0348 - val_acc: 0.3040\n",
      "Epoch 224/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0046 - acc: 0.5160 - val_loss: 0.0348 - val_acc: 0.2800\n",
      "Epoch 225/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0036 - acc: 0.5413 - val_loss: 0.0328 - val_acc: 0.2600\n",
      "Epoch 226/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0033 - acc: 0.5533 - val_loss: 0.0338 - val_acc: 0.2880\n",
      "Epoch 227/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0033 - acc: 0.5947 - val_loss: 0.0348 - val_acc: 0.2760\n",
      "Epoch 228/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0035 - acc: 0.5587 - val_loss: 0.0341 - val_acc: 0.2840\n",
      "Epoch 229/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0037 - acc: 0.5267 - val_loss: 0.0359 - val_acc: 0.2880\n",
      "Epoch 230/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0034 - acc: 0.5453 - val_loss: 0.0347 - val_acc: 0.2880\n",
      "Epoch 231/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0037 - acc: 0.5600 - val_loss: 0.0361 - val_acc: 0.2640\n",
      "Epoch 232/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0034 - acc: 0.5640 - val_loss: 0.0340 - val_acc: 0.2960\n",
      "Epoch 233/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0033 - acc: 0.5973 - val_loss: 0.0339 - val_acc: 0.2880\n",
      "Epoch 234/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0031 - acc: 0.6120 - val_loss: 0.0335 - val_acc: 0.2880\n",
      "Epoch 235/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0033 - acc: 0.6147 - val_loss: 0.0349 - val_acc: 0.2880\n",
      "Epoch 236/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0036 - acc: 0.5413 - val_loss: 0.0338 - val_acc: 0.3200\n",
      "Epoch 237/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0043 - acc: 0.5200 - val_loss: 0.0392 - val_acc: 0.3080\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 188us/step - loss: 0.0039 - acc: 0.5267 - val_loss: 0.0329 - val_acc: 0.2880\n",
      "Epoch 239/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0031 - acc: 0.6293 - val_loss: 0.0341 - val_acc: 0.2880\n",
      "Epoch 240/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0029 - acc: 0.6747 - val_loss: 0.0345 - val_acc: 0.3040\n",
      "Epoch 241/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0029 - acc: 0.6653 - val_loss: 0.0344 - val_acc: 0.3040\n",
      "Epoch 242/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0028 - acc: 0.6773 - val_loss: 0.0343 - val_acc: 0.3120\n",
      "Epoch 243/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0027 - acc: 0.6747 - val_loss: 0.0341 - val_acc: 0.3240\n",
      "Epoch 244/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0033 - acc: 0.6000 - val_loss: 0.0348 - val_acc: 0.2640\n",
      "Epoch 245/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0041 - acc: 0.5293 - val_loss: 0.0335 - val_acc: 0.2760\n",
      "Epoch 246/1000\n",
      "750/750 [==============================] - 0s 217us/step - loss: 0.0036 - acc: 0.5627 - val_loss: 0.0332 - val_acc: 0.3080\n",
      "Epoch 247/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0028 - acc: 0.6600 - val_loss: 0.0340 - val_acc: 0.2880\n",
      "Epoch 248/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0026 - acc: 0.7067 - val_loss: 0.0346 - val_acc: 0.2920\n",
      "Epoch 249/1000\n",
      "750/750 [==============================] - 0s 213us/step - loss: 0.0026 - acc: 0.7253 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 250/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0025 - acc: 0.7227 - val_loss: 0.0343 - val_acc: 0.2920\n",
      "Epoch 251/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0025 - acc: 0.7227 - val_loss: 0.0343 - val_acc: 0.3120\n",
      "Epoch 252/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0025 - acc: 0.7093 - val_loss: 0.0342 - val_acc: 0.2800\n",
      "Epoch 253/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0026 - acc: 0.7120 - val_loss: 0.0350 - val_acc: 0.2840\n",
      "Epoch 254/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0036 - acc: 0.5853 - val_loss: 0.0373 - val_acc: 0.2760\n",
      "Epoch 255/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0048 - acc: 0.5227 - val_loss: 0.0336 - val_acc: 0.3080\n",
      "Epoch 256/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0034 - acc: 0.6133 - val_loss: 0.0356 - val_acc: 0.2640\n",
      "Epoch 257/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0026 - acc: 0.6987 - val_loss: 0.0353 - val_acc: 0.2880\n",
      "Epoch 258/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0025 - acc: 0.7373 - val_loss: 0.0352 - val_acc: 0.2800\n",
      "Epoch 259/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0025 - acc: 0.7387 - val_loss: 0.0352 - val_acc: 0.2840\n",
      "Epoch 260/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0025 - acc: 0.7400 - val_loss: 0.0352 - val_acc: 0.2920\n",
      "Epoch 261/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0025 - acc: 0.7440 - val_loss: 0.0352 - val_acc: 0.2960\n",
      "Epoch 262/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0025 - acc: 0.7427 - val_loss: 0.0352 - val_acc: 0.3000\n",
      "Epoch 263/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0024 - acc: 0.7587 - val_loss: 0.0352 - val_acc: 0.2920\n",
      "Epoch 264/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0025 - acc: 0.7587 - val_loss: 0.0356 - val_acc: 0.3080\n",
      "Epoch 265/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0025 - acc: 0.7373 - val_loss: 0.0348 - val_acc: 0.3160\n",
      "Epoch 266/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0027 - acc: 0.6760 - val_loss: 0.0412 - val_acc: 0.3200\n",
      "Epoch 267/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0041 - acc: 0.5573 - val_loss: 0.0337 - val_acc: 0.3160\n",
      "Epoch 268/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0036 - acc: 0.5867 - val_loss: 0.0358 - val_acc: 0.2520\n",
      "Epoch 269/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0028 - acc: 0.6440 - val_loss: 0.0333 - val_acc: 0.2760\n",
      "Epoch 270/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0025 - acc: 0.7840 - val_loss: 0.0339 - val_acc: 0.3080\n",
      "Epoch 271/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.7960 - val_loss: 0.0341 - val_acc: 0.3080\n",
      "Epoch 272/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.7880 - val_loss: 0.0343 - val_acc: 0.3080\n",
      "Epoch 273/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0024 - acc: 0.8067 - val_loss: 0.0343 - val_acc: 0.3040\n",
      "Epoch 274/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0024 - acc: 0.8040 - val_loss: 0.0344 - val_acc: 0.3040\n",
      "Epoch 275/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.8067 - val_loss: 0.0345 - val_acc: 0.3000\n",
      "Epoch 276/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.8080 - val_loss: 0.0345 - val_acc: 0.3000\n",
      "Epoch 277/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0024 - acc: 0.8067 - val_loss: 0.0345 - val_acc: 0.3040\n",
      "Epoch 278/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0024 - acc: 0.8160 - val_loss: 0.0345 - val_acc: 0.3080\n",
      "Epoch 279/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.8253 - val_loss: 0.0346 - val_acc: 0.3040\n",
      "Epoch 280/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.7973 - val_loss: 0.0353 - val_acc: 0.3200\n",
      "Epoch 281/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0051 - acc: 0.5413 - val_loss: 0.0344 - val_acc: 0.3120\n",
      "Epoch 282/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0042 - acc: 0.6093 - val_loss: 0.0354 - val_acc: 0.2960\n",
      "Epoch 283/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0026 - acc: 0.6973 - val_loss: 0.0349 - val_acc: 0.3080\n",
      "Epoch 284/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0025 - acc: 0.8187 - val_loss: 0.0354 - val_acc: 0.2880\n",
      "Epoch 285/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.7813 - val_loss: 0.0352 - val_acc: 0.2920\n",
      "Epoch 286/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.8200 - val_loss: 0.0353 - val_acc: 0.2920\n",
      "Epoch 287/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.8200 - val_loss: 0.0353 - val_acc: 0.2920\n",
      "Epoch 288/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.8240 - val_loss: 0.0353 - val_acc: 0.2960\n",
      "Epoch 289/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.8240 - val_loss: 0.0353 - val_acc: 0.2960\n",
      "Epoch 290/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0024 - acc: 0.8320 - val_loss: 0.0353 - val_acc: 0.2960\n",
      "Epoch 291/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.8387 - val_loss: 0.0353 - val_acc: 0.2920\n",
      "Epoch 292/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.8493 - val_loss: 0.0353 - val_acc: 0.2960\n",
      "Epoch 293/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.8507 - val_loss: 0.0353 - val_acc: 0.2880\n",
      "Epoch 294/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0024 - acc: 0.8600 - val_loss: 0.0353 - val_acc: 0.2960\n",
      "Epoch 295/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0024 - acc: 0.8667 - val_loss: 0.0353 - val_acc: 0.3000\n",
      "Epoch 296/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0024 - acc: 0.8827 - val_loss: 0.0354 - val_acc: 0.2840\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.8840 - val_loss: 0.0357 - val_acc: 0.2560\n",
      "Epoch 298/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0040 - acc: 0.6347 - val_loss: 0.0384 - val_acc: 0.2320\n",
      "Epoch 299/1000\n",
      "750/750 [==============================] - 0s 217us/step - loss: 0.0036 - acc: 0.5947 - val_loss: 0.0362 - val_acc: 0.3240\n",
      "Epoch 300/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0027 - acc: 0.7587 - val_loss: 0.0355 - val_acc: 0.3080\n",
      "Epoch 301/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.8333 - val_loss: 0.0350 - val_acc: 0.3120\n",
      "Epoch 302/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0024 - acc: 0.8520 - val_loss: 0.0352 - val_acc: 0.3080\n",
      "Epoch 303/1000\n",
      "750/750 [==============================] - 0s 218us/step - loss: 0.0024 - acc: 0.8653 - val_loss: 0.0352 - val_acc: 0.3080\n",
      "Epoch 304/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.8760 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 305/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0024 - acc: 0.8733 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 306/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.8747 - val_loss: 0.0352 - val_acc: 0.3080\n",
      "Epoch 307/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.8840 - val_loss: 0.0352 - val_acc: 0.3000\n",
      "Epoch 308/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.8867 - val_loss: 0.0351 - val_acc: 0.3040\n",
      "Epoch 309/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0024 - acc: 0.8920 - val_loss: 0.0351 - val_acc: 0.3000\n",
      "Epoch 310/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.8987 - val_loss: 0.0351 - val_acc: 0.3080\n",
      "Epoch 311/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0024 - acc: 0.9080 - val_loss: 0.0351 - val_acc: 0.3000\n",
      "Epoch 312/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.9120 - val_loss: 0.0352 - val_acc: 0.3080\n",
      "Epoch 313/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.9093 - val_loss: 0.0351 - val_acc: 0.3080\n",
      "Epoch 314/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.9307 - val_loss: 0.0352 - val_acc: 0.3040\n",
      "Epoch 315/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.9093 - val_loss: 0.0352 - val_acc: 0.3040\n",
      "Epoch 316/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.9067 - val_loss: 0.0354 - val_acc: 0.2880\n",
      "Epoch 317/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0041 - acc: 0.5973 - val_loss: 0.0360 - val_acc: 0.3200\n",
      "Epoch 318/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0039 - acc: 0.6027 - val_loss: 0.0373 - val_acc: 0.3160\n",
      "Epoch 319/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0026 - acc: 0.7400 - val_loss: 0.0340 - val_acc: 0.3160\n",
      "Epoch 320/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0024 - acc: 0.8387 - val_loss: 0.0349 - val_acc: 0.2880\n",
      "Epoch 321/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0024 - acc: 0.8560 - val_loss: 0.0349 - val_acc: 0.2920\n",
      "Epoch 322/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0023 - acc: 0.8680 - val_loss: 0.0350 - val_acc: 0.2880\n",
      "Epoch 323/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0023 - acc: 0.8707 - val_loss: 0.0350 - val_acc: 0.2880\n",
      "Epoch 324/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0023 - acc: 0.8787 - val_loss: 0.0350 - val_acc: 0.2920\n",
      "Epoch 325/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0023 - acc: 0.8773 - val_loss: 0.0350 - val_acc: 0.2880\n",
      "Epoch 326/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0023 - acc: 0.8760 - val_loss: 0.0350 - val_acc: 0.2880\n",
      "Epoch 327/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0023 - acc: 0.8853 - val_loss: 0.0350 - val_acc: 0.2920\n",
      "Epoch 328/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0023 - acc: 0.8867 - val_loss: 0.0350 - val_acc: 0.2960\n",
      "Epoch 329/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0023 - acc: 0.8973 - val_loss: 0.0350 - val_acc: 0.2880\n",
      "Epoch 330/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0023 - acc: 0.9027 - val_loss: 0.0350 - val_acc: 0.2840\n",
      "Epoch 331/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0023 - acc: 0.9000 - val_loss: 0.0350 - val_acc: 0.2840\n",
      "Epoch 332/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0023 - acc: 0.9120 - val_loss: 0.0351 - val_acc: 0.2920\n",
      "Epoch 333/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0023 - acc: 0.8933 - val_loss: 0.0352 - val_acc: 0.2800\n",
      "Epoch 334/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0023 - acc: 0.8947 - val_loss: 0.0349 - val_acc: 0.2760\n",
      "Epoch 335/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0023 - acc: 0.9040 - val_loss: 0.0347 - val_acc: 0.3200\n",
      "Epoch 336/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0033 - acc: 0.7347 - val_loss: 0.0431 - val_acc: 0.3120\n",
      "Epoch 337/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0052 - acc: 0.6107 - val_loss: 0.0339 - val_acc: 0.3400\n",
      "Epoch 338/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0026 - acc: 0.7213 - val_loss: 0.0345 - val_acc: 0.3200\n",
      "Epoch 339/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0023 - acc: 0.7947 - val_loss: 0.0345 - val_acc: 0.3080\n",
      "Epoch 340/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0023 - acc: 0.8347 - val_loss: 0.0346 - val_acc: 0.3120\n",
      "Epoch 341/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0023 - acc: 0.8413 - val_loss: 0.0347 - val_acc: 0.3080\n",
      "Epoch 342/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0023 - acc: 0.8440 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 343/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0023 - acc: 0.8493 - val_loss: 0.0347 - val_acc: 0.3080\n",
      "Epoch 344/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0023 - acc: 0.8573 - val_loss: 0.0347 - val_acc: 0.3080\n",
      "Epoch 345/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0022 - acc: 0.8680 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 346/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0022 - acc: 0.8733 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 347/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0022 - acc: 0.8760 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 348/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0022 - acc: 0.8933 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 349/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0022 - acc: 0.8947 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 350/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0022 - acc: 0.9067 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 351/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0022 - acc: 0.9187 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 352/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0022 - acc: 0.9067 - val_loss: 0.0348 - val_acc: 0.3080\n",
      "Epoch 353/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0022 - acc: 0.8907 - val_loss: 0.0350 - val_acc: 0.3200\n",
      "Epoch 354/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0024 - acc: 0.7973 - val_loss: 0.0376 - val_acc: 0.2400\n",
      "Epoch 355/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0052 - acc: 0.5787 - val_loss: 0.0311 - val_acc: 0.3080\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 210us/step - loss: 0.0033 - acc: 0.7107 - val_loss: 0.0344 - val_acc: 0.3200\n",
      "Epoch 357/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0026 - acc: 0.8307 - val_loss: 0.0342 - val_acc: 0.3280\n",
      "Epoch 358/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0025 - acc: 0.8600 - val_loss: 0.0343 - val_acc: 0.3160\n",
      "Epoch 359/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0022 - acc: 0.8773 - val_loss: 0.0341 - val_acc: 0.3240\n",
      "Epoch 360/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0022 - acc: 0.8800 - val_loss: 0.0341 - val_acc: 0.3240\n",
      "Epoch 361/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0022 - acc: 0.8960 - val_loss: 0.0341 - val_acc: 0.3240\n",
      "Epoch 362/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0022 - acc: 0.8960 - val_loss: 0.0341 - val_acc: 0.3280\n",
      "Epoch 363/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0022 - acc: 0.8973 - val_loss: 0.0342 - val_acc: 0.3280\n",
      "Epoch 364/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0022 - acc: 0.9000 - val_loss: 0.0342 - val_acc: 0.3280\n",
      "Epoch 365/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0022 - acc: 0.9040 - val_loss: 0.0342 - val_acc: 0.3280\n",
      "Epoch 366/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0022 - acc: 0.9107 - val_loss: 0.0342 - val_acc: 0.3280\n",
      "Epoch 367/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0022 - acc: 0.9133 - val_loss: 0.0342 - val_acc: 0.3280\n",
      "Epoch 368/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0022 - acc: 0.9160 - val_loss: 0.0342 - val_acc: 0.3280\n",
      "Epoch 369/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9147 - val_loss: 0.0343 - val_acc: 0.3320\n",
      "Epoch 370/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9240 - val_loss: 0.0340 - val_acc: 0.3200\n",
      "Epoch 371/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9213 - val_loss: 0.0346 - val_acc: 0.3240\n",
      "Epoch 372/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9253 - val_loss: 0.0340 - val_acc: 0.3240\n",
      "Epoch 373/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9200 - val_loss: 0.0346 - val_acc: 0.3360\n",
      "Epoch 374/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9200 - val_loss: 0.0340 - val_acc: 0.3200\n",
      "Epoch 375/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0022 - acc: 0.9107 - val_loss: 0.0349 - val_acc: 0.3280\n",
      "Epoch 376/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0022 - acc: 0.8747 - val_loss: 0.0360 - val_acc: 0.2400\n",
      "Epoch 377/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0044 - acc: 0.5933 - val_loss: 0.0365 - val_acc: 0.2360\n",
      "Epoch 378/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0026 - acc: 0.7467 - val_loss: 0.0352 - val_acc: 0.2960\n",
      "Epoch 379/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0023 - acc: 0.8440 - val_loss: 0.0341 - val_acc: 0.2960\n",
      "Epoch 380/1000\n",
      "750/750 [==============================] - 0s 213us/step - loss: 0.0022 - acc: 0.8920 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 381/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9080 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 382/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0022 - acc: 0.9147 - val_loss: 0.0344 - val_acc: 0.2960\n",
      "Epoch 383/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0022 - acc: 0.9160 - val_loss: 0.0344 - val_acc: 0.2960\n",
      "Epoch 384/1000\n",
      "750/750 [==============================] - 0s 213us/step - loss: 0.0022 - acc: 0.9187 - val_loss: 0.0344 - val_acc: 0.2960\n",
      "Epoch 385/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9267 - val_loss: 0.0344 - val_acc: 0.2960\n",
      "Epoch 386/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0022 - acc: 0.9267 - val_loss: 0.0344 - val_acc: 0.2960\n",
      "Epoch 387/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0022 - acc: 0.9293 - val_loss: 0.0344 - val_acc: 0.2960\n",
      "Epoch 388/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0022 - acc: 0.9333 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 389/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0022 - acc: 0.9360 - val_loss: 0.0344 - val_acc: 0.2880\n",
      "Epoch 390/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0022 - acc: 0.9427 - val_loss: 0.0344 - val_acc: 0.2880\n",
      "Epoch 391/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0022 - acc: 0.9427 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 392/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0022 - acc: 0.9427 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 393/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0022 - acc: 0.9440 - val_loss: 0.0344 - val_acc: 0.2840\n",
      "Epoch 394/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0022 - acc: 0.9400 - val_loss: 0.0345 - val_acc: 0.2920\n",
      "Epoch 395/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9333 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 396/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9347 - val_loss: 0.0345 - val_acc: 0.2960\n",
      "Epoch 397/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8933 - val_loss: 0.0346 - val_acc: 0.3280\n",
      "Epoch 398/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0044 - acc: 0.6080 - val_loss: 0.0383 - val_acc: 0.2760\n",
      "Epoch 399/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0026 - acc: 0.7573 - val_loss: 0.0331 - val_acc: 0.3040\n",
      "Epoch 400/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0024 - acc: 0.8533 - val_loss: 0.0363 - val_acc: 0.2960\n",
      "Epoch 401/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0022 - acc: 0.8933 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 402/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0022 - acc: 0.9027 - val_loss: 0.0356 - val_acc: 0.2920\n",
      "Epoch 403/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0022 - acc: 0.9080 - val_loss: 0.0356 - val_acc: 0.2920\n",
      "Epoch 404/1000\n",
      "750/750 [==============================] - 0s 213us/step - loss: 0.0022 - acc: 0.9133 - val_loss: 0.0356 - val_acc: 0.2920\n",
      "Epoch 405/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0022 - acc: 0.9160 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 406/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0022 - acc: 0.9187 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 407/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0022 - acc: 0.9213 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 408/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0022 - acc: 0.9200 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 409/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0022 - acc: 0.9200 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 410/1000\n",
      "750/750 [==============================] - 0s 213us/step - loss: 0.0022 - acc: 0.9253 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 411/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0022 - acc: 0.9307 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 412/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0022 - acc: 0.9320 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 413/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9360 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 414/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9400 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9480 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 416/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9453 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 417/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9507 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 418/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9533 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 419/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9533 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 420/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9560 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 421/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9560 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 422/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9560 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 423/1000\n",
      "750/750 [==============================] - 0s 217us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 424/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 425/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 426/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 427/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 428/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 429/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 430/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 431/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 432/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 433/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 434/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 435/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 436/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 437/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 438/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 439/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 440/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 441/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 442/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 443/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 444/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 445/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 446/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 447/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 448/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 449/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 450/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 451/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 452/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 453/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 454/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 455/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 456/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 457/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 458/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 459/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 460/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 461/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 462/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 463/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 464/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 465/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 466/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 467/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 468/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 469/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 470/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 471/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 472/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 473/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 475/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 476/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 477/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 478/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 479/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 480/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 481/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 482/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 483/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 484/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 485/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 486/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 487/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 488/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 489/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 490/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 491/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 492/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 493/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 494/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 495/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 496/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 497/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 498/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 499/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 500/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 501/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 502/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 503/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 504/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 505/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 506/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 507/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 508/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 509/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 510/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 511/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 512/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 513/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 514/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 515/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 516/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 517/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 518/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 519/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 520/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 521/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 522/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 523/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 524/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 525/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 526/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 527/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 528/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 529/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 530/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 531/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 532/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 534/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 535/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 536/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 537/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 538/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 539/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 540/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 541/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 542/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 543/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 544/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 545/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 546/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 547/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 548/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 549/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 550/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 551/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 552/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 553/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 554/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 555/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 556/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 557/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 558/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 559/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 560/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 561/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 562/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 563/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 564/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 565/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 566/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 567/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 568/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 569/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 570/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 571/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 572/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 573/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 574/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 575/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 576/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 577/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 578/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 579/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 580/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 581/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 582/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 583/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 584/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 585/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 586/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 587/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 588/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 589/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 590/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 591/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 593/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 594/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 595/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 596/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 597/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 598/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 599/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 600/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 601/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 602/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 603/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 604/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 605/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 606/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 607/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 608/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 609/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 610/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 611/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 612/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 613/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 614/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 615/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 616/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 617/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 618/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 619/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 620/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 621/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 622/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 623/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 624/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 625/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 626/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 627/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 628/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 629/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 630/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 631/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 632/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 633/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 634/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 635/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 636/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 637/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 638/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 639/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 640/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 641/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 642/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 643/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 644/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 645/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 646/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 647/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 648/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 649/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 650/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 652/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 653/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 654/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 655/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 656/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 657/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 658/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 659/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 660/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 661/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 662/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 663/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 664/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 665/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 666/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 667/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 668/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 669/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 670/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 671/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 672/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 673/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 674/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 675/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 676/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 677/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 678/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 679/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 680/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 681/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 682/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 683/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 684/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 685/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 686/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 687/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 688/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 689/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 690/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 691/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 692/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 693/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 694/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 695/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 696/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 697/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 698/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 699/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 700/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 701/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 702/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 703/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 704/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 705/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 706/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 707/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 708/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 709/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 711/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 712/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 713/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 714/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 715/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 716/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 717/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 718/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 719/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 720/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 721/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 722/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 723/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 724/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 725/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 726/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 727/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 728/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 729/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 730/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 731/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 732/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 733/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 734/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 735/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 736/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 737/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 738/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 739/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 740/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 741/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 742/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 743/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 744/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 745/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 746/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 747/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 748/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 749/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 750/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 751/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 752/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 753/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 754/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 755/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 756/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 757/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 758/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 759/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 760/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 761/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 762/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 763/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 764/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 765/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 766/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 767/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 768/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 770/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 771/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 772/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 773/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 774/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 775/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 776/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 777/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 778/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 779/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 780/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 781/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 782/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 783/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 784/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 785/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 786/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 787/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 788/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 789/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 790/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 791/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 792/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 793/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 794/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 795/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 796/1000\n",
      "750/750 [==============================] - 0s 217us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 797/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 798/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 799/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 800/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 801/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 802/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 803/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 804/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 805/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 806/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 807/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 808/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 809/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 810/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 811/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 812/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 813/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 814/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 815/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 816/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 817/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 818/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 819/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 820/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 821/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 822/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 823/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 824/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 825/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 826/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 827/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 829/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 830/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 831/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 832/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 833/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 834/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 835/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 836/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 837/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 838/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 839/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 840/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 841/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 842/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 843/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 844/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 845/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 846/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 847/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 848/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 849/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 850/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 851/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 852/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 853/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 854/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 855/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 856/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 857/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 858/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 859/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 860/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 861/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 862/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 863/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 864/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 865/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 866/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 867/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 868/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 869/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 870/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 871/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 872/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 873/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 874/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 875/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 876/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 877/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 878/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 879/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 880/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 881/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 882/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 883/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 884/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 885/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 886/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 888/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 889/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 890/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 891/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 892/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 893/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 894/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 895/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 896/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 897/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 898/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 899/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 900/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 901/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 902/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 903/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 904/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 905/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 906/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 907/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 908/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 909/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 910/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 911/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 912/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 913/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 914/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 915/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 916/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 917/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 918/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 919/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 920/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 921/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 922/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 923/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 924/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 925/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 926/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 927/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 928/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 929/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 930/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 931/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 932/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 933/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 934/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 935/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 936/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 937/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 938/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 939/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 940/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 941/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 942/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 943/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 944/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 945/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 947/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 948/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 949/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 950/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 951/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 952/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 953/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 954/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 955/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 956/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 957/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 958/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 959/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 960/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 961/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 962/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 963/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 964/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 965/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 966/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 967/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 968/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 969/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 970/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 971/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 972/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 973/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 974/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 975/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 976/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 977/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 978/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 979/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 980/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 981/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 982/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 983/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 984/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 985/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 986/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 987/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 988/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 989/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 990/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 991/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 992/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 993/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 994/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 995/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 996/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 997/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 998/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 999/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n",
      "Epoch 1000/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0356 - val_acc: 0.2960\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense, Flatten,LSTM, TimeDistributed, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TIME_STEPS = 10\n",
    "INPUT_SIZE = 512\n",
    "BATCH_SIZE = 250\n",
    "BATCH_INDEX = 0\n",
    "OUTPUT_SIZE = 512\n",
    "#CELL_SIZE = 800\n",
    "LR = 0.001\n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "# loading data\n",
    "X_train = np.loadtxt(\"0220_spec_train_1000*5120.txt\")\n",
    "y_train = np.loadtxt(\"0220_mask_train_1000*512.txt\")\n",
    "\n",
    "X_test = np.loadtxt(\"0220_spec_test_1000*5120.txt\")\n",
    "y_test = np.loadtxt(\"0220_mask_test_1000*512.txt\")\n",
    "\n",
    "# batch_size=y_test.shape[0]\n",
    "\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 10, 512)\n",
    "#y_train = y_train.reshape(-1, 3, 512)\n",
    "X_test = X_test.reshape(-1, 10, 512)\n",
    "#y_test = y_test.reshape(-1, 3, 512)\n",
    "\n",
    "\n",
    "#  build RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# RNN cell\n",
    "\n",
    "model.add(LSTM(\n",
    "    units =512,\n",
    "    batch_input_shape=( BATCH_SIZE, TIME_STEPS, INPUT_SIZE),\n",
    "    #input_dim=INPUT_SIZE,\n",
    "    #input_length=TIME_STEPS,\n",
    "    #output_dim=CELL_SIZE,\n",
    "    #return_sequences=True,\n",
    "    #stateful=True \n",
    "    unroll=False\n",
    "))\n",
    "\n",
    "# output layer\n",
    "#model.add(Flatten())\n",
    "model.add((Dense(OUTPUT_SIZE)))  #TimeDistributed\n",
    "model.add(Activation('hard_sigmoid'))\n",
    "#model.add(Dropout(rate = 0.2)) \n",
    "\n",
    "# # optimizer\n",
    "#\n",
    "# optimizer\n",
    "\n",
    "rmsprop = RMSprop(lr=LR, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # training\n",
    "#\n",
    "\n",
    "# for step in range(51):\n",
    "#     # data shape = (batch_num, steps, inputs/outputs)\n",
    "#     X_batch = X_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :, :]\n",
    "#     Y_batch = y_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :]\n",
    "#     cost = model.train_on_batch(X_batch, Y_batch)\n",
    "#     BATCH_INDEX += BATCH_SIZE\n",
    "#     BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "\n",
    "#     if step % 50 == 0:\n",
    "#         print('Next_Train----------: step = ', step)\n",
    "#         train_cost, train_accuracy = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('train_cost: ', train_cost, 'train_accuracy: ', train_accuracy)\n",
    "#         cost, accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "        \n",
    "       \n",
    "\n",
    "print('Train-------------------------')\n",
    "\n",
    "history = model.fit(X_test, y_test, validation_split=0.25, epochs=1000, shuffle=False, batch_size=250, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "#                                   [model.layers[1].output])\n",
    "# layer_output1 = get_3rd_layer_output([X_train])[0]\n",
    "\n",
    "# print(layer_output1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-------------------------\n",
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/1000\n",
      "750/750 [==============================] - 1s 881us/step - loss: 0.2007 - acc: 0.0040 - val_loss: 0.0391 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "750/750 [==============================] - 0s 220us/step - loss: 0.0419 - acc: 0.0093 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0394 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "750/750 [==============================] - 0s 218us/step - loss: 0.0395 - acc: 0.0120 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0389 - acc: 0.0093 - val_loss: 0.0315 - val_acc: 0.0360\n",
      "Epoch 6/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0386 - acc: 0.0280 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0389 - acc: 0.0187 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "750/750 [==============================] - 0s 220us/step - loss: 0.0382 - acc: 0.0227 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0390 - acc: 0.0347 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0376 - acc: 0.0000e+00 - val_loss: 0.0302 - val_acc: 0.0080\n",
      "Epoch 11/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0379 - acc: 0.0227 - val_loss: 0.0326 - val_acc: 0.0320\n",
      "Epoch 12/1000\n",
      "750/750 [==============================] - 0s 218us/step - loss: 0.0373 - acc: 0.0253 - val_loss: 0.0294 - val_acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0361 - acc: 0.0080 - val_loss: 0.0366 - val_acc: 0.0320\n",
      "Epoch 14/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0374 - acc: 0.0147 - val_loss: 0.0287 - val_acc: 0.0760\n",
      "Epoch 15/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0358 - acc: 0.0440 - val_loss: 0.0335 - val_acc: 0.0320\n",
      "Epoch 16/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0352 - acc: 0.0187 - val_loss: 0.0292 - val_acc: 0.0280\n",
      "Epoch 17/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0353 - acc: 0.0133 - val_loss: 0.0341 - val_acc: 0.0240\n",
      "Epoch 18/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0351 - acc: 0.0093 - val_loss: 0.0285 - val_acc: 0.0200\n",
      "Epoch 19/1000\n",
      "750/750 [==============================] - 0s 213us/step - loss: 0.0347 - acc: 0.0320 - val_loss: 0.0290 - val_acc: 0.0480\n",
      "Epoch 20/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0335 - acc: 0.0187 - val_loss: 0.0305 - val_acc: 0.0320\n",
      "Epoch 21/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0337 - acc: 0.0227 - val_loss: 0.0286 - val_acc: 0.0200\n",
      "Epoch 22/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0330 - acc: 0.0333 - val_loss: 0.0329 - val_acc: 0.0280\n",
      "Epoch 23/1000\n",
      "750/750 [==============================] - 0s 217us/step - loss: 0.0343 - acc: 0.0240 - val_loss: 0.0281 - val_acc: 0.0400\n",
      "Epoch 24/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0316 - acc: 0.0280 - val_loss: 0.0282 - val_acc: 0.0480\n",
      "Epoch 25/1000\n",
      "750/750 [==============================] - 0s 220us/step - loss: 0.0310 - acc: 0.0280 - val_loss: 0.0333 - val_acc: 0.0280\n",
      "Epoch 26/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0336 - acc: 0.0187 - val_loss: 0.0289 - val_acc: 0.0960\n",
      "Epoch 27/1000\n",
      "750/750 [==============================] - 0s 218us/step - loss: 0.0326 - acc: 0.0267 - val_loss: 0.0292 - val_acc: 0.0240\n",
      "Epoch 28/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0307 - acc: 0.0187 - val_loss: 0.0274 - val_acc: 0.0600\n",
      "Epoch 29/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0312 - acc: 0.0347 - val_loss: 0.0325 - val_acc: 0.0600\n",
      "Epoch 30/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0324 - acc: 0.0173 - val_loss: 0.0277 - val_acc: 0.0840\n",
      "Epoch 31/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0307 - acc: 0.0413 - val_loss: 0.0295 - val_acc: 0.0440\n",
      "Epoch 32/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0305 - acc: 0.0267 - val_loss: 0.0278 - val_acc: 0.0640\n",
      "Epoch 33/1000\n",
      "750/750 [==============================] - 0s 220us/step - loss: 0.0308 - acc: 0.0440 - val_loss: 0.0349 - val_acc: 0.0520\n",
      "Epoch 34/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0317 - acc: 0.0320 - val_loss: 0.0275 - val_acc: 0.0560\n",
      "Epoch 35/1000\n",
      "750/750 [==============================] - 0s 218us/step - loss: 0.0297 - acc: 0.0387 - val_loss: 0.0281 - val_acc: 0.0600\n",
      "Epoch 36/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0287 - acc: 0.0333 - val_loss: 0.0299 - val_acc: 0.1000\n",
      "Epoch 37/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0299 - acc: 0.0387 - val_loss: 0.0281 - val_acc: 0.1200\n",
      "Epoch 38/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0325 - acc: 0.1293 - val_loss: 0.0306 - val_acc: 0.0360\n",
      "Epoch 39/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0300 - acc: 0.0267 - val_loss: 0.0269 - val_acc: 0.0920\n",
      "Epoch 40/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0287 - acc: 0.0440 - val_loss: 0.0286 - val_acc: 0.0160\n",
      "Epoch 41/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0288 - acc: 0.0280 - val_loss: 0.0269 - val_acc: 0.1000\n",
      "Epoch 42/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0289 - acc: 0.0640 - val_loss: 0.0314 - val_acc: 0.0600\n",
      "Epoch 43/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0288 - acc: 0.0773 - val_loss: 0.0265 - val_acc: 0.1080\n",
      "Epoch 44/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0281 - acc: 0.0680 - val_loss: 0.0307 - val_acc: 0.0560\n",
      "Epoch 45/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0284 - acc: 0.0413 - val_loss: 0.0270 - val_acc: 0.0720\n",
      "Epoch 46/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0288 - acc: 0.0493 - val_loss: 0.0320 - val_acc: 0.0280\n",
      "Epoch 47/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0285 - acc: 0.0453 - val_loss: 0.0283 - val_acc: 0.1440\n",
      "Epoch 48/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0288 - acc: 0.0853 - val_loss: 0.0275 - val_acc: 0.0920\n",
      "Epoch 49/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0264 - acc: 0.0653 - val_loss: 0.0278 - val_acc: 0.0320\n",
      "Epoch 50/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0259 - acc: 0.0853 - val_loss: 0.0270 - val_acc: 0.0440\n",
      "Epoch 51/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0282 - acc: 0.0453 - val_loss: 0.0321 - val_acc: 0.0560\n",
      "Epoch 52/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0281 - acc: 0.0627 - val_loss: 0.0266 - val_acc: 0.1000\n",
      "Epoch 53/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0268 - acc: 0.0560 - val_loss: 0.0284 - val_acc: 0.0360\n",
      "Epoch 54/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0262 - acc: 0.0533 - val_loss: 0.0264 - val_acc: 0.1600\n",
      "Epoch 55/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0264 - acc: 0.0680 - val_loss: 0.0293 - val_acc: 0.0560\n",
      "Epoch 56/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0262 - acc: 0.0560 - val_loss: 0.0267 - val_acc: 0.1720\n",
      "Epoch 57/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0266 - acc: 0.1173 - val_loss: 0.0301 - val_acc: 0.0560\n",
      "Epoch 58/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0276 - acc: 0.0760 - val_loss: 0.0267 - val_acc: 0.0400\n",
      "Epoch 59/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0259 - acc: 0.0520 - val_loss: 0.0274 - val_acc: 0.0680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0245 - acc: 0.0853 - val_loss: 0.0282 - val_acc: 0.0400\n",
      "Epoch 61/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0247 - acc: 0.0600 - val_loss: 0.0266 - val_acc: 0.1320\n",
      "Epoch 62/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0246 - acc: 0.0813 - val_loss: 0.0303 - val_acc: 0.0520\n",
      "Epoch 63/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0265 - acc: 0.0867 - val_loss: 0.0272 - val_acc: 0.1680\n",
      "Epoch 64/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0258 - acc: 0.1080 - val_loss: 0.0266 - val_acc: 0.0720\n",
      "Epoch 65/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0244 - acc: 0.0627 - val_loss: 0.0282 - val_acc: 0.0480\n",
      "Epoch 66/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0240 - acc: 0.0693 - val_loss: 0.0263 - val_acc: 0.0680\n",
      "Epoch 67/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0243 - acc: 0.0733 - val_loss: 0.0289 - val_acc: 0.1320\n",
      "Epoch 68/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0234 - acc: 0.1200 - val_loss: 0.0284 - val_acc: 0.1080\n",
      "Epoch 69/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0240 - acc: 0.0813 - val_loss: 0.0266 - val_acc: 0.1880\n",
      "Epoch 70/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0257 - acc: 0.1160 - val_loss: 0.0302 - val_acc: 0.1000\n",
      "Epoch 71/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0256 - acc: 0.0800 - val_loss: 0.0267 - val_acc: 0.0920\n",
      "Epoch 72/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0233 - acc: 0.1107 - val_loss: 0.0276 - val_acc: 0.0920\n",
      "Epoch 73/1000\n",
      "750/750 [==============================] - 0s 213us/step - loss: 0.0229 - acc: 0.0960 - val_loss: 0.0267 - val_acc: 0.1160\n",
      "Epoch 74/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0227 - acc: 0.1000 - val_loss: 0.0277 - val_acc: 0.0840\n",
      "Epoch 75/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0227 - acc: 0.0973 - val_loss: 0.0266 - val_acc: 0.1680\n",
      "Epoch 76/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0229 - acc: 0.1227 - val_loss: 0.0290 - val_acc: 0.1560\n",
      "Epoch 77/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0229 - acc: 0.1240 - val_loss: 0.0271 - val_acc: 0.1040\n",
      "Epoch 78/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0227 - acc: 0.1400 - val_loss: 0.0293 - val_acc: 0.1160\n",
      "Epoch 79/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0220 - acc: 0.0960 - val_loss: 0.0277 - val_acc: 0.1600\n",
      "Epoch 80/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0215 - acc: 0.1293 - val_loss: 0.0295 - val_acc: 0.1000\n",
      "Epoch 81/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0226 - acc: 0.1107 - val_loss: 0.0262 - val_acc: 0.1400\n",
      "Epoch 82/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0227 - acc: 0.1293 - val_loss: 0.0290 - val_acc: 0.1160\n",
      "Epoch 83/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0220 - acc: 0.1053 - val_loss: 0.0270 - val_acc: 0.1680\n",
      "Epoch 84/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0213 - acc: 0.1413 - val_loss: 0.0290 - val_acc: 0.1080\n",
      "Epoch 85/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0208 - acc: 0.1307 - val_loss: 0.0265 - val_acc: 0.1240\n",
      "Epoch 86/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0211 - acc: 0.1440 - val_loss: 0.0300 - val_acc: 0.1440\n",
      "Epoch 87/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0214 - acc: 0.1267 - val_loss: 0.0269 - val_acc: 0.2120\n",
      "Epoch 88/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0220 - acc: 0.1640 - val_loss: 0.0285 - val_acc: 0.1600\n",
      "Epoch 89/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0204 - acc: 0.1227 - val_loss: 0.0269 - val_acc: 0.1520\n",
      "Epoch 90/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0198 - acc: 0.1520 - val_loss: 0.0297 - val_acc: 0.0960\n",
      "Epoch 91/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0199 - acc: 0.1267 - val_loss: 0.0283 - val_acc: 0.1600\n",
      "Epoch 92/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0199 - acc: 0.1693 - val_loss: 0.0268 - val_acc: 0.2280\n",
      "Epoch 93/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0205 - acc: 0.1547 - val_loss: 0.0299 - val_acc: 0.1520\n",
      "Epoch 94/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0206 - acc: 0.1680 - val_loss: 0.0267 - val_acc: 0.1040\n",
      "Epoch 95/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0199 - acc: 0.1547 - val_loss: 0.0265 - val_acc: 0.1240\n",
      "Epoch 96/1000\n",
      "750/750 [==============================] - 0s 220us/step - loss: 0.0190 - acc: 0.1493 - val_loss: 0.0286 - val_acc: 0.1280\n",
      "Epoch 97/1000\n",
      "750/750 [==============================] - 0s 227us/step - loss: 0.0187 - acc: 0.1773 - val_loss: 0.0268 - val_acc: 0.1720\n",
      "Epoch 98/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0200 - acc: 0.1547 - val_loss: 0.0325 - val_acc: 0.1920\n",
      "Epoch 99/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0202 - acc: 0.1760 - val_loss: 0.0279 - val_acc: 0.1680\n",
      "Epoch 100/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0183 - acc: 0.1733 - val_loss: 0.0290 - val_acc: 0.1600\n",
      "Epoch 101/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0180 - acc: 0.1880 - val_loss: 0.0269 - val_acc: 0.1400\n",
      "Epoch 102/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0182 - acc: 0.1773 - val_loss: 0.0377 - val_acc: 0.1560\n",
      "Epoch 103/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0199 - acc: 0.1933 - val_loss: 0.0278 - val_acc: 0.1920\n",
      "Epoch 104/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0186 - acc: 0.1960 - val_loss: 0.0281 - val_acc: 0.1920\n",
      "Epoch 105/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0173 - acc: 0.2067 - val_loss: 0.0312 - val_acc: 0.1360\n",
      "Epoch 106/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0176 - acc: 0.1907 - val_loss: 0.0268 - val_acc: 0.1680\n",
      "Epoch 107/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0174 - acc: 0.1973 - val_loss: 0.0291 - val_acc: 0.1920\n",
      "Epoch 108/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0177 - acc: 0.2173 - val_loss: 0.0278 - val_acc: 0.2000\n",
      "Epoch 109/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0182 - acc: 0.2187 - val_loss: 0.0308 - val_acc: 0.1760\n",
      "Epoch 110/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0171 - acc: 0.2093 - val_loss: 0.0280 - val_acc: 0.1960\n",
      "Epoch 111/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0167 - acc: 0.2080 - val_loss: 0.0323 - val_acc: 0.1560\n",
      "Epoch 112/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0170 - acc: 0.1707 - val_loss: 0.0272 - val_acc: 0.1840\n",
      "Epoch 113/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0168 - acc: 0.2267 - val_loss: 0.0299 - val_acc: 0.1960\n",
      "Epoch 114/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0162 - acc: 0.2160 - val_loss: 0.0290 - val_acc: 0.2040\n",
      "Epoch 115/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0157 - acc: 0.2187 - val_loss: 0.0291 - val_acc: 0.1960\n",
      "Epoch 116/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0161 - acc: 0.2307 - val_loss: 0.0272 - val_acc: 0.1920\n",
      "Epoch 117/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0171 - acc: 0.2093 - val_loss: 0.0320 - val_acc: 0.1360\n",
      "Epoch 118/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0167 - acc: 0.2147 - val_loss: 0.0279 - val_acc: 0.1840\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 199us/step - loss: 0.0153 - acc: 0.2360 - val_loss: 0.0299 - val_acc: 0.1800\n",
      "Epoch 120/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0149 - acc: 0.2147 - val_loss: 0.0281 - val_acc: 0.2280\n",
      "Epoch 121/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0149 - acc: 0.2307 - val_loss: 0.0316 - val_acc: 0.1960\n",
      "Epoch 122/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0151 - acc: 0.2427 - val_loss: 0.0292 - val_acc: 0.2200\n",
      "Epoch 123/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0148 - acc: 0.2773 - val_loss: 0.0318 - val_acc: 0.2000\n",
      "Epoch 124/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0156 - acc: 0.2587 - val_loss: 0.0269 - val_acc: 0.1760\n",
      "Epoch 125/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0163 - acc: 0.1867 - val_loss: 0.0292 - val_acc: 0.2240\n",
      "Epoch 126/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0139 - acc: 0.2400 - val_loss: 0.0297 - val_acc: 0.1800\n",
      "Epoch 127/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0137 - acc: 0.2467 - val_loss: 0.0309 - val_acc: 0.2360\n",
      "Epoch 128/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0140 - acc: 0.2400 - val_loss: 0.0290 - val_acc: 0.2040\n",
      "Epoch 129/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0140 - acc: 0.2280 - val_loss: 0.0355 - val_acc: 0.1880\n",
      "Epoch 130/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0143 - acc: 0.2533 - val_loss: 0.0278 - val_acc: 0.2160\n",
      "Epoch 131/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0141 - acc: 0.2560 - val_loss: 0.0311 - val_acc: 0.1760\n",
      "Epoch 132/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0132 - acc: 0.2547 - val_loss: 0.0294 - val_acc: 0.1560\n",
      "Epoch 133/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0133 - acc: 0.2307 - val_loss: 0.0301 - val_acc: 0.2160\n",
      "Epoch 134/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0130 - acc: 0.2467 - val_loss: 0.0284 - val_acc: 0.2080\n",
      "Epoch 135/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0124 - acc: 0.2680 - val_loss: 0.0306 - val_acc: 0.1920\n",
      "Epoch 136/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0127 - acc: 0.2520 - val_loss: 0.0302 - val_acc: 0.2040\n",
      "Epoch 137/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0129 - acc: 0.2720 - val_loss: 0.0287 - val_acc: 0.2200\n",
      "Epoch 138/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0125 - acc: 0.2853 - val_loss: 0.0339 - val_acc: 0.2320\n",
      "Epoch 139/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0129 - acc: 0.2693 - val_loss: 0.0266 - val_acc: 0.2400\n",
      "Epoch 140/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0137 - acc: 0.2947 - val_loss: 0.0307 - val_acc: 0.2040\n",
      "Epoch 141/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0113 - acc: 0.2800 - val_loss: 0.0300 - val_acc: 0.2040\n",
      "Epoch 142/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0113 - acc: 0.2653 - val_loss: 0.0311 - val_acc: 0.2280\n",
      "Epoch 143/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0112 - acc: 0.2720 - val_loss: 0.0291 - val_acc: 0.1680\n",
      "Epoch 144/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0123 - acc: 0.2627 - val_loss: 0.0307 - val_acc: 0.1960\n",
      "Epoch 145/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0115 - acc: 0.2840 - val_loss: 0.0291 - val_acc: 0.2240\n",
      "Epoch 146/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0112 - acc: 0.3107 - val_loss: 0.0347 - val_acc: 0.2120\n",
      "Epoch 147/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0112 - acc: 0.2787 - val_loss: 0.0288 - val_acc: 0.2320\n",
      "Epoch 148/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0104 - acc: 0.2800 - val_loss: 0.0306 - val_acc: 0.1920\n",
      "Epoch 149/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0106 - acc: 0.2947 - val_loss: 0.0306 - val_acc: 0.2200\n",
      "Epoch 150/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0103 - acc: 0.2787 - val_loss: 0.0303 - val_acc: 0.2400\n",
      "Epoch 151/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0106 - acc: 0.3213 - val_loss: 0.0315 - val_acc: 0.2200\n",
      "Epoch 152/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0101 - acc: 0.3107 - val_loss: 0.0292 - val_acc: 0.2040\n",
      "Epoch 153/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0105 - acc: 0.3467 - val_loss: 0.0347 - val_acc: 0.1920\n",
      "Epoch 154/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0101 - acc: 0.3067 - val_loss: 0.0288 - val_acc: 0.2160\n",
      "Epoch 155/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0105 - acc: 0.3240 - val_loss: 0.0326 - val_acc: 0.1960\n",
      "Epoch 156/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0092 - acc: 0.3093 - val_loss: 0.0300 - val_acc: 0.2240\n",
      "Epoch 157/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0089 - acc: 0.3253 - val_loss: 0.0306 - val_acc: 0.2320\n",
      "Epoch 158/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0088 - acc: 0.3240 - val_loss: 0.0325 - val_acc: 0.1960\n",
      "Epoch 159/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0095 - acc: 0.3160 - val_loss: 0.0281 - val_acc: 0.2120\n",
      "Epoch 160/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0106 - acc: 0.3360 - val_loss: 0.0352 - val_acc: 0.2040\n",
      "Epoch 161/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0092 - acc: 0.2907 - val_loss: 0.0312 - val_acc: 0.2120\n",
      "Epoch 162/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0083 - acc: 0.3760 - val_loss: 0.0310 - val_acc: 0.2240\n",
      "Epoch 163/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0084 - acc: 0.3200 - val_loss: 0.0336 - val_acc: 0.1920\n",
      "Epoch 164/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0090 - acc: 0.3493 - val_loss: 0.0310 - val_acc: 0.1880\n",
      "Epoch 165/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0095 - acc: 0.3240 - val_loss: 0.0316 - val_acc: 0.1960\n",
      "Epoch 166/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0081 - acc: 0.3520 - val_loss: 0.0309 - val_acc: 0.2320\n",
      "Epoch 167/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0076 - acc: 0.3520 - val_loss: 0.0320 - val_acc: 0.2080\n",
      "Epoch 168/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0076 - acc: 0.3560 - val_loss: 0.0297 - val_acc: 0.2680\n",
      "Epoch 169/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0085 - acc: 0.3507 - val_loss: 0.0364 - val_acc: 0.2320\n",
      "Epoch 170/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0085 - acc: 0.3187 - val_loss: 0.0306 - val_acc: 0.2360\n",
      "Epoch 171/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0075 - acc: 0.3720 - val_loss: 0.0326 - val_acc: 0.2280\n",
      "Epoch 172/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0071 - acc: 0.3440 - val_loss: 0.0315 - val_acc: 0.2520\n",
      "Epoch 173/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0069 - acc: 0.3747 - val_loss: 0.0335 - val_acc: 0.2240\n",
      "Epoch 174/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0080 - acc: 0.3707 - val_loss: 0.0313 - val_acc: 0.1920\n",
      "Epoch 175/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0080 - acc: 0.3613 - val_loss: 0.0339 - val_acc: 0.2080\n",
      "Epoch 176/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0071 - acc: 0.3987 - val_loss: 0.0320 - val_acc: 0.2160\n",
      "Epoch 177/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0067 - acc: 0.3627 - val_loss: 0.0316 - val_acc: 0.2680\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 188us/step - loss: 0.0066 - acc: 0.4107 - val_loss: 0.0340 - val_acc: 0.2160\n",
      "Epoch 179/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0080 - acc: 0.3827 - val_loss: 0.0332 - val_acc: 0.2400\n",
      "Epoch 180/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0079 - acc: 0.3427 - val_loss: 0.0342 - val_acc: 0.2400\n",
      "Epoch 181/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0064 - acc: 0.4227 - val_loss: 0.0323 - val_acc: 0.2360\n",
      "Epoch 182/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0060 - acc: 0.4280 - val_loss: 0.0339 - val_acc: 0.2360\n",
      "Epoch 183/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0061 - acc: 0.3733 - val_loss: 0.0323 - val_acc: 0.2400\n",
      "Epoch 184/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0059 - acc: 0.4093 - val_loss: 0.0338 - val_acc: 0.2440\n",
      "Epoch 185/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0066 - acc: 0.3960 - val_loss: 0.0335 - val_acc: 0.2080\n",
      "Epoch 186/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0068 - acc: 0.4107 - val_loss: 0.0307 - val_acc: 0.2600\n",
      "Epoch 187/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0060 - acc: 0.4440 - val_loss: 0.0349 - val_acc: 0.2320\n",
      "Epoch 188/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0060 - acc: 0.4320 - val_loss: 0.0314 - val_acc: 0.2240\n",
      "Epoch 189/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0061 - acc: 0.4253 - val_loss: 0.0338 - val_acc: 0.2040\n",
      "Epoch 190/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0059 - acc: 0.4187 - val_loss: 0.0316 - val_acc: 0.2080\n",
      "Epoch 191/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0055 - acc: 0.4320 - val_loss: 0.0336 - val_acc: 0.2640\n",
      "Epoch 192/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0054 - acc: 0.4227 - val_loss: 0.0327 - val_acc: 0.2120\n",
      "Epoch 193/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0052 - acc: 0.4560 - val_loss: 0.0337 - val_acc: 0.2120\n",
      "Epoch 194/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0055 - acc: 0.4520 - val_loss: 0.0320 - val_acc: 0.2680\n",
      "Epoch 195/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0055 - acc: 0.4520 - val_loss: 0.0397 - val_acc: 0.2280\n",
      "Epoch 196/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0071 - acc: 0.4227 - val_loss: 0.0315 - val_acc: 0.2960\n",
      "Epoch 197/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0056 - acc: 0.4600 - val_loss: 0.0333 - val_acc: 0.2480\n",
      "Epoch 198/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0047 - acc: 0.4907 - val_loss: 0.0327 - val_acc: 0.2680\n",
      "Epoch 199/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0046 - acc: 0.5120 - val_loss: 0.0343 - val_acc: 0.2320\n",
      "Epoch 200/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0048 - acc: 0.4707 - val_loss: 0.0323 - val_acc: 0.2560\n",
      "Epoch 201/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0050 - acc: 0.4667 - val_loss: 0.0353 - val_acc: 0.2640\n",
      "Epoch 202/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0050 - acc: 0.4893 - val_loss: 0.0338 - val_acc: 0.2640\n",
      "Epoch 203/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0052 - acc: 0.4627 - val_loss: 0.0344 - val_acc: 0.2520\n",
      "Epoch 204/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0045 - acc: 0.5293 - val_loss: 0.0326 - val_acc: 0.2240\n",
      "Epoch 205/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0041 - acc: 0.5253 - val_loss: 0.0337 - val_acc: 0.2360\n",
      "Epoch 206/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0041 - acc: 0.5173 - val_loss: 0.0343 - val_acc: 0.2680\n",
      "Epoch 207/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0046 - acc: 0.4587 - val_loss: 0.0352 - val_acc: 0.2320\n",
      "Epoch 208/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0045 - acc: 0.5213 - val_loss: 0.0336 - val_acc: 0.2800\n",
      "Epoch 209/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0045 - acc: 0.5053 - val_loss: 0.0371 - val_acc: 0.2200\n",
      "Epoch 210/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0054 - acc: 0.4880 - val_loss: 0.0306 - val_acc: 0.2600\n",
      "Epoch 211/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0050 - acc: 0.4973 - val_loss: 0.0332 - val_acc: 0.2400\n",
      "Epoch 212/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0038 - acc: 0.5587 - val_loss: 0.0330 - val_acc: 0.2640\n",
      "Epoch 213/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0036 - acc: 0.5667 - val_loss: 0.0333 - val_acc: 0.2560\n",
      "Epoch 214/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0035 - acc: 0.5587 - val_loss: 0.0332 - val_acc: 0.2680\n",
      "Epoch 215/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0036 - acc: 0.5907 - val_loss: 0.0344 - val_acc: 0.2320\n",
      "Epoch 216/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0044 - acc: 0.5173 - val_loss: 0.0328 - val_acc: 0.2440\n",
      "Epoch 217/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0040 - acc: 0.5720 - val_loss: 0.0350 - val_acc: 0.2400\n",
      "Epoch 218/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0039 - acc: 0.5453 - val_loss: 0.0349 - val_acc: 0.3080\n",
      "Epoch 219/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0035 - acc: 0.5720 - val_loss: 0.0336 - val_acc: 0.2840\n",
      "Epoch 220/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0032 - acc: 0.6200 - val_loss: 0.0342 - val_acc: 0.2560\n",
      "Epoch 221/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0032 - acc: 0.6013 - val_loss: 0.0334 - val_acc: 0.2560\n",
      "Epoch 222/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0036 - acc: 0.5413 - val_loss: 0.0348 - val_acc: 0.2440\n",
      "Epoch 223/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0045 - acc: 0.4960 - val_loss: 0.0328 - val_acc: 0.2720\n",
      "Epoch 224/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0032 - acc: 0.5960 - val_loss: 0.0343 - val_acc: 0.2840\n",
      "Epoch 225/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0029 - acc: 0.6653 - val_loss: 0.0338 - val_acc: 0.2680\n",
      "Epoch 226/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0029 - acc: 0.6533 - val_loss: 0.0343 - val_acc: 0.2720\n",
      "Epoch 227/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0028 - acc: 0.6720 - val_loss: 0.0339 - val_acc: 0.2720\n",
      "Epoch 228/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0030 - acc: 0.6320 - val_loss: 0.0360 - val_acc: 0.2280\n",
      "Epoch 229/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0036 - acc: 0.5547 - val_loss: 0.0333 - val_acc: 0.2600\n",
      "Epoch 230/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0040 - acc: 0.5413 - val_loss: 0.0342 - val_acc: 0.2760\n",
      "Epoch 231/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0032 - acc: 0.5880 - val_loss: 0.0341 - val_acc: 0.2720\n",
      "Epoch 232/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0027 - acc: 0.6920 - val_loss: 0.0337 - val_acc: 0.2880\n",
      "Epoch 233/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0026 - acc: 0.6840 - val_loss: 0.0339 - val_acc: 0.2640\n",
      "Epoch 234/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0026 - acc: 0.7013 - val_loss: 0.0338 - val_acc: 0.2760\n",
      "Epoch 235/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0026 - acc: 0.7120 - val_loss: 0.0342 - val_acc: 0.2760\n",
      "Epoch 236/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0027 - acc: 0.6733 - val_loss: 0.0335 - val_acc: 0.2880\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 189us/step - loss: 0.0039 - acc: 0.6080 - val_loss: 0.0438 - val_acc: 0.2520\n",
      "Epoch 238/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0058 - acc: 0.5173 - val_loss: 0.0327 - val_acc: 0.3000\n",
      "Epoch 239/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0033 - acc: 0.6307 - val_loss: 0.0344 - val_acc: 0.2760\n",
      "Epoch 240/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0026 - acc: 0.6533 - val_loss: 0.0343 - val_acc: 0.2880\n",
      "Epoch 241/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0026 - acc: 0.6920 - val_loss: 0.0343 - val_acc: 0.2760\n",
      "Epoch 242/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0025 - acc: 0.6867 - val_loss: 0.0343 - val_acc: 0.2960\n",
      "Epoch 243/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0025 - acc: 0.7040 - val_loss: 0.0343 - val_acc: 0.2880\n",
      "Epoch 244/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0025 - acc: 0.7200 - val_loss: 0.0343 - val_acc: 0.2880\n",
      "Epoch 245/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0025 - acc: 0.7187 - val_loss: 0.0344 - val_acc: 0.2720\n",
      "Epoch 246/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0025 - acc: 0.7320 - val_loss: 0.0342 - val_acc: 0.2680\n",
      "Epoch 247/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0025 - acc: 0.7280 - val_loss: 0.0347 - val_acc: 0.2960\n",
      "Epoch 248/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0027 - acc: 0.6680 - val_loss: 0.0343 - val_acc: 0.2360\n",
      "Epoch 249/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0037 - acc: 0.5893 - val_loss: 0.0332 - val_acc: 0.2560\n",
      "Epoch 250/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0037 - acc: 0.5933 - val_loss: 0.0347 - val_acc: 0.2360\n",
      "Epoch 251/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0026 - acc: 0.7173 - val_loss: 0.0341 - val_acc: 0.2480\n",
      "Epoch 252/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.7613 - val_loss: 0.0340 - val_acc: 0.2680\n",
      "Epoch 253/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.7760 - val_loss: 0.0341 - val_acc: 0.2880\n",
      "Epoch 254/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0024 - acc: 0.7573 - val_loss: 0.0342 - val_acc: 0.2880\n",
      "Epoch 255/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.7760 - val_loss: 0.0340 - val_acc: 0.3000\n",
      "Epoch 256/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.7920 - val_loss: 0.0340 - val_acc: 0.2960\n",
      "Epoch 257/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.7920 - val_loss: 0.0342 - val_acc: 0.2920\n",
      "Epoch 258/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.7920 - val_loss: 0.0340 - val_acc: 0.3120\n",
      "Epoch 259/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.7907 - val_loss: 0.0344 - val_acc: 0.2640\n",
      "Epoch 260/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0046 - acc: 0.5373 - val_loss: 0.0350 - val_acc: 0.2280\n",
      "Epoch 261/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0035 - acc: 0.6080 - val_loss: 0.0340 - val_acc: 0.2920\n",
      "Epoch 262/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0025 - acc: 0.7627 - val_loss: 0.0347 - val_acc: 0.2720\n",
      "Epoch 263/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.7947 - val_loss: 0.0346 - val_acc: 0.2880\n",
      "Epoch 264/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 0.8067 - val_loss: 0.0345 - val_acc: 0.2800\n",
      "Epoch 265/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0023 - acc: 0.8067 - val_loss: 0.0345 - val_acc: 0.2760\n",
      "Epoch 266/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0023 - acc: 0.8187 - val_loss: 0.0345 - val_acc: 0.2960\n",
      "Epoch 267/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 0.8213 - val_loss: 0.0345 - val_acc: 0.2840\n",
      "Epoch 268/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0023 - acc: 0.8347 - val_loss: 0.0345 - val_acc: 0.2720\n",
      "Epoch 269/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0023 - acc: 0.8280 - val_loss: 0.0345 - val_acc: 0.2680\n",
      "Epoch 270/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0023 - acc: 0.8507 - val_loss: 0.0344 - val_acc: 0.2840\n",
      "Epoch 271/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0023 - acc: 0.8453 - val_loss: 0.0347 - val_acc: 0.2480\n",
      "Epoch 272/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0025 - acc: 0.7960 - val_loss: 0.0351 - val_acc: 0.2920\n",
      "Epoch 273/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0045 - acc: 0.5667 - val_loss: 0.0435 - val_acc: 0.2960\n",
      "Epoch 274/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0040 - acc: 0.6507 - val_loss: 0.0342 - val_acc: 0.2920\n",
      "Epoch 275/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.7573 - val_loss: 0.0345 - val_acc: 0.3000\n",
      "Epoch 276/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 0.7840 - val_loss: 0.0346 - val_acc: 0.2960\n",
      "Epoch 277/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0023 - acc: 0.7973 - val_loss: 0.0347 - val_acc: 0.2880\n",
      "Epoch 278/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0023 - acc: 0.8000 - val_loss: 0.0346 - val_acc: 0.2880\n",
      "Epoch 279/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 0.8267 - val_loss: 0.0347 - val_acc: 0.2840\n",
      "Epoch 280/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0023 - acc: 0.8280 - val_loss: 0.0347 - val_acc: 0.2800\n",
      "Epoch 281/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0023 - acc: 0.8320 - val_loss: 0.0347 - val_acc: 0.2800\n",
      "Epoch 282/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0023 - acc: 0.8413 - val_loss: 0.0347 - val_acc: 0.2760\n",
      "Epoch 283/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 0.8480 - val_loss: 0.0347 - val_acc: 0.2760\n",
      "Epoch 284/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0023 - acc: 0.8507 - val_loss: 0.0347 - val_acc: 0.2800\n",
      "Epoch 285/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0023 - acc: 0.8707 - val_loss: 0.0347 - val_acc: 0.2800\n",
      "Epoch 286/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 0.8840 - val_loss: 0.0347 - val_acc: 0.2840\n",
      "Epoch 287/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0023 - acc: 0.8773 - val_loss: 0.0348 - val_acc: 0.2880\n",
      "Epoch 288/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0023 - acc: 0.8867 - val_loss: 0.0353 - val_acc: 0.2600\n",
      "Epoch 289/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0037 - acc: 0.6773 - val_loss: 0.0318 - val_acc: 0.2960\n",
      "Epoch 290/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0048 - acc: 0.5920 - val_loss: 0.0365 - val_acc: 0.2680\n",
      "Epoch 291/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0025 - acc: 0.7240 - val_loss: 0.0344 - val_acc: 0.2960\n",
      "Epoch 292/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0023 - acc: 0.8080 - val_loss: 0.0345 - val_acc: 0.3040\n",
      "Epoch 293/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0023 - acc: 0.8293 - val_loss: 0.0345 - val_acc: 0.3000\n",
      "Epoch 294/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 0.8360 - val_loss: 0.0345 - val_acc: 0.3000\n",
      "Epoch 295/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0023 - acc: 0.8533 - val_loss: 0.0345 - val_acc: 0.3040\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8560 - val_loss: 0.0345 - val_acc: 0.3080\n",
      "Epoch 297/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.8680 - val_loss: 0.0345 - val_acc: 0.3040\n",
      "Epoch 298/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8720 - val_loss: 0.0345 - val_acc: 0.3040\n",
      "Epoch 299/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.8760 - val_loss: 0.0345 - val_acc: 0.3080\n",
      "Epoch 300/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8827 - val_loss: 0.0345 - val_acc: 0.3080\n",
      "Epoch 301/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.8973 - val_loss: 0.0345 - val_acc: 0.3080\n",
      "Epoch 302/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8973 - val_loss: 0.0345 - val_acc: 0.3040\n",
      "Epoch 303/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8973 - val_loss: 0.0345 - val_acc: 0.3120\n",
      "Epoch 304/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9120 - val_loss: 0.0345 - val_acc: 0.3040\n",
      "Epoch 305/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9187 - val_loss: 0.0345 - val_acc: 0.3040\n",
      "Epoch 306/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9133 - val_loss: 0.0345 - val_acc: 0.3040\n",
      "Epoch 307/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9280 - val_loss: 0.0345 - val_acc: 0.2960\n",
      "Epoch 308/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 0.8427 - val_loss: 0.0370 - val_acc: 0.2560\n",
      "Epoch 309/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0052 - acc: 0.5493 - val_loss: 0.0347 - val_acc: 0.3200\n",
      "Epoch 310/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0027 - acc: 0.7227 - val_loss: 0.0343 - val_acc: 0.2800\n",
      "Epoch 311/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 0.8307 - val_loss: 0.0344 - val_acc: 0.2960\n",
      "Epoch 312/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.8507 - val_loss: 0.0344 - val_acc: 0.3000\n",
      "Epoch 313/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.8680 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 314/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.8640 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 315/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8733 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 316/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.8707 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 317/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.8800 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 318/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.8920 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 319/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.8853 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 320/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9027 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 321/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9027 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 322/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9120 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 323/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9040 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 324/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9267 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 325/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9213 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 326/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9360 - val_loss: 0.0344 - val_acc: 0.2920\n",
      "Epoch 327/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9360 - val_loss: 0.0343 - val_acc: 0.2920\n",
      "Epoch 328/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9253 - val_loss: 0.0344 - val_acc: 0.2760\n",
      "Epoch 329/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0037 - acc: 0.7373 - val_loss: 0.0410 - val_acc: 0.2360\n",
      "Epoch 330/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0045 - acc: 0.6453 - val_loss: 0.0342 - val_acc: 0.2800\n",
      "Epoch 331/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.7907 - val_loss: 0.0346 - val_acc: 0.2880\n",
      "Epoch 332/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.8173 - val_loss: 0.0346 - val_acc: 0.2760\n",
      "Epoch 333/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8413 - val_loss: 0.0346 - val_acc: 0.2800\n",
      "Epoch 334/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8467 - val_loss: 0.0346 - val_acc: 0.2800\n",
      "Epoch 335/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.8493 - val_loss: 0.0346 - val_acc: 0.2840\n",
      "Epoch 336/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8653 - val_loss: 0.0347 - val_acc: 0.2840\n",
      "Epoch 337/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.8800 - val_loss: 0.0347 - val_acc: 0.2800\n",
      "Epoch 338/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.8933 - val_loss: 0.0347 - val_acc: 0.2800\n",
      "Epoch 339/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.8933 - val_loss: 0.0347 - val_acc: 0.2840\n",
      "Epoch 340/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8920 - val_loss: 0.0347 - val_acc: 0.2880\n",
      "Epoch 341/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9093 - val_loss: 0.0347 - val_acc: 0.2880\n",
      "Epoch 342/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8987 - val_loss: 0.0347 - val_acc: 0.2800\n",
      "Epoch 343/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9227 - val_loss: 0.0346 - val_acc: 0.2840\n",
      "Epoch 344/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8933 - val_loss: 0.0347 - val_acc: 0.2840\n",
      "Epoch 345/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9227 - val_loss: 0.0347 - val_acc: 0.2720\n",
      "Epoch 346/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9227 - val_loss: 0.0347 - val_acc: 0.2840\n",
      "Epoch 347/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9347 - val_loss: 0.0347 - val_acc: 0.2720\n",
      "Epoch 348/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9213 - val_loss: 0.0348 - val_acc: 0.2680\n",
      "Epoch 349/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9093 - val_loss: 0.0331 - val_acc: 0.3080\n",
      "Epoch 350/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0050 - acc: 0.5800 - val_loss: 0.0344 - val_acc: 0.2720\n",
      "Epoch 351/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 0.7880 - val_loss: 0.0335 - val_acc: 0.2720\n",
      "Epoch 352/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.8613 - val_loss: 0.0336 - val_acc: 0.2640\n",
      "Epoch 353/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.8787 - val_loss: 0.0336 - val_acc: 0.2800\n",
      "Epoch 354/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.8893 - val_loss: 0.0336 - val_acc: 0.2760\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.8947 - val_loss: 0.0337 - val_acc: 0.2760\n",
      "Epoch 356/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0021 - acc: 0.9000 - val_loss: 0.0336 - val_acc: 0.2760\n",
      "Epoch 357/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.8960 - val_loss: 0.0336 - val_acc: 0.2760\n",
      "Epoch 358/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9053 - val_loss: 0.0336 - val_acc: 0.2760\n",
      "Epoch 359/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0021 - acc: 0.9120 - val_loss: 0.0337 - val_acc: 0.2760\n",
      "Epoch 360/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0021 - acc: 0.9107 - val_loss: 0.0336 - val_acc: 0.2760\n",
      "Epoch 361/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9267 - val_loss: 0.0337 - val_acc: 0.2760\n",
      "Epoch 362/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0021 - acc: 0.9280 - val_loss: 0.0337 - val_acc: 0.2760\n",
      "Epoch 363/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9387 - val_loss: 0.0337 - val_acc: 0.2760\n",
      "Epoch 364/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9373 - val_loss: 0.0337 - val_acc: 0.2760\n",
      "Epoch 365/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9413 - val_loss: 0.0337 - val_acc: 0.2720\n",
      "Epoch 366/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0021 - acc: 0.9360 - val_loss: 0.0337 - val_acc: 0.2800\n",
      "Epoch 367/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9333 - val_loss: 0.0337 - val_acc: 0.2760\n",
      "Epoch 368/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9427 - val_loss: 0.0337 - val_acc: 0.2800\n",
      "Epoch 369/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0021 - acc: 0.9560 - val_loss: 0.0337 - val_acc: 0.2800\n",
      "Epoch 370/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9547 - val_loss: 0.0337 - val_acc: 0.2800\n",
      "Epoch 371/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9427 - val_loss: 0.0336 - val_acc: 0.2800\n",
      "Epoch 372/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0021 - acc: 0.9160 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 373/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0049 - acc: 0.5987 - val_loss: 0.0350 - val_acc: 0.2040\n",
      "Epoch 374/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0024 - acc: 0.6920 - val_loss: 0.0348 - val_acc: 0.2720\n",
      "Epoch 375/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.8480 - val_loss: 0.0345 - val_acc: 0.2680\n",
      "Epoch 376/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.8840 - val_loss: 0.0345 - val_acc: 0.2680\n",
      "Epoch 377/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.8880 - val_loss: 0.0345 - val_acc: 0.2680\n",
      "Epoch 378/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.8907 - val_loss: 0.0346 - val_acc: 0.2680\n",
      "Epoch 379/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9013 - val_loss: 0.0345 - val_acc: 0.2680\n",
      "Epoch 380/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9120 - val_loss: 0.0345 - val_acc: 0.2680\n",
      "Epoch 381/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0021 - acc: 0.9120 - val_loss: 0.0345 - val_acc: 0.2680\n",
      "Epoch 382/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9173 - val_loss: 0.0345 - val_acc: 0.2680\n",
      "Epoch 383/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9187 - val_loss: 0.0345 - val_acc: 0.2680\n",
      "Epoch 384/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9200 - val_loss: 0.0345 - val_acc: 0.2640\n",
      "Epoch 385/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9240 - val_loss: 0.0345 - val_acc: 0.2680\n",
      "Epoch 386/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9293 - val_loss: 0.0345 - val_acc: 0.2640\n",
      "Epoch 387/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0021 - acc: 0.9293 - val_loss: 0.0345 - val_acc: 0.2600\n",
      "Epoch 388/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9427 - val_loss: 0.0345 - val_acc: 0.2600\n",
      "Epoch 389/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0021 - acc: 0.9373 - val_loss: 0.0344 - val_acc: 0.2560\n",
      "Epoch 390/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9387 - val_loss: 0.0346 - val_acc: 0.2520\n",
      "Epoch 391/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9307 - val_loss: 0.0343 - val_acc: 0.2640\n",
      "Epoch 392/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 0.8107 - val_loss: 0.0381 - val_acc: 0.2480\n",
      "Epoch 393/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0043 - acc: 0.6147 - val_loss: 0.0316 - val_acc: 0.2800\n",
      "Epoch 394/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.8227 - val_loss: 0.0340 - val_acc: 0.2920\n",
      "Epoch 395/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.8907 - val_loss: 0.0338 - val_acc: 0.2720\n",
      "Epoch 396/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9000 - val_loss: 0.0338 - val_acc: 0.2720\n",
      "Epoch 397/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.8907 - val_loss: 0.0339 - val_acc: 0.2720\n",
      "Epoch 398/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9013 - val_loss: 0.0339 - val_acc: 0.2720\n",
      "Epoch 399/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.8933 - val_loss: 0.0339 - val_acc: 0.2760\n",
      "Epoch 400/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9067 - val_loss: 0.0339 - val_acc: 0.2800\n",
      "Epoch 401/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9053 - val_loss: 0.0339 - val_acc: 0.2760\n",
      "Epoch 402/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9147 - val_loss: 0.0339 - val_acc: 0.2800\n",
      "Epoch 403/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9093 - val_loss: 0.0339 - val_acc: 0.2800\n",
      "Epoch 404/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9147 - val_loss: 0.0339 - val_acc: 0.2800\n",
      "Epoch 405/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9347 - val_loss: 0.0340 - val_acc: 0.2760\n",
      "Epoch 406/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9347 - val_loss: 0.0338 - val_acc: 0.2760\n",
      "Epoch 407/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9387 - val_loss: 0.0339 - val_acc: 0.2840\n",
      "Epoch 408/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9547 - val_loss: 0.0339 - val_acc: 0.2760\n",
      "Epoch 409/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9547 - val_loss: 0.0339 - val_acc: 0.2760\n",
      "Epoch 410/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9533 - val_loss: 0.0339 - val_acc: 0.2760\n",
      "Epoch 411/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9547 - val_loss: 0.0339 - val_acc: 0.2720\n",
      "Epoch 412/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9520 - val_loss: 0.0339 - val_acc: 0.2760\n",
      "Epoch 413/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0020 - acc: 0.9547 - val_loss: 0.0339 - val_acc: 0.2760\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9480 - val_loss: 0.0339 - val_acc: 0.2760\n",
      "Epoch 415/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.8773 - val_loss: 0.0361 - val_acc: 0.2680\n",
      "Epoch 416/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0040 - acc: 0.6320 - val_loss: 0.0342 - val_acc: 0.3200\n",
      "Epoch 417/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0021 - acc: 0.8467 - val_loss: 0.0354 - val_acc: 0.3080\n",
      "Epoch 418/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9093 - val_loss: 0.0353 - val_acc: 0.3160\n",
      "Epoch 419/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9187 - val_loss: 0.0353 - val_acc: 0.3160\n",
      "Epoch 420/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9213 - val_loss: 0.0352 - val_acc: 0.3160\n",
      "Epoch 421/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9267 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 422/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9293 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 423/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9320 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 424/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9333 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 425/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9347 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 426/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9400 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 427/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9427 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 428/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9467 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 429/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9520 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 430/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9440 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 431/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9507 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 432/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9573 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 433/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9507 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 434/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9587 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 435/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 436/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9587 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 437/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 438/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 439/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 440/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 441/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 442/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 443/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 444/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 445/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 446/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 447/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 448/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 449/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 450/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 451/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 452/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 453/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 454/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 455/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 456/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 457/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 458/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 459/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 460/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 461/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 462/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 463/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 464/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 465/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 466/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 467/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 468/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 469/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 470/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 471/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 472/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 204us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 474/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 475/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 476/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 477/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 478/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 479/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 480/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 481/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 482/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 483/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 484/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 485/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 486/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 487/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 488/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 489/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 490/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 491/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 492/1000\n",
      "750/750 [==============================] - 0s 213us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 493/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 494/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 495/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 496/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 497/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 498/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 499/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 500/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 501/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 502/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 503/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 504/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 505/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 506/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 507/1000\n",
      "750/750 [==============================] - 0s 212us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 508/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 509/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 510/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 511/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 512/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 513/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 514/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 515/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 516/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 517/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 518/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 519/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 520/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 521/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 522/1000\n",
      "750/750 [==============================] - 0s 222us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 523/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 524/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 525/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 526/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 527/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 528/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 529/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 530/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 531/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 533/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 534/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 535/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 536/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 537/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 538/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 539/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 540/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 541/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 542/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 543/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 544/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 545/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 546/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 547/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 548/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 549/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 550/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 551/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 552/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 553/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 554/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 555/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 556/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 557/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 558/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 559/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 560/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 561/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 562/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 563/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 564/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 565/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 566/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 567/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 568/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 569/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 570/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 571/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 572/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 573/1000\n",
      "750/750 [==============================] - 0s 218us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 574/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 575/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 576/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 577/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 578/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 579/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 580/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 581/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 582/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 583/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 584/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 585/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 586/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 587/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 588/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 589/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 590/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 221us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 592/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 593/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 594/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 595/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 596/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 597/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 598/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 599/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 600/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 601/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 602/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 603/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 604/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 605/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 606/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 607/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 608/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 609/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 610/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 611/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 612/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 613/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 614/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 615/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 616/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 617/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 618/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 619/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 620/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 621/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 622/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 623/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 624/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 625/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 626/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 627/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 628/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 629/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 630/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 631/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 632/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 633/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 634/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 635/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 636/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 637/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 638/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 639/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 640/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 641/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 642/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 643/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 644/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 645/1000\n",
      "750/750 [==============================] - 0s 222us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 646/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 647/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 648/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 649/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 650/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 194us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 651/1000\n",
      "750/750 [==============================] - 0s 217us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 652/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 653/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 654/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 655/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 656/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 657/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 658/1000\n",
      "750/750 [==============================] - 0s 218us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 659/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 660/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 661/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 662/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 663/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 664/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 665/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 666/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 667/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 668/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 669/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 670/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 671/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 672/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 673/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 674/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 675/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 676/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 677/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 678/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 679/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 680/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 681/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 682/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 683/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 684/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 685/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 686/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 687/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 688/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 689/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 690/1000\n",
      "750/750 [==============================] - 0s 213us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 691/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 692/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 693/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 694/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 695/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 696/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 697/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 698/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 699/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 700/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 701/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 702/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 703/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 704/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 705/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 706/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 707/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 708/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 709/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 710/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 711/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 712/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 713/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 714/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 715/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 716/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 717/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 718/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 719/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 720/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 721/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 722/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 723/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 724/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 725/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 726/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 727/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 728/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 729/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 730/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 731/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 732/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 733/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 734/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 735/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 736/1000\n",
      "750/750 [==============================] - 0s 201us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 737/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 738/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 739/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 740/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 741/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 742/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 743/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 744/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 745/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 746/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 747/1000\n",
      "750/750 [==============================] - 0s 200us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 748/1000\n",
      "750/750 [==============================] - 0s 199us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 749/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 750/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 751/1000\n",
      "750/750 [==============================] - 0s 202us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 752/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 753/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 754/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 755/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 756/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 757/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 758/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 759/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 760/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 761/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 762/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 763/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 764/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 765/1000\n",
      "750/750 [==============================] - 0s 213us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 766/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 767/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 769/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 770/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 771/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 772/1000\n",
      "750/750 [==============================] - 0s 213us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 773/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 774/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 775/1000\n",
      "750/750 [==============================] - 0s 217us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 776/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 777/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 778/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 779/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 780/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 781/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 782/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 783/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 784/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 785/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 786/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 787/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 788/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 789/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 790/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 791/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 792/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 793/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 794/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 795/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 796/1000\n",
      "750/750 [==============================] - 0s 197us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 797/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 798/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 799/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 800/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 801/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 802/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 803/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 804/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 805/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 806/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 807/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 808/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 809/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 810/1000\n",
      "750/750 [==============================] - 0s 217us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 811/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 812/1000\n",
      "750/750 [==============================] - 0s 216us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 813/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 814/1000\n",
      "750/750 [==============================] - 0s 214us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 815/1000\n",
      "750/750 [==============================] - 0s 194us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 816/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 817/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 818/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 819/1000\n",
      "750/750 [==============================] - 0s 205us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 820/1000\n",
      "750/750 [==============================] - 0s 210us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 821/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 822/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 823/1000\n",
      "750/750 [==============================] - 0s 209us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 824/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 825/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 826/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 828/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 829/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 830/1000\n",
      "750/750 [==============================] - 0s 198us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 831/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 832/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 833/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 834/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 835/1000\n",
      "750/750 [==============================] - 0s 195us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 836/1000\n",
      "750/750 [==============================] - 0s 222us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 837/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 838/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 839/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 840/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 841/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 842/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 843/1000\n",
      "750/750 [==============================] - 0s 218us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 844/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 845/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 846/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 847/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 848/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 849/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 850/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 851/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 852/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 853/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 854/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 855/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 856/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 857/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 858/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 859/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 860/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 861/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 862/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 863/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 864/1000\n",
      "750/750 [==============================] - 0s 206us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 865/1000\n",
      "750/750 [==============================] - 0s 220us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 866/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 867/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 868/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 869/1000\n",
      "750/750 [==============================] - 0s 215us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 870/1000\n",
      "750/750 [==============================] - 0s 204us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 871/1000\n",
      "750/750 [==============================] - 0s 217us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 872/1000\n",
      "750/750 [==============================] - 0s 196us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 873/1000\n",
      "750/750 [==============================] - 0s 218us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 874/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 875/1000\n",
      "750/750 [==============================] - 0s 207us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 876/1000\n",
      "750/750 [==============================] - 0s 208us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 877/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 878/1000\n",
      "750/750 [==============================] - 0s 211us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 879/1000\n",
      "750/750 [==============================] - 0s 203us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 880/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 881/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 882/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 883/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 884/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 885/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 887/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 888/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 889/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 890/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 891/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 892/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 893/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 894/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 895/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 896/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 897/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 898/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 899/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 900/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 901/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 902/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 903/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 904/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 905/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 906/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 907/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 908/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 909/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 910/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 911/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 912/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 913/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 914/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 915/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 916/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 917/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 918/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 919/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 920/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 921/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 922/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 923/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 924/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 925/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 926/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 927/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 928/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 929/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 930/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 931/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 932/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 933/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 934/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 935/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 936/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 937/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 938/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 939/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 940/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 941/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 942/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 943/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 944/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 945/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 946/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 947/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 948/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 949/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 950/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 951/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 952/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 953/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 954/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 955/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 956/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 957/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 958/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 959/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 960/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 961/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 962/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 963/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 964/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 965/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 966/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 967/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 968/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 969/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 970/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 971/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 972/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 973/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 974/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 975/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 976/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 977/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 978/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 979/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 980/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 981/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 982/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 983/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 984/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 985/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 986/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 987/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 988/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 989/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 990/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 991/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 992/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 993/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 994/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 995/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 996/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 997/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 998/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 999/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n",
      "Epoch 1000/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0020 - acc: 0.9600 - val_loss: 0.0352 - val_acc: 0.3120\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense, Flatten,LSTM, TimeDistributed, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TIME_STEPS = 10\n",
    "INPUT_SIZE = 512\n",
    "BATCH_SIZE = 250\n",
    "BATCH_INDEX = 0\n",
    "OUTPUT_SIZE = 512\n",
    "#CELL_SIZE = 800\n",
    "LR = 0.001\n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "# loading data\n",
    "X_train = np.loadtxt(\"0220_spec_train_1000*5120.txt\")\n",
    "y_train = np.loadtxt(\"0220_mask_train_1000*512.txt\")\n",
    "\n",
    "X_test = np.loadtxt(\"0220_spec_test_1000*5120.txt\")\n",
    "y_test = np.loadtxt(\"0220_mask_test_1000*512.txt\")\n",
    "\n",
    "# batch_size=y_test.shape[0]\n",
    "\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 10, 512)\n",
    "#y_train = y_train.reshape(-1, 3, 512)\n",
    "X_test = X_test.reshape(-1, 10, 512)\n",
    "#y_test = y_test.reshape(-1, 3, 512)\n",
    "\n",
    "\n",
    "#  build RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# RNN cell\n",
    "\n",
    "model.add(LSTM(\n",
    "    units =512,\n",
    "    batch_input_shape=( BATCH_SIZE, TIME_STEPS, INPUT_SIZE),\n",
    "    #input_dim=INPUT_SIZE,\n",
    "    #input_length=TIME_STEPS,\n",
    "    #output_dim=CELL_SIZE,\n",
    "    #return_sequences=True,\n",
    "    #stateful=True \n",
    "    unroll=False\n",
    "))\n",
    "\n",
    "# output layer\n",
    "#model.add(Flatten())\n",
    "model.add((Dense(OUTPUT_SIZE)))  #TimeDistributed\n",
    "model.add(Activation('hard_sigmoid'))\n",
    "#model.add(Dropout(rate = 0.2)) \n",
    "\n",
    "# # optimizer\n",
    "#\n",
    "# optimizer\n",
    "\n",
    "rmsprop = RMSprop(lr=LR, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # training\n",
    "#\n",
    "\n",
    "# for step in range(51):\n",
    "#     # data shape = (batch_num, steps, inputs/outputs)\n",
    "#     X_batch = X_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :, :]\n",
    "#     Y_batch = y_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :]\n",
    "#     cost = model.train_on_batch(X_batch, Y_batch)\n",
    "#     BATCH_INDEX += BATCH_SIZE\n",
    "#     BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "\n",
    "#     if step % 50 == 0:\n",
    "#         print('Next_Train----------: step = ', step)\n",
    "#         train_cost, train_accuracy = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('train_cost: ', train_cost, 'train_accuracy: ', train_accuracy)\n",
    "#         cost, accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "        \n",
    "       \n",
    "\n",
    "print('Train-------------------------')\n",
    "\n",
    "history = model.fit(X_test, y_test, validation_split=0.25, epochs=1000, shuffle=True, batch_size=250, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "#                                   [model.layers[1].output])\n",
    "# layer_output1 = get_3rd_layer_output([X_train])[0]\n",
    "\n",
    "# print(layer_output1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [32,512] vs. [250,512]\n\t [[Node: lstm_2/while/add_7 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_2/while/BiasAdd_3, lstm_2/while/MatMul_7)]]\n\t [[Node: activation_2/clip_by_value/_129 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_249_activation_2/clip_by_value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cd3a18128abf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction of the model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1536\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[0;32m-> 1454\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [32,512] vs. [250,512]\n\t [[Node: lstm_2/while/add_7 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_2/while/BiasAdd_3, lstm_2/while/MatMul_7)]]\n\t [[Node: activation_2/clip_by_value/_129 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_249_activation_2/clip_by_value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "x_pred = model.predict(X_train[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1536)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Predicted_Training_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mask = y_test.reshape(1000,1536)\n",
    "plt.imshow(abs(y_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = model.predict(X_test[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1536)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Predicted_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear_spec_input_250.txt\n",
    "#clear_mask_generated_from_threshold_250.txt\n",
    "\n",
    "y_c = np.loadtxt(\"clear_mask_generated_from_threshold_250.txt\")\n",
    "\n",
    "y_c = y_c.reshape(250,1024)\n",
    "plt.imshow(abs(y_c[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c = np.loadtxt(\"clear_spec_input_250.txt\")\n",
    "\n",
    "\n",
    "x_c = model.predict(x_c)\n",
    "print('prediction of the model', x_c)\n",
    "print('prediction size', x_c.size)\n",
    "\n",
    "x_c = x_c.reshape(250,1024)\n",
    "plt.imshow(abs(x_c[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Predicted_Mask_for_checking\", fontsize = 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
