{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM test by data-10*512 to 1*512\n",
    "# 5000 steps with lr = 0.001\n",
    "# batch size = 500\n",
    "# no dropout\n",
    "# units = 512\n",
    "# This one is using test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are better than\n",
    "best run: \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-------------------------\n",
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/1000\n",
      "750/750 [==============================] - 1s 2ms/step - loss: 0.2019 - acc: 0.0053 - val_loss: 0.0412 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0431 - acc: 0.0013 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0396 - acc: 0.0253 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0394 - acc: 0.0227 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0390 - acc: 0.0120 - val_loss: 0.0315 - val_acc: 0.0240\n",
      "Epoch 6/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0388 - acc: 0.0240 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0386 - acc: 0.0107 - val_loss: 0.0312 - val_acc: 0.0320\n",
      "Epoch 8/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0389 - acc: 0.0240 - val_loss: 0.0308 - val_acc: 0.0280\n",
      "Epoch 9/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0379 - acc: 0.0187 - val_loss: 0.0306 - val_acc: 0.0360\n",
      "Epoch 10/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0378 - acc: 0.0453 - val_loss: 0.0315 - val_acc: 0.0080\n",
      "Epoch 11/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0393 - acc: 0.0027 - val_loss: 0.0299 - val_acc: 0.0360\n",
      "Epoch 12/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0364 - acc: 0.0320 - val_loss: 0.0318 - val_acc: 0.0040\n",
      "Epoch 13/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0383 - acc: 0.0400 - val_loss: 0.0297 - val_acc: 0.0080\n",
      "Epoch 14/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0351 - acc: 0.0147 - val_loss: 0.0293 - val_acc: 0.0280\n",
      "Epoch 15/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0345 - acc: 0.0187 - val_loss: 0.0309 - val_acc: 0.0600\n",
      "Epoch 16/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0379 - acc: 0.0467 - val_loss: 0.0291 - val_acc: 0.0280\n",
      "Epoch 17/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0349 - acc: 0.0213 - val_loss: 0.0287 - val_acc: 0.0480\n",
      "Epoch 18/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0347 - acc: 0.0293 - val_loss: 0.0294 - val_acc: 0.0320\n",
      "Epoch 19/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0335 - acc: 0.0200 - val_loss: 0.0280 - val_acc: 0.0480\n",
      "Epoch 20/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0346 - acc: 0.0280 - val_loss: 0.0302 - val_acc: 0.0520\n",
      "Epoch 21/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0337 - acc: 0.0280 - val_loss: 0.0293 - val_acc: 0.0320\n",
      "Epoch 22/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0339 - acc: 0.0293 - val_loss: 0.0303 - val_acc: 0.0640\n",
      "Epoch 23/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0345 - acc: 0.0307 - val_loss: 0.0287 - val_acc: 0.0400\n",
      "Epoch 24/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0324 - acc: 0.0360 - val_loss: 0.0285 - val_acc: 0.0440\n",
      "Epoch 25/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0313 - acc: 0.0240 - val_loss: 0.0306 - val_acc: 0.0240\n",
      "Epoch 26/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0338 - acc: 0.0213 - val_loss: 0.0286 - val_acc: 0.0840\n",
      "Epoch 27/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0326 - acc: 0.0373 - val_loss: 0.0288 - val_acc: 0.0400\n",
      "Epoch 28/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0312 - acc: 0.0267 - val_loss: 0.0279 - val_acc: 0.0360\n",
      "Epoch 29/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0310 - acc: 0.0267 - val_loss: 0.0317 - val_acc: 0.0240\n",
      "Epoch 30/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0329 - acc: 0.0213 - val_loss: 0.0289 - val_acc: 0.0280\n",
      "Epoch 31/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0323 - acc: 0.0427 - val_loss: 0.0294 - val_acc: 0.0320\n",
      "Epoch 32/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0309 - acc: 0.0333 - val_loss: 0.0277 - val_acc: 0.0480\n",
      "Epoch 33/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0319 - acc: 0.0387 - val_loss: 0.0296 - val_acc: 0.0120\n",
      "Epoch 34/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0309 - acc: 0.0213 - val_loss: 0.0276 - val_acc: 0.0360\n",
      "Epoch 35/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0304 - acc: 0.0387 - val_loss: 0.0287 - val_acc: 0.0480\n",
      "Epoch 36/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0296 - acc: 0.0520 - val_loss: 0.0283 - val_acc: 0.0960\n",
      "Epoch 37/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0312 - acc: 0.0573 - val_loss: 0.0315 - val_acc: 0.0120\n",
      "Epoch 38/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0311 - acc: 0.0120 - val_loss: 0.0273 - val_acc: 0.0600\n",
      "Epoch 39/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0297 - acc: 0.0440 - val_loss: 0.0280 - val_acc: 0.0360\n",
      "Epoch 40/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0287 - acc: 0.0493 - val_loss: 0.0283 - val_acc: 0.0440\n",
      "Epoch 41/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0300 - acc: 0.0907 - val_loss: 0.0336 - val_acc: 0.0600\n",
      "Epoch 42/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0313 - acc: 0.0360 - val_loss: 0.0273 - val_acc: 0.0760\n",
      "Epoch 43/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0292 - acc: 0.0427 - val_loss: 0.0285 - val_acc: 0.0440\n",
      "Epoch 44/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0280 - acc: 0.0413 - val_loss: 0.0278 - val_acc: 0.0600\n",
      "Epoch 45/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0282 - acc: 0.0573 - val_loss: 0.0282 - val_acc: 0.0520\n",
      "Epoch 46/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0288 - acc: 0.0373 - val_loss: 0.0286 - val_acc: 0.1080\n",
      "Epoch 47/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0289 - acc: 0.0760 - val_loss: 0.0310 - val_acc: 0.0280\n",
      "Epoch 48/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0302 - acc: 0.0240 - val_loss: 0.0272 - val_acc: 0.1000\n",
      "Epoch 49/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0293 - acc: 0.0693 - val_loss: 0.0274 - val_acc: 0.0440\n",
      "Epoch 50/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0275 - acc: 0.0253 - val_loss: 0.0267 - val_acc: 0.1160\n",
      "Epoch 51/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0278 - acc: 0.0573 - val_loss: 0.0290 - val_acc: 0.0240\n",
      "Epoch 52/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0276 - acc: 0.0440 - val_loss: 0.0266 - val_acc: 0.0840\n",
      "Epoch 53/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0281 - acc: 0.0453 - val_loss: 0.0284 - val_acc: 0.0320\n",
      "Epoch 54/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0271 - acc: 0.0333 - val_loss: 0.0268 - val_acc: 0.1160\n",
      "Epoch 55/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0272 - acc: 0.0800 - val_loss: 0.0284 - val_acc: 0.0480\n",
      "Epoch 56/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0268 - acc: 0.0360 - val_loss: 0.0267 - val_acc: 0.1040\n",
      "Epoch 57/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0271 - acc: 0.0640 - val_loss: 0.0292 - val_acc: 0.0360\n",
      "Epoch 58/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0266 - acc: 0.0440 - val_loss: 0.0264 - val_acc: 0.1360\n",
      "Epoch 59/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0270 - acc: 0.0627 - val_loss: 0.0285 - val_acc: 0.0440\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 167us/step - loss: 0.0258 - acc: 0.0467 - val_loss: 0.0273 - val_acc: 0.0840\n",
      "Epoch 61/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0255 - acc: 0.0787 - val_loss: 0.0297 - val_acc: 0.0440\n",
      "Epoch 62/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0272 - acc: 0.0533 - val_loss: 0.0271 - val_acc: 0.1080\n",
      "Epoch 63/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0278 - acc: 0.0800 - val_loss: 0.0288 - val_acc: 0.0240\n",
      "Epoch 64/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0251 - acc: 0.0360 - val_loss: 0.0270 - val_acc: 0.0360\n",
      "Epoch 65/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0252 - acc: 0.0587 - val_loss: 0.0287 - val_acc: 0.0800\n",
      "Epoch 66/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0259 - acc: 0.0813 - val_loss: 0.0267 - val_acc: 0.1440\n",
      "Epoch 67/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0255 - acc: 0.1093 - val_loss: 0.0286 - val_acc: 0.0560\n",
      "Epoch 68/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0247 - acc: 0.0720 - val_loss: 0.0267 - val_acc: 0.1200\n",
      "Epoch 69/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0249 - acc: 0.0720 - val_loss: 0.0282 - val_acc: 0.0480\n",
      "Epoch 70/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0241 - acc: 0.0653 - val_loss: 0.0265 - val_acc: 0.1000\n",
      "Epoch 71/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0244 - acc: 0.0827 - val_loss: 0.0290 - val_acc: 0.0880\n",
      "Epoch 72/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0248 - acc: 0.1013 - val_loss: 0.0265 - val_acc: 0.1600\n",
      "Epoch 73/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0252 - acc: 0.1173 - val_loss: 0.0282 - val_acc: 0.0520\n",
      "Epoch 74/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0235 - acc: 0.0653 - val_loss: 0.0268 - val_acc: 0.0920\n",
      "Epoch 75/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0240 - acc: 0.0920 - val_loss: 0.0292 - val_acc: 0.0600\n",
      "Epoch 76/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0250 - acc: 0.1080 - val_loss: 0.0265 - val_acc: 0.0800\n",
      "Epoch 77/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0240 - acc: 0.1000 - val_loss: 0.0278 - val_acc: 0.0960\n",
      "Epoch 78/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0224 - acc: 0.0880 - val_loss: 0.0271 - val_acc: 0.1080\n",
      "Epoch 79/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0224 - acc: 0.1280 - val_loss: 0.0294 - val_acc: 0.1040\n",
      "Epoch 80/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0241 - acc: 0.0933 - val_loss: 0.0277 - val_acc: 0.1720\n",
      "Epoch 81/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0235 - acc: 0.1333 - val_loss: 0.0285 - val_acc: 0.1400\n",
      "Epoch 82/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0226 - acc: 0.1067 - val_loss: 0.0266 - val_acc: 0.1640\n",
      "Epoch 83/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0221 - acc: 0.1040 - val_loss: 0.0283 - val_acc: 0.1240\n",
      "Epoch 84/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0231 - acc: 0.1040 - val_loss: 0.0263 - val_acc: 0.1600\n",
      "Epoch 85/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0228 - acc: 0.0973 - val_loss: 0.0298 - val_acc: 0.1400\n",
      "Epoch 86/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0220 - acc: 0.1253 - val_loss: 0.0275 - val_acc: 0.2200\n",
      "Epoch 87/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0220 - acc: 0.1333 - val_loss: 0.0277 - val_acc: 0.1360\n",
      "Epoch 88/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0218 - acc: 0.1107 - val_loss: 0.0274 - val_acc: 0.1160\n",
      "Epoch 89/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0212 - acc: 0.1333 - val_loss: 0.0278 - val_acc: 0.1680\n",
      "Epoch 90/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0210 - acc: 0.0960 - val_loss: 0.0271 - val_acc: 0.1720\n",
      "Epoch 91/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0207 - acc: 0.1347 - val_loss: 0.0292 - val_acc: 0.1440\n",
      "Epoch 92/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0227 - acc: 0.1373 - val_loss: 0.0262 - val_acc: 0.1680\n",
      "Epoch 93/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0230 - acc: 0.1373 - val_loss: 0.0299 - val_acc: 0.1160\n",
      "Epoch 94/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0206 - acc: 0.0973 - val_loss: 0.0275 - val_acc: 0.1240\n",
      "Epoch 95/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0198 - acc: 0.1280 - val_loss: 0.0275 - val_acc: 0.1320\n",
      "Epoch 96/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0198 - acc: 0.1147 - val_loss: 0.0282 - val_acc: 0.2040\n",
      "Epoch 97/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0200 - acc: 0.1680 - val_loss: 0.0289 - val_acc: 0.1560\n",
      "Epoch 98/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0205 - acc: 0.1520 - val_loss: 0.0268 - val_acc: 0.2120\n",
      "Epoch 99/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0203 - acc: 0.1360 - val_loss: 0.0294 - val_acc: 0.1240\n",
      "Epoch 100/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0202 - acc: 0.1227 - val_loss: 0.0271 - val_acc: 0.2200\n",
      "Epoch 101/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0192 - acc: 0.1293 - val_loss: 0.0285 - val_acc: 0.1640\n",
      "Epoch 102/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0195 - acc: 0.1387 - val_loss: 0.0271 - val_acc: 0.2400\n",
      "Epoch 103/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0196 - acc: 0.1627 - val_loss: 0.0295 - val_acc: 0.2040\n",
      "Epoch 104/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0194 - acc: 0.1267 - val_loss: 0.0287 - val_acc: 0.1760\n",
      "Epoch 105/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0185 - acc: 0.1760 - val_loss: 0.0280 - val_acc: 0.1960\n",
      "Epoch 106/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0184 - acc: 0.1453 - val_loss: 0.0279 - val_acc: 0.1760\n",
      "Epoch 107/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0195 - acc: 0.1347 - val_loss: 0.0284 - val_acc: 0.2720\n",
      "Epoch 108/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0188 - acc: 0.1853 - val_loss: 0.0298 - val_acc: 0.1720\n",
      "Epoch 109/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0181 - acc: 0.1547 - val_loss: 0.0277 - val_acc: 0.2400\n",
      "Epoch 110/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0190 - acc: 0.1733 - val_loss: 0.0303 - val_acc: 0.1200\n",
      "Epoch 111/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0190 - acc: 0.1533 - val_loss: 0.0271 - val_acc: 0.1960\n",
      "Epoch 112/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0171 - acc: 0.1600 - val_loss: 0.0288 - val_acc: 0.1800\n",
      "Epoch 113/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0168 - acc: 0.1640 - val_loss: 0.0291 - val_acc: 0.1800\n",
      "Epoch 114/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0170 - acc: 0.1680 - val_loss: 0.0299 - val_acc: 0.2680\n",
      "Epoch 115/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0173 - acc: 0.2147 - val_loss: 0.0302 - val_acc: 0.1880\n",
      "Epoch 116/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0182 - acc: 0.1333 - val_loss: 0.0281 - val_acc: 0.2440\n",
      "Epoch 117/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0179 - acc: 0.2040 - val_loss: 0.0315 - val_acc: 0.2040\n",
      "Epoch 118/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0176 - acc: 0.1760 - val_loss: 0.0283 - val_acc: 0.2160\n",
      "Epoch 119/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0164 - acc: 0.1733 - val_loss: 0.0302 - val_acc: 0.1760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0158 - acc: 0.1867 - val_loss: 0.0294 - val_acc: 0.2000\n",
      "Epoch 121/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0157 - acc: 0.1773 - val_loss: 0.0301 - val_acc: 0.1600\n",
      "Epoch 122/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0160 - acc: 0.2040 - val_loss: 0.0298 - val_acc: 0.2320\n",
      "Epoch 123/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0159 - acc: 0.2067 - val_loss: 0.0307 - val_acc: 0.2000\n",
      "Epoch 124/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0164 - acc: 0.1987 - val_loss: 0.0302 - val_acc: 0.2240\n",
      "Epoch 125/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0156 - acc: 0.2360 - val_loss: 0.0313 - val_acc: 0.1800\n",
      "Epoch 126/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0156 - acc: 0.1680 - val_loss: 0.0298 - val_acc: 0.2360\n",
      "Epoch 127/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0154 - acc: 0.1947 - val_loss: 0.0296 - val_acc: 0.1600\n",
      "Epoch 128/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0147 - acc: 0.1773 - val_loss: 0.0298 - val_acc: 0.1920\n",
      "Epoch 129/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0144 - acc: 0.2027 - val_loss: 0.0309 - val_acc: 0.2000\n",
      "Epoch 130/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0144 - acc: 0.1920 - val_loss: 0.0291 - val_acc: 0.2120\n",
      "Epoch 131/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0143 - acc: 0.2173 - val_loss: 0.0311 - val_acc: 0.1680\n",
      "Epoch 132/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0153 - acc: 0.2253 - val_loss: 0.0286 - val_acc: 0.2280\n",
      "Epoch 133/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0142 - acc: 0.2213 - val_loss: 0.0304 - val_acc: 0.1960\n",
      "Epoch 134/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0135 - acc: 0.2413 - val_loss: 0.0310 - val_acc: 0.2000\n",
      "Epoch 135/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0135 - acc: 0.2440 - val_loss: 0.0299 - val_acc: 0.2160\n",
      "Epoch 136/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0137 - acc: 0.2040 - val_loss: 0.0313 - val_acc: 0.2000\n",
      "Epoch 137/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0140 - acc: 0.2333 - val_loss: 0.0321 - val_acc: 0.1680\n",
      "Epoch 138/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0136 - acc: 0.2120 - val_loss: 0.0288 - val_acc: 0.2360\n",
      "Epoch 139/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0130 - acc: 0.2440 - val_loss: 0.0307 - val_acc: 0.2040\n",
      "Epoch 140/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0125 - acc: 0.2293 - val_loss: 0.0300 - val_acc: 0.2240\n",
      "Epoch 141/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0123 - acc: 0.2240 - val_loss: 0.0311 - val_acc: 0.2160\n",
      "Epoch 142/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0119 - acc: 0.2267 - val_loss: 0.0321 - val_acc: 0.1960\n",
      "Epoch 143/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0126 - acc: 0.2320 - val_loss: 0.0328 - val_acc: 0.2320\n",
      "Epoch 144/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0122 - acc: 0.2453 - val_loss: 0.0304 - val_acc: 0.2120\n",
      "Epoch 145/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0121 - acc: 0.2547 - val_loss: 0.0327 - val_acc: 0.2400\n",
      "Epoch 146/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0116 - acc: 0.2480 - val_loss: 0.0317 - val_acc: 0.1920\n",
      "Epoch 147/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0115 - acc: 0.2320 - val_loss: 0.0302 - val_acc: 0.2240\n",
      "Epoch 148/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0114 - acc: 0.2400 - val_loss: 0.0320 - val_acc: 0.2240\n",
      "Epoch 149/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0115 - acc: 0.2573 - val_loss: 0.0311 - val_acc: 0.1880\n",
      "Epoch 150/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0120 - acc: 0.2827 - val_loss: 0.0344 - val_acc: 0.2080\n",
      "Epoch 151/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0116 - acc: 0.2467 - val_loss: 0.0285 - val_acc: 0.1960\n",
      "Epoch 152/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0108 - acc: 0.2693 - val_loss: 0.0307 - val_acc: 0.1760\n",
      "Epoch 153/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0102 - acc: 0.2467 - val_loss: 0.0300 - val_acc: 0.2040\n",
      "Epoch 154/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0097 - acc: 0.2733 - val_loss: 0.0312 - val_acc: 0.2040\n",
      "Epoch 155/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0100 - acc: 0.2640 - val_loss: 0.0311 - val_acc: 0.2320\n",
      "Epoch 156/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0098 - acc: 0.2720 - val_loss: 0.0321 - val_acc: 0.2040\n",
      "Epoch 157/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0096 - acc: 0.2533 - val_loss: 0.0307 - val_acc: 0.2200\n",
      "Epoch 158/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0099 - acc: 0.2600 - val_loss: 0.0354 - val_acc: 0.2400\n",
      "Epoch 159/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0107 - acc: 0.2893 - val_loss: 0.0298 - val_acc: 0.2680\n",
      "Epoch 160/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0109 - acc: 0.3293 - val_loss: 0.0315 - val_acc: 0.1880\n",
      "Epoch 161/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0092 - acc: 0.2773 - val_loss: 0.0303 - val_acc: 0.2200\n",
      "Epoch 162/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0086 - acc: 0.2880 - val_loss: 0.0313 - val_acc: 0.2320\n",
      "Epoch 163/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0085 - acc: 0.2760 - val_loss: 0.0325 - val_acc: 0.2240\n",
      "Epoch 164/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0084 - acc: 0.2800 - val_loss: 0.0318 - val_acc: 0.2240\n",
      "Epoch 165/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0083 - acc: 0.3080 - val_loss: 0.0331 - val_acc: 0.2160\n",
      "Epoch 166/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0088 - acc: 0.2707 - val_loss: 0.0317 - val_acc: 0.1960\n",
      "Epoch 167/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0087 - acc: 0.2867 - val_loss: 0.0333 - val_acc: 0.2440\n",
      "Epoch 168/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0079 - acc: 0.3053 - val_loss: 0.0309 - val_acc: 0.2360\n",
      "Epoch 169/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0078 - acc: 0.2947 - val_loss: 0.0342 - val_acc: 0.2200\n",
      "Epoch 170/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0082 - acc: 0.2893 - val_loss: 0.0323 - val_acc: 0.2560\n",
      "Epoch 171/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0089 - acc: 0.2707 - val_loss: 0.0329 - val_acc: 0.2320\n",
      "Epoch 172/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0085 - acc: 0.3080 - val_loss: 0.0340 - val_acc: 0.2160\n",
      "Epoch 173/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0080 - acc: 0.3040 - val_loss: 0.0298 - val_acc: 0.2320\n",
      "Epoch 174/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0075 - acc: 0.3467 - val_loss: 0.0340 - val_acc: 0.2200\n",
      "Epoch 175/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0069 - acc: 0.3320 - val_loss: 0.0318 - val_acc: 0.2520\n",
      "Epoch 176/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0069 - acc: 0.3413 - val_loss: 0.0342 - val_acc: 0.2160\n",
      "Epoch 177/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0070 - acc: 0.3293 - val_loss: 0.0327 - val_acc: 0.2560\n",
      "Epoch 178/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0070 - acc: 0.3747 - val_loss: 0.0344 - val_acc: 0.2480\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 168us/step - loss: 0.0071 - acc: 0.3120 - val_loss: 0.0326 - val_acc: 0.2000\n",
      "Epoch 180/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0064 - acc: 0.3200 - val_loss: 0.0335 - val_acc: 0.2480\n",
      "Epoch 181/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0063 - acc: 0.3147 - val_loss: 0.0324 - val_acc: 0.2560\n",
      "Epoch 182/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0064 - acc: 0.3427 - val_loss: 0.0340 - val_acc: 0.2400\n",
      "Epoch 183/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0068 - acc: 0.3347 - val_loss: 0.0321 - val_acc: 0.2440\n",
      "Epoch 184/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0070 - acc: 0.3507 - val_loss: 0.0359 - val_acc: 0.2440\n",
      "Epoch 185/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0065 - acc: 0.3213 - val_loss: 0.0315 - val_acc: 0.2400\n",
      "Epoch 186/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0060 - acc: 0.3507 - val_loss: 0.0336 - val_acc: 0.2320\n",
      "Epoch 187/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0056 - acc: 0.3373 - val_loss: 0.0312 - val_acc: 0.2440\n",
      "Epoch 188/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0055 - acc: 0.3587 - val_loss: 0.0343 - val_acc: 0.2680\n",
      "Epoch 189/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0053 - acc: 0.3440 - val_loss: 0.0323 - val_acc: 0.2480\n",
      "Epoch 190/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0055 - acc: 0.3960 - val_loss: 0.0342 - val_acc: 0.2840\n",
      "Epoch 191/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0059 - acc: 0.3640 - val_loss: 0.0350 - val_acc: 0.2720\n",
      "Epoch 192/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0052 - acc: 0.3800 - val_loss: 0.0301 - val_acc: 0.2400\n",
      "Epoch 193/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0055 - acc: 0.3947 - val_loss: 0.0341 - val_acc: 0.2480\n",
      "Epoch 194/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0062 - acc: 0.3507 - val_loss: 0.0321 - val_acc: 0.2800\n",
      "Epoch 195/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0053 - acc: 0.4147 - val_loss: 0.0342 - val_acc: 0.2400\n",
      "Epoch 196/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0046 - acc: 0.4133 - val_loss: 0.0327 - val_acc: 0.2560\n",
      "Epoch 197/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0045 - acc: 0.4427 - val_loss: 0.0339 - val_acc: 0.2520\n",
      "Epoch 198/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0046 - acc: 0.3973 - val_loss: 0.0335 - val_acc: 0.2800\n",
      "Epoch 199/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0053 - acc: 0.4173 - val_loss: 0.0345 - val_acc: 0.2800\n",
      "Epoch 200/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0053 - acc: 0.4040 - val_loss: 0.0336 - val_acc: 0.2560\n",
      "Epoch 201/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0050 - acc: 0.4053 - val_loss: 0.0331 - val_acc: 0.2840\n",
      "Epoch 202/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0047 - acc: 0.4600 - val_loss: 0.0352 - val_acc: 0.2560\n",
      "Epoch 203/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0042 - acc: 0.4147 - val_loss: 0.0322 - val_acc: 0.2920\n",
      "Epoch 204/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0040 - acc: 0.4693 - val_loss: 0.0354 - val_acc: 0.2600\n",
      "Epoch 205/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0040 - acc: 0.4373 - val_loss: 0.0336 - val_acc: 0.2880\n",
      "Epoch 206/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0042 - acc: 0.4533 - val_loss: 0.0356 - val_acc: 0.2640\n",
      "Epoch 207/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0045 - acc: 0.4387 - val_loss: 0.0339 - val_acc: 0.3120\n",
      "Epoch 208/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0048 - acc: 0.4400 - val_loss: 0.0365 - val_acc: 0.2760\n",
      "Epoch 209/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0042 - acc: 0.4733 - val_loss: 0.0326 - val_acc: 0.2560\n",
      "Epoch 210/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0038 - acc: 0.4973 - val_loss: 0.0352 - val_acc: 0.2640\n",
      "Epoch 211/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0036 - acc: 0.5000 - val_loss: 0.0331 - val_acc: 0.2960\n",
      "Epoch 212/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0037 - acc: 0.4840 - val_loss: 0.0356 - val_acc: 0.2640\n",
      "Epoch 213/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0041 - acc: 0.4707 - val_loss: 0.0319 - val_acc: 0.2800\n",
      "Epoch 214/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0047 - acc: 0.4907 - val_loss: 0.0364 - val_acc: 0.2680\n",
      "Epoch 215/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0051 - acc: 0.4320 - val_loss: 0.0309 - val_acc: 0.2520\n",
      "Epoch 216/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0037 - acc: 0.5040 - val_loss: 0.0338 - val_acc: 0.2800\n",
      "Epoch 217/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0033 - acc: 0.5227 - val_loss: 0.0340 - val_acc: 0.2880\n",
      "Epoch 218/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0032 - acc: 0.5333 - val_loss: 0.0337 - val_acc: 0.2840\n",
      "Epoch 219/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0031 - acc: 0.5400 - val_loss: 0.0347 - val_acc: 0.2920\n",
      "Epoch 220/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0032 - acc: 0.5227 - val_loss: 0.0339 - val_acc: 0.2800\n",
      "Epoch 221/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0037 - acc: 0.4987 - val_loss: 0.0368 - val_acc: 0.2400\n",
      "Epoch 222/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0055 - acc: 0.4400 - val_loss: 0.0332 - val_acc: 0.2760\n",
      "Epoch 223/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0045 - acc: 0.5520 - val_loss: 0.0344 - val_acc: 0.3040\n",
      "Epoch 224/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0033 - acc: 0.5640 - val_loss: 0.0339 - val_acc: 0.3160\n",
      "Epoch 225/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0030 - acc: 0.5853 - val_loss: 0.0339 - val_acc: 0.3080\n",
      "Epoch 226/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0029 - acc: 0.5933 - val_loss: 0.0343 - val_acc: 0.3040\n",
      "Epoch 227/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0028 - acc: 0.5907 - val_loss: 0.0342 - val_acc: 0.3040\n",
      "Epoch 228/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0028 - acc: 0.5893 - val_loss: 0.0348 - val_acc: 0.2880\n",
      "Epoch 229/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0030 - acc: 0.5493 - val_loss: 0.0352 - val_acc: 0.2720\n",
      "Epoch 230/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0035 - acc: 0.5147 - val_loss: 0.0385 - val_acc: 0.2840\n",
      "Epoch 231/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0038 - acc: 0.5227 - val_loss: 0.0344 - val_acc: 0.2680\n",
      "Epoch 232/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0032 - acc: 0.6000 - val_loss: 0.0337 - val_acc: 0.2680\n",
      "Epoch 233/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0031 - acc: 0.6067 - val_loss: 0.0342 - val_acc: 0.2960\n",
      "Epoch 234/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0030 - acc: 0.5973 - val_loss: 0.0333 - val_acc: 0.3200\n",
      "Epoch 235/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0026 - acc: 0.6507 - val_loss: 0.0336 - val_acc: 0.2840\n",
      "Epoch 236/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0025 - acc: 0.6467 - val_loss: 0.0345 - val_acc: 0.2720\n",
      "Epoch 237/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0025 - acc: 0.6653 - val_loss: 0.0347 - val_acc: 0.2960\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 168us/step - loss: 0.0026 - acc: 0.6373 - val_loss: 0.0353 - val_acc: 0.3080\n",
      "Epoch 239/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0032 - acc: 0.5840 - val_loss: 0.0325 - val_acc: 0.2520\n",
      "Epoch 240/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0044 - acc: 0.4960 - val_loss: 0.0384 - val_acc: 0.2560\n",
      "Epoch 241/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0036 - acc: 0.5480 - val_loss: 0.0319 - val_acc: 0.2880\n",
      "Epoch 242/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0027 - acc: 0.6400 - val_loss: 0.0344 - val_acc: 0.2720\n",
      "Epoch 243/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0025 - acc: 0.6947 - val_loss: 0.0340 - val_acc: 0.3120\n",
      "Epoch 244/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.7000 - val_loss: 0.0341 - val_acc: 0.3120\n",
      "Epoch 245/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.7013 - val_loss: 0.0341 - val_acc: 0.2880\n",
      "Epoch 246/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0024 - acc: 0.7267 - val_loss: 0.0342 - val_acc: 0.3040\n",
      "Epoch 247/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0024 - acc: 0.7227 - val_loss: 0.0343 - val_acc: 0.2920\n",
      "Epoch 248/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0024 - acc: 0.7173 - val_loss: 0.0343 - val_acc: 0.2720\n",
      "Epoch 249/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0027 - acc: 0.6480 - val_loss: 0.0371 - val_acc: 0.3040\n",
      "Epoch 250/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0042 - acc: 0.5333 - val_loss: 0.0296 - val_acc: 0.2640\n",
      "Epoch 251/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0044 - acc: 0.5707 - val_loss: 0.0331 - val_acc: 0.2920\n",
      "Epoch 252/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0027 - acc: 0.6427 - val_loss: 0.0340 - val_acc: 0.2880\n",
      "Epoch 253/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0024 - acc: 0.7080 - val_loss: 0.0340 - val_acc: 0.2960\n",
      "Epoch 254/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0023 - acc: 0.7373 - val_loss: 0.0340 - val_acc: 0.2920\n",
      "Epoch 255/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0023 - acc: 0.7373 - val_loss: 0.0340 - val_acc: 0.2880\n",
      "Epoch 256/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0023 - acc: 0.7520 - val_loss: 0.0341 - val_acc: 0.2920\n",
      "Epoch 257/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0023 - acc: 0.7560 - val_loss: 0.0341 - val_acc: 0.3080\n",
      "Epoch 258/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.7520 - val_loss: 0.0343 - val_acc: 0.3080\n",
      "Epoch 259/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.7360 - val_loss: 0.0344 - val_acc: 0.3000\n",
      "Epoch 260/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.7747 - val_loss: 0.0347 - val_acc: 0.3280\n",
      "Epoch 261/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0036 - acc: 0.5947 - val_loss: 0.0359 - val_acc: 0.2800\n",
      "Epoch 262/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0038 - acc: 0.5640 - val_loss: 0.0362 - val_acc: 0.3040\n",
      "Epoch 263/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0025 - acc: 0.7213 - val_loss: 0.0353 - val_acc: 0.2800\n",
      "Epoch 264/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0024 - acc: 0.7707 - val_loss: 0.0350 - val_acc: 0.2760\n",
      "Epoch 265/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0023 - acc: 0.8253 - val_loss: 0.0350 - val_acc: 0.2720\n",
      "Epoch 266/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.7947 - val_loss: 0.0348 - val_acc: 0.2720\n",
      "Epoch 267/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.8440 - val_loss: 0.0350 - val_acc: 0.2680\n",
      "Epoch 268/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8227 - val_loss: 0.0350 - val_acc: 0.2720\n",
      "Epoch 269/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8333 - val_loss: 0.0349 - val_acc: 0.2720\n",
      "Epoch 270/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0023 - acc: 0.8293 - val_loss: 0.0349 - val_acc: 0.2800\n",
      "Epoch 271/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0023 - acc: 0.8320 - val_loss: 0.0349 - val_acc: 0.2720\n",
      "Epoch 272/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0023 - acc: 0.8413 - val_loss: 0.0352 - val_acc: 0.2680\n",
      "Epoch 273/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.8173 - val_loss: 0.0353 - val_acc: 0.3080\n",
      "Epoch 274/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0041 - acc: 0.6200 - val_loss: 0.0407 - val_acc: 0.2760\n",
      "Epoch 275/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0038 - acc: 0.5760 - val_loss: 0.0373 - val_acc: 0.2400\n",
      "Epoch 276/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0026 - acc: 0.6667 - val_loss: 0.0347 - val_acc: 0.3080\n",
      "Epoch 277/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.7920 - val_loss: 0.0352 - val_acc: 0.3080\n",
      "Epoch 278/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.7987 - val_loss: 0.0351 - val_acc: 0.3040\n",
      "Epoch 279/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0023 - acc: 0.8133 - val_loss: 0.0351 - val_acc: 0.3040\n",
      "Epoch 280/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.8240 - val_loss: 0.0351 - val_acc: 0.3040\n",
      "Epoch 281/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.8307 - val_loss: 0.0351 - val_acc: 0.3040\n",
      "Epoch 282/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.8320 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 283/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.8400 - val_loss: 0.0351 - val_acc: 0.3040\n",
      "Epoch 284/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.8373 - val_loss: 0.0350 - val_acc: 0.3000\n",
      "Epoch 285/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.8560 - val_loss: 0.0351 - val_acc: 0.3160\n",
      "Epoch 286/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.8573 - val_loss: 0.0350 - val_acc: 0.2840\n",
      "Epoch 287/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.8253 - val_loss: 0.0365 - val_acc: 0.3160\n",
      "Epoch 288/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0044 - acc: 0.5960 - val_loss: 0.0332 - val_acc: 0.3280\n",
      "Epoch 289/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0036 - acc: 0.6387 - val_loss: 0.0351 - val_acc: 0.2800\n",
      "Epoch 290/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0024 - acc: 0.7733 - val_loss: 0.0346 - val_acc: 0.2840\n",
      "Epoch 291/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.8267 - val_loss: 0.0347 - val_acc: 0.2880\n",
      "Epoch 292/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.8467 - val_loss: 0.0348 - val_acc: 0.2920\n",
      "Epoch 293/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0022 - acc: 0.8493 - val_loss: 0.0348 - val_acc: 0.2920\n",
      "Epoch 294/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.8587 - val_loss: 0.0348 - val_acc: 0.2920\n",
      "Epoch 295/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.8640 - val_loss: 0.0348 - val_acc: 0.2880\n",
      "Epoch 296/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.8667 - val_loss: 0.0348 - val_acc: 0.2880\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 185us/step - loss: 0.0022 - acc: 0.8693 - val_loss: 0.0349 - val_acc: 0.2880\n",
      "Epoch 298/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.8707 - val_loss: 0.0349 - val_acc: 0.2960\n",
      "Epoch 299/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.8707 - val_loss: 0.0349 - val_acc: 0.2920\n",
      "Epoch 300/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.8773 - val_loss: 0.0348 - val_acc: 0.2920\n",
      "Epoch 301/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9000 - val_loss: 0.0348 - val_acc: 0.2800\n",
      "Epoch 302/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.8920 - val_loss: 0.0349 - val_acc: 0.2880\n",
      "Epoch 303/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9040 - val_loss: 0.0349 - val_acc: 0.2800\n",
      "Epoch 304/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0023 - acc: 0.8187 - val_loss: 0.0348 - val_acc: 0.2760\n",
      "Epoch 305/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0054 - acc: 0.5200 - val_loss: 0.0367 - val_acc: 0.2520\n",
      "Epoch 306/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0043 - acc: 0.6013 - val_loss: 0.0332 - val_acc: 0.3400\n",
      "Epoch 307/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0025 - acc: 0.8027 - val_loss: 0.0338 - val_acc: 0.3000\n",
      "Epoch 308/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0023 - acc: 0.8213 - val_loss: 0.0337 - val_acc: 0.3080\n",
      "Epoch 309/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.8387 - val_loss: 0.0337 - val_acc: 0.2960\n",
      "Epoch 310/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.8560 - val_loss: 0.0337 - val_acc: 0.2960\n",
      "Epoch 311/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.8613 - val_loss: 0.0338 - val_acc: 0.2960\n",
      "Epoch 312/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.8653 - val_loss: 0.0338 - val_acc: 0.2960\n",
      "Epoch 313/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.8680 - val_loss: 0.0338 - val_acc: 0.3000\n",
      "Epoch 314/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.8787 - val_loss: 0.0338 - val_acc: 0.3040\n",
      "Epoch 315/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.8773 - val_loss: 0.0338 - val_acc: 0.3040\n",
      "Epoch 316/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.8827 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 317/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.8880 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 318/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.8920 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 319/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.8947 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 320/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9027 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 321/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9053 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 322/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9160 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 323/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9187 - val_loss: 0.0338 - val_acc: 0.3040\n",
      "Epoch 324/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9280 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 325/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9267 - val_loss: 0.0338 - val_acc: 0.3000\n",
      "Epoch 326/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9253 - val_loss: 0.0338 - val_acc: 0.3040\n",
      "Epoch 327/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0034 - acc: 0.7267 - val_loss: 0.0416 - val_acc: 0.2640\n",
      "Epoch 328/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0059 - acc: 0.5760 - val_loss: 0.0323 - val_acc: 0.2880\n",
      "Epoch 329/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0025 - acc: 0.7360 - val_loss: 0.0341 - val_acc: 0.3160\n",
      "Epoch 330/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.8080 - val_loss: 0.0337 - val_acc: 0.3240\n",
      "Epoch 331/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.8227 - val_loss: 0.0338 - val_acc: 0.3280\n",
      "Epoch 332/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.8400 - val_loss: 0.0337 - val_acc: 0.3320\n",
      "Epoch 333/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.8493 - val_loss: 0.0338 - val_acc: 0.3320\n",
      "Epoch 334/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.8560 - val_loss: 0.0337 - val_acc: 0.3320\n",
      "Epoch 335/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.8707 - val_loss: 0.0338 - val_acc: 0.3320\n",
      "Epoch 336/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.8787 - val_loss: 0.0338 - val_acc: 0.3360\n",
      "Epoch 337/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.8867 - val_loss: 0.0336 - val_acc: 0.3120\n",
      "Epoch 338/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0025 - acc: 0.7787 - val_loss: 0.0359 - val_acc: 0.2920\n",
      "Epoch 339/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0029 - acc: 0.7067 - val_loss: 0.0334 - val_acc: 0.3040\n",
      "Epoch 340/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0028 - acc: 0.6947 - val_loss: 0.0342 - val_acc: 0.3200\n",
      "Epoch 341/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.8693 - val_loss: 0.0342 - val_acc: 0.3360\n",
      "Epoch 342/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.8840 - val_loss: 0.0341 - val_acc: 0.3280\n",
      "Epoch 343/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0022 - acc: 0.9107 - val_loss: 0.0340 - val_acc: 0.3400\n",
      "Epoch 344/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9200 - val_loss: 0.0341 - val_acc: 0.3280\n",
      "Epoch 345/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9053 - val_loss: 0.0341 - val_acc: 0.3400\n",
      "Epoch 346/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9107 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 347/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9133 - val_loss: 0.0341 - val_acc: 0.3320\n",
      "Epoch 348/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9093 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 349/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9267 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 350/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9240 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 351/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9413 - val_loss: 0.0341 - val_acc: 0.3320\n",
      "Epoch 352/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9413 - val_loss: 0.0341 - val_acc: 0.3400\n",
      "Epoch 353/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9413 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 354/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9493 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 355/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9467 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 184us/step - loss: 0.0022 - acc: 0.9520 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 357/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9520 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 358/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 359/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 360/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9560 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 361/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 362/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 363/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 364/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 365/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 366/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 367/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 368/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 369/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 370/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 371/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 372/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 373/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 374/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 375/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 376/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 377/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 378/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 379/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 380/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 381/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 382/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 383/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 384/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 385/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 386/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 387/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 388/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 389/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 390/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 391/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 392/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 393/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 394/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 395/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 396/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 397/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 398/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 399/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 400/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 401/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 402/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 403/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 404/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 405/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 406/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 407/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 408/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 409/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 410/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 411/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 412/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 413/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 414/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 416/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 417/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 418/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 419/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 420/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 421/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 422/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 423/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 424/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 425/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 426/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 427/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 428/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 429/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 430/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 431/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 432/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 433/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 434/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 435/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 436/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 437/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 438/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 439/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 440/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 441/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 442/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 443/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 444/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 445/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 446/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 447/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 448/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 449/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 450/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 451/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 452/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 453/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 454/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 455/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 456/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 457/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 458/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 459/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 460/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 461/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 462/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 463/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 464/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 465/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 466/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 467/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 468/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 469/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 470/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 471/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 472/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 473/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 475/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 476/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 477/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 478/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 479/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 480/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 481/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 482/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 483/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 484/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 485/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 486/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 487/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 488/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 489/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 490/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 491/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 492/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 493/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 494/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 495/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 496/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 497/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 498/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 499/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 500/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 501/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 502/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 503/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 504/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 505/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 506/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 507/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 508/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 509/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 510/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 511/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 512/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 513/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 514/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 515/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 516/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 517/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 518/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 519/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 520/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 521/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 522/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 523/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 524/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 525/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 526/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 527/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 528/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 529/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 530/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 531/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 532/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 534/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 535/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 536/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 537/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 538/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 539/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 540/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 541/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 542/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 543/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 544/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 545/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 546/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 547/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 548/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 549/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 550/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 551/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 552/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 553/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 554/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 555/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 556/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 557/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 558/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 559/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 560/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 561/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 562/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 563/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 564/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 565/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 566/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 567/1000\n",
      "750/750 [==============================] - 0s 159us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 568/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 569/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 570/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 571/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 572/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 573/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 574/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 575/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 576/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 577/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 578/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 579/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 580/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 581/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 582/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 583/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 584/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 585/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 586/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 587/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 588/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 589/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 590/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 591/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 593/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 594/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 595/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 596/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 597/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 598/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 599/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 600/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 601/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 602/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 603/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 604/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 605/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 606/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 607/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 608/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 609/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 610/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 611/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 612/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 613/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 614/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 615/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 616/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 617/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 618/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 619/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 620/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 621/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 622/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 623/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 624/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 625/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 626/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 627/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 628/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 629/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 630/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 631/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 632/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 633/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 634/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 635/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 636/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 637/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 638/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 639/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 640/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 641/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 642/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 643/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 644/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 645/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 646/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 647/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 648/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 649/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 650/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 652/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 653/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 654/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 655/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 656/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 657/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 658/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 659/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 660/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 661/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 662/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 663/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 664/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 665/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 666/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 667/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 668/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 669/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 670/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 671/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 672/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 673/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 674/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 675/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 676/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 677/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 678/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 679/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 680/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 681/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 682/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 683/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 684/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 685/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 686/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 687/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 688/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 689/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 690/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 691/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 692/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 693/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 694/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 695/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 696/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 697/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 698/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 699/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 700/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 701/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 702/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 703/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 704/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 705/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 706/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 707/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 708/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 709/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 711/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 712/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 713/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 714/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 715/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 716/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 717/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 718/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 719/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 720/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 721/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 722/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 723/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 724/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 725/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 726/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 727/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 728/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 729/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 730/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 731/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 732/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 733/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 734/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 735/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 736/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 737/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 738/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 739/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 740/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 741/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 742/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 743/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 744/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 745/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 746/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 747/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 748/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 749/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 750/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 751/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 752/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 753/1000\n",
      "750/750 [==============================] - 0s 159us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 754/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 755/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 756/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 757/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 758/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 759/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 760/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 761/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 762/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 763/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 764/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 765/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 766/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 767/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 768/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 770/1000\n",
      "750/750 [==============================] - 0s 159us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 771/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 772/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 773/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 774/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 775/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 776/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 777/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 778/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 779/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 780/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 781/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 782/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 783/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 784/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 785/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 786/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 787/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 788/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 789/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 790/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 791/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 792/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 793/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 794/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 795/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 796/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 797/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 798/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 799/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 800/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 801/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 802/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 803/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 804/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 805/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 806/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 807/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 808/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 809/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 810/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 811/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 812/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 813/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 814/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 815/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 816/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 817/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 818/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 819/1000\n",
      "750/750 [==============================] - 0s 160us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 820/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 821/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 822/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 823/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 824/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 825/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 826/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 827/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 829/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 830/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 831/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 832/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 833/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 834/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 835/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 836/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 837/1000\n",
      "750/750 [==============================] - 0s 162us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 838/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 839/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 840/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 841/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 842/1000\n",
      "750/750 [==============================] - 0s 161us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 843/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 844/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 845/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 846/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 847/1000\n",
      "750/750 [==============================] - 0s 163us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 848/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 849/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 850/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 851/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 852/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 853/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 854/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 855/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 856/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 857/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 858/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 859/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 860/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 861/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 862/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 863/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 864/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 865/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 866/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 867/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 868/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 869/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 870/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 871/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 872/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 873/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 874/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 875/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 876/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 877/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 878/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 879/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 880/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 881/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 882/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 883/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 884/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 885/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 886/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 888/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 889/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 890/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 891/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 892/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 893/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 894/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 895/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 896/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 897/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 898/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 899/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 900/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 901/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 902/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 903/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 904/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 905/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 906/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 907/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 908/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 909/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 910/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 911/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 912/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 913/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 914/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 915/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 916/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 917/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 918/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 919/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 920/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 921/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 922/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 923/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 924/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 925/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 926/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 927/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 928/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 929/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 930/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 931/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 932/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 933/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 934/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 935/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 936/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 937/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 938/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 939/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 940/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 941/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 942/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 943/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 944/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 945/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 947/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 948/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 949/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 950/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 951/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 952/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 953/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 954/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 955/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 956/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 957/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 958/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 959/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 960/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 961/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 962/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 963/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 964/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 965/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 966/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 967/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 968/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 969/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 970/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 971/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 972/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 973/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 974/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 975/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 976/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 977/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 978/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 979/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 980/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 981/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 982/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 983/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 984/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 985/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 986/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 987/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 988/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 989/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 990/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 991/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 992/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 993/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 994/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 995/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 996/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 997/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 998/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 999/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n",
      "Epoch 1000/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0022 - acc: 0.9573 - val_loss: 0.0341 - val_acc: 0.3360\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmYFdWd//H3h2YVQQRaRRYBRRPUiNgSl0RjYhRNRrJohGhcM4xJ/GVVg5kZNZhMdCaTRKOjMopbjEZRI2MwxN0YFUFF1hBWoQWVRRbZevv+/qhquDTd996m+9JN9+f1PPV01alzqk5x9X7vOaeqjiICMzOzXdWmqStgZmZ7NgcSMzNrEAcSMzNrEAcSMzNrEAcSMzNrEAcSMzNrEAcSswKR1F9SSGqbR96LJL3c0OOYNQUHEjNA0hJJZZJ61kifnn6J92+ampk1fw4kZtstBkZVb0g6EujUdNUx2zM4kJhtdz9wQcb2hcB9mRkk7SPpPkkrJb0j6d8ktUn3FUn6paRVkhYBX6il7F2SVkh6V9LPJBXVt5KSDpQ0UdIaSQsk/XPGvmGSpklaL+l9Sb9K0ztK+p2k1ZLWSpoqaf/6ntusNg4kZtu9BnSV9PH0C/5c4Hc18vwW2AcYCJxMEnguTvf9M/BF4GigBDi7Rtl7gQrgkDTPacA3d6GeDwKlwIHpOf5D0ufSfTcBN0VEV+Bg4OE0/cK03n2BHsBlwOZdOLfZThxIzHZU3Sr5PPB34N3qHRnB5eqI2BARS4D/Br6RZvka8JuIWBYRa4BfZJTdHzgD+H5EbIyID4BfAyPrUzlJfYFPAT+OiC0RMR24M6MO5cAhknpGxEcR8VpGeg/gkIiojIg3ImJ9fc5tVhcHErMd3Q98HbiIGt1aQE+gPfBORto7QO90/UBgWY191Q4C2gEr0q6ltcAdwH71rN+BwJqI2FBHHS4FDgX+nnZffTHjuiYDD0laLuk/JbWr57nNauVAYpYhIt4hGXQ/E3isxu5VJL/sD8pI68f2VssKkq6jzH3VlgFbgZ4R0S1dukbE4fWs4nKgu6QutdUhIuZHxCiSAHUjMEFS54goj4ifRsRg4ASSLrgLMGsEDiRmO7sU+GxEbMxMjIhKkjGHn0vqIukg4IdsH0d5GPiupD6S9gXGZJRdAfwF+G9JXSW1kXSwpJPrU7GIWAa8AvwiHUD/RFrfBwAknS+pOCKqgLVpsUpJp0g6Mu2eW08SECvrc26zujiQmNUQEQsjYlodu/8fsBFYBLwM/B4Yn+77X5Luo7eBN9m5RXMBSdfYHOBDYALQaxeqOAroT9I6eRy4NiKeTvcNB2ZL+ohk4H1kRGwBDkjPtx6YC7zIzjcSmO0SeWIrMzNrCLdIzMysQRxIzMysQRxIzMysQRxIzMysQVrFa6l79uwZ/fv3b+pqmJntUd54441VEVGcK1+rCCT9+/dn2rS67uY0M7PaSHondy53bZmZWQM5kJiZWYM4kJiZWYO0ijGS2pSXl1NaWsqWLVuauiq7RceOHenTpw/t2vmFr2bWuFptICktLaVLly70798fSU1dnYKKCFavXk1paSkDBgxo6uqYWQvTaru2tmzZQo8ePVp8EAGQRI8ePVpN68vMdq9WG0iAVhFEqrWmazWz3auggUTScEnzJC2QNKaW/T+UNEfSDEnPpvM7VO+7UNL8dLkwI/0YSTPTY96sAn5DfripjNUfbS3U4c3MWoSCBZJ0Ap1bSeapHgyMkjS4Rra3gJKI+ATJXAn/mZbtDlwLfBIYBlybThQEcBswGhiULsMLdQ1rN5WzZlNZQY69evVqhgwZwpAhQzjggAPo3bv3tu2ysvzOefHFFzNv3ryC1M/MLF+FHGwfBiyIiEUAkh4CRpBM6gNARDyfkf814Px0/XTg6YhYk5Z9Ghgu6QWga0S8mqbfB3wJeKpgV1Gg6Vp69OjB9OnTAbjuuuvYe++9ueKKK3Y8dQQRQZs2tcf7u+++uzCVMzOrh0J2bfUmmae6WmmaVpdL2R4Q6irbO13PeUxJoyVNkzRt5cqV9ax6eoxdKtUwCxYs4IgjjuCyyy5j6NChrFixgtGjR1NSUsLhhx/O2LFjt+X91Kc+xfTp06moqKBbt26MGTOGo446iuOPP54PPvigCWpvZq1RIVsktX0P1/r7XtL5QAlQPX91XWXzPmZEjAPGAZSUlGRtV/z0/2YzZ/n6ndK3lFcSQKd2RdmK12rwgV259p8Or3c5gDlz5nD33Xdz++23A3DDDTfQvXt3KioqOOWUUzj77LMZPHjHXsJ169Zx8sknc8MNN/DDH/6Q8ePHM2bMTsNSZmaNrpAtklKgb8Z2H5I5pncg6VTgX4GzImJrjrKl6XrWY+7pDj74YI499tht2w8++CBDhw5l6NChzJ07lzlz5uxUplOnTpxxxhkAHHPMMSxZsmR3VdfMWrlCtkimAoMkDQDeBUYCX8/MIOlo4A5geERk9sVMBv4jY4D9NODqiFgjaYOk44ApwAXAbxta0bpaDktWbaS8sopB+3dp6CnqpXPnztvW58+fz0033cTrr79Ot27dOP/882t9HqR9+/bb1ouKiqioqNgtdTUzK1iLJCIqgMtJgsJc4OGImC1prKSz0mz/BewNPCJpuqSJadk1wPUkwWgqMLZ64B34FnAnsABYSCEH2puB9evX06VLF7p27cqKFSuYPHlyU1fJzGwHBX1FSkRMAibVSLsmY/3ULGXHA+NrSZ8GHNGI1WzWhg4dyuDBgzniiCMYOHAgJ554YlNXycxsB4oo0P2tzUhJSUnUnNhq7ty5fPzjH89arqm6tgoln2s2M6sm6Y2IKMmVr1W/IiUfLT/Mmpk1jAOJmZk1iAOJmZk1iAOJmZk1iAOJmZk1iANJFp7Cw8wsNweSJtIYr5EHGD9+PO+9914Ba2pmll2rnbO9qeXzGvl8jB8/nqFDh3LAAQc0dhXNzPLiQNIM3Xvvvdx6662UlZVxwgkncMstt1BVVcXFF1/M9OnTiQhGjx7N/vvvz/Tp0zn33HPp1KkTr7/++g7v3DIz2x0cSACeGgPvzdwpef+KSqoioN0u/DMdcCSccUO9i82aNYvHH3+cV155hbZt2zJ69GgeeughDj74YFatWsXMmUk9165dS7du3fjtb3/LLbfcwpAhQ+pfRzOzRuBAkstufrT9mWeeYerUqZSUJG8l2Lx5M3379uX0009n3rx5fO973+PMM8/ktNNO270VMzOrgwMJ1NlyeH/1RraWV3HoAbvvXVsRwSWXXML111+/074ZM2bw1FNPcfPNN/Poo48ybty43VYvM7O6+K6tHHb3u7ZOPfVUHn74YVatWgUkd3ctXbqUlStXEhGcc845/PSnP+XNN98EoEuXLmzYsGE319LMbDu3SJqZI488kmuvvZZTTz2Vqqoq2rVrx+23305RURGXXnopEYEkbrzxRgAuvvhivvnNb3qw3cyajF8jn8U7qzeypbyKw3Zj11Yh+TXyZlYfzeI18pKGS5onaYGkMbXsP0nSm5IqJJ2dkX5KOmNi9bJF0pfSffdIWpyxz7crmZk1oYJ1bUkqAm4FPg+UAlMlTYyIORnZlgIXATs8iRcRzwND0uN0J5lW9y8ZWa6MiAmFqruZmeWvkGMkw4AFEbEIQNJDwAhgWyCJiCXpvqosxzkbeCoiNjV2BavHG+rSkl611Rq6MM2saRSya6s3sCxjuzRNq6+RwIM10n4uaYakX0vqUFshSaMlTZM0beXKlTvt79ixI6tXr24VX7ARwerVq+nYsWNTV8XMWqBCtkhq+0Ffr29tSb2AI4HJGclXA+8B7YFxwI+BsTudKGJcup+SkpKdztunTx9KS0upLchUW7OxjPLKKqo+3PO/gDt27EifPn2auhpm1gIVMpCUAn0ztvsAy+t5jK8Bj0dEeXVCRKxIV7dKupsa4yv5ateuHQMGDMia5/89+Baz3l3H81ccvSunMDNrFQrZtTUVGCRpgKT2JF1UE+t5jFHU6NZKWykoGdz4EjCrEepaq5Y0RmJmVigFCyQRUQFcTtItNRd4OCJmSxor6SwAScdKKgXOAe6QNLu6vKT+JC2aF2sc+gFJM4GZQE/gZ4W6hvQ6Cnl4M7M9XkGfbI+IScCkGmnXZKxPJenyqq3sEmoZnI+IzzZuLevmGRLNzHLzu7ZycHvEzCw7B5Is3CAxM8vNgSQHD5GYmWXnQJJFtqfezcws4UCSQ3iUxMwsKweSLNweMTPLzYEkB4+RmJll50CSjZskZmY5OZCYmVmDOJDk4K4tM7PsHEiykPu2zMxyciAxM7MGcSDJws8jmpnl5kCSg18jb2aWnQNJFm6QmJnlVtBAImm4pHmSFkgaU8v+kyS9KalC0tk19lVKmp4uEzPSB0iaImm+pD+ksy8WjNsjZmbZFSyQSCoCbgXOAAYDoyQNrpFtKXAR8PtaDrE5Ioaky1kZ6TcCv46IQcCHwKWNXvmUx0jMzHIrZItkGLAgIhZFRBnwEDAiM0NELImIGUBVPgdM52n/LDAhTbqXZN72gvEQiZlZdoUMJL2BZRnbpdQydW4WHSVNk/SapOpg0QNYm84HvyvHrBc/R2Jmllsh52yv7Vu4Pr/v+0XEckkDgeckzQTW53tMSaOB0QD9+vWrx2lrHtxNEjOzbArZIikF+mZs9wGW51s4IpanfxcBLwBHA6uAbpKqA2Cdx4yIcRFREhElxcXF9a89HiMxM8tHIQPJVGBQepdVe2AkMDFHGQAk7SupQ7reEzgRmBPJQx3PA9V3eF0IPNHoNc/gMRIzs+wKFkjScYzLgcnAXODhiJgtaaykswAkHSupFDgHuEPS7LT4x4Fpkt4mCRw3RMScdN+PgR9KWkAyZnJXoa7BLRIzs9wKOUZCREwCJtVIuyZjfSpJ91TNcq8AR9ZxzEUkd4TtFm6QmJll5yfbs3KTxMwsFweSHDxGYmaWnQNJFh4jMTPLzYEkJzdJzMyycSDJwg0SM7PcHEhy8BiJmVl2DiRZeIzEzCw3B5Ic3CAxM8vOgSQLv/3XzCw3B5IcPGe7mVl2DiRZeIzEzCw3B5Ic3B4xM8vOgSQLN0jMzHJzIMnBQyRmZtk5kGQhD5KYmeXkQJKD79oyM8uuoIFE0nBJ8yQtkDSmlv0nSXpTUoWkszPSh0h6VdJsSTMknZux7x5JiyVNT5chhbwGMzPLrmAzJEoqAm4FPg+UAlMlTcyYMhdgKXARcEWN4puACyJivqQDgTckTY6Iten+KyNiQqHqnsntETOz7Ao51e4wYEE6NS6SHgJGANsCSUQsSfdVZRaMiH9krC+X9AFQDKxlN/IQiZlZboXs2uoNLMvYLk3T6kXSMKA9sDAj+edpl9evJXWoo9xoSdMkTVu5cmV9T7udmyRmZlkVMpDU9nu+Xl/LknoB9wMXR0R1q+Vq4GPAsUB34Me1lY2IcRFREhElxcXF9Tnt9vP7SRIzs5wKGUhKgb4Z232A5fkWltQV+BPwbxHxWnV6RKyIxFbgbpIutIJxg8TMLLtCBpKpwCBJAyS1B0YCE/MpmOZ/HLgvIh6psa9X+lfAl4BZjVrrHc5VqCObmbUcBQskEVEBXA5MBuYCD0fEbEljJZ0FIOlYSaXAOcAdkmanxb8GnARcVMttvg9ImgnMBHoCPyvUNaTXUcjDm5nt8Qp51xYRMQmYVCPtmoz1qSRdXjXL/Q74XR3H/GwjV7NObpCYmeXmJ9tzcHvEzCw7B5IsPEZiZpabA0kOHiIxM8vOgSQLv/3XzCw3B5IcwqMkZmZZOZBk4faImVluDiQ5eIzEzCw7B5Js3CQxM8vJgSQHN0jMzLLLK5BIOrj6de2SPiPpu5K6FbZqTc9v/zUzyy3fFsmjQKWkQ4C7gAHA7wtWq+bETRIzs6zyDSRV6UsYvwz8JiJ+APQqXLWaBz9GYmaWW76BpFzSKOBC4Mk0rV1hqtS8+DkSM7Ps8g0kFwPHAz+PiMWSBlDH23lbEjdIzMxyy+s18hExB/gugKR9gS4RcUMhK9Zc+DkSM7Ps8r1r6wVJXSV1B94G7pb0q8JWrel5jMTMLLd8u7b2iYj1wFeAuyPiGODUXIUkDZc0T9ICSWNq2X+SpDclVUg6u8a+CyXNT5cLM9KPkTQzPebNKvCbFd0gMTPLLt9A0jadK/1rbB9sz0pSEXArcAYwGBglaXCNbEuBi6hxK3Ha8rkW+CQwDLg27VIDuA0YDQxKl+F5XkO9+TkSM7Pc8g0kY0nmXl8YEVMlDQTm5ygzDFgQEYsiogx4CBiRmSEilkTEDKCqRtnTgacjYk1EfAg8DQxPg1nXiHg1ksnU7wO+lOc17BLP2W5mll2+g+2PAI9kbC8CvpqjWG9gWcZ2KUkLIx+1le2dLqW1pO9E0miSlgv9+vXL87Q1j7FLxczMWpV8B9v7SHpc0geS3pf0qKQ+uYrVkpbvz/u6yuZ9zIgYFxElEVFSXFyc52nzPLiZmW2Tb9fW3cBE4ECSFsD/pWnZlAJ9M7b7AMvzPF9dZUvT9V05Zr25QWJmllu+gaQ4Iu6OiIp0uQfI9TN/KjBI0gBJ7YGRJMEoH5OB0yTtmw6ynwZMjogVwAZJx6V3a10APJHnMXeJh0jMzLLLN5CsknS+pKJ0OR9Yna1A+m6uy0mCwlzg4YiYLWmspLMAJB0rqRQ4B7hD0uy07BrgepJgNBUYm6YBfAu4E1gALASeqsf11o8HSczMcsprsB24BLgF+DXJsMErJK9NySoiJgGTaqRdk7E+lR27qjLzjQfG15I+DTgiz3qbmVmB5dUiiYilEXFWRBRHxH4R8SWShxNbNLdHzMxya8gMiT9stFo0c36WxMysbg0JJC3+B7uHSMzMcmtIIGk1P9PdIDEzq1vWwXZJG6g9YAjoVJAaNSN+15aZWW5ZA0lEdNldFWnO3CAxM6tbQ7q2WjyPkZiZ5eZAkgfftWVmVjcHkizcIDEzy82BJA9uj5iZ1c2BJAuPkZiZ5eZAkgcPkZiZ1c2BJAu5SWJmlpMDSR7CoyRmZnVyIDEzswZxIMmDx0jMzOpW0EAiabikeZIWSBpTy/4Okv6Q7p8iqX+afp6k6RlLlaQh6b4X0mNW79uvkNdgZmbZFSyQSCoCbgXOAAYDoyQNrpHtUuDDiDiEZPbFGwEi4oGIGBIRQ4BvAEsiYnpGufOq90fEB4W7hkId2cys5Shki2QYsCAiFkVEGfAQMKJGnhHAven6BOBz2vlWqVHAgwWsp5mZNUAhA0lvYFnGdmmaVmueiKgA1gE9auQ5l50Dyd1pt9a/1xJ4AJA0WtI0SdNWrly5Sxfg18ibmeVWyEBS27dwzWHrrHkkfRLYFBGzMvafFxFHAp9Ol2/UdvKIGBcRJRFRUlxcXL+a73SsBhU3M2vRChlISoG+Gdt9gOV15ZHUFtgHWJOxfyQ1WiMR8W76dwPwe5IutILwGImZWW6FDCRTgUGSBkhqTxIUJtbIMxG4MF0/G3gu0ne2S2oDnEMytkKa1lZSz3S9HfBFYBYF5gcSzczqlnWGxIaIiApJlwOTgSJgfETMljQWmBYRE4G7gPslLSBpiYzMOMRJQGlELMpI6wBMToNIEfAM8L+FugY3SMzMcitYIAGIiEnApBpp12SsbyFpddRW9gXguBppG4FjGr2iOXiMxMysbn6yPQuPkZiZ5eZAkgc3SMzM6uZAkoWfIzEzy82BJA/hQRIzszo5kGThMRIzs9wcSPLg9oiZWd0cSMzMrEEcSPLgIRIzs7o5kGRRx4uFzcwsgwNJPtwiMTOrkwNJFm6PmJnl5kCSB7/918ysbg4kWXiIxMwsNweSPPiuLTOzujmQZOEGiZlZbgUNJJKGS5onaYGkMbXs7yDpD+n+KZL6p+n9JW2WND1dbs8oc4ykmWmZm7Ub7tF1g8TMrG4FCySSioBbgTOAwcAoSYNrZLsU+DAiDgF+DdyYsW9hRAxJl8sy0m8DRgOD0mV4Aa+hUIc2M2sxCtkiGQYsiIhFEVFGMvf6iBp5RgD3pusTgM9la2FI6gV0jYhX07nd7wO+1PhV35Hf/mtmVrdCBpLewLKM7dI0rdY8EVEBrAN6pPsGSHpL0ouSPp2RvzTHMRuNGyRmZrkVcs722r6Ga/60ryvPCqBfRKyWdAzwR0mH53nM5MDSaJIuMPr165d3pWvj9oiZWd0K2SIpBfpmbPcBlteVR1JbYB9gTURsjYjVABHxBrAQODTN3yfHMUnLjYuIkogoKS4u3qULcIPEzCy3QgaSqcAgSQMktQdGAhNr5JkIXJiunw08FxEhqTgdrEfSQJJB9UURsQLYIOm4dCzlAuCJAl4D4OdIzMyyKVjXVkRUSLocmAwUAeMjYrakscC0iJgI3AXcL2kBsIYk2ACcBIyVVAFUApdFxJp037eAe4BOwFPpUhgeJDEzy6mQYyRExCRgUo20azLWtwDn1FLuUeDROo45DTiicWuand+1ZWZWNz/ZnoXbI2ZmuTmQZNG2TRJKyivdIjEzq4sDSRaDV/2ZUUXPsuajsqauii2bCrd9Cso2NXVNzKwGB5Is+i1/iq8XPcuqj7Y2dVX2fG/cC/9z/K6Xn3w1vD8T3p/VeHUys0ZR0MH2PV37jnvRkXJe/MdKgmBreRVnHNmrqau1Z/q/7yZ/yzZC+871L199D7b828esufH/lVl02qsz3TtUcs8rS7jknml864E3mb18nd+99fS1sPC5ZH3KHbD4pfzLbnhv184ZVemKb4Ewa24cSLJQu050b1/JKYdtfzL+Cze/zO+mLG3CWjWRygqoKIOqSvjbb+D+LyfpT10F9/5T0mKY8wSUb669fLu0FbJhxS5WIA3elR6vMmtuHEiyadsJlW9h/EXH0qHt9n+qSTN29cuwmdmyDirLa983cwI8/wuYMg5mPQb/ewr8Ry/YtKb2/ItfgocvgOd/nmyXbYTXboOtG5Lt6u6s6hbJ3P+DSVfteIzNH8J1+8CsWh4hqm6RVGxJ/q5fUXfdzWy38hhJNu06QsVmJPH0D07mpP96HoDKPaVr67XboecgOORzte+/oR8MHgGn/wLadYK9usP65fA/xyVBpjYfvb99ffn07etr30n+blyd/P3rfyfLsinwiZGw8YMk/ckfQMVWeOLbyfYxF0JR+6SlseCZtN63wRFf3fG8mYGkbCP86mNQcil88Vf5/VuYWcE4kGTTthNUVUBlBf167EUbQVXA64vX0H/Mn7jjG8dw2uD9m9cEWBveg6evgS/+Bv784yTtunWwrhSWvAwIptwGg9NpXOY8kSwAR5wNsyZkP/7tJ25fH3fy9vVJVyZ/F7+YtGLefijZnv14slTbun57EAG47YSdzxEB696F8k1Q9lFyy+97M5N9sx7b3iqZdhcUH5Z0p1VV0LTvaW5G/w2YZTrmYujcI3e+BlBrGDguKSmJadOm1b/g325KvpSvLoUOXVi08iNG3Po3Nmyp2JblG8cdxFXDD6NLx3bw1u+SX9Pf+lsj1j5PEUm301NXJcHgK3fCY99M9n37taSVsTt1Hwhn3QJRmdxp1ak7rF0KXXtBx24w+Sfw9yehqAOMuBXatk/y/eH83VtPs5buO1Oh+NBdKirpjYgoyZXPLZJs2u2V/P3oA+jQhYHd2jL1X0/l3/44iwlvJPNr3f/aO9z/2jvMGXs6ez3xnSR/ZQUU7aZ/2soKmPcnWPQCTBu/PX1Dxtv1GyOI9BoCK6bDpc/AgUPgwZGwdAqUpWMgVy2G/xyQrH9/FnTtDW1qDMHtnzHT8ufHQuk0uOTP0H3A9vRj/xmWvQbHfjMZoG/fOeliXLMI/vSjJM8XfpVc6ye+lnSbdegCbYqa7tbgVvBjzPZgRe0Kfgq3SLJZvRBuOxG6HghrFiZpF0yEgSdz/C+epe36d/hrhx9wcdmVHKnF/LBd0i208ZKX6LxXZ+h5SONdxPtzkl/xIx+AV/8n+YWxfjm89F+waXXjnKNNW/jRPLj7DDjrt8mA+Ku3JPt+NA+6HLBj/spyuL5nsn7dumSgvHq9sVVVwhPfgeMvhwN26zs7zVqtfFskDiS5zH8GHqgx8HvKv26/Owl4qvJYziiaulPRin//kLZFbZJfrFUVdf8y2PA+7L1fctdSZdmOX9gLnoFFL8IrN+9a/WvzmavhM2Ng4fNwf8aU9z9ZvvPDgvd/OXlm5Jo1ya/+miq2JmMZnfYtbCAxs93OXVuNZdCpcMV8+OWg7WkZQQSoNYgATP/bnyk5aN+kJbH8TfjBHOhcnKwvmwKr5kPvY+DJ78NJV8FL/5kUPOZi+HBJ8gW9bEr+de1dkhx728N7qfMmQK+j4M374Lnr4aB0gPvgU5Iv/Vdvhed+vr0rL9PXH05u4a0tiAC07ZAsZtZquUWSr/ItMOlHyYB6U7vsb0lwWvzi9rReQ+BfXkxaCD/bD9p2hB/9HTauSm4BhqRltOLtZIyjEJa+Bnv12H4+M9ujNYuuLUnDgZtIZki8MyJuqLG/A3AfcAywGjg3IpZI+jxwA9AeKAOujIjn0jIvAL2A6keoT4uID7LVo1ECSbUZD8Nj/7xT99Zuc+kz0PfYZH35W8ktypCM43TsmqxPvQsGfgZ6HLz762dmLUaTB5J0zvV/AJ8HSknmcB8VEXMy8nwb+EREXCZpJPDliDhX0tHA+xGxXNIRwOSI6J2WeQG4Ip0pMS+NGkgyVVXBlrXw1v2gIlj6anKH15CvJ91VDfXpK5LWwx/Oh4v+BP0/1fBjmpnlqTmMkQwDFkTEorRCDwEjgDkZeUYA16XrE4BbJCki3srIMxvoKKlDRDSv97m3aZM8DX7i95LtEy7fvm/gyTDlDlbGPkx+ZRrXVlzEEVrMV4r+yvDiNSzrdBh9TxzF/utmJF1UIx9MHtT7xNdg7wNgv8Hbb5/14LWZNWOFDCS9gWUZ26XAJ+vKExEVktYBPYBVGXm+CrxVI4jcLamSZF73n0UtzSpJo4HRAP369WvgpeyC7gPhjBspBk4ctpGjHp7Om0uLeLviEK6tflXXog3cNPLLjDgvDUBfGbf762lm1kCFfIKrtndG1PzCz5pH0uHAjcC/ZOw/LyKOBD6dLt+o7eQRMS4iSiKipLi4uLYsu82MeNK0AAANc0lEQVSAnp157NsnsvgXZ3LyoTvW5XsPTef6J+ewtaKSt5Z+yN8WrKrjKGZmzVMhWySlQN+M7T7A8jrylEpqC+wDrAGQ1Ad4HLggIhZWF4iId9O/GyT9nqQL7b5CXURjksS9lwxjxbrNXDVhBn+dnwSNu15ezLz3NvByGkSW3PCFpqymmVm9FLJFMhUYJGmApPbASGBijTwTgQvT9bOB5yIiJHUD/gRcHRHbXlwlqa2knul6O+CLwB4392qvfTpx63lDObekL0f2Th7iezmjJVJZ1fJvyTazlqPQt/+eCfyG5Pbf8RHxc0ljgWkRMVFSR+B+4GiSlsjIiFgk6d+Aq4H5GYc7DdgIvAS0S4/5DPDDiKjMVo+C3bXVSCqrgrNueZnZy9dvS/uXkwZy5emHJU/Gm5k1gSa//bc5ae6BBJJgMnn2e3z/oemUVe74ZPq/nDyQ731uEHu194sIzGz3aQ63/1o9FLURZx7Zi6P6dmNLeSVXPPI2by1dC8AdLy7ivXVbOOyALlx20sG0aeO5L8ys+XAgaWZ6d0ueVH/82yfy2Jul/OxPc1mzsYwnpif3KXTfqz0jhzXB7cxmZnVwB3wz9pWhfXjz3z/PKYcV07l98tLEMY/NZPA1f2b6srVNXDszs4THSPYAFZVVbCyr5N5XlvCrp/8BQBvBl47uzSd678NFJw7IcQQzs/rzGEkL0raoDft0asPlpxzCKYftx+bySi4YP4XH3nyXx958l41llVxw/EHJdL9mZruZu7b2IG3aiCP77MOwAd257bxjaJ/eGvxfk+fxk8dnsaU8613QZmYF4a6tPVhE8KeZK3hq1nv8aUbyAq+fnPkxyiuDC0/oz94d3OA0s13nrq1WQBJf/MSBnHFEL9ZvLuev81fxH5P+DsD6zeVcdvLBPD33fb46tA9FvmXYzArEgaQFKGoj7r/0k2zcWsET05fzq6f/wR0vLeKOlxYBULx3B0752H5NXEsza6kcSFqQzh3a8vVP9uPI3vvwT7e8vC39L3PeZ1NZJW2LxICenTl0/y5NWEsza2k8RtJCrd9Szrsfbua6ibOZsnjNDvvmjD3dr1sxs5z8rq0MrTGQVFu3uZwnpr/L9U/Oobwy+ayPG9idAT07U9ylI5/92H4M6dutiWtpZs2RA0mG1hxIqkUEVQFXTZjBo2+Wbksv7tKBK047lLv/toRvfnogZx/Tp87ym8oq6dxEd4JFBL9/fSmnDT6A4i4dmqQOZq2NA0kGB5IdVVUFf5z+LjNK13HPK0t22Nejc3u+c8ohnPKx/VizcStby6v4y5z3OfzArlw5YQYvXvkZDurReYdjSckdZPUVETuU27i1giOvm8wvzzmKrwzdMaAt+OAjTv3Vi5x8aDH3XjKs3ucys/rLN5D4gcRWqE0b8ZWhfbjurMN57NsncG5JXwbttzcAqzeWMfbJOZzyyxf46m2v8vU7p3DPK0u486+LAXhp/ir+8f4GpixaDcDxNzzLVRNmAHDlI2/zhZv/SkSwcWsFD09dxtaK5CHJ1xev4SePz9z20OTs5esYcPUkpi3ZPn6z7MNNVAVc8cjbO9V51Udbd/hrZs2HR1xbuaH99mVov32JCF5ZuJre3Tpx58uLmPXu+h1eDDnv/Q0AjHtpIf/+x2RSym8cdxDvr9/KI2+U8u1TDuGRN5Ius3dWb+LeV5dw99+WsLWyim8cdxA3Pzuflxes4pMDujNiSG9eXZgEottfXMSd/bsDsHJDEiRqmyBy6ZpNALRvm/z2eWXBKpas3sSoYX13qTVkZo2n0DMkDgduIpnN8M6IuKHG/g4k860fA6wGzo2IJem+q4FLgUrguxExOZ9j1sZdW7tm7aYyPtpawasLV/PX+avovW8nHp66jNUby+jRuT2rN5bldZzO7YvYWLb99S377tWOTWWVbK1IJvDquXd7JG0LJNVp7YraUB0iNmypYMPWCgB67dORFeu2AMkYT5eO2X8P5RNmcgUjhyrbU9114bH067HXLpVt8ifbJRUBtwKfB0qBqZImRsScjGyXAh9GxCGSRgI3AudKGkwyx/vhwIHAM5IOTcvkOqY1km57tafbXu05p2QvzinpC8BVpx9GBAQwZdFq9uvagQ1bKpj57jqK9+5Ax3ZFvF26lorKoH/Pzixbs4mP0gDQd99OLF+3hc1llRS1EXt3aMtHWysor6xKWyHBPp3a00awdnM55RU7zhS5T6d2bKmoZEt5FXu1L6JTuyLeXbs56zXk9TMpR6bI7yhmzVJ1K76QCtm1NQxYEBGLACQ9BIwAMr/0RwDXpesTgFuU/DQcATwUEVuBxZIWpMcjj2NaAUmi+sf7CYf03JZ+dL99t637KXqz1qWQoao3sCxjuzRNqzVPRFQA64AeWcrmc0wAJI2WNE3StJUrVzbgMszMLJtCBpLaupVr9hHUlae+6TsnRoyLiJKIKCkuLs5aUTMz23WFDCSlQN+M7T7A8rrySGoL7AOsyVI2n2OamdluVMhAMhUYJGmApPYkg+cTa+SZCFyYrp8NPBfJbWQTgZGSOkgaAAwCXs/zmGZmthsVbLA9IiokXQ5MJrlVd3xEzJY0FpgWEROBu4D708H0NSSBgTTfwySD6BXAdyKiEqC2YxbqGszMLDe/IsXMzGrlV6SYmdlu4UBiZmYN0iq6tiStBN7ZxeI9gVWNWJ09ga+5dfA1tw4NueaDIiLn8xOtIpA0hKRp+fQRtiS+5tbB19w67I5rdteWmZk1iAOJmZk1iANJbuOaugJNwNfcOviaW4eCX7PHSMzMrEHcIjEzswZxIDEzswZxIMlC0nBJ8yQtkDSmqevTGCT1lfS8pLmSZkv6XpreXdLTkuanf/dN0yXp5vTfYIakoU17BbtOUpGktyQ9mW4PkDQlveY/pC8CJX1Z6B/Sa54iqX9T1ntXSeomaYKkv6ef9/Et/XOW9IP0v+tZkh6U1LGlfc6Sxkv6QNKsjLR6f66SLkzzz5d0YW3nypcDSR0ypgo+AxgMjEqnAN7TVQA/ioiPA8cB30mvawzwbEQMAp5NtyG5/kHpMhq4bfdXudF8D5ibsX0j8Ov0mj8kmfoZMqaABn6d5tsT3QT8OSI+BhxFcu0t9nOW1Bv4LlASEUeQvNi1egrvlvQ53wMMr5FWr89VUnfgWuCTJLPPXlsdfHZJRHipZQGOByZnbF8NXN3U9SrAdT4BfB6YB/RK03oB89L1O4BRGfm35duTFpK5a54FPgs8STJJ2iqgbc3Pm+Tt0sen623TfGrqa6jn9XYFFtesd0v+nNk+g2r39HN7Eji9JX7OQH9g1q5+rsAo4I6M9B3y1Xdxi6RueU/ru6dKm/JHA1OA/SNiBUD6t3ri9Zby7/Ab4CqgKt3uAayNZIpn2PG66poCek8yEFgJ3J12590pqTMt+HOOiHeBXwJLgRUkn9sbtOzPuVp9P9dG/bwdSOqW97S+eyJJewOPAt+PiPXZstaStkf9O0j6IvBBRLyRmVxL1shj356iLTAUuC0ijgY2sr27ozZ7/DWnXTMjgAHAgUBnkq6dmlrS55xLg6ctz4cDSd1a7LS+ktqRBJEHIuKxNPl9Sb3S/b2AD9L0lvDvcCJwlqQlwEMk3Vu/AbopmeIZdryuuqaA3pOUAqURMSXdnkASWFry53wqsDgiVkZEOfAYcAIt+3OuVt/PtVE/bweSurXIaX0liWRmyrkR8auMXZnTHl9IMnZSnX5BevfHccC66ib0niIiro6IPhHRn+RzfC4izgOeJ5niGXa+5tqmgN5jRMR7wDJJh6VJnyOZcbTFfs4kXVrHSdor/e+8+ppb7Oecob6f62TgNEn7pi2509K0XdPUg0bNeQHOBP4BLAT+tanr00jX9CmSJuwMYHq6nEnSN/wsMD/92z3NL5K71xYCM0nuiGny62jA9X8GeDJdHwi8DiwAHgE6pOkd0+0F6f6BTV3vXbzWIcC09LP+I7BvS/+cgZ8CfwdmAfcDHVra5ww8SDIGVE7Ssrh0Vz5X4JL02hcAFzekTn5FipmZNYi7tszMrEEcSMzMrEEcSMzMrEEcSMzMrEEcSMzMrEEcSMwagaRKSdMzlkZ7W7Sk/plvejVrbtrmzmJmedgcEUOauhJmTcEtErMCkrRE0o2SXk+XQ9L0gyQ9m84R8aykfmn6/pIel/R2upyQHqpI0v+mc238RVKnJrsosxocSMwaR6caXVvnZuxbHxHDgFtI3vFFun5fRHwCeAC4OU2/GXgxIo4ieTfW7DR9EHBrRBwOrAW+WuDrMcubn2w3awSSPoqIvWtJXwJ8NiIWpS/LfC8iekhaRTJ/RHmaviIiekpaCfSJiK0Zx+gPPB3JpEVI+jHQLiJ+VvgrM8vNLRKzwos61uvKU5utGeuVeHzTmhEHErPCOzfj76vp+iskbyIGOA94OV1/FvgWbJtjvuvuqqTZrvKvGrPG0UnS9IztP0dE9S3AHSRNIfnhNipN+y4wXtKVJDMZXpymfw8YJ+lSkpbHt0je9GrWbHmMxKyA0jGSkohY1dR1MSsUd22ZmVmDuEViZmYN4haJmZk1iAOJmZk1iAOJmZk1iAOJmZk1iAOJmZk1yP8HEF57bnAHdEsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense, Flatten,LSTM, TimeDistributed, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TIME_STEPS = 10\n",
    "INPUT_SIZE = 512\n",
    "BATCH_SIZE = 250\n",
    "BATCH_INDEX = 0\n",
    "OUTPUT_SIZE = 512\n",
    "#CELL_SIZE = 800\n",
    "LR = 0.001\n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "# loading data\n",
    "X_train = np.loadtxt(\"0220_spec_train_1000*5120.txt\")\n",
    "y_train = np.loadtxt(\"0220_mask_train_1000*512.txt\")\n",
    "\n",
    "X_test = np.loadtxt(\"0220_spec_test_1000*5120.txt\")\n",
    "y_test = np.loadtxt(\"0220_mask_test_1000*512.txt\")\n",
    "\n",
    "# batch_size=y_test.shape[0]\n",
    "\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 10, 512)\n",
    "#y_train = y_train.reshape(-1, 3, 512)\n",
    "X_test = X_test.reshape(-1, 10, 512)\n",
    "#y_test = y_test.reshape(-1, 3, 512)\n",
    "\n",
    "\n",
    "#  build RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# RNN cell\n",
    "\n",
    "model.add(LSTM(\n",
    "    units =512,\n",
    "    batch_input_shape=( BATCH_SIZE, TIME_STEPS, INPUT_SIZE),\n",
    "    #input_dim=INPUT_SIZE,\n",
    "    #input_length=TIME_STEPS,\n",
    "    #output_dim=CELL_SIZE,\n",
    "    #return_sequences=True,\n",
    "    #stateful=True \n",
    "    unroll=True\n",
    "))\n",
    "\n",
    "# output layer\n",
    "#model.add(Flatten())\n",
    "model.add((Dense(OUTPUT_SIZE)))  #TimeDistributed\n",
    "model.add(Activation('hard_sigmoid'))\n",
    "#model.add(Dropout(rate = 0.2)) \n",
    "\n",
    "# # optimizer\n",
    "#\n",
    "# optimizer\n",
    "\n",
    "rmsprop = RMSprop(lr=LR, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # training\n",
    "#\n",
    "\n",
    "# for step in range(51):\n",
    "#     # data shape = (batch_num, steps, inputs/outputs)\n",
    "#     X_batch = X_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :, :]\n",
    "#     Y_batch = y_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :]\n",
    "#     cost = model.train_on_batch(X_batch, Y_batch)\n",
    "#     BATCH_INDEX += BATCH_SIZE\n",
    "#     BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "\n",
    "#     if step % 50 == 0:\n",
    "#         print('Next_Train----------: step = ', step)\n",
    "#         train_cost, train_accuracy = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('train_cost: ', train_cost, 'train_accuracy: ', train_accuracy)\n",
    "#         cost, accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "        \n",
    "       \n",
    "\n",
    "print('Train-------------------------')\n",
    "\n",
    "history = model.fit(X_test, y_test, validation_split=0.25, epochs=1000, shuffle=False, batch_size=250, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "#                                   [model.layers[1].output])\n",
    "# layer_output1 = get_3rd_layer_output([X_train])[0]\n",
    "\n",
    "# print(layer_output1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-------------------------\n",
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/1000\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 0.2007 - acc: 0.0040 - val_loss: 0.0391 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0419 - acc: 0.0093 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0394 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0395 - acc: 0.0120 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0389 - acc: 0.0093 - val_loss: 0.0315 - val_acc: 0.0360\n",
      "Epoch 6/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0386 - acc: 0.0280 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0389 - acc: 0.0187 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0382 - acc: 0.0240 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0390 - acc: 0.0280 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0376 - acc: 0.0013 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0380 - acc: 0.0253 - val_loss: 0.0322 - val_acc: 0.0320\n",
      "Epoch 12/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0372 - acc: 0.0187 - val_loss: 0.0296 - val_acc: 0.0200\n",
      "Epoch 13/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0365 - acc: 0.0107 - val_loss: 0.0339 - val_acc: 0.0320\n",
      "Epoch 14/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0369 - acc: 0.0147 - val_loss: 0.0288 - val_acc: 0.0200\n",
      "Epoch 15/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0356 - acc: 0.0147 - val_loss: 0.0303 - val_acc: 0.0040\n",
      "Epoch 16/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0353 - acc: 0.0173 - val_loss: 0.0295 - val_acc: 0.0240\n",
      "Epoch 17/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0360 - acc: 0.0213 - val_loss: 0.0309 - val_acc: 0.0360\n",
      "Epoch 18/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0347 - acc: 0.0240 - val_loss: 0.0298 - val_acc: 0.0280\n",
      "Epoch 19/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0333 - acc: 0.0160 - val_loss: 0.0282 - val_acc: 0.0600\n",
      "Epoch 20/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0344 - acc: 0.0253 - val_loss: 0.0305 - val_acc: 0.0280\n",
      "Epoch 21/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0333 - acc: 0.0227 - val_loss: 0.0295 - val_acc: 0.0160\n",
      "Epoch 22/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0333 - acc: 0.0200 - val_loss: 0.0288 - val_acc: 0.0040\n",
      "Epoch 23/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0326 - acc: 0.0227 - val_loss: 0.0298 - val_acc: 0.0520\n",
      "Epoch 24/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0343 - acc: 0.0267 - val_loss: 0.0287 - val_acc: 0.0320\n",
      "Epoch 25/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0312 - acc: 0.0293 - val_loss: 0.0306 - val_acc: 0.0160\n",
      "Epoch 26/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0314 - acc: 0.0147 - val_loss: 0.0276 - val_acc: 0.0840\n",
      "Epoch 27/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0331 - acc: 0.0547 - val_loss: 0.0311 - val_acc: 0.0360\n",
      "Epoch 28/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0319 - acc: 0.0200 - val_loss: 0.0282 - val_acc: 0.1080\n",
      "Epoch 29/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0304 - acc: 0.0480 - val_loss: 0.0276 - val_acc: 0.0240\n",
      "Epoch 30/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0311 - acc: 0.0307 - val_loss: 0.0316 - val_acc: 0.0360\n",
      "Epoch 31/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0325 - acc: 0.0333 - val_loss: 0.0282 - val_acc: 0.0800\n",
      "Epoch 32/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0314 - acc: 0.0373 - val_loss: 0.0283 - val_acc: 0.0320\n",
      "Epoch 33/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0296 - acc: 0.0293 - val_loss: 0.0278 - val_acc: 0.1960\n",
      "Epoch 34/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0298 - acc: 0.0747 - val_loss: 0.0292 - val_acc: 0.0400\n",
      "Epoch 35/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0304 - acc: 0.0293 - val_loss: 0.0276 - val_acc: 0.0720\n",
      "Epoch 36/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0307 - acc: 0.0307 - val_loss: 0.0282 - val_acc: 0.0760\n",
      "Epoch 37/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0285 - acc: 0.0280 - val_loss: 0.0270 - val_acc: 0.1080\n",
      "Epoch 38/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0310 - acc: 0.0507 - val_loss: 0.0303 - val_acc: 0.0760\n",
      "Epoch 39/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0306 - acc: 0.0800 - val_loss: 0.0272 - val_acc: 0.0360\n",
      "Epoch 40/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0290 - acc: 0.0493 - val_loss: 0.0284 - val_acc: 0.0200\n",
      "Epoch 41/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0298 - acc: 0.0320 - val_loss: 0.0268 - val_acc: 0.1520\n",
      "Epoch 42/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0294 - acc: 0.0773 - val_loss: 0.0298 - val_acc: 0.0280\n",
      "Epoch 43/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0281 - acc: 0.0387 - val_loss: 0.0266 - val_acc: 0.0720\n",
      "Epoch 44/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0285 - acc: 0.0373 - val_loss: 0.0307 - val_acc: 0.0440\n",
      "Epoch 45/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0283 - acc: 0.0427 - val_loss: 0.0263 - val_acc: 0.1080\n",
      "Epoch 46/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0281 - acc: 0.0493 - val_loss: 0.0302 - val_acc: 0.1040\n",
      "Epoch 47/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0280 - acc: 0.0453 - val_loss: 0.0278 - val_acc: 0.0960\n",
      "Epoch 48/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0290 - acc: 0.0600 - val_loss: 0.0301 - val_acc: 0.0840\n",
      "Epoch 49/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0270 - acc: 0.0573 - val_loss: 0.0263 - val_acc: 0.0400\n",
      "Epoch 50/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0271 - acc: 0.0840 - val_loss: 0.0305 - val_acc: 0.0320\n",
      "Epoch 51/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0272 - acc: 0.0680 - val_loss: 0.0268 - val_acc: 0.1800\n",
      "Epoch 52/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0263 - acc: 0.0840 - val_loss: 0.0292 - val_acc: 0.1720\n",
      "Epoch 53/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0265 - acc: 0.0587 - val_loss: 0.0266 - val_acc: 0.1720\n",
      "Epoch 54/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0282 - acc: 0.1200 - val_loss: 0.0315 - val_acc: 0.0800\n",
      "Epoch 55/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0274 - acc: 0.0987 - val_loss: 0.0273 - val_acc: 0.0920\n",
      "Epoch 56/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0259 - acc: 0.0707 - val_loss: 0.0271 - val_acc: 0.0880\n",
      "Epoch 57/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0262 - acc: 0.0920 - val_loss: 0.0279 - val_acc: 0.0400\n",
      "Epoch 58/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0254 - acc: 0.0453 - val_loss: 0.0265 - val_acc: 0.1520\n",
      "Epoch 59/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0261 - acc: 0.1120 - val_loss: 0.0285 - val_acc: 0.0800\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 164us/step - loss: 0.0249 - acc: 0.0987 - val_loss: 0.0279 - val_acc: 0.1520\n",
      "Epoch 61/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0251 - acc: 0.0787 - val_loss: 0.0300 - val_acc: 0.0840\n",
      "Epoch 62/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0266 - acc: 0.0853 - val_loss: 0.0265 - val_acc: 0.0480\n",
      "Epoch 63/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0259 - acc: 0.0787 - val_loss: 0.0263 - val_acc: 0.0520\n",
      "Epoch 64/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0240 - acc: 0.1000 - val_loss: 0.0269 - val_acc: 0.1160\n",
      "Epoch 65/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0243 - acc: 0.0907 - val_loss: 0.0277 - val_acc: 0.0640\n",
      "Epoch 66/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0239 - acc: 0.0853 - val_loss: 0.0299 - val_acc: 0.1120\n",
      "Epoch 67/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0254 - acc: 0.0947 - val_loss: 0.0262 - val_acc: 0.1600\n",
      "Epoch 68/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0257 - acc: 0.0907 - val_loss: 0.0284 - val_acc: 0.1160\n",
      "Epoch 69/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0237 - acc: 0.0827 - val_loss: 0.0266 - val_acc: 0.1680\n",
      "Epoch 70/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0228 - acc: 0.1040 - val_loss: 0.0282 - val_acc: 0.0920\n",
      "Epoch 71/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0229 - acc: 0.0920 - val_loss: 0.0259 - val_acc: 0.1200\n",
      "Epoch 72/1000\n",
      "750/750 [==============================] - 0s 182us/step - loss: 0.0244 - acc: 0.1067 - val_loss: 0.0294 - val_acc: 0.0760\n",
      "Epoch 73/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0234 - acc: 0.0960 - val_loss: 0.0264 - val_acc: 0.1120\n",
      "Epoch 74/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0231 - acc: 0.1013 - val_loss: 0.0279 - val_acc: 0.1040\n",
      "Epoch 75/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0230 - acc: 0.0973 - val_loss: 0.0265 - val_acc: 0.1160\n",
      "Epoch 76/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0227 - acc: 0.1093 - val_loss: 0.0282 - val_acc: 0.1520\n",
      "Epoch 77/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0223 - acc: 0.1520 - val_loss: 0.0267 - val_acc: 0.1120\n",
      "Epoch 78/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0226 - acc: 0.1467 - val_loss: 0.0297 - val_acc: 0.1160\n",
      "Epoch 79/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0221 - acc: 0.1227 - val_loss: 0.0279 - val_acc: 0.1560\n",
      "Epoch 80/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0212 - acc: 0.1640 - val_loss: 0.0271 - val_acc: 0.1120\n",
      "Epoch 81/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0223 - acc: 0.1227 - val_loss: 0.0267 - val_acc: 0.2280\n",
      "Epoch 82/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0229 - acc: 0.1867 - val_loss: 0.0303 - val_acc: 0.1480\n",
      "Epoch 83/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0224 - acc: 0.1133 - val_loss: 0.0265 - val_acc: 0.1800\n",
      "Epoch 84/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0211 - acc: 0.1360 - val_loss: 0.0283 - val_acc: 0.1200\n",
      "Epoch 85/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0204 - acc: 0.1347 - val_loss: 0.0275 - val_acc: 0.1680\n",
      "Epoch 86/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0202 - acc: 0.1787 - val_loss: 0.0277 - val_acc: 0.1680\n",
      "Epoch 87/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0209 - acc: 0.1680 - val_loss: 0.0320 - val_acc: 0.1840\n",
      "Epoch 88/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0216 - acc: 0.1347 - val_loss: 0.0278 - val_acc: 0.1200\n",
      "Epoch 89/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0202 - acc: 0.1440 - val_loss: 0.0287 - val_acc: 0.1600\n",
      "Epoch 90/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0205 - acc: 0.1507 - val_loss: 0.0260 - val_acc: 0.1480\n",
      "Epoch 91/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0219 - acc: 0.1507 - val_loss: 0.0305 - val_acc: 0.0960\n",
      "Epoch 92/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0200 - acc: 0.1293 - val_loss: 0.0272 - val_acc: 0.1560\n",
      "Epoch 93/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0191 - acc: 0.1560 - val_loss: 0.0274 - val_acc: 0.1800\n",
      "Epoch 94/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0189 - acc: 0.1693 - val_loss: 0.0275 - val_acc: 0.1360\n",
      "Epoch 95/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0192 - acc: 0.1960 - val_loss: 0.0311 - val_acc: 0.1760\n",
      "Epoch 96/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0199 - acc: 0.1840 - val_loss: 0.0271 - val_acc: 0.0960\n",
      "Epoch 97/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0198 - acc: 0.1840 - val_loss: 0.0311 - val_acc: 0.1560\n",
      "Epoch 98/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0188 - acc: 0.1653 - val_loss: 0.0260 - val_acc: 0.1880\n",
      "Epoch 99/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0199 - acc: 0.1787 - val_loss: 0.0276 - val_acc: 0.1640\n",
      "Epoch 100/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0189 - acc: 0.1733 - val_loss: 0.0277 - val_acc: 0.1640\n",
      "Epoch 101/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0182 - acc: 0.1907 - val_loss: 0.0286 - val_acc: 0.1720\n",
      "Epoch 102/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0175 - acc: 0.1867 - val_loss: 0.0313 - val_acc: 0.2160\n",
      "Epoch 103/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0183 - acc: 0.2000 - val_loss: 0.0297 - val_acc: 0.1600\n",
      "Epoch 104/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0183 - acc: 0.1973 - val_loss: 0.0278 - val_acc: 0.1440\n",
      "Epoch 105/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0174 - acc: 0.2040 - val_loss: 0.0293 - val_acc: 0.1720\n",
      "Epoch 106/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0175 - acc: 0.2053 - val_loss: 0.0314 - val_acc: 0.1960\n",
      "Epoch 107/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0189 - acc: 0.2360 - val_loss: 0.0259 - val_acc: 0.1560\n",
      "Epoch 108/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0190 - acc: 0.2120 - val_loss: 0.0289 - val_acc: 0.1280\n",
      "Epoch 109/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0170 - acc: 0.1973 - val_loss: 0.0287 - val_acc: 0.2000\n",
      "Epoch 110/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0162 - acc: 0.2147 - val_loss: 0.0287 - val_acc: 0.1880\n",
      "Epoch 111/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0160 - acc: 0.2240 - val_loss: 0.0298 - val_acc: 0.1720\n",
      "Epoch 112/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0165 - acc: 0.2040 - val_loss: 0.0296 - val_acc: 0.1880\n",
      "Epoch 113/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0167 - acc: 0.2427 - val_loss: 0.0274 - val_acc: 0.1760\n",
      "Epoch 114/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0177 - acc: 0.2213 - val_loss: 0.0320 - val_acc: 0.1400\n",
      "Epoch 115/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0172 - acc: 0.2053 - val_loss: 0.0275 - val_acc: 0.2000\n",
      "Epoch 116/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0156 - acc: 0.2520 - val_loss: 0.0291 - val_acc: 0.1760\n",
      "Epoch 117/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0155 - acc: 0.2547 - val_loss: 0.0285 - val_acc: 0.1720\n",
      "Epoch 118/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0155 - acc: 0.2240 - val_loss: 0.0318 - val_acc: 0.2240\n",
      "Epoch 119/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0156 - acc: 0.2707 - val_loss: 0.0280 - val_acc: 0.1560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0154 - acc: 0.2280 - val_loss: 0.0288 - val_acc: 0.1760\n",
      "Epoch 121/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0148 - acc: 0.2347 - val_loss: 0.0289 - val_acc: 0.2000\n",
      "Epoch 122/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0150 - acc: 0.2467 - val_loss: 0.0339 - val_acc: 0.2120\n",
      "Epoch 123/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0164 - acc: 0.2467 - val_loss: 0.0271 - val_acc: 0.2040\n",
      "Epoch 124/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0153 - acc: 0.2680 - val_loss: 0.0307 - val_acc: 0.1800\n",
      "Epoch 125/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0140 - acc: 0.2520 - val_loss: 0.0282 - val_acc: 0.2120\n",
      "Epoch 126/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0136 - acc: 0.2507 - val_loss: 0.0311 - val_acc: 0.1560\n",
      "Epoch 127/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0140 - acc: 0.2573 - val_loss: 0.0292 - val_acc: 0.2200\n",
      "Epoch 128/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0137 - acc: 0.2600 - val_loss: 0.0290 - val_acc: 0.2000\n",
      "Epoch 129/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0146 - acc: 0.2827 - val_loss: 0.0365 - val_acc: 0.1840\n",
      "Epoch 130/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0154 - acc: 0.2373 - val_loss: 0.0275 - val_acc: 0.1880\n",
      "Epoch 131/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0142 - acc: 0.2440 - val_loss: 0.0310 - val_acc: 0.1920\n",
      "Epoch 132/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0131 - acc: 0.2440 - val_loss: 0.0306 - val_acc: 0.1920\n",
      "Epoch 133/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0129 - acc: 0.2267 - val_loss: 0.0287 - val_acc: 0.2360\n",
      "Epoch 134/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0130 - acc: 0.2493 - val_loss: 0.0307 - val_acc: 0.2000\n",
      "Epoch 135/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0127 - acc: 0.2640 - val_loss: 0.0295 - val_acc: 0.1760\n",
      "Epoch 136/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0128 - acc: 0.2547 - val_loss: 0.0336 - val_acc: 0.2080\n",
      "Epoch 137/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0127 - acc: 0.2827 - val_loss: 0.0277 - val_acc: 0.2200\n",
      "Epoch 138/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0130 - acc: 0.3080 - val_loss: 0.0343 - val_acc: 0.2000\n",
      "Epoch 139/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0126 - acc: 0.2587 - val_loss: 0.0278 - val_acc: 0.2480\n",
      "Epoch 140/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0120 - acc: 0.2933 - val_loss: 0.0338 - val_acc: 0.2040\n",
      "Epoch 141/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0119 - acc: 0.2827 - val_loss: 0.0282 - val_acc: 0.2240\n",
      "Epoch 142/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0122 - acc: 0.2733 - val_loss: 0.0316 - val_acc: 0.2360\n",
      "Epoch 143/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0118 - acc: 0.3080 - val_loss: 0.0290 - val_acc: 0.1960\n",
      "Epoch 144/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0114 - acc: 0.2773 - val_loss: 0.0319 - val_acc: 0.2120\n",
      "Epoch 145/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0111 - acc: 0.2920 - val_loss: 0.0289 - val_acc: 0.2200\n",
      "Epoch 146/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0109 - acc: 0.2933 - val_loss: 0.0340 - val_acc: 0.2000\n",
      "Epoch 147/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0116 - acc: 0.2840 - val_loss: 0.0278 - val_acc: 0.2440\n",
      "Epoch 148/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0113 - acc: 0.3120 - val_loss: 0.0320 - val_acc: 0.2080\n",
      "Epoch 149/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0105 - acc: 0.2920 - val_loss: 0.0301 - val_acc: 0.2360\n",
      "Epoch 150/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0099 - acc: 0.2827 - val_loss: 0.0299 - val_acc: 0.2080\n",
      "Epoch 151/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0101 - acc: 0.2987 - val_loss: 0.0322 - val_acc: 0.2240\n",
      "Epoch 152/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0099 - acc: 0.3093 - val_loss: 0.0297 - val_acc: 0.2400\n",
      "Epoch 153/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0105 - acc: 0.3173 - val_loss: 0.0307 - val_acc: 0.1880\n",
      "Epoch 154/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0100 - acc: 0.2733 - val_loss: 0.0321 - val_acc: 0.2200\n",
      "Epoch 155/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0101 - acc: 0.3400 - val_loss: 0.0301 - val_acc: 0.2360\n",
      "Epoch 156/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0103 - acc: 0.3320 - val_loss: 0.0341 - val_acc: 0.1960\n",
      "Epoch 157/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0100 - acc: 0.3227 - val_loss: 0.0291 - val_acc: 0.2280\n",
      "Epoch 158/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0090 - acc: 0.3133 - val_loss: 0.0316 - val_acc: 0.2120\n",
      "Epoch 159/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0086 - acc: 0.3187 - val_loss: 0.0306 - val_acc: 0.2360\n",
      "Epoch 160/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0091 - acc: 0.2880 - val_loss: 0.0306 - val_acc: 0.2280\n",
      "Epoch 161/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0089 - acc: 0.3320 - val_loss: 0.0357 - val_acc: 0.2360\n",
      "Epoch 162/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0091 - acc: 0.3467 - val_loss: 0.0298 - val_acc: 0.2240\n",
      "Epoch 163/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0085 - acc: 0.3613 - val_loss: 0.0328 - val_acc: 0.2160\n",
      "Epoch 164/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0095 - acc: 0.3120 - val_loss: 0.0309 - val_acc: 0.2240\n",
      "Epoch 165/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0098 - acc: 0.3040 - val_loss: 0.0319 - val_acc: 0.2360\n",
      "Epoch 166/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0082 - acc: 0.3693 - val_loss: 0.0303 - val_acc: 0.2520\n",
      "Epoch 167/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0078 - acc: 0.3587 - val_loss: 0.0312 - val_acc: 0.2400\n",
      "Epoch 168/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0076 - acc: 0.3347 - val_loss: 0.0318 - val_acc: 0.2320\n",
      "Epoch 169/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0075 - acc: 0.3453 - val_loss: 0.0320 - val_acc: 0.2400\n",
      "Epoch 170/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0077 - acc: 0.3520 - val_loss: 0.0312 - val_acc: 0.2640\n",
      "Epoch 171/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0078 - acc: 0.3453 - val_loss: 0.0382 - val_acc: 0.2600\n",
      "Epoch 172/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0102 - acc: 0.3680 - val_loss: 0.0282 - val_acc: 0.2320\n",
      "Epoch 173/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0077 - acc: 0.3560 - val_loss: 0.0327 - val_acc: 0.2440\n",
      "Epoch 174/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0069 - acc: 0.3627 - val_loss: 0.0316 - val_acc: 0.2320\n",
      "Epoch 175/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0067 - acc: 0.3760 - val_loss: 0.0316 - val_acc: 0.2360\n",
      "Epoch 176/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0070 - acc: 0.3560 - val_loss: 0.0334 - val_acc: 0.2440\n",
      "Epoch 177/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0082 - acc: 0.3333 - val_loss: 0.0309 - val_acc: 0.2600\n",
      "Epoch 178/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0070 - acc: 0.3760 - val_loss: 0.0327 - val_acc: 0.2440\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 172us/step - loss: 0.0065 - acc: 0.3973 - val_loss: 0.0312 - val_acc: 0.2720\n",
      "Epoch 180/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0064 - acc: 0.3773 - val_loss: 0.0329 - val_acc: 0.2440\n",
      "Epoch 181/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0063 - acc: 0.4027 - val_loss: 0.0326 - val_acc: 0.2720\n",
      "Epoch 182/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0069 - acc: 0.3960 - val_loss: 0.0310 - val_acc: 0.2400\n",
      "Epoch 183/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0070 - acc: 0.3667 - val_loss: 0.0351 - val_acc: 0.2400\n",
      "Epoch 184/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0064 - acc: 0.4027 - val_loss: 0.0321 - val_acc: 0.2680\n",
      "Epoch 185/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0061 - acc: 0.4187 - val_loss: 0.0340 - val_acc: 0.2320\n",
      "Epoch 186/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0068 - acc: 0.4547 - val_loss: 0.0306 - val_acc: 0.2880\n",
      "Epoch 187/1000\n",
      "750/750 [==============================] - 0s 191us/step - loss: 0.0068 - acc: 0.4227 - val_loss: 0.0357 - val_acc: 0.2080\n",
      "Epoch 188/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0068 - acc: 0.4027 - val_loss: 0.0307 - val_acc: 0.2360\n",
      "Epoch 189/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0056 - acc: 0.4680 - val_loss: 0.0329 - val_acc: 0.2640\n",
      "Epoch 190/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0057 - acc: 0.4587 - val_loss: 0.0311 - val_acc: 0.2240\n",
      "Epoch 191/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0064 - acc: 0.4213 - val_loss: 0.0338 - val_acc: 0.2480\n",
      "Epoch 192/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0060 - acc: 0.4213 - val_loss: 0.0320 - val_acc: 0.2680\n",
      "Epoch 193/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0054 - acc: 0.4560 - val_loss: 0.0331 - val_acc: 0.2680\n",
      "Epoch 194/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0051 - acc: 0.4933 - val_loss: 0.0328 - val_acc: 0.2760\n",
      "Epoch 195/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0054 - acc: 0.4600 - val_loss: 0.0336 - val_acc: 0.2480\n",
      "Epoch 196/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0059 - acc: 0.4213 - val_loss: 0.0310 - val_acc: 0.2760\n",
      "Epoch 197/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0064 - acc: 0.4253 - val_loss: 0.0392 - val_acc: 0.2160\n",
      "Epoch 198/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0054 - acc: 0.4760 - val_loss: 0.0327 - val_acc: 0.2880\n",
      "Epoch 199/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0049 - acc: 0.4773 - val_loss: 0.0326 - val_acc: 0.2920\n",
      "Epoch 200/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0049 - acc: 0.4987 - val_loss: 0.0344 - val_acc: 0.2720\n",
      "Epoch 201/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0053 - acc: 0.5187 - val_loss: 0.0327 - val_acc: 0.2480\n",
      "Epoch 202/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0057 - acc: 0.4520 - val_loss: 0.0343 - val_acc: 0.2680\n",
      "Epoch 203/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0048 - acc: 0.4693 - val_loss: 0.0328 - val_acc: 0.2720\n",
      "Epoch 204/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0045 - acc: 0.5280 - val_loss: 0.0335 - val_acc: 0.2720\n",
      "Epoch 205/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0046 - acc: 0.5133 - val_loss: 0.0324 - val_acc: 0.2440\n",
      "Epoch 206/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0052 - acc: 0.4800 - val_loss: 0.0417 - val_acc: 0.2560\n",
      "Epoch 207/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0065 - acc: 0.4600 - val_loss: 0.0304 - val_acc: 0.2760\n",
      "Epoch 208/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0051 - acc: 0.4907 - val_loss: 0.0329 - val_acc: 0.2640\n",
      "Epoch 209/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0042 - acc: 0.5400 - val_loss: 0.0328 - val_acc: 0.2960\n",
      "Epoch 210/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0041 - acc: 0.5653 - val_loss: 0.0330 - val_acc: 0.3080\n",
      "Epoch 211/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0043 - acc: 0.5400 - val_loss: 0.0337 - val_acc: 0.2760\n",
      "Epoch 212/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0048 - acc: 0.5387 - val_loss: 0.0352 - val_acc: 0.2520\n",
      "Epoch 213/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0047 - acc: 0.5427 - val_loss: 0.0329 - val_acc: 0.3000\n",
      "Epoch 214/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0041 - acc: 0.5720 - val_loss: 0.0337 - val_acc: 0.2680\n",
      "Epoch 215/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0040 - acc: 0.5893 - val_loss: 0.0333 - val_acc: 0.2800\n",
      "Epoch 216/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0039 - acc: 0.5640 - val_loss: 0.0339 - val_acc: 0.2640\n",
      "Epoch 217/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0041 - acc: 0.5227 - val_loss: 0.0347 - val_acc: 0.3080\n",
      "Epoch 218/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0041 - acc: 0.5680 - val_loss: 0.0338 - val_acc: 0.2560\n",
      "Epoch 219/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0040 - acc: 0.5587 - val_loss: 0.0324 - val_acc: 0.2800\n",
      "Epoch 220/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0061 - acc: 0.4987 - val_loss: 0.0395 - val_acc: 0.2240\n",
      "Epoch 221/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0057 - acc: 0.4987 - val_loss: 0.0328 - val_acc: 0.2440\n",
      "Epoch 222/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0038 - acc: 0.5853 - val_loss: 0.0336 - val_acc: 0.2840\n",
      "Epoch 223/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0036 - acc: 0.6293 - val_loss: 0.0337 - val_acc: 0.2920\n",
      "Epoch 224/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0035 - acc: 0.6307 - val_loss: 0.0338 - val_acc: 0.2960\n",
      "Epoch 225/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0035 - acc: 0.6520 - val_loss: 0.0338 - val_acc: 0.2760\n",
      "Epoch 226/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0035 - acc: 0.6253 - val_loss: 0.0344 - val_acc: 0.2680\n",
      "Epoch 227/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0035 - acc: 0.6453 - val_loss: 0.0336 - val_acc: 0.2640\n",
      "Epoch 228/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0038 - acc: 0.5933 - val_loss: 0.0358 - val_acc: 0.2480\n",
      "Epoch 229/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0041 - acc: 0.6040 - val_loss: 0.0333 - val_acc: 0.3080\n",
      "Epoch 230/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0037 - acc: 0.6387 - val_loss: 0.0348 - val_acc: 0.2720\n",
      "Epoch 231/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0034 - acc: 0.6813 - val_loss: 0.0338 - val_acc: 0.2880\n",
      "Epoch 232/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0034 - acc: 0.7040 - val_loss: 0.0347 - val_acc: 0.3040\n",
      "Epoch 233/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0034 - acc: 0.6800 - val_loss: 0.0322 - val_acc: 0.2920\n",
      "Epoch 234/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0050 - acc: 0.5253 - val_loss: 0.0467 - val_acc: 0.2240\n",
      "Epoch 235/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0056 - acc: 0.5333 - val_loss: 0.0323 - val_acc: 0.3080\n",
      "Epoch 236/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0036 - acc: 0.6680 - val_loss: 0.0329 - val_acc: 0.3040\n",
      "Epoch 237/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0033 - acc: 0.6920 - val_loss: 0.0330 - val_acc: 0.2920\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 168us/step - loss: 0.0032 - acc: 0.7067 - val_loss: 0.0331 - val_acc: 0.3080\n",
      "Epoch 239/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0032 - acc: 0.7093 - val_loss: 0.0331 - val_acc: 0.2880\n",
      "Epoch 240/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0031 - acc: 0.7147 - val_loss: 0.0333 - val_acc: 0.3200\n",
      "Epoch 241/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0031 - acc: 0.7213 - val_loss: 0.0336 - val_acc: 0.3120\n",
      "Epoch 242/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0035 - acc: 0.6573 - val_loss: 0.0334 - val_acc: 0.3320\n",
      "Epoch 243/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0052 - acc: 0.5373 - val_loss: 0.0334 - val_acc: 0.2600\n",
      "Epoch 244/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0038 - acc: 0.6520 - val_loss: 0.0335 - val_acc: 0.3160\n",
      "Epoch 245/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0033 - acc: 0.7027 - val_loss: 0.0340 - val_acc: 0.3120\n",
      "Epoch 246/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0031 - acc: 0.7373 - val_loss: 0.0336 - val_acc: 0.3040\n",
      "Epoch 247/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0030 - acc: 0.7440 - val_loss: 0.0337 - val_acc: 0.3160\n",
      "Epoch 248/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0029 - acc: 0.7427 - val_loss: 0.0336 - val_acc: 0.2920\n",
      "Epoch 249/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0028 - acc: 0.7267 - val_loss: 0.0339 - val_acc: 0.2920\n",
      "Epoch 250/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0028 - acc: 0.7480 - val_loss: 0.0340 - val_acc: 0.3120\n",
      "Epoch 251/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0028 - acc: 0.7080 - val_loss: 0.0345 - val_acc: 0.2760\n",
      "Epoch 252/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0040 - acc: 0.5640 - val_loss: 0.0365 - val_acc: 0.2600\n",
      "Epoch 253/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0052 - acc: 0.5560 - val_loss: 0.0328 - val_acc: 0.2840\n",
      "Epoch 254/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0029 - acc: 0.6880 - val_loss: 0.0341 - val_acc: 0.3000\n",
      "Epoch 255/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 0.7560 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 256/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0026 - acc: 0.7760 - val_loss: 0.0339 - val_acc: 0.3120\n",
      "Epoch 257/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7693 - val_loss: 0.0339 - val_acc: 0.3080\n",
      "Epoch 258/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7827 - val_loss: 0.0338 - val_acc: 0.3160\n",
      "Epoch 259/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0026 - acc: 0.7867 - val_loss: 0.0339 - val_acc: 0.2960\n",
      "Epoch 260/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0026 - acc: 0.7933 - val_loss: 0.0339 - val_acc: 0.3120\n",
      "Epoch 261/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.8000 - val_loss: 0.0338 - val_acc: 0.3080\n",
      "Epoch 262/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7987 - val_loss: 0.0339 - val_acc: 0.2680\n",
      "Epoch 263/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.8133 - val_loss: 0.0347 - val_acc: 0.2680\n",
      "Epoch 264/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0040 - acc: 0.6280 - val_loss: 0.0313 - val_acc: 0.2560\n",
      "Epoch 265/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0050 - acc: 0.5987 - val_loss: 0.0340 - val_acc: 0.2520\n",
      "Epoch 266/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 0.7133 - val_loss: 0.0337 - val_acc: 0.2960\n",
      "Epoch 267/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0026 - acc: 0.7787 - val_loss: 0.0338 - val_acc: 0.2960\n",
      "Epoch 268/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0025 - acc: 0.7853 - val_loss: 0.0339 - val_acc: 0.2960\n",
      "Epoch 269/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.7960 - val_loss: 0.0339 - val_acc: 0.3040\n",
      "Epoch 270/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0025 - acc: 0.7987 - val_loss: 0.0339 - val_acc: 0.3000\n",
      "Epoch 271/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8067 - val_loss: 0.0340 - val_acc: 0.2920\n",
      "Epoch 272/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8200 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 273/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8200 - val_loss: 0.0340 - val_acc: 0.3160\n",
      "Epoch 274/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8373 - val_loss: 0.0340 - val_acc: 0.2840\n",
      "Epoch 275/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8187 - val_loss: 0.0339 - val_acc: 0.3240\n",
      "Epoch 276/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.8093 - val_loss: 0.0344 - val_acc: 0.2640\n",
      "Epoch 277/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0039 - acc: 0.6667 - val_loss: 0.0322 - val_acc: 0.2560\n",
      "Epoch 278/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0053 - acc: 0.5280 - val_loss: 0.0362 - val_acc: 0.3120\n",
      "Epoch 279/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.7533 - val_loss: 0.0342 - val_acc: 0.3320\n",
      "Epoch 280/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0025 - acc: 0.7760 - val_loss: 0.0343 - val_acc: 0.3200\n",
      "Epoch 281/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0024 - acc: 0.7987 - val_loss: 0.0343 - val_acc: 0.3200\n",
      "Epoch 282/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0024 - acc: 0.8000 - val_loss: 0.0343 - val_acc: 0.3200\n",
      "Epoch 283/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8107 - val_loss: 0.0343 - val_acc: 0.3200\n",
      "Epoch 284/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8107 - val_loss: 0.0343 - val_acc: 0.3200\n",
      "Epoch 285/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8293 - val_loss: 0.0343 - val_acc: 0.3200\n",
      "Epoch 286/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8347 - val_loss: 0.0343 - val_acc: 0.3160\n",
      "Epoch 287/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8413 - val_loss: 0.0344 - val_acc: 0.3160\n",
      "Epoch 288/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.8520 - val_loss: 0.0344 - val_acc: 0.3200\n",
      "Epoch 289/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8720 - val_loss: 0.0344 - val_acc: 0.3200\n",
      "Epoch 290/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8653 - val_loss: 0.0344 - val_acc: 0.3120\n",
      "Epoch 291/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8800 - val_loss: 0.0344 - val_acc: 0.3200\n",
      "Epoch 292/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8893 - val_loss: 0.0344 - val_acc: 0.3000\n",
      "Epoch 293/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0026 - acc: 0.7827 - val_loss: 0.0354 - val_acc: 0.2720\n",
      "Epoch 294/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0049 - acc: 0.5773 - val_loss: 0.0425 - val_acc: 0.2440\n",
      "Epoch 295/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0031 - acc: 0.6973 - val_loss: 0.0331 - val_acc: 0.3160\n",
      "Epoch 296/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8040 - val_loss: 0.0335 - val_acc: 0.3120\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8347 - val_loss: 0.0337 - val_acc: 0.3080\n",
      "Epoch 298/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8467 - val_loss: 0.0338 - val_acc: 0.3040\n",
      "Epoch 299/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8520 - val_loss: 0.0338 - val_acc: 0.3080\n",
      "Epoch 300/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8587 - val_loss: 0.0338 - val_acc: 0.3040\n",
      "Epoch 301/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8653 - val_loss: 0.0339 - val_acc: 0.3080\n",
      "Epoch 302/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8760 - val_loss: 0.0339 - val_acc: 0.3160\n",
      "Epoch 303/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.8853 - val_loss: 0.0339 - val_acc: 0.3160\n",
      "Epoch 304/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0024 - acc: 0.8800 - val_loss: 0.0339 - val_acc: 0.3080\n",
      "Epoch 305/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8920 - val_loss: 0.0339 - val_acc: 0.3200\n",
      "Epoch 306/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8987 - val_loss: 0.0339 - val_acc: 0.3160\n",
      "Epoch 307/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.9093 - val_loss: 0.0340 - val_acc: 0.3200\n",
      "Epoch 308/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.9133 - val_loss: 0.0339 - val_acc: 0.3120\n",
      "Epoch 309/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.9253 - val_loss: 0.0339 - val_acc: 0.3200\n",
      "Epoch 310/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.9240 - val_loss: 0.0339 - val_acc: 0.3080\n",
      "Epoch 311/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.9347 - val_loss: 0.0339 - val_acc: 0.3200\n",
      "Epoch 312/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0024 - acc: 0.9320 - val_loss: 0.0339 - val_acc: 0.3080\n",
      "Epoch 313/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.9360 - val_loss: 0.0339 - val_acc: 0.3120\n",
      "Epoch 314/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.9307 - val_loss: 0.0348 - val_acc: 0.2640\n",
      "Epoch 315/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0047 - acc: 0.6320 - val_loss: 0.0315 - val_acc: 0.2760\n",
      "Epoch 316/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0034 - acc: 0.6760 - val_loss: 0.0364 - val_acc: 0.3240\n",
      "Epoch 317/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 0.8467 - val_loss: 0.0347 - val_acc: 0.3080\n",
      "Epoch 318/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8587 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 319/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8613 - val_loss: 0.0347 - val_acc: 0.3160\n",
      "Epoch 320/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8707 - val_loss: 0.0347 - val_acc: 0.3160\n",
      "Epoch 321/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8680 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 322/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8800 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 323/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8787 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 324/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8867 - val_loss: 0.0347 - val_acc: 0.3080\n",
      "Epoch 325/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.8947 - val_loss: 0.0347 - val_acc: 0.3080\n",
      "Epoch 326/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0024 - acc: 0.9013 - val_loss: 0.0347 - val_acc: 0.3080\n",
      "Epoch 327/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0024 - acc: 0.9000 - val_loss: 0.0347 - val_acc: 0.3080\n",
      "Epoch 328/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.9293 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 329/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.9213 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 330/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.9400 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 331/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0024 - acc: 0.9360 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 332/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0024 - acc: 0.9413 - val_loss: 0.0348 - val_acc: 0.3160\n",
      "Epoch 333/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.9440 - val_loss: 0.0347 - val_acc: 0.3160\n",
      "Epoch 334/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.9507 - val_loss: 0.0348 - val_acc: 0.3160\n",
      "Epoch 335/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.9547 - val_loss: 0.0348 - val_acc: 0.3160\n",
      "Epoch 336/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.9427 - val_loss: 0.0348 - val_acc: 0.3160\n",
      "Epoch 337/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.9547 - val_loss: 0.0348 - val_acc: 0.3160\n",
      "Epoch 338/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0024 - acc: 0.9533 - val_loss: 0.0348 - val_acc: 0.3160\n",
      "Epoch 339/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0024 - acc: 0.9573 - val_loss: 0.0348 - val_acc: 0.3120\n",
      "Epoch 340/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 0.9440 - val_loss: 0.0354 - val_acc: 0.2880\n",
      "Epoch 341/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0053 - acc: 0.6200 - val_loss: 0.0372 - val_acc: 0.2760\n",
      "Epoch 342/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0036 - acc: 0.6467 - val_loss: 0.0340 - val_acc: 0.3080\n",
      "Epoch 343/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0028 - acc: 0.7960 - val_loss: 0.0343 - val_acc: 0.3160\n",
      "Epoch 344/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0027 - acc: 0.8160 - val_loss: 0.0343 - val_acc: 0.3120\n",
      "Epoch 345/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0028 - acc: 0.8120 - val_loss: 0.0339 - val_acc: 0.2960\n",
      "Epoch 346/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0026 - acc: 0.8053 - val_loss: 0.0356 - val_acc: 0.3000\n",
      "Epoch 347/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0027 - acc: 0.7893 - val_loss: 0.0354 - val_acc: 0.2960\n",
      "Epoch 348/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0024 - acc: 0.8400 - val_loss: 0.0346 - val_acc: 0.3080\n",
      "Epoch 349/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0024 - acc: 0.8747 - val_loss: 0.0347 - val_acc: 0.3160\n",
      "Epoch 350/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0023 - acc: 0.8813 - val_loss: 0.0347 - val_acc: 0.3160\n",
      "Epoch 351/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0023 - acc: 0.8907 - val_loss: 0.0346 - val_acc: 0.3120\n",
      "Epoch 352/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0023 - acc: 0.8907 - val_loss: 0.0346 - val_acc: 0.3120\n",
      "Epoch 353/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0023 - acc: 0.9040 - val_loss: 0.0346 - val_acc: 0.3160\n",
      "Epoch 354/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0023 - acc: 0.9080 - val_loss: 0.0346 - val_acc: 0.3120\n",
      "Epoch 355/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0023 - acc: 0.9213 - val_loss: 0.0346 - val_acc: 0.3160\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 172us/step - loss: 0.0023 - acc: 0.9107 - val_loss: 0.0346 - val_acc: 0.3240\n",
      "Epoch 357/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0023 - acc: 0.9307 - val_loss: 0.0347 - val_acc: 0.3120\n",
      "Epoch 358/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0024 - acc: 0.8307 - val_loss: 0.0378 - val_acc: 0.2360\n",
      "Epoch 359/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0048 - acc: 0.5747 - val_loss: 0.0326 - val_acc: 0.2680\n",
      "Epoch 360/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0025 - acc: 0.7120 - val_loss: 0.0345 - val_acc: 0.3120\n",
      "Epoch 361/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0023 - acc: 0.8227 - val_loss: 0.0345 - val_acc: 0.3160\n",
      "Epoch 362/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0023 - acc: 0.8480 - val_loss: 0.0345 - val_acc: 0.3120\n",
      "Epoch 363/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0023 - acc: 0.8560 - val_loss: 0.0345 - val_acc: 0.3120\n",
      "Epoch 364/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.8627 - val_loss: 0.0345 - val_acc: 0.3120\n",
      "Epoch 365/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.8707 - val_loss: 0.0345 - val_acc: 0.3160\n",
      "Epoch 366/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.8867 - val_loss: 0.0346 - val_acc: 0.3240\n",
      "Epoch 367/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9000 - val_loss: 0.0344 - val_acc: 0.3160\n",
      "Epoch 368/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.8907 - val_loss: 0.0346 - val_acc: 0.3200\n",
      "Epoch 369/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9053 - val_loss: 0.0344 - val_acc: 0.3240\n",
      "Epoch 370/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9053 - val_loss: 0.0347 - val_acc: 0.3240\n",
      "Epoch 371/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0022 - acc: 0.9147 - val_loss: 0.0345 - val_acc: 0.3240\n",
      "Epoch 372/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.9253 - val_loss: 0.0346 - val_acc: 0.3280\n",
      "Epoch 373/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.9200 - val_loss: 0.0344 - val_acc: 0.3200\n",
      "Epoch 374/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0032 - acc: 0.7453 - val_loss: 0.0433 - val_acc: 0.2560\n",
      "Epoch 375/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0040 - acc: 0.6613 - val_loss: 0.0348 - val_acc: 0.2720\n",
      "Epoch 376/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0023 - acc: 0.8400 - val_loss: 0.0350 - val_acc: 0.3000\n",
      "Epoch 377/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.8760 - val_loss: 0.0350 - val_acc: 0.2960\n",
      "Epoch 378/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0022 - acc: 0.8840 - val_loss: 0.0350 - val_acc: 0.2920\n",
      "Epoch 379/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0022 - acc: 0.8987 - val_loss: 0.0350 - val_acc: 0.2960\n",
      "Epoch 380/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.8920 - val_loss: 0.0350 - val_acc: 0.2960\n",
      "Epoch 381/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9133 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 382/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9147 - val_loss: 0.0349 - val_acc: 0.3000\n",
      "Epoch 383/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9227 - val_loss: 0.0350 - val_acc: 0.3080\n",
      "Epoch 384/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9120 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 385/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9333 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 386/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9320 - val_loss: 0.0350 - val_acc: 0.3000\n",
      "Epoch 387/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9360 - val_loss: 0.0350 - val_acc: 0.3000\n",
      "Epoch 388/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9347 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 389/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9440 - val_loss: 0.0350 - val_acc: 0.3000\n",
      "Epoch 390/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9480 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 391/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9533 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 392/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9507 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 393/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9533 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 394/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9573 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 395/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 396/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9573 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 397/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9587 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 398/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0021 - acc: 0.9573 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 399/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 400/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 401/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 402/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 403/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 404/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 405/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 406/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 407/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 408/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 409/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 410/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 411/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 412/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 413/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 414/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 416/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 417/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 418/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 419/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 420/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 421/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 422/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 423/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 424/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 425/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 426/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 427/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 428/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 429/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 430/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 431/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 432/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 433/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 434/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 435/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 436/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 437/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 438/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 439/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 440/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 441/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 442/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 443/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 444/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 445/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 446/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 447/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 448/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 449/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 450/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 451/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 452/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 453/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 454/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 455/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 456/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 457/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 458/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 459/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 460/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 461/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 462/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 463/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 464/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 465/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 466/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 467/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 468/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 469/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 470/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 471/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 472/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 473/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 176us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 475/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 476/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 477/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 478/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 479/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 480/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 481/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 482/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 483/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 484/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 485/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 486/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 487/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 488/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 489/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 490/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 491/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 492/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 493/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 494/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 495/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 496/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 497/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 498/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 499/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 500/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 501/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 502/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 503/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 504/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 505/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 506/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 507/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 508/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 509/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 510/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 511/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 512/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 513/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 514/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 515/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 516/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 517/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 518/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 519/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 520/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 521/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 522/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 523/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 524/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 525/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 526/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 527/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 528/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 529/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 530/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 531/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 532/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 534/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 535/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 536/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 537/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 538/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 539/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 540/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 541/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 542/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 543/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 544/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 545/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 546/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 547/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 548/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 549/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 550/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 551/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 552/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 553/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 554/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 555/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 556/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 557/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 558/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 559/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 560/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 561/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 562/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 563/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 564/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 565/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 566/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 567/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 568/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 569/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 570/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 571/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 572/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 573/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 574/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 575/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 576/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 577/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 578/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 579/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 580/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 581/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 582/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 583/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 584/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 585/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 586/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 587/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 588/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 589/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 590/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 591/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 593/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 594/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 595/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 596/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 597/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 598/1000\n",
      "750/750 [==============================] - 0s 164us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 599/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 600/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 601/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 602/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 603/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 604/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 605/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 606/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 607/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 608/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 609/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 610/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 611/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 612/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 613/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 614/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 615/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 616/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 617/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 618/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 619/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 620/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 621/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 622/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 623/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 624/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 625/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 626/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 627/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 628/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 629/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 630/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 631/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 632/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 633/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 634/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 635/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 636/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 637/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 638/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 639/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 640/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 641/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 642/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 643/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 644/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 645/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 646/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 647/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 648/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 649/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 650/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 652/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 653/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 654/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 655/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 656/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 657/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 658/1000\n",
      "750/750 [==============================] - 0s 193us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 659/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 660/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 661/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 662/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 663/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 664/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 665/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 666/1000\n",
      "750/750 [==============================] - 0s 192us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 667/1000\n",
      "750/750 [==============================] - 0s 183us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 668/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 669/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 670/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 671/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 672/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 673/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 674/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 675/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 676/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 677/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 678/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 679/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 680/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 681/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 682/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 683/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 684/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 685/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 686/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 687/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 688/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 689/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 690/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 691/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 692/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 693/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 694/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 695/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 696/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 697/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 698/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 699/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 700/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 701/1000\n",
      "750/750 [==============================] - 0s 187us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 702/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 703/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 704/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 705/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 706/1000\n",
      "750/750 [==============================] - 0s 185us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 707/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 708/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 709/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 711/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 712/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 713/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 714/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 715/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 716/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 717/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 718/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 719/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 720/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 721/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 722/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 723/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 724/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 725/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 726/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 727/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 728/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 729/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 730/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 731/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 732/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 733/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 734/1000\n",
      "750/750 [==============================] - 0s 184us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 735/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 736/1000\n",
      "750/750 [==============================] - 0s 189us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 737/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 738/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 739/1000\n",
      "750/750 [==============================] - 0s 186us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 740/1000\n",
      "750/750 [==============================] - 0s 181us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 741/1000\n",
      "750/750 [==============================] - 0s 180us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 742/1000\n",
      "750/750 [==============================] - 0s 188us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 743/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 744/1000\n",
      "750/750 [==============================] - 0s 190us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 745/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 746/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 747/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 748/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 749/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 750/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 751/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 752/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 753/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 754/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 755/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 756/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 757/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 758/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 759/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 760/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 761/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 762/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 763/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 764/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 765/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 766/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 767/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 768/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 770/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 771/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 772/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 773/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 774/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 775/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 776/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 777/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 778/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 779/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 780/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 781/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 782/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 783/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 784/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 785/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 786/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 787/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 788/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 789/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 790/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 791/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 792/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 793/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 794/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 795/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 796/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 797/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 798/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 799/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 800/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 801/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 802/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 803/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 804/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 805/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 806/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 807/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 808/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 809/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 810/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 811/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 812/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 813/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 814/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 815/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 816/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 817/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 818/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 819/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 820/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 821/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 822/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 823/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 824/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 825/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 826/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 827/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 829/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 830/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 831/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 832/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 833/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 834/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 835/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 836/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 837/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 838/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 839/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 840/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 841/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 842/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 843/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 844/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 845/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 846/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 847/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 848/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 849/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 850/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 851/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 852/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 853/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 854/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 855/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 856/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 857/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 858/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 859/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 860/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 861/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 862/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 863/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 864/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 865/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 866/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 867/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 868/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 869/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 870/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 871/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 872/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 873/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 874/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 875/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 876/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 877/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 878/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 879/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 880/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 881/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 882/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 883/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 884/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 885/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 886/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 888/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 889/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 890/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 891/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 892/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 893/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 894/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 895/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 896/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 897/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 898/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 899/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 900/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 901/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 902/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 903/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 904/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 905/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 906/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 907/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 908/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 909/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 910/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 911/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 912/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 913/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 914/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 915/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 916/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 917/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 918/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 919/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 920/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 921/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 922/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 923/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 924/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 925/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 926/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 927/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 928/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 929/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 930/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 931/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 932/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 933/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 934/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 935/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 936/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 937/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 938/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 939/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 940/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 941/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 942/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 943/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 944/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 945/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 947/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 948/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 949/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 950/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 951/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 952/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 953/1000\n",
      "750/750 [==============================] - 0s 165us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 954/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 955/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 956/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 957/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 958/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 959/1000\n",
      "750/750 [==============================] - 0s 172us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 960/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 961/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 962/1000\n",
      "750/750 [==============================] - 0s 171us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 963/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 964/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 965/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 966/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 967/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 968/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 969/1000\n",
      "750/750 [==============================] - 0s 177us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 970/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 971/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 972/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 973/1000\n",
      "750/750 [==============================] - 0s 169us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 974/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 975/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 976/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 977/1000\n",
      "750/750 [==============================] - 0s 168us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 978/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 979/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 980/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 981/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 982/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 983/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 984/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 985/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 986/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 987/1000\n",
      "750/750 [==============================] - 0s 166us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 988/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 989/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 990/1000\n",
      "750/750 [==============================] - 0s 174us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 991/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 992/1000\n",
      "750/750 [==============================] - 0s 170us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 993/1000\n",
      "750/750 [==============================] - 0s 176us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 994/1000\n",
      "750/750 [==============================] - 0s 179us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 995/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 996/1000\n",
      "750/750 [==============================] - 0s 175us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 997/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 998/1000\n",
      "750/750 [==============================] - 0s 167us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 999/1000\n",
      "750/750 [==============================] - 0s 173us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n",
      "Epoch 1000/1000\n",
      "750/750 [==============================] - 0s 178us/step - loss: 0.0021 - acc: 0.9600 - val_loss: 0.0350 - val_acc: 0.3040\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense, Flatten,LSTM, TimeDistributed, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TIME_STEPS = 10\n",
    "INPUT_SIZE = 512\n",
    "BATCH_SIZE = 250\n",
    "BATCH_INDEX = 0\n",
    "OUTPUT_SIZE = 512\n",
    "#CELL_SIZE = 800\n",
    "LR = 0.001\n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "# loading data\n",
    "X_train = np.loadtxt(\"0220_spec_train_1000*5120.txt\")\n",
    "y_train = np.loadtxt(\"0220_mask_train_1000*512.txt\")\n",
    "\n",
    "X_test = np.loadtxt(\"0220_spec_test_1000*5120.txt\")\n",
    "y_test = np.loadtxt(\"0220_mask_test_1000*512.txt\")\n",
    "\n",
    "# batch_size=y_test.shape[0]\n",
    "\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 10, 512)\n",
    "#y_train = y_train.reshape(-1, 3, 512)\n",
    "X_test = X_test.reshape(-1, 10, 512)\n",
    "#y_test = y_test.reshape(-1, 3, 512)\n",
    "\n",
    "\n",
    "#  build RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# RNN cell\n",
    "\n",
    "model.add(LSTM(\n",
    "    units =512,\n",
    "    batch_input_shape=( BATCH_SIZE, TIME_STEPS, INPUT_SIZE),\n",
    "    #input_dim=INPUT_SIZE,\n",
    "    #input_length=TIME_STEPS,\n",
    "    #output_dim=CELL_SIZE,\n",
    "    #return_sequences=True,\n",
    "    #stateful=True \n",
    "    unroll=True\n",
    "))\n",
    "\n",
    "# output layer\n",
    "#model.add(Flatten())\n",
    "model.add((Dense(OUTPUT_SIZE)))  #TimeDistributed\n",
    "model.add(Activation('hard_sigmoid'))\n",
    "#model.add(Dropout(rate = 0.2)) \n",
    "\n",
    "# # optimizer\n",
    "#\n",
    "# optimizer\n",
    "\n",
    "rmsprop = RMSprop(lr=LR, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # training\n",
    "#\n",
    "\n",
    "# for step in range(51):\n",
    "#     # data shape = (batch_num, steps, inputs/outputs)\n",
    "#     X_batch = X_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :, :]\n",
    "#     Y_batch = y_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :]\n",
    "#     cost = model.train_on_batch(X_batch, Y_batch)\n",
    "#     BATCH_INDEX += BATCH_SIZE\n",
    "#     BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "\n",
    "#     if step % 50 == 0:\n",
    "#         print('Next_Train----------: step = ', step)\n",
    "#         train_cost, train_accuracy = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('train_cost: ', train_cost, 'train_accuracy: ', train_accuracy)\n",
    "#         cost, accuracy = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=False)\n",
    "#         print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "        \n",
    "       \n",
    "\n",
    "print('Train-------------------------')\n",
    "\n",
    "history = model.fit(X_test, y_test, validation_split=0.25, epochs=1000, shuffle=True, batch_size=250, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "#                                   [model.layers[1].output])\n",
    "# layer_output1 = get_3rd_layer_output([X_train])[0]\n",
    "\n",
    "# print(layer_output1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [32,512] vs. [250,512]\n\t [[Node: lstm_2/add_6 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_2/BiasAdd_3, lstm_2/MatMul_7)]]\n\t [[Node: activation_2/clip_by_value/_99 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_733_activation_2/clip_by_value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cd3a18128abf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction of the model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1536\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[0;32m-> 1454\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [32,512] vs. [250,512]\n\t [[Node: lstm_2/add_6 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_2/BiasAdd_3, lstm_2/MatMul_7)]]\n\t [[Node: activation_2/clip_by_value/_99 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_733_activation_2/clip_by_value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "x_pred = model.predict(X_train[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1536)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Predicted_Training_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mask = y_test.reshape(1000,1536)\n",
    "plt.imshow(abs(y_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = model.predict(X_test[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1536)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Predicted_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear_spec_input_250.txt\n",
    "#clear_mask_generated_from_threshold_250.txt\n",
    "\n",
    "y_c = np.loadtxt(\"clear_mask_generated_from_threshold_250.txt\")\n",
    "\n",
    "y_c = y_c.reshape(250,1024)\n",
    "plt.imshow(abs(y_c[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_c = np.loadtxt(\"clear_spec_input_250.txt\")\n",
    "\n",
    "\n",
    "x_c = model.predict(x_c)\n",
    "print('prediction of the model', x_c)\n",
    "print('prediction size', x_c.size)\n",
    "\n",
    "x_c = x_c.reshape(250,1024)\n",
    "plt.imshow(abs(x_c[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Predicted_Mask_for_checking\", fontsize = 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
