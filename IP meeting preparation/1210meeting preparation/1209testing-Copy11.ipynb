{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.09 testing 1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import part\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loading data\n",
    "X_train = np.loadtxt(\"1209.2_spec_train_1000.txt\")\n",
    "y_train = np.loadtxt(\"1209.2_mask_train_1000.txt\")\n",
    "\n",
    "X_test = np.loadtxt(\"1209.2_spec_test_1000.txt\")\n",
    "y_test = np.loadtxt(\"1209.2_mask_test_1000.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No hiden layer. just fully connected\n",
    "# sigmoid as activation function\n",
    "model = Sequential([\n",
    "    Dense(1024, input_dim=1024),\n",
    "    Activation('relu'), \n",
    "    Dense(1024),\n",
    "    Activation('relu'), \n",
    "    Dense(1024),\n",
    "    Activation('hard_sigmoid'),  # ,sigmoid softmax\n",
    "    #Dense(247),\n",
    "    #Activation('relu'),\n",
    "    #Dense(2470),\n",
    "    #Activation('sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-------------------------\n",
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/2000\n",
      "750/750 [==============================] - 1s 936us/step - loss: 0.2289 - acc: 0.0040 - val_loss: 0.1920 - val_acc: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "750/750 [==============================] - 0s 133us/step - loss: 0.1512 - acc: 0.0013 - val_loss: 0.0978 - val_acc: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0818 - acc: 0.0040 - val_loss: 0.0503 - val_acc: 0.0400\n",
      "Epoch 4/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0517 - acc: 0.0227 - val_loss: 0.0357 - val_acc: 0.0280\n",
      "Epoch 5/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0413 - acc: 0.0147 - val_loss: 0.0310 - val_acc: 0.0360\n",
      "Epoch 6/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0375 - acc: 0.0160 - val_loss: 0.0294 - val_acc: 0.0320\n",
      "Epoch 7/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0361 - acc: 0.0147 - val_loss: 0.0286 - val_acc: 0.0440\n",
      "Epoch 8/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0351 - acc: 0.0080 - val_loss: 0.0281 - val_acc: 0.0440\n",
      "Epoch 9/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0344 - acc: 0.0227 - val_loss: 0.0275 - val_acc: 0.0680\n",
      "Epoch 10/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0337 - acc: 0.0173 - val_loss: 0.0270 - val_acc: 0.0480\n",
      "Epoch 11/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0328 - acc: 0.0173 - val_loss: 0.0265 - val_acc: 0.0720\n",
      "Epoch 12/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0321 - acc: 0.0253 - val_loss: 0.0260 - val_acc: 0.0640\n",
      "Epoch 13/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0312 - acc: 0.0240 - val_loss: 0.0255 - val_acc: 0.0600\n",
      "Epoch 14/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0304 - acc: 0.0280 - val_loss: 0.0250 - val_acc: 0.0640\n",
      "Epoch 15/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0297 - acc: 0.0320 - val_loss: 0.0245 - val_acc: 0.0720\n",
      "Epoch 16/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0292 - acc: 0.0400 - val_loss: 0.0242 - val_acc: 0.0800\n",
      "Epoch 17/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0285 - acc: 0.0440 - val_loss: 0.0237 - val_acc: 0.0880\n",
      "Epoch 18/2000\n",
      "750/750 [==============================] - 0s 125us/step - loss: 0.0281 - acc: 0.0587 - val_loss: 0.0233 - val_acc: 0.0880\n",
      "Epoch 19/2000\n",
      "750/750 [==============================] - 0s 128us/step - loss: 0.0276 - acc: 0.0587 - val_loss: 0.0231 - val_acc: 0.0920\n",
      "Epoch 20/2000\n",
      "750/750 [==============================] - 0s 128us/step - loss: 0.0272 - acc: 0.0720 - val_loss: 0.0227 - val_acc: 0.0960\n",
      "Epoch 21/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0269 - acc: 0.0627 - val_loss: 0.0225 - val_acc: 0.0960\n",
      "Epoch 22/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0265 - acc: 0.0893 - val_loss: 0.0222 - val_acc: 0.1000\n",
      "Epoch 23/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0262 - acc: 0.0813 - val_loss: 0.0220 - val_acc: 0.0920\n",
      "Epoch 24/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0259 - acc: 0.0667 - val_loss: 0.0218 - val_acc: 0.0960\n",
      "Epoch 25/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0257 - acc: 0.0920 - val_loss: 0.0217 - val_acc: 0.0960\n",
      "Epoch 26/2000\n",
      "750/750 [==============================] - 0s 126us/step - loss: 0.0254 - acc: 0.0853 - val_loss: 0.0215 - val_acc: 0.1000\n",
      "Epoch 27/2000\n",
      "750/750 [==============================] - 0s 133us/step - loss: 0.0251 - acc: 0.0827 - val_loss: 0.0214 - val_acc: 0.1160\n",
      "Epoch 28/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0249 - acc: 0.1000 - val_loss: 0.0213 - val_acc: 0.1200\n",
      "Epoch 29/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0246 - acc: 0.0973 - val_loss: 0.0212 - val_acc: 0.1240\n",
      "Epoch 30/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0244 - acc: 0.1053 - val_loss: 0.0210 - val_acc: 0.1200\n",
      "Epoch 31/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0243 - acc: 0.1000 - val_loss: 0.0210 - val_acc: 0.1240\n",
      "Epoch 32/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0240 - acc: 0.1080 - val_loss: 0.0209 - val_acc: 0.1400\n",
      "Epoch 33/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0239 - acc: 0.1133 - val_loss: 0.0208 - val_acc: 0.1520\n",
      "Epoch 34/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0238 - acc: 0.1267 - val_loss: 0.0206 - val_acc: 0.1800\n",
      "Epoch 35/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0236 - acc: 0.1267 - val_loss: 0.0206 - val_acc: 0.1800\n",
      "Epoch 36/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0235 - acc: 0.1227 - val_loss: 0.0206 - val_acc: 0.1800\n",
      "Epoch 37/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0234 - acc: 0.1227 - val_loss: 0.0205 - val_acc: 0.1360\n",
      "Epoch 38/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0231 - acc: 0.1227 - val_loss: 0.0205 - val_acc: 0.1200\n",
      "Epoch 39/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0230 - acc: 0.1187 - val_loss: 0.0203 - val_acc: 0.1480\n",
      "Epoch 40/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0230 - acc: 0.1347 - val_loss: 0.0203 - val_acc: 0.2000\n",
      "Epoch 41/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0227 - acc: 0.1413 - val_loss: 0.0203 - val_acc: 0.1320\n",
      "Epoch 42/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0227 - acc: 0.1200 - val_loss: 0.0202 - val_acc: 0.1120\n",
      "Epoch 43/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0225 - acc: 0.1453 - val_loss: 0.0202 - val_acc: 0.1040\n",
      "Epoch 44/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0224 - acc: 0.1360 - val_loss: 0.0202 - val_acc: 0.1520\n",
      "Epoch 45/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0224 - acc: 0.1387 - val_loss: 0.0201 - val_acc: 0.1840\n",
      "Epoch 46/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0223 - acc: 0.1373 - val_loss: 0.0201 - val_acc: 0.2120\n",
      "Epoch 47/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0221 - acc: 0.1413 - val_loss: 0.0200 - val_acc: 0.2160\n",
      "Epoch 48/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0220 - acc: 0.1480 - val_loss: 0.0200 - val_acc: 0.1280\n",
      "Epoch 49/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0219 - acc: 0.1507 - val_loss: 0.0201 - val_acc: 0.1360\n",
      "Epoch 50/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0218 - acc: 0.1560 - val_loss: 0.0201 - val_acc: 0.1440\n",
      "Epoch 51/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0217 - acc: 0.1453 - val_loss: 0.0200 - val_acc: 0.1440\n",
      "Epoch 52/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0216 - acc: 0.1707 - val_loss: 0.0200 - val_acc: 0.2120\n",
      "Epoch 53/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0217 - acc: 0.1627 - val_loss: 0.0199 - val_acc: 0.1800\n",
      "Epoch 54/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0215 - acc: 0.1533 - val_loss: 0.0199 - val_acc: 0.1200\n",
      "Epoch 55/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0213 - acc: 0.1547 - val_loss: 0.0199 - val_acc: 0.1640\n",
      "Epoch 56/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0213 - acc: 0.1613 - val_loss: 0.0198 - val_acc: 0.1600\n",
      "Epoch 57/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0212 - acc: 0.1547 - val_loss: 0.0198 - val_acc: 0.1280\n",
      "Epoch 58/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0210 - acc: 0.1640 - val_loss: 0.0198 - val_acc: 0.1320\n",
      "Epoch 59/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0211 - acc: 0.1413 - val_loss: 0.0198 - val_acc: 0.2240\n",
      "Epoch 60/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 117us/step - loss: 0.0209 - acc: 0.1773 - val_loss: 0.0198 - val_acc: 0.1960\n",
      "Epoch 61/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0209 - acc: 0.1453 - val_loss: 0.0198 - val_acc: 0.2320\n",
      "Epoch 62/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0209 - acc: 0.1680 - val_loss: 0.0198 - val_acc: 0.1400\n",
      "Epoch 63/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0207 - acc: 0.1640 - val_loss: 0.0198 - val_acc: 0.2360\n",
      "Epoch 64/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0207 - acc: 0.1827 - val_loss: 0.0197 - val_acc: 0.2200\n",
      "Epoch 65/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0207 - acc: 0.1893 - val_loss: 0.0197 - val_acc: 0.1360\n",
      "Epoch 66/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0205 - acc: 0.1587 - val_loss: 0.0197 - val_acc: 0.1440\n",
      "Epoch 67/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0204 - acc: 0.1720 - val_loss: 0.0197 - val_acc: 0.1440\n",
      "Epoch 68/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0204 - acc: 0.1680 - val_loss: 0.0197 - val_acc: 0.1360\n",
      "Epoch 69/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0203 - acc: 0.1667 - val_loss: 0.0197 - val_acc: 0.1600\n",
      "Epoch 70/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0203 - acc: 0.1707 - val_loss: 0.0197 - val_acc: 0.2120\n",
      "Epoch 71/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0201 - acc: 0.1600 - val_loss: 0.0197 - val_acc: 0.1560\n",
      "Epoch 72/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0202 - acc: 0.1747 - val_loss: 0.0197 - val_acc: 0.2080\n",
      "Epoch 73/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0202 - acc: 0.1907 - val_loss: 0.0197 - val_acc: 0.1520\n",
      "Epoch 74/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0200 - acc: 0.1920 - val_loss: 0.0197 - val_acc: 0.1520\n",
      "Epoch 75/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0200 - acc: 0.1840 - val_loss: 0.0196 - val_acc: 0.1520\n",
      "Epoch 76/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0199 - acc: 0.1827 - val_loss: 0.0197 - val_acc: 0.1520\n",
      "Epoch 77/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0198 - acc: 0.1773 - val_loss: 0.0197 - val_acc: 0.1440\n",
      "Epoch 78/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0198 - acc: 0.1760 - val_loss: 0.0196 - val_acc: 0.1920\n",
      "Epoch 79/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0197 - acc: 0.1987 - val_loss: 0.0197 - val_acc: 0.1560\n",
      "Epoch 80/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0196 - acc: 0.1840 - val_loss: 0.0196 - val_acc: 0.1800\n",
      "Epoch 81/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0196 - acc: 0.2040 - val_loss: 0.0196 - val_acc: 0.1520\n",
      "Epoch 82/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0195 - acc: 0.1720 - val_loss: 0.0196 - val_acc: 0.1520\n",
      "Epoch 83/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0195 - acc: 0.1747 - val_loss: 0.0196 - val_acc: 0.1680\n",
      "Epoch 84/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0194 - acc: 0.1880 - val_loss: 0.0196 - val_acc: 0.1880\n",
      "Epoch 85/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0194 - acc: 0.1867 - val_loss: 0.0196 - val_acc: 0.2440\n",
      "Epoch 86/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0192 - acc: 0.1920 - val_loss: 0.0196 - val_acc: 0.2120\n",
      "Epoch 87/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0193 - acc: 0.1960 - val_loss: 0.0196 - val_acc: 0.2360\n",
      "Epoch 88/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0192 - acc: 0.2000 - val_loss: 0.0196 - val_acc: 0.1880\n",
      "Epoch 89/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0192 - acc: 0.1947 - val_loss: 0.0196 - val_acc: 0.2360\n",
      "Epoch 90/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0191 - acc: 0.1840 - val_loss: 0.0196 - val_acc: 0.2560\n",
      "Epoch 91/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0191 - acc: 0.2027 - val_loss: 0.0196 - val_acc: 0.2600\n",
      "Epoch 92/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0189 - acc: 0.2107 - val_loss: 0.0196 - val_acc: 0.2040\n",
      "Epoch 93/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0190 - acc: 0.2147 - val_loss: 0.0196 - val_acc: 0.2400\n",
      "Epoch 94/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0188 - acc: 0.2133 - val_loss: 0.0196 - val_acc: 0.2000\n",
      "Epoch 95/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0188 - acc: 0.2013 - val_loss: 0.0196 - val_acc: 0.1960\n",
      "Epoch 96/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0188 - acc: 0.2120 - val_loss: 0.0196 - val_acc: 0.1920\n",
      "Epoch 97/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0186 - acc: 0.2120 - val_loss: 0.0196 - val_acc: 0.2000\n",
      "Epoch 98/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0187 - acc: 0.2093 - val_loss: 0.0196 - val_acc: 0.2160\n",
      "Epoch 99/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0187 - acc: 0.2080 - val_loss: 0.0195 - val_acc: 0.2000\n",
      "Epoch 100/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0186 - acc: 0.2160 - val_loss: 0.0195 - val_acc: 0.2560\n",
      "Epoch 101/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0186 - acc: 0.2013 - val_loss: 0.0196 - val_acc: 0.2080\n",
      "Epoch 102/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0185 - acc: 0.2040 - val_loss: 0.0196 - val_acc: 0.2240\n",
      "Epoch 103/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0185 - acc: 0.2093 - val_loss: 0.0196 - val_acc: 0.2000\n",
      "Epoch 104/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0184 - acc: 0.2267 - val_loss: 0.0195 - val_acc: 0.2040\n",
      "Epoch 105/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0183 - acc: 0.2293 - val_loss: 0.0195 - val_acc: 0.2040\n",
      "Epoch 106/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0183 - acc: 0.2240 - val_loss: 0.0196 - val_acc: 0.2000\n",
      "Epoch 107/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0183 - acc: 0.2387 - val_loss: 0.0195 - val_acc: 0.2080\n",
      "Epoch 108/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0183 - acc: 0.2373 - val_loss: 0.0195 - val_acc: 0.2200\n",
      "Epoch 109/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0182 - acc: 0.2293 - val_loss: 0.0195 - val_acc: 0.2120\n",
      "Epoch 110/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0181 - acc: 0.2320 - val_loss: 0.0195 - val_acc: 0.2240\n",
      "Epoch 111/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0181 - acc: 0.2293 - val_loss: 0.0194 - val_acc: 0.2120\n",
      "Epoch 112/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0180 - acc: 0.2560 - val_loss: 0.0195 - val_acc: 0.2160\n",
      "Epoch 113/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0180 - acc: 0.2467 - val_loss: 0.0195 - val_acc: 0.2040\n",
      "Epoch 114/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0180 - acc: 0.2280 - val_loss: 0.0195 - val_acc: 0.2040\n",
      "Epoch 115/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0180 - acc: 0.2427 - val_loss: 0.0195 - val_acc: 0.2000\n",
      "Epoch 116/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0178 - acc: 0.2347 - val_loss: 0.0195 - val_acc: 0.2000\n",
      "Epoch 117/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0178 - acc: 0.2400 - val_loss: 0.0194 - val_acc: 0.2080\n",
      "Epoch 118/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0178 - acc: 0.2533 - val_loss: 0.0195 - val_acc: 0.2120\n",
      "Epoch 119/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0178 - acc: 0.2573 - val_loss: 0.0195 - val_acc: 0.2280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0178 - acc: 0.2627 - val_loss: 0.0195 - val_acc: 0.2240\n",
      "Epoch 121/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0177 - acc: 0.2640 - val_loss: 0.0195 - val_acc: 0.2080\n",
      "Epoch 122/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0177 - acc: 0.2600 - val_loss: 0.0195 - val_acc: 0.2360\n",
      "Epoch 123/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0176 - acc: 0.2613 - val_loss: 0.0195 - val_acc: 0.2160\n",
      "Epoch 124/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0175 - acc: 0.2533 - val_loss: 0.0195 - val_acc: 0.2240\n",
      "Epoch 125/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0175 - acc: 0.2520 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 126/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0174 - acc: 0.2507 - val_loss: 0.0195 - val_acc: 0.2200\n",
      "Epoch 127/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0175 - acc: 0.2733 - val_loss: 0.0195 - val_acc: 0.2120\n",
      "Epoch 128/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0174 - acc: 0.2907 - val_loss: 0.0195 - val_acc: 0.2160\n",
      "Epoch 129/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0174 - acc: 0.2480 - val_loss: 0.0195 - val_acc: 0.2240\n",
      "Epoch 130/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0173 - acc: 0.2787 - val_loss: 0.0194 - val_acc: 0.2160\n",
      "Epoch 131/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0173 - acc: 0.2507 - val_loss: 0.0195 - val_acc: 0.2440\n",
      "Epoch 132/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0173 - acc: 0.2680 - val_loss: 0.0195 - val_acc: 0.2360\n",
      "Epoch 133/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0173 - acc: 0.2680 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 134/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0171 - acc: 0.2760 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 135/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0172 - acc: 0.2787 - val_loss: 0.0195 - val_acc: 0.2320\n",
      "Epoch 136/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0171 - acc: 0.2560 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 137/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0171 - acc: 0.2653 - val_loss: 0.0195 - val_acc: 0.2240\n",
      "Epoch 138/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0170 - acc: 0.2840 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 139/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0170 - acc: 0.2613 - val_loss: 0.0195 - val_acc: 0.2320\n",
      "Epoch 140/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0169 - acc: 0.3067 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 141/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0168 - acc: 0.2987 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 142/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0168 - acc: 0.2707 - val_loss: 0.0195 - val_acc: 0.2280\n",
      "Epoch 143/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0169 - acc: 0.2853 - val_loss: 0.0194 - val_acc: 0.2320\n",
      "Epoch 144/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0168 - acc: 0.3013 - val_loss: 0.0195 - val_acc: 0.2320\n",
      "Epoch 145/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0168 - acc: 0.2840 - val_loss: 0.0195 - val_acc: 0.2400\n",
      "Epoch 146/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0168 - acc: 0.2840 - val_loss: 0.0195 - val_acc: 0.2360\n",
      "Epoch 147/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0167 - acc: 0.2720 - val_loss: 0.0194 - val_acc: 0.2320\n",
      "Epoch 148/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0167 - acc: 0.2920 - val_loss: 0.0195 - val_acc: 0.2480\n",
      "Epoch 149/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0167 - acc: 0.2907 - val_loss: 0.0194 - val_acc: 0.2360\n",
      "Epoch 150/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0166 - acc: 0.2760 - val_loss: 0.0194 - val_acc: 0.2320\n",
      "Epoch 151/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0166 - acc: 0.2907 - val_loss: 0.0194 - val_acc: 0.2440\n",
      "Epoch 152/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0166 - acc: 0.3027 - val_loss: 0.0194 - val_acc: 0.2400\n",
      "Epoch 153/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0166 - acc: 0.2987 - val_loss: 0.0195 - val_acc: 0.2360\n",
      "Epoch 154/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0165 - acc: 0.2947 - val_loss: 0.0195 - val_acc: 0.2440\n",
      "Epoch 155/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0165 - acc: 0.2947 - val_loss: 0.0195 - val_acc: 0.2440\n",
      "Epoch 156/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0165 - acc: 0.3253 - val_loss: 0.0195 - val_acc: 0.2400\n",
      "Epoch 157/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0164 - acc: 0.3267 - val_loss: 0.0195 - val_acc: 0.2480\n",
      "Epoch 158/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0163 - acc: 0.3040 - val_loss: 0.0195 - val_acc: 0.2520\n",
      "Epoch 159/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0163 - acc: 0.3293 - val_loss: 0.0195 - val_acc: 0.2480\n",
      "Epoch 160/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0162 - acc: 0.3107 - val_loss: 0.0194 - val_acc: 0.2280\n",
      "Epoch 161/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0163 - acc: 0.3160 - val_loss: 0.0195 - val_acc: 0.2440\n",
      "Epoch 162/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0163 - acc: 0.3067 - val_loss: 0.0195 - val_acc: 0.2480\n",
      "Epoch 163/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0163 - acc: 0.3227 - val_loss: 0.0196 - val_acc: 0.2480\n",
      "Epoch 164/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0162 - acc: 0.3213 - val_loss: 0.0194 - val_acc: 0.2480\n",
      "Epoch 165/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0162 - acc: 0.3053 - val_loss: 0.0195 - val_acc: 0.2440\n",
      "Epoch 166/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0162 - acc: 0.3200 - val_loss: 0.0195 - val_acc: 0.2520\n",
      "Epoch 167/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0161 - acc: 0.3120 - val_loss: 0.0195 - val_acc: 0.2520\n",
      "Epoch 168/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0161 - acc: 0.3253 - val_loss: 0.0196 - val_acc: 0.2600\n",
      "Epoch 169/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0160 - acc: 0.3040 - val_loss: 0.0195 - val_acc: 0.2880\n",
      "Epoch 170/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0161 - acc: 0.3173 - val_loss: 0.0195 - val_acc: 0.2520\n",
      "Epoch 171/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0161 - acc: 0.3093 - val_loss: 0.0195 - val_acc: 0.2560\n",
      "Epoch 172/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0159 - acc: 0.3333 - val_loss: 0.0195 - val_acc: 0.2560\n",
      "Epoch 173/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0160 - acc: 0.3373 - val_loss: 0.0195 - val_acc: 0.2560\n",
      "Epoch 174/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0160 - acc: 0.3253 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 175/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0159 - acc: 0.3373 - val_loss: 0.0195 - val_acc: 0.2560\n",
      "Epoch 176/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0159 - acc: 0.3173 - val_loss: 0.0195 - val_acc: 0.2520\n",
      "Epoch 177/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0158 - acc: 0.3267 - val_loss: 0.0195 - val_acc: 0.2640\n",
      "Epoch 178/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0158 - acc: 0.3413 - val_loss: 0.0195 - val_acc: 0.2520\n",
      "Epoch 179/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 114us/step - loss: 0.0159 - acc: 0.3253 - val_loss: 0.0194 - val_acc: 0.2640\n",
      "Epoch 180/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0158 - acc: 0.3333 - val_loss: 0.0194 - val_acc: 0.2640\n",
      "Epoch 181/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0157 - acc: 0.3240 - val_loss: 0.0194 - val_acc: 0.2640\n",
      "Epoch 182/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0157 - acc: 0.3320 - val_loss: 0.0194 - val_acc: 0.2600\n",
      "Epoch 183/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0158 - acc: 0.3373 - val_loss: 0.0195 - val_acc: 0.2520\n",
      "Epoch 184/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0157 - acc: 0.3333 - val_loss: 0.0195 - val_acc: 0.2560\n",
      "Epoch 185/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0157 - acc: 0.3347 - val_loss: 0.0195 - val_acc: 0.2600\n",
      "Epoch 186/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0157 - acc: 0.3400 - val_loss: 0.0195 - val_acc: 0.3080\n",
      "Epoch 187/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0156 - acc: 0.3520 - val_loss: 0.0195 - val_acc: 0.3120\n",
      "Epoch 188/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0156 - acc: 0.3427 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 189/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0155 - acc: 0.3293 - val_loss: 0.0195 - val_acc: 0.2640\n",
      "Epoch 190/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0154 - acc: 0.3547 - val_loss: 0.0195 - val_acc: 0.2640\n",
      "Epoch 191/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0154 - acc: 0.3453 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 192/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0156 - acc: 0.3640 - val_loss: 0.0196 - val_acc: 0.2640\n",
      "Epoch 193/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0154 - acc: 0.3293 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 194/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0154 - acc: 0.3627 - val_loss: 0.0195 - val_acc: 0.2640\n",
      "Epoch 195/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0154 - acc: 0.3387 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 196/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0154 - acc: 0.3413 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 197/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0154 - acc: 0.3493 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 198/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0154 - acc: 0.3360 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 199/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0154 - acc: 0.3640 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 200/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0152 - acc: 0.3640 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 201/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0152 - acc: 0.3440 - val_loss: 0.0194 - val_acc: 0.2720\n",
      "Epoch 202/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0152 - acc: 0.3680 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 203/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0152 - acc: 0.3467 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 204/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0152 - acc: 0.3533 - val_loss: 0.0194 - val_acc: 0.2800\n",
      "Epoch 205/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0151 - acc: 0.3747 - val_loss: 0.0194 - val_acc: 0.2760\n",
      "Epoch 206/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0151 - acc: 0.3640 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 207/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0151 - acc: 0.3640 - val_loss: 0.0195 - val_acc: 0.2800\n",
      "Epoch 208/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0152 - acc: 0.3533 - val_loss: 0.0196 - val_acc: 0.2840\n",
      "Epoch 209/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0151 - acc: 0.3640 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 210/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0149 - acc: 0.3640 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 211/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0150 - acc: 0.3760 - val_loss: 0.0196 - val_acc: 0.2760\n",
      "Epoch 212/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0150 - acc: 0.3467 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 213/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0150 - acc: 0.3613 - val_loss: 0.0195 - val_acc: 0.2720\n",
      "Epoch 214/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0149 - acc: 0.3613 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 215/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0149 - acc: 0.3493 - val_loss: 0.0195 - val_acc: 0.2760\n",
      "Epoch 216/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0148 - acc: 0.3733 - val_loss: 0.0195 - val_acc: 0.2800\n",
      "Epoch 217/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0148 - acc: 0.3693 - val_loss: 0.0195 - val_acc: 0.2680\n",
      "Epoch 218/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0148 - acc: 0.3667 - val_loss: 0.0195 - val_acc: 0.2800\n",
      "Epoch 219/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0148 - acc: 0.3827 - val_loss: 0.0195 - val_acc: 0.2800\n",
      "Epoch 220/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0149 - acc: 0.3613 - val_loss: 0.0194 - val_acc: 0.2800\n",
      "Epoch 221/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0148 - acc: 0.3787 - val_loss: 0.0195 - val_acc: 0.2920\n",
      "Epoch 222/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0148 - acc: 0.3853 - val_loss: 0.0195 - val_acc: 0.2800\n",
      "Epoch 223/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0146 - acc: 0.3827 - val_loss: 0.0195 - val_acc: 0.2840\n",
      "Epoch 224/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0148 - acc: 0.3653 - val_loss: 0.0196 - val_acc: 0.2880\n",
      "Epoch 225/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0147 - acc: 0.3773 - val_loss: 0.0195 - val_acc: 0.2920\n",
      "Epoch 226/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0147 - acc: 0.3707 - val_loss: 0.0194 - val_acc: 0.3080\n",
      "Epoch 227/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0146 - acc: 0.3733 - val_loss: 0.0195 - val_acc: 0.2960\n",
      "Epoch 228/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0146 - acc: 0.3787 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 229/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0147 - acc: 0.3893 - val_loss: 0.0195 - val_acc: 0.2920\n",
      "Epoch 230/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0146 - acc: 0.4120 - val_loss: 0.0195 - val_acc: 0.2880\n",
      "Epoch 231/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0146 - acc: 0.3800 - val_loss: 0.0195 - val_acc: 0.2960\n",
      "Epoch 232/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0145 - acc: 0.3600 - val_loss: 0.0195 - val_acc: 0.3000\n",
      "Epoch 233/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0145 - acc: 0.3800 - val_loss: 0.0195 - val_acc: 0.2960\n",
      "Epoch 234/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0146 - acc: 0.3867 - val_loss: 0.0195 - val_acc: 0.2920\n",
      "Epoch 235/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0146 - acc: 0.3813 - val_loss: 0.0195 - val_acc: 0.3000\n",
      "Epoch 236/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0145 - acc: 0.3920 - val_loss: 0.0195 - val_acc: 0.2920\n",
      "Epoch 237/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0144 - acc: 0.3893 - val_loss: 0.0195 - val_acc: 0.2840\n",
      "Epoch 238/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 118us/step - loss: 0.0145 - acc: 0.3760 - val_loss: 0.0195 - val_acc: 0.2960\n",
      "Epoch 239/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0144 - acc: 0.3867 - val_loss: 0.0195 - val_acc: 0.2920\n",
      "Epoch 240/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0144 - acc: 0.3880 - val_loss: 0.0195 - val_acc: 0.2920\n",
      "Epoch 241/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0143 - acc: 0.3813 - val_loss: 0.0195 - val_acc: 0.3000\n",
      "Epoch 242/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0143 - acc: 0.3987 - val_loss: 0.0195 - val_acc: 0.3000\n",
      "Epoch 243/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0143 - acc: 0.3827 - val_loss: 0.0195 - val_acc: 0.2880\n",
      "Epoch 244/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0143 - acc: 0.4027 - val_loss: 0.0195 - val_acc: 0.3040\n",
      "Epoch 245/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0143 - acc: 0.3880 - val_loss: 0.0195 - val_acc: 0.2920\n",
      "Epoch 246/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0143 - acc: 0.3800 - val_loss: 0.0195 - val_acc: 0.2920\n",
      "Epoch 247/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0143 - acc: 0.3973 - val_loss: 0.0195 - val_acc: 0.2960\n",
      "Epoch 248/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0142 - acc: 0.3693 - val_loss: 0.0195 - val_acc: 0.2920\n",
      "Epoch 249/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0142 - acc: 0.4000 - val_loss: 0.0195 - val_acc: 0.2960\n",
      "Epoch 250/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0142 - acc: 0.3973 - val_loss: 0.0195 - val_acc: 0.3080\n",
      "Epoch 251/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0143 - acc: 0.4013 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 252/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0142 - acc: 0.3947 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 253/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0143 - acc: 0.4227 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 254/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0140 - acc: 0.3960 - val_loss: 0.0195 - val_acc: 0.3120\n",
      "Epoch 255/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0140 - acc: 0.4107 - val_loss: 0.0195 - val_acc: 0.3240\n",
      "Epoch 256/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0141 - acc: 0.4040 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 257/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0141 - acc: 0.4067 - val_loss: 0.0196 - val_acc: 0.3080\n",
      "Epoch 258/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0140 - acc: 0.3920 - val_loss: 0.0196 - val_acc: 0.3080\n",
      "Epoch 259/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0142 - acc: 0.4253 - val_loss: 0.0196 - val_acc: 0.3080\n",
      "Epoch 260/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0140 - acc: 0.4027 - val_loss: 0.0196 - val_acc: 0.3000\n",
      "Epoch 261/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0140 - acc: 0.4133 - val_loss: 0.0196 - val_acc: 0.3040\n",
      "Epoch 262/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0139 - acc: 0.4267 - val_loss: 0.0196 - val_acc: 0.2920\n",
      "Epoch 263/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0139 - acc: 0.3880 - val_loss: 0.0196 - val_acc: 0.3080\n",
      "Epoch 264/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0139 - acc: 0.3893 - val_loss: 0.0197 - val_acc: 0.3000\n",
      "Epoch 265/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0139 - acc: 0.4067 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 266/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0139 - acc: 0.4320 - val_loss: 0.0195 - val_acc: 0.3080\n",
      "Epoch 267/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0138 - acc: 0.4187 - val_loss: 0.0195 - val_acc: 0.3120\n",
      "Epoch 268/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0138 - acc: 0.4187 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 269/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0139 - acc: 0.4080 - val_loss: 0.0195 - val_acc: 0.3240\n",
      "Epoch 270/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0139 - acc: 0.4147 - val_loss: 0.0196 - val_acc: 0.3200\n",
      "Epoch 271/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0138 - acc: 0.4133 - val_loss: 0.0195 - val_acc: 0.2960\n",
      "Epoch 272/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0138 - acc: 0.3893 - val_loss: 0.0195 - val_acc: 0.3080\n",
      "Epoch 273/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0138 - acc: 0.4187 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 274/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0137 - acc: 0.4053 - val_loss: 0.0195 - val_acc: 0.3040\n",
      "Epoch 275/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0137 - acc: 0.4213 - val_loss: 0.0195 - val_acc: 0.3080\n",
      "Epoch 276/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0137 - acc: 0.4253 - val_loss: 0.0195 - val_acc: 0.3240\n",
      "Epoch 277/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0137 - acc: 0.4453 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 278/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0137 - acc: 0.4187 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 279/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0137 - acc: 0.4147 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 280/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0137 - acc: 0.4267 - val_loss: 0.0195 - val_acc: 0.3240\n",
      "Epoch 281/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0136 - acc: 0.4253 - val_loss: 0.0195 - val_acc: 0.3040\n",
      "Epoch 282/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0135 - acc: 0.4187 - val_loss: 0.0195 - val_acc: 0.3040\n",
      "Epoch 283/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0136 - acc: 0.4067 - val_loss: 0.0194 - val_acc: 0.3040\n",
      "Epoch 284/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0137 - acc: 0.4240 - val_loss: 0.0196 - val_acc: 0.3120\n",
      "Epoch 285/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0136 - acc: 0.4280 - val_loss: 0.0195 - val_acc: 0.3040\n",
      "Epoch 286/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0136 - acc: 0.4280 - val_loss: 0.0196 - val_acc: 0.3040\n",
      "Epoch 287/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0136 - acc: 0.4333 - val_loss: 0.0195 - val_acc: 0.3040\n",
      "Epoch 288/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0135 - acc: 0.4187 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 289/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0135 - acc: 0.4293 - val_loss: 0.0195 - val_acc: 0.3000\n",
      "Epoch 290/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0135 - acc: 0.4133 - val_loss: 0.0195 - val_acc: 0.3120\n",
      "Epoch 291/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0135 - acc: 0.4173 - val_loss: 0.0195 - val_acc: 0.3080\n",
      "Epoch 292/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0135 - acc: 0.4293 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 293/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0135 - acc: 0.4187 - val_loss: 0.0195 - val_acc: 0.3280\n",
      "Epoch 294/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0134 - acc: 0.4120 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 295/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0135 - acc: 0.4240 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 296/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0133 - acc: 0.4027 - val_loss: 0.0195 - val_acc: 0.3120\n",
      "Epoch 297/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 118us/step - loss: 0.0135 - acc: 0.4413 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 298/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0134 - acc: 0.4267 - val_loss: 0.0195 - val_acc: 0.3240\n",
      "Epoch 299/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0133 - acc: 0.4373 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 300/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0133 - acc: 0.4307 - val_loss: 0.0195 - val_acc: 0.3320\n",
      "Epoch 301/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0133 - acc: 0.4307 - val_loss: 0.0195 - val_acc: 0.3240\n",
      "Epoch 302/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0133 - acc: 0.4280 - val_loss: 0.0196 - val_acc: 0.3200\n",
      "Epoch 303/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0133 - acc: 0.4240 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 304/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0133 - acc: 0.4507 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 305/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0133 - acc: 0.4240 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 306/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0132 - acc: 0.4520 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 307/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0133 - acc: 0.4160 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 308/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0132 - acc: 0.4347 - val_loss: 0.0196 - val_acc: 0.3240\n",
      "Epoch 309/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0132 - acc: 0.4427 - val_loss: 0.0195 - val_acc: 0.3080\n",
      "Epoch 310/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0132 - acc: 0.4387 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 311/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0131 - acc: 0.4213 - val_loss: 0.0194 - val_acc: 0.3240\n",
      "Epoch 312/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0132 - acc: 0.4200 - val_loss: 0.0195 - val_acc: 0.3280\n",
      "Epoch 313/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0131 - acc: 0.4373 - val_loss: 0.0194 - val_acc: 0.3360\n",
      "Epoch 314/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0132 - acc: 0.4453 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 315/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0131 - acc: 0.4453 - val_loss: 0.0194 - val_acc: 0.3200\n",
      "Epoch 316/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0131 - acc: 0.4387 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 317/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0131 - acc: 0.4347 - val_loss: 0.0195 - val_acc: 0.3360\n",
      "Epoch 318/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0131 - acc: 0.4440 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 319/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0131 - acc: 0.4480 - val_loss: 0.0195 - val_acc: 0.3280\n",
      "Epoch 320/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0130 - acc: 0.4520 - val_loss: 0.0195 - val_acc: 0.3240\n",
      "Epoch 321/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0131 - acc: 0.4320 - val_loss: 0.0195 - val_acc: 0.3280\n",
      "Epoch 322/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0130 - acc: 0.4533 - val_loss: 0.0195 - val_acc: 0.3240\n",
      "Epoch 323/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0130 - acc: 0.4360 - val_loss: 0.0196 - val_acc: 0.3240\n",
      "Epoch 324/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0129 - acc: 0.4400 - val_loss: 0.0195 - val_acc: 0.3280\n",
      "Epoch 325/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0128 - acc: 0.4320 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 326/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0129 - acc: 0.4587 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 327/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0129 - acc: 0.4680 - val_loss: 0.0196 - val_acc: 0.3200\n",
      "Epoch 328/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0129 - acc: 0.4653 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 329/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0129 - acc: 0.4560 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 330/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0129 - acc: 0.4547 - val_loss: 0.0195 - val_acc: 0.3200\n",
      "Epoch 331/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0129 - acc: 0.4480 - val_loss: 0.0195 - val_acc: 0.3160\n",
      "Epoch 332/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0130 - acc: 0.4627 - val_loss: 0.0196 - val_acc: 0.3240\n",
      "Epoch 333/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0129 - acc: 0.4507 - val_loss: 0.0195 - val_acc: 0.3240\n",
      "Epoch 334/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0128 - acc: 0.4587 - val_loss: 0.0196 - val_acc: 0.3240\n",
      "Epoch 335/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0129 - acc: 0.4560 - val_loss: 0.0195 - val_acc: 0.3280\n",
      "Epoch 336/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0128 - acc: 0.4693 - val_loss: 0.0197 - val_acc: 0.3280\n",
      "Epoch 337/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0129 - acc: 0.4533 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 338/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0128 - acc: 0.4733 - val_loss: 0.0196 - val_acc: 0.3320\n",
      "Epoch 339/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0127 - acc: 0.4653 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 340/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0128 - acc: 0.4427 - val_loss: 0.0195 - val_acc: 0.3280\n",
      "Epoch 341/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0127 - acc: 0.4507 - val_loss: 0.0196 - val_acc: 0.3320\n",
      "Epoch 342/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0128 - acc: 0.4587 - val_loss: 0.0195 - val_acc: 0.3360\n",
      "Epoch 343/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0126 - acc: 0.4840 - val_loss: 0.0197 - val_acc: 0.3400\n",
      "Epoch 344/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0126 - acc: 0.4627 - val_loss: 0.0196 - val_acc: 0.3320\n",
      "Epoch 345/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0127 - acc: 0.4627 - val_loss: 0.0196 - val_acc: 0.3400\n",
      "Epoch 346/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0126 - acc: 0.4640 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 347/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0127 - acc: 0.4613 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 348/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0128 - acc: 0.4493 - val_loss: 0.0196 - val_acc: 0.3440\n",
      "Epoch 349/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0126 - acc: 0.4400 - val_loss: 0.0195 - val_acc: 0.3440\n",
      "Epoch 350/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0126 - acc: 0.4640 - val_loss: 0.0195 - val_acc: 0.3520\n",
      "Epoch 351/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0126 - acc: 0.4747 - val_loss: 0.0196 - val_acc: 0.3440\n",
      "Epoch 352/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0125 - acc: 0.4373 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 353/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0126 - acc: 0.4627 - val_loss: 0.0196 - val_acc: 0.3240\n",
      "Epoch 354/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0126 - acc: 0.4627 - val_loss: 0.0195 - val_acc: 0.3280\n",
      "Epoch 355/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0126 - acc: 0.4800 - val_loss: 0.0196 - val_acc: 0.3400\n",
      "Epoch 356/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 116us/step - loss: 0.0125 - acc: 0.4653 - val_loss: 0.0195 - val_acc: 0.3640\n",
      "Epoch 357/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0126 - acc: 0.4693 - val_loss: 0.0195 - val_acc: 0.3600\n",
      "Epoch 358/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0125 - acc: 0.4813 - val_loss: 0.0196 - val_acc: 0.3240\n",
      "Epoch 359/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0125 - acc: 0.4760 - val_loss: 0.0196 - val_acc: 0.3160\n",
      "Epoch 360/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0124 - acc: 0.4480 - val_loss: 0.0196 - val_acc: 0.3400\n",
      "Epoch 361/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0125 - acc: 0.4720 - val_loss: 0.0198 - val_acc: 0.3240\n",
      "Epoch 362/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0125 - acc: 0.4653 - val_loss: 0.0196 - val_acc: 0.3240\n",
      "Epoch 363/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0124 - acc: 0.4680 - val_loss: 0.0196 - val_acc: 0.3320\n",
      "Epoch 364/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0125 - acc: 0.4893 - val_loss: 0.0197 - val_acc: 0.3280\n",
      "Epoch 365/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0125 - acc: 0.4773 - val_loss: 0.0196 - val_acc: 0.3160\n",
      "Epoch 366/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0124 - acc: 0.4507 - val_loss: 0.0196 - val_acc: 0.3160\n",
      "Epoch 367/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0124 - acc: 0.4627 - val_loss: 0.0196 - val_acc: 0.3200\n",
      "Epoch 368/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0125 - acc: 0.4600 - val_loss: 0.0196 - val_acc: 0.3120\n",
      "Epoch 369/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0124 - acc: 0.4667 - val_loss: 0.0197 - val_acc: 0.3160\n",
      "Epoch 370/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0125 - acc: 0.4613 - val_loss: 0.0196 - val_acc: 0.3160\n",
      "Epoch 371/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0124 - acc: 0.4800 - val_loss: 0.0196 - val_acc: 0.3160\n",
      "Epoch 372/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0124 - acc: 0.4693 - val_loss: 0.0197 - val_acc: 0.3240\n",
      "Epoch 373/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0123 - acc: 0.4653 - val_loss: 0.0196 - val_acc: 0.3320\n",
      "Epoch 374/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0124 - acc: 0.4613 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 375/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0123 - acc: 0.4840 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 376/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0123 - acc: 0.4920 - val_loss: 0.0196 - val_acc: 0.3320\n",
      "Epoch 377/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0123 - acc: 0.4813 - val_loss: 0.0196 - val_acc: 0.3320\n",
      "Epoch 378/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0123 - acc: 0.4853 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 379/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0123 - acc: 0.4773 - val_loss: 0.0196 - val_acc: 0.3320\n",
      "Epoch 380/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0123 - acc: 0.4640 - val_loss: 0.0196 - val_acc: 0.3240\n",
      "Epoch 381/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0123 - acc: 0.4707 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 382/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0121 - acc: 0.4840 - val_loss: 0.0196 - val_acc: 0.3360\n",
      "Epoch 383/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0122 - acc: 0.4733 - val_loss: 0.0196 - val_acc: 0.3400\n",
      "Epoch 384/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0121 - acc: 0.4880 - val_loss: 0.0195 - val_acc: 0.3440\n",
      "Epoch 385/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0121 - acc: 0.4733 - val_loss: 0.0196 - val_acc: 0.3360\n",
      "Epoch 386/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0122 - acc: 0.4853 - val_loss: 0.0195 - val_acc: 0.3560\n",
      "Epoch 387/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0121 - acc: 0.5013 - val_loss: 0.0196 - val_acc: 0.3520\n",
      "Epoch 388/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0121 - acc: 0.4733 - val_loss: 0.0197 - val_acc: 0.3560\n",
      "Epoch 389/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0123 - acc: 0.4800 - val_loss: 0.0196 - val_acc: 0.3520\n",
      "Epoch 390/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0122 - acc: 0.4733 - val_loss: 0.0197 - val_acc: 0.3360\n",
      "Epoch 391/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0121 - acc: 0.4773 - val_loss: 0.0197 - val_acc: 0.3280\n",
      "Epoch 392/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0120 - acc: 0.4773 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 393/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0120 - acc: 0.4680 - val_loss: 0.0197 - val_acc: 0.3240\n",
      "Epoch 394/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0121 - acc: 0.4920 - val_loss: 0.0197 - val_acc: 0.3280\n",
      "Epoch 395/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0120 - acc: 0.4933 - val_loss: 0.0197 - val_acc: 0.3280\n",
      "Epoch 396/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0120 - acc: 0.4867 - val_loss: 0.0196 - val_acc: 0.3320\n",
      "Epoch 397/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0120 - acc: 0.4987 - val_loss: 0.0197 - val_acc: 0.3240\n",
      "Epoch 398/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0121 - acc: 0.4680 - val_loss: 0.0197 - val_acc: 0.3400\n",
      "Epoch 399/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0121 - acc: 0.4760 - val_loss: 0.0196 - val_acc: 0.3440\n",
      "Epoch 400/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0120 - acc: 0.5067 - val_loss: 0.0196 - val_acc: 0.3400\n",
      "Epoch 401/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0121 - acc: 0.4867 - val_loss: 0.0196 - val_acc: 0.3440\n",
      "Epoch 402/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0120 - acc: 0.4827 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 403/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0120 - acc: 0.4800 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 404/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0121 - acc: 0.4867 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 405/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0120 - acc: 0.4880 - val_loss: 0.0196 - val_acc: 0.3360\n",
      "Epoch 406/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0120 - acc: 0.4880 - val_loss: 0.0196 - val_acc: 0.3440\n",
      "Epoch 407/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0120 - acc: 0.4773 - val_loss: 0.0196 - val_acc: 0.3600\n",
      "Epoch 408/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0119 - acc: 0.4760 - val_loss: 0.0197 - val_acc: 0.3320\n",
      "Epoch 409/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0118 - acc: 0.4920 - val_loss: 0.0197 - val_acc: 0.3320\n",
      "Epoch 410/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0119 - acc: 0.4907 - val_loss: 0.0197 - val_acc: 0.3360\n",
      "Epoch 411/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0120 - acc: 0.4880 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 412/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0119 - acc: 0.4973 - val_loss: 0.0197 - val_acc: 0.3520\n",
      "Epoch 413/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0119 - acc: 0.5053 - val_loss: 0.0196 - val_acc: 0.3400\n",
      "Epoch 414/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0118 - acc: 0.4667 - val_loss: 0.0197 - val_acc: 0.3320\n",
      "Epoch 415/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 117us/step - loss: 0.0120 - acc: 0.4840 - val_loss: 0.0196 - val_acc: 0.3480\n",
      "Epoch 416/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0118 - acc: 0.5013 - val_loss: 0.0196 - val_acc: 0.3280\n",
      "Epoch 417/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0119 - acc: 0.5080 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 418/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0118 - acc: 0.5093 - val_loss: 0.0196 - val_acc: 0.3520\n",
      "Epoch 419/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0118 - acc: 0.4920 - val_loss: 0.0196 - val_acc: 0.3440\n",
      "Epoch 420/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0118 - acc: 0.4880 - val_loss: 0.0196 - val_acc: 0.3360\n",
      "Epoch 421/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0118 - acc: 0.4960 - val_loss: 0.0197 - val_acc: 0.3280\n",
      "Epoch 422/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0118 - acc: 0.4920 - val_loss: 0.0197 - val_acc: 0.3520\n",
      "Epoch 423/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0118 - acc: 0.4787 - val_loss: 0.0196 - val_acc: 0.3400\n",
      "Epoch 424/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0118 - acc: 0.5053 - val_loss: 0.0197 - val_acc: 0.3440\n",
      "Epoch 425/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0118 - acc: 0.5013 - val_loss: 0.0196 - val_acc: 0.3560\n",
      "Epoch 426/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0118 - acc: 0.5093 - val_loss: 0.0196 - val_acc: 0.3520\n",
      "Epoch 427/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0117 - acc: 0.5053 - val_loss: 0.0196 - val_acc: 0.3600\n",
      "Epoch 428/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0117 - acc: 0.5147 - val_loss: 0.0196 - val_acc: 0.3480\n",
      "Epoch 429/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0118 - acc: 0.5120 - val_loss: 0.0196 - val_acc: 0.3320\n",
      "Epoch 430/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0117 - acc: 0.4880 - val_loss: 0.0197 - val_acc: 0.3200\n",
      "Epoch 431/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0117 - acc: 0.5107 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 432/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0116 - acc: 0.5000 - val_loss: 0.0196 - val_acc: 0.3360\n",
      "Epoch 433/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0117 - acc: 0.5013 - val_loss: 0.0197 - val_acc: 0.3400\n",
      "Epoch 434/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0117 - acc: 0.4920 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 435/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0117 - acc: 0.5373 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 436/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0117 - acc: 0.4853 - val_loss: 0.0197 - val_acc: 0.3560\n",
      "Epoch 437/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0116 - acc: 0.5027 - val_loss: 0.0198 - val_acc: 0.3360\n",
      "Epoch 438/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0117 - acc: 0.5147 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 439/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0116 - acc: 0.5053 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 440/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0117 - acc: 0.5107 - val_loss: 0.0196 - val_acc: 0.3440\n",
      "Epoch 441/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0116 - acc: 0.5067 - val_loss: 0.0197 - val_acc: 0.3240\n",
      "Epoch 442/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0116 - acc: 0.5173 - val_loss: 0.0196 - val_acc: 0.3360\n",
      "Epoch 443/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0115 - acc: 0.5133 - val_loss: 0.0196 - val_acc: 0.3400\n",
      "Epoch 444/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0116 - acc: 0.5000 - val_loss: 0.0196 - val_acc: 0.3440\n",
      "Epoch 445/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0116 - acc: 0.4893 - val_loss: 0.0196 - val_acc: 0.3240\n",
      "Epoch 446/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0115 - acc: 0.5040 - val_loss: 0.0197 - val_acc: 0.3440\n",
      "Epoch 447/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0115 - acc: 0.5173 - val_loss: 0.0197 - val_acc: 0.3440\n",
      "Epoch 448/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0115 - acc: 0.5067 - val_loss: 0.0196 - val_acc: 0.3560\n",
      "Epoch 449/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0116 - acc: 0.4907 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 450/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0115 - acc: 0.4947 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 451/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0114 - acc: 0.5133 - val_loss: 0.0196 - val_acc: 0.3440\n",
      "Epoch 452/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0115 - acc: 0.5093 - val_loss: 0.0197 - val_acc: 0.3360\n",
      "Epoch 453/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0115 - acc: 0.4933 - val_loss: 0.0197 - val_acc: 0.3520\n",
      "Epoch 454/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0115 - acc: 0.5013 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 455/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0115 - acc: 0.5147 - val_loss: 0.0197 - val_acc: 0.3720\n",
      "Epoch 456/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0115 - acc: 0.5173 - val_loss: 0.0197 - val_acc: 0.3320\n",
      "Epoch 457/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0114 - acc: 0.5187 - val_loss: 0.0196 - val_acc: 0.3320\n",
      "Epoch 458/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0115 - acc: 0.4933 - val_loss: 0.0196 - val_acc: 0.3400\n",
      "Epoch 459/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0115 - acc: 0.5080 - val_loss: 0.0196 - val_acc: 0.3400\n",
      "Epoch 460/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0115 - acc: 0.5200 - val_loss: 0.0197 - val_acc: 0.3440\n",
      "Epoch 461/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0114 - acc: 0.5120 - val_loss: 0.0198 - val_acc: 0.3400\n",
      "Epoch 462/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0114 - acc: 0.5053 - val_loss: 0.0198 - val_acc: 0.3440\n",
      "Epoch 463/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0114 - acc: 0.5320 - val_loss: 0.0198 - val_acc: 0.3480\n",
      "Epoch 464/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0114 - acc: 0.5013 - val_loss: 0.0197 - val_acc: 0.3360\n",
      "Epoch 465/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0115 - acc: 0.5160 - val_loss: 0.0197 - val_acc: 0.3400\n",
      "Epoch 466/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0113 - acc: 0.5227 - val_loss: 0.0197 - val_acc: 0.3520\n",
      "Epoch 467/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0114 - acc: 0.4960 - val_loss: 0.0196 - val_acc: 0.3640\n",
      "Epoch 468/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0114 - acc: 0.5307 - val_loss: 0.0196 - val_acc: 0.3600\n",
      "Epoch 469/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0114 - acc: 0.5307 - val_loss: 0.0196 - val_acc: 0.3720\n",
      "Epoch 470/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0114 - acc: 0.5267 - val_loss: 0.0196 - val_acc: 0.3600\n",
      "Epoch 471/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0114 - acc: 0.5173 - val_loss: 0.0196 - val_acc: 0.3600\n",
      "Epoch 472/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0114 - acc: 0.5040 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 473/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0113 - acc: 0.5133 - val_loss: 0.0196 - val_acc: 0.3640\n",
      "Epoch 474/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 116us/step - loss: 0.0113 - acc: 0.5187 - val_loss: 0.0197 - val_acc: 0.3760\n",
      "Epoch 475/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0112 - acc: 0.5160 - val_loss: 0.0197 - val_acc: 0.3720\n",
      "Epoch 476/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0113 - acc: 0.5373 - val_loss: 0.0198 - val_acc: 0.3640\n",
      "Epoch 477/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0113 - acc: 0.5160 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 478/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0112 - acc: 0.5173 - val_loss: 0.0197 - val_acc: 0.3520\n",
      "Epoch 479/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0112 - acc: 0.5200 - val_loss: 0.0196 - val_acc: 0.3520\n",
      "Epoch 480/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0113 - acc: 0.5400 - val_loss: 0.0197 - val_acc: 0.3520\n",
      "Epoch 481/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0113 - acc: 0.5293 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 482/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0113 - acc: 0.5093 - val_loss: 0.0198 - val_acc: 0.3600\n",
      "Epoch 483/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0112 - acc: 0.5160 - val_loss: 0.0197 - val_acc: 0.3560\n",
      "Epoch 484/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0112 - acc: 0.5467 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 485/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0112 - acc: 0.5120 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 486/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0111 - acc: 0.5267 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 487/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0113 - acc: 0.5093 - val_loss: 0.0197 - val_acc: 0.3760\n",
      "Epoch 488/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0112 - acc: 0.5360 - val_loss: 0.0197 - val_acc: 0.3760\n",
      "Epoch 489/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0112 - acc: 0.5333 - val_loss: 0.0197 - val_acc: 0.3680\n",
      "Epoch 490/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0112 - acc: 0.5187 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 491/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0112 - acc: 0.5213 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 492/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0112 - acc: 0.5453 - val_loss: 0.0198 - val_acc: 0.3680\n",
      "Epoch 493/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0112 - acc: 0.5333 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 494/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0111 - acc: 0.5427 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 495/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0111 - acc: 0.5200 - val_loss: 0.0198 - val_acc: 0.3480\n",
      "Epoch 496/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0111 - acc: 0.5027 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 497/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0111 - acc: 0.5333 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 498/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0111 - acc: 0.5507 - val_loss: 0.0198 - val_acc: 0.3560\n",
      "Epoch 499/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0111 - acc: 0.5427 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 500/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0110 - acc: 0.5347 - val_loss: 0.0197 - val_acc: 0.3360\n",
      "Epoch 501/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0111 - acc: 0.5520 - val_loss: 0.0198 - val_acc: 0.3280\n",
      "Epoch 502/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0110 - acc: 0.5267 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 503/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0112 - acc: 0.5467 - val_loss: 0.0198 - val_acc: 0.3560\n",
      "Epoch 504/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0111 - acc: 0.5160 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 505/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0110 - acc: 0.5533 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 506/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0110 - acc: 0.5467 - val_loss: 0.0198 - val_acc: 0.3480\n",
      "Epoch 507/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0110 - acc: 0.5280 - val_loss: 0.0197 - val_acc: 0.3400\n",
      "Epoch 508/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0110 - acc: 0.5107 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 509/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0110 - acc: 0.5387 - val_loss: 0.0198 - val_acc: 0.3560\n",
      "Epoch 510/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0110 - acc: 0.5200 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 511/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0110 - acc: 0.5347 - val_loss: 0.0198 - val_acc: 0.3520\n",
      "Epoch 512/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0111 - acc: 0.5493 - val_loss: 0.0198 - val_acc: 0.3600\n",
      "Epoch 513/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0110 - acc: 0.5373 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 514/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0110 - acc: 0.5107 - val_loss: 0.0196 - val_acc: 0.3600\n",
      "Epoch 515/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0111 - acc: 0.5493 - val_loss: 0.0196 - val_acc: 0.3600\n",
      "Epoch 516/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0109 - acc: 0.5320 - val_loss: 0.0196 - val_acc: 0.3560\n",
      "Epoch 517/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0109 - acc: 0.5333 - val_loss: 0.0197 - val_acc: 0.3520\n",
      "Epoch 518/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0109 - acc: 0.5440 - val_loss: 0.0197 - val_acc: 0.3560\n",
      "Epoch 519/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0110 - acc: 0.5493 - val_loss: 0.0196 - val_acc: 0.3480\n",
      "Epoch 520/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0110 - acc: 0.5387 - val_loss: 0.0197 - val_acc: 0.3320\n",
      "Epoch 521/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0111 - acc: 0.5227 - val_loss: 0.0196 - val_acc: 0.3480\n",
      "Epoch 522/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0109 - acc: 0.5373 - val_loss: 0.0197 - val_acc: 0.3520\n",
      "Epoch 523/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0108 - acc: 0.5347 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 524/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0109 - acc: 0.5360 - val_loss: 0.0198 - val_acc: 0.3480\n",
      "Epoch 525/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0109 - acc: 0.5360 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 526/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0110 - acc: 0.5480 - val_loss: 0.0197 - val_acc: 0.3720\n",
      "Epoch 527/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0109 - acc: 0.5333 - val_loss: 0.0197 - val_acc: 0.3720\n",
      "Epoch 528/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0108 - acc: 0.5560 - val_loss: 0.0198 - val_acc: 0.3560\n",
      "Epoch 529/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0109 - acc: 0.5347 - val_loss: 0.0197 - val_acc: 0.3800\n",
      "Epoch 530/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0109 - acc: 0.5467 - val_loss: 0.0196 - val_acc: 0.3720\n",
      "Epoch 531/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0110 - acc: 0.5480 - val_loss: 0.0196 - val_acc: 0.3680\n",
      "Epoch 532/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0108 - acc: 0.5427 - val_loss: 0.0197 - val_acc: 0.3680\n",
      "Epoch 533/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 115us/step - loss: 0.0108 - acc: 0.5427 - val_loss: 0.0197 - val_acc: 0.3680\n",
      "Epoch 534/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0108 - acc: 0.5467 - val_loss: 0.0197 - val_acc: 0.3720\n",
      "Epoch 535/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0109 - acc: 0.5387 - val_loss: 0.0197 - val_acc: 0.3680\n",
      "Epoch 536/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0108 - acc: 0.5200 - val_loss: 0.0197 - val_acc: 0.3680\n",
      "Epoch 537/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0108 - acc: 0.5347 - val_loss: 0.0196 - val_acc: 0.3720\n",
      "Epoch 538/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0108 - acc: 0.5507 - val_loss: 0.0196 - val_acc: 0.3640\n",
      "Epoch 539/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0108 - acc: 0.5667 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 540/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0108 - acc: 0.5587 - val_loss: 0.0198 - val_acc: 0.3600\n",
      "Epoch 541/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0107 - acc: 0.5360 - val_loss: 0.0198 - val_acc: 0.3440\n",
      "Epoch 542/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0108 - acc: 0.5773 - val_loss: 0.0198 - val_acc: 0.3520\n",
      "Epoch 543/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0108 - acc: 0.5507 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 544/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0108 - acc: 0.5480 - val_loss: 0.0197 - val_acc: 0.3560\n",
      "Epoch 545/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0108 - acc: 0.5547 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 546/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0108 - acc: 0.5520 - val_loss: 0.0197 - val_acc: 0.3480\n",
      "Epoch 547/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0107 - acc: 0.5547 - val_loss: 0.0198 - val_acc: 0.3560\n",
      "Epoch 548/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0107 - acc: 0.5427 - val_loss: 0.0197 - val_acc: 0.3680\n",
      "Epoch 549/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0107 - acc: 0.5493 - val_loss: 0.0198 - val_acc: 0.3440\n",
      "Epoch 550/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0107 - acc: 0.5427 - val_loss: 0.0198 - val_acc: 0.3600\n",
      "Epoch 551/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0107 - acc: 0.5480 - val_loss: 0.0197 - val_acc: 0.3680\n",
      "Epoch 552/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0107 - acc: 0.5520 - val_loss: 0.0198 - val_acc: 0.3520\n",
      "Epoch 553/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0107 - acc: 0.5493 - val_loss: 0.0198 - val_acc: 0.3600\n",
      "Epoch 554/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0107 - acc: 0.5720 - val_loss: 0.0198 - val_acc: 0.3520\n",
      "Epoch 555/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0107 - acc: 0.5707 - val_loss: 0.0198 - val_acc: 0.3600\n",
      "Epoch 556/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0107 - acc: 0.5440 - val_loss: 0.0198 - val_acc: 0.3560\n",
      "Epoch 557/2000\n",
      "750/750 [==============================] - 0s 126us/step - loss: 0.0107 - acc: 0.5413 - val_loss: 0.0198 - val_acc: 0.3480\n",
      "Epoch 558/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0107 - acc: 0.5587 - val_loss: 0.0197 - val_acc: 0.3560\n",
      "Epoch 559/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0106 - acc: 0.5320 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 560/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0108 - acc: 0.5413 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 561/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0106 - acc: 0.5480 - val_loss: 0.0197 - val_acc: 0.3520\n",
      "Epoch 562/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0106 - acc: 0.5400 - val_loss: 0.0197 - val_acc: 0.3600\n",
      "Epoch 563/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0106 - acc: 0.5640 - val_loss: 0.0198 - val_acc: 0.3520\n",
      "Epoch 564/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0107 - acc: 0.5427 - val_loss: 0.0198 - val_acc: 0.3600\n",
      "Epoch 565/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0107 - acc: 0.5440 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 566/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0106 - acc: 0.5627 - val_loss: 0.0198 - val_acc: 0.3640\n",
      "Epoch 567/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0107 - acc: 0.5627 - val_loss: 0.0198 - val_acc: 0.3640\n",
      "Epoch 568/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0107 - acc: 0.5373 - val_loss: 0.0198 - val_acc: 0.3640\n",
      "Epoch 569/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0106 - acc: 0.5453 - val_loss: 0.0198 - val_acc: 0.3760\n",
      "Epoch 570/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0105 - acc: 0.5533 - val_loss: 0.0198 - val_acc: 0.3640\n",
      "Epoch 571/2000\n",
      "750/750 [==============================] - 0s 125us/step - loss: 0.0106 - acc: 0.5613 - val_loss: 0.0197 - val_acc: 0.3640\n",
      "Epoch 572/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0106 - acc: 0.5693 - val_loss: 0.0198 - val_acc: 0.3680\n",
      "Epoch 573/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0106 - acc: 0.5547 - val_loss: 0.0198 - val_acc: 0.3680\n",
      "Epoch 574/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0106 - acc: 0.5493 - val_loss: 0.0198 - val_acc: 0.3760\n",
      "Epoch 575/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0106 - acc: 0.5480 - val_loss: 0.0198 - val_acc: 0.3600\n",
      "Epoch 576/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0106 - acc: 0.5587 - val_loss: 0.0198 - val_acc: 0.3640\n",
      "Epoch 577/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0105 - acc: 0.5560 - val_loss: 0.0197 - val_acc: 0.3800\n",
      "Epoch 578/2000\n",
      "750/750 [==============================] - 0s 125us/step - loss: 0.0106 - acc: 0.5587 - val_loss: 0.0197 - val_acc: 0.3680\n",
      "Epoch 579/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0106 - acc: 0.5667 - val_loss: 0.0197 - val_acc: 0.3680\n",
      "Epoch 580/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0106 - acc: 0.5653 - val_loss: 0.0198 - val_acc: 0.3560\n",
      "Epoch 581/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0105 - acc: 0.5520 - val_loss: 0.0198 - val_acc: 0.3720\n",
      "Epoch 582/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0105 - acc: 0.5587 - val_loss: 0.0198 - val_acc: 0.3720\n",
      "Epoch 583/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0104 - acc: 0.5587 - val_loss: 0.0199 - val_acc: 0.3720\n",
      "Epoch 584/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0105 - acc: 0.5787 - val_loss: 0.0198 - val_acc: 0.3760\n",
      "Epoch 585/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0105 - acc: 0.5587 - val_loss: 0.0199 - val_acc: 0.3720\n",
      "Epoch 586/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0105 - acc: 0.5560 - val_loss: 0.0198 - val_acc: 0.3760\n",
      "Epoch 587/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0105 - acc: 0.5547 - val_loss: 0.0198 - val_acc: 0.3760\n",
      "Epoch 588/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0104 - acc: 0.5373 - val_loss: 0.0199 - val_acc: 0.3760\n",
      "Epoch 589/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0104 - acc: 0.5653 - val_loss: 0.0198 - val_acc: 0.3680\n",
      "Epoch 590/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0103 - acc: 0.5600 - val_loss: 0.0197 - val_acc: 0.3920\n",
      "Epoch 591/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0104 - acc: 0.5467 - val_loss: 0.0198 - val_acc: 0.3920\n",
      "Epoch 592/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 115us/step - loss: 0.0104 - acc: 0.5880 - val_loss: 0.0198 - val_acc: 0.3760\n",
      "Epoch 593/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0105 - acc: 0.5600 - val_loss: 0.0198 - val_acc: 0.3800\n",
      "Epoch 594/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0105 - acc: 0.5480 - val_loss: 0.0198 - val_acc: 0.3760\n",
      "Epoch 595/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0104 - acc: 0.5640 - val_loss: 0.0198 - val_acc: 0.3560\n",
      "Epoch 596/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0104 - acc: 0.5827 - val_loss: 0.0198 - val_acc: 0.3680\n",
      "Epoch 597/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0104 - acc: 0.5493 - val_loss: 0.0198 - val_acc: 0.3800\n",
      "Epoch 598/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0104 - acc: 0.5600 - val_loss: 0.0198 - val_acc: 0.3800\n",
      "Epoch 599/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0105 - acc: 0.5907 - val_loss: 0.0198 - val_acc: 0.3760\n",
      "Epoch 600/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0104 - acc: 0.5947 - val_loss: 0.0198 - val_acc: 0.3720\n",
      "Epoch 601/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0105 - acc: 0.5560 - val_loss: 0.0198 - val_acc: 0.3880\n",
      "Epoch 602/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0103 - acc: 0.5520 - val_loss: 0.0198 - val_acc: 0.3840\n",
      "Epoch 603/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0103 - acc: 0.5520 - val_loss: 0.0198 - val_acc: 0.3920\n",
      "Epoch 604/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0104 - acc: 0.5493 - val_loss: 0.0198 - val_acc: 0.3920\n",
      "Epoch 605/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0103 - acc: 0.5880 - val_loss: 0.0198 - val_acc: 0.3880\n",
      "Epoch 606/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0104 - acc: 0.5987 - val_loss: 0.0198 - val_acc: 0.3680\n",
      "Epoch 607/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0103 - acc: 0.5707 - val_loss: 0.0198 - val_acc: 0.3800\n",
      "Epoch 608/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0104 - acc: 0.5707 - val_loss: 0.0198 - val_acc: 0.3880\n",
      "Epoch 609/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0104 - acc: 0.5707 - val_loss: 0.0198 - val_acc: 0.3880\n",
      "Epoch 610/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0103 - acc: 0.5613 - val_loss: 0.0198 - val_acc: 0.3880\n",
      "Epoch 611/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0103 - acc: 0.5680 - val_loss: 0.0198 - val_acc: 0.3920\n",
      "Epoch 612/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0104 - acc: 0.5720 - val_loss: 0.0198 - val_acc: 0.3880\n",
      "Epoch 613/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0102 - acc: 0.5773 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 614/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0103 - acc: 0.5827 - val_loss: 0.0198 - val_acc: 0.3640\n",
      "Epoch 615/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0103 - acc: 0.5800 - val_loss: 0.0198 - val_acc: 0.3840\n",
      "Epoch 616/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0102 - acc: 0.5707 - val_loss: 0.0199 - val_acc: 0.3800\n",
      "Epoch 617/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0103 - acc: 0.5587 - val_loss: 0.0199 - val_acc: 0.3800\n",
      "Epoch 618/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0104 - acc: 0.5640 - val_loss: 0.0198 - val_acc: 0.3880\n",
      "Epoch 619/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0103 - acc: 0.5693 - val_loss: 0.0199 - val_acc: 0.3880\n",
      "Epoch 620/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0102 - acc: 0.5733 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 621/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0103 - acc: 0.5600 - val_loss: 0.0198 - val_acc: 0.3840\n",
      "Epoch 622/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0102 - acc: 0.5813 - val_loss: 0.0198 - val_acc: 0.3720\n",
      "Epoch 623/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0103 - acc: 0.5707 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 624/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0102 - acc: 0.5760 - val_loss: 0.0199 - val_acc: 0.3800\n",
      "Epoch 625/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0102 - acc: 0.5693 - val_loss: 0.0200 - val_acc: 0.3600\n",
      "Epoch 626/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0102 - acc: 0.5707 - val_loss: 0.0198 - val_acc: 0.3840\n",
      "Epoch 627/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0103 - acc: 0.5747 - val_loss: 0.0199 - val_acc: 0.3800\n",
      "Epoch 628/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0102 - acc: 0.5827 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 629/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0102 - acc: 0.5680 - val_loss: 0.0199 - val_acc: 0.3880\n",
      "Epoch 630/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0102 - acc: 0.5880 - val_loss: 0.0199 - val_acc: 0.3760\n",
      "Epoch 631/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0102 - acc: 0.5653 - val_loss: 0.0199 - val_acc: 0.3760\n",
      "Epoch 632/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0103 - acc: 0.5920 - val_loss: 0.0199 - val_acc: 0.3800\n",
      "Epoch 633/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0103 - acc: 0.5787 - val_loss: 0.0198 - val_acc: 0.3840\n",
      "Epoch 634/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0102 - acc: 0.6000 - val_loss: 0.0199 - val_acc: 0.3800\n",
      "Epoch 635/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0102 - acc: 0.5773 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 636/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0102 - acc: 0.5800 - val_loss: 0.0198 - val_acc: 0.3760\n",
      "Epoch 637/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0101 - acc: 0.5960 - val_loss: 0.0199 - val_acc: 0.3760\n",
      "Epoch 638/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0102 - acc: 0.5680 - val_loss: 0.0198 - val_acc: 0.3800\n",
      "Epoch 639/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0101 - acc: 0.5733 - val_loss: 0.0199 - val_acc: 0.3760\n",
      "Epoch 640/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0101 - acc: 0.5893 - val_loss: 0.0198 - val_acc: 0.3720\n",
      "Epoch 641/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0101 - acc: 0.5947 - val_loss: 0.0198 - val_acc: 0.3720\n",
      "Epoch 642/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0103 - acc: 0.5840 - val_loss: 0.0198 - val_acc: 0.3760\n",
      "Epoch 643/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0101 - acc: 0.5813 - val_loss: 0.0198 - val_acc: 0.3800\n",
      "Epoch 644/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0102 - acc: 0.5720 - val_loss: 0.0198 - val_acc: 0.3760\n",
      "Epoch 645/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0101 - acc: 0.5587 - val_loss: 0.0198 - val_acc: 0.3720\n",
      "Epoch 646/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0101 - acc: 0.5733 - val_loss: 0.0199 - val_acc: 0.3680\n",
      "Epoch 647/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0101 - acc: 0.5760 - val_loss: 0.0199 - val_acc: 0.3640\n",
      "Epoch 648/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0101 - acc: 0.5773 - val_loss: 0.0198 - val_acc: 0.3760\n",
      "Epoch 649/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0101 - acc: 0.5893 - val_loss: 0.0199 - val_acc: 0.3680\n",
      "Epoch 650/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0101 - acc: 0.5840 - val_loss: 0.0198 - val_acc: 0.3840\n",
      "Epoch 651/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 118us/step - loss: 0.0102 - acc: 0.5987 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 652/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0101 - acc: 0.5653 - val_loss: 0.0200 - val_acc: 0.3680\n",
      "Epoch 653/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0100 - acc: 0.5827 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 654/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0100 - acc: 0.5960 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 655/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0101 - acc: 0.5667 - val_loss: 0.0199 - val_acc: 0.3680\n",
      "Epoch 656/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0101 - acc: 0.5733 - val_loss: 0.0199 - val_acc: 0.3680\n",
      "Epoch 657/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0101 - acc: 0.5600 - val_loss: 0.0199 - val_acc: 0.3640\n",
      "Epoch 658/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0101 - acc: 0.5773 - val_loss: 0.0199 - val_acc: 0.3760\n",
      "Epoch 659/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0101 - acc: 0.5747 - val_loss: 0.0198 - val_acc: 0.3600\n",
      "Epoch 660/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0101 - acc: 0.5773 - val_loss: 0.0199 - val_acc: 0.3640\n",
      "Epoch 661/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0100 - acc: 0.5893 - val_loss: 0.0198 - val_acc: 0.3640\n",
      "Epoch 662/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0101 - acc: 0.5933 - val_loss: 0.0199 - val_acc: 0.3800\n",
      "Epoch 663/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0101 - acc: 0.5627 - val_loss: 0.0199 - val_acc: 0.3720\n",
      "Epoch 664/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0100 - acc: 0.6093 - val_loss: 0.0199 - val_acc: 0.3760\n",
      "Epoch 665/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0100 - acc: 0.5853 - val_loss: 0.0198 - val_acc: 0.3800\n",
      "Epoch 666/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0100 - acc: 0.5880 - val_loss: 0.0199 - val_acc: 0.3880\n",
      "Epoch 667/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0100 - acc: 0.5880 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 668/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0100 - acc: 0.5733 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 669/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0100 - acc: 0.5840 - val_loss: 0.0199 - val_acc: 0.3760\n",
      "Epoch 670/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0100 - acc: 0.5600 - val_loss: 0.0199 - val_acc: 0.3760\n",
      "Epoch 671/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0099 - acc: 0.5987 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 672/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0100 - acc: 0.6133 - val_loss: 0.0199 - val_acc: 0.3720\n",
      "Epoch 673/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0099 - acc: 0.5933 - val_loss: 0.0200 - val_acc: 0.3760\n",
      "Epoch 674/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0099 - acc: 0.5613 - val_loss: 0.0200 - val_acc: 0.3800\n",
      "Epoch 675/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0100 - acc: 0.5933 - val_loss: 0.0200 - val_acc: 0.3680\n",
      "Epoch 676/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0099 - acc: 0.5760 - val_loss: 0.0199 - val_acc: 0.3720\n",
      "Epoch 677/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0098 - acc: 0.5867 - val_loss: 0.0199 - val_acc: 0.3720\n",
      "Epoch 678/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0100 - acc: 0.6067 - val_loss: 0.0199 - val_acc: 0.3800\n",
      "Epoch 679/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0099 - acc: 0.5920 - val_loss: 0.0200 - val_acc: 0.3760\n",
      "Epoch 680/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0099 - acc: 0.5827 - val_loss: 0.0200 - val_acc: 0.3840\n",
      "Epoch 681/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0099 - acc: 0.5893 - val_loss: 0.0200 - val_acc: 0.3800\n",
      "Epoch 682/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0099 - acc: 0.6040 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 683/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0099 - acc: 0.6067 - val_loss: 0.0199 - val_acc: 0.4000\n",
      "Epoch 684/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0100 - acc: 0.5907 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 685/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0099 - acc: 0.5707 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 686/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0099 - acc: 0.6053 - val_loss: 0.0199 - val_acc: 0.4000\n",
      "Epoch 687/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0098 - acc: 0.5653 - val_loss: 0.0199 - val_acc: 0.4000\n",
      "Epoch 688/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0098 - acc: 0.5733 - val_loss: 0.0200 - val_acc: 0.3880\n",
      "Epoch 689/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0100 - acc: 0.5787 - val_loss: 0.0200 - val_acc: 0.3880\n",
      "Epoch 690/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0099 - acc: 0.5600 - val_loss: 0.0200 - val_acc: 0.3920\n",
      "Epoch 691/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0098 - acc: 0.5947 - val_loss: 0.0200 - val_acc: 0.3880\n",
      "Epoch 692/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0098 - acc: 0.5907 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 693/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0098 - acc: 0.5907 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 694/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0099 - acc: 0.6040 - val_loss: 0.0200 - val_acc: 0.3880\n",
      "Epoch 695/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0099 - acc: 0.5813 - val_loss: 0.0200 - val_acc: 0.3920\n",
      "Epoch 696/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0099 - acc: 0.5853 - val_loss: 0.0199 - val_acc: 0.3880\n",
      "Epoch 697/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0098 - acc: 0.6013 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 698/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0099 - acc: 0.6080 - val_loss: 0.0199 - val_acc: 0.3840\n",
      "Epoch 699/2000\n",
      "750/750 [==============================] - 0s 125us/step - loss: 0.0099 - acc: 0.5773 - val_loss: 0.0198 - val_acc: 0.4000\n",
      "Epoch 700/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0098 - acc: 0.5787 - val_loss: 0.0199 - val_acc: 0.4040\n",
      "Epoch 701/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0098 - acc: 0.5840 - val_loss: 0.0199 - val_acc: 0.3880\n",
      "Epoch 702/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0098 - acc: 0.5867 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 703/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0098 - acc: 0.5893 - val_loss: 0.0199 - val_acc: 0.3880\n",
      "Epoch 704/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0098 - acc: 0.5973 - val_loss: 0.0199 - val_acc: 0.3880\n",
      "Epoch 705/2000\n",
      "750/750 [==============================] - 0s 125us/step - loss: 0.0098 - acc: 0.5853 - val_loss: 0.0200 - val_acc: 0.3840\n",
      "Epoch 706/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0098 - acc: 0.5907 - val_loss: 0.0199 - val_acc: 0.4000\n",
      "Epoch 707/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0098 - acc: 0.6000 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 708/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0098 - acc: 0.5893 - val_loss: 0.0200 - val_acc: 0.3920\n",
      "Epoch 709/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0097 - acc: 0.5973 - val_loss: 0.0199 - val_acc: 0.4040\n",
      "Epoch 710/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 117us/step - loss: 0.0098 - acc: 0.6000 - val_loss: 0.0200 - val_acc: 0.3920\n",
      "Epoch 711/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0098 - acc: 0.5907 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 712/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.6053 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 713/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0097 - acc: 0.6280 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 714/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0098 - acc: 0.5960 - val_loss: 0.0200 - val_acc: 0.3800\n",
      "Epoch 715/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.6080 - val_loss: 0.0198 - val_acc: 0.3880\n",
      "Epoch 716/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.6080 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 717/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0098 - acc: 0.5800 - val_loss: 0.0199 - val_acc: 0.3880\n",
      "Epoch 718/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0098 - acc: 0.5947 - val_loss: 0.0199 - val_acc: 0.3880\n",
      "Epoch 719/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0097 - acc: 0.6027 - val_loss: 0.0200 - val_acc: 0.3920\n",
      "Epoch 720/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0096 - acc: 0.5693 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 721/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.5773 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 722/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.6000 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 723/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0097 - acc: 0.5987 - val_loss: 0.0198 - val_acc: 0.3960\n",
      "Epoch 724/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0096 - acc: 0.6040 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 725/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0097 - acc: 0.5933 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 726/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0097 - acc: 0.6227 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 727/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0097 - acc: 0.6173 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 728/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.5867 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 729/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.5987 - val_loss: 0.0199 - val_acc: 0.4000\n",
      "Epoch 730/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.5947 - val_loss: 0.0199 - val_acc: 0.4000\n",
      "Epoch 731/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.5747 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 732/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0096 - acc: 0.5973 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 733/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.5933 - val_loss: 0.0199 - val_acc: 0.4000\n",
      "Epoch 734/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.6000 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 735/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0097 - acc: 0.6120 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 736/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.5947 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 737/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.5947 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 738/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.6040 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 739/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0096 - acc: 0.5973 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 740/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0096 - acc: 0.5853 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 741/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.5947 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 742/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0097 - acc: 0.6187 - val_loss: 0.0198 - val_acc: 0.3880\n",
      "Epoch 743/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0096 - acc: 0.5907 - val_loss: 0.0199 - val_acc: 0.3880\n",
      "Epoch 744/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0096 - acc: 0.6120 - val_loss: 0.0200 - val_acc: 0.3800\n",
      "Epoch 745/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0095 - acc: 0.5947 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 746/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0096 - acc: 0.6040 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 747/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0096 - acc: 0.6080 - val_loss: 0.0200 - val_acc: 0.3920\n",
      "Epoch 748/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0095 - acc: 0.6227 - val_loss: 0.0200 - val_acc: 0.3800\n",
      "Epoch 749/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0096 - acc: 0.5987 - val_loss: 0.0200 - val_acc: 0.3880\n",
      "Epoch 750/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0097 - acc: 0.5853 - val_loss: 0.0199 - val_acc: 0.3880\n",
      "Epoch 751/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0095 - acc: 0.5933 - val_loss: 0.0199 - val_acc: 0.4000\n",
      "Epoch 752/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0095 - acc: 0.5813 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 753/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0095 - acc: 0.6067 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 754/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0096 - acc: 0.5933 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 755/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0096 - acc: 0.6027 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 756/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0096 - acc: 0.6067 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 757/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0095 - acc: 0.6053 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 758/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0094 - acc: 0.6347 - val_loss: 0.0199 - val_acc: 0.4000\n",
      "Epoch 759/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0096 - acc: 0.5973 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 760/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0095 - acc: 0.6000 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 761/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0095 - acc: 0.6067 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 762/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0094 - acc: 0.5973 - val_loss: 0.0200 - val_acc: 0.3920\n",
      "Epoch 763/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0094 - acc: 0.6333 - val_loss: 0.0200 - val_acc: 0.3920\n",
      "Epoch 764/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0094 - acc: 0.6107 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 765/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0095 - acc: 0.6160 - val_loss: 0.0200 - val_acc: 0.3880\n",
      "Epoch 766/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0095 - acc: 0.6133 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 767/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0095 - acc: 0.6080 - val_loss: 0.0199 - val_acc: 0.4000\n",
      "Epoch 768/2000\n",
      "750/750 [==============================] - 0s 133us/step - loss: 0.0095 - acc: 0.5907 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 769/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 113us/step - loss: 0.0095 - acc: 0.5920 - val_loss: 0.0199 - val_acc: 0.4000\n",
      "Epoch 770/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0096 - acc: 0.6080 - val_loss: 0.0199 - val_acc: 0.4040\n",
      "Epoch 771/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0094 - acc: 0.5960 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 772/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0095 - acc: 0.5840 - val_loss: 0.0199 - val_acc: 0.3920\n",
      "Epoch 773/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0095 - acc: 0.5907 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 774/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0094 - acc: 0.6013 - val_loss: 0.0200 - val_acc: 0.3920\n",
      "Epoch 775/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0094 - acc: 0.5947 - val_loss: 0.0200 - val_acc: 0.3880\n",
      "Epoch 776/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0095 - acc: 0.5987 - val_loss: 0.0199 - val_acc: 0.3960\n",
      "Epoch 777/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0095 - acc: 0.6067 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 778/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0093 - acc: 0.6013 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 779/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0094 - acc: 0.6227 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 780/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0094 - acc: 0.6147 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 781/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0095 - acc: 0.6027 - val_loss: 0.0200 - val_acc: 0.4080\n",
      "Epoch 782/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0094 - acc: 0.6240 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 783/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0095 - acc: 0.6160 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 784/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0094 - acc: 0.6480 - val_loss: 0.0200 - val_acc: 0.3840\n",
      "Epoch 785/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0093 - acc: 0.5987 - val_loss: 0.0200 - val_acc: 0.4080\n",
      "Epoch 786/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0094 - acc: 0.6213 - val_loss: 0.0200 - val_acc: 0.4080\n",
      "Epoch 787/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0094 - acc: 0.6387 - val_loss: 0.0200 - val_acc: 0.3880\n",
      "Epoch 788/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0093 - acc: 0.6000 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 789/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0094 - acc: 0.6227 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 790/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0093 - acc: 0.6093 - val_loss: 0.0200 - val_acc: 0.4160\n",
      "Epoch 791/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0094 - acc: 0.6440 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 792/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0095 - acc: 0.6067 - val_loss: 0.0199 - val_acc: 0.4080\n",
      "Epoch 793/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0094 - acc: 0.6080 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 794/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0094 - acc: 0.6160 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 795/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0094 - acc: 0.6227 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 796/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0094 - acc: 0.6067 - val_loss: 0.0199 - val_acc: 0.4120\n",
      "Epoch 797/2000\n",
      "750/750 [==============================] - 0s 130us/step - loss: 0.0093 - acc: 0.6000 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 798/2000\n",
      "750/750 [==============================] - 0s 130us/step - loss: 0.0094 - acc: 0.6187 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 799/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0094 - acc: 0.6147 - val_loss: 0.0200 - val_acc: 0.4080\n",
      "Epoch 800/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0093 - acc: 0.6307 - val_loss: 0.0200 - val_acc: 0.4080\n",
      "Epoch 801/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0094 - acc: 0.6213 - val_loss: 0.0200 - val_acc: 0.4080\n",
      "Epoch 802/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0094 - acc: 0.5933 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 803/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0094 - acc: 0.6093 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 804/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0094 - acc: 0.6307 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 805/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0093 - acc: 0.5893 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 806/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0093 - acc: 0.6307 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 807/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0093 - acc: 0.6200 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 808/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0094 - acc: 0.6373 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 809/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0093 - acc: 0.6280 - val_loss: 0.0200 - val_acc: 0.4200\n",
      "Epoch 810/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0093 - acc: 0.6373 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 811/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0092 - acc: 0.6160 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 812/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0094 - acc: 0.6133 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 813/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0093 - acc: 0.6107 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 814/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0093 - acc: 0.6240 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 815/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0093 - acc: 0.6187 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 816/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0092 - acc: 0.6227 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 817/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0093 - acc: 0.6213 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 818/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0092 - acc: 0.6307 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 819/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0093 - acc: 0.6267 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 820/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0093 - acc: 0.6293 - val_loss: 0.0202 - val_acc: 0.3920\n",
      "Epoch 821/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0093 - acc: 0.6240 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 822/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0092 - acc: 0.6213 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 823/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0092 - acc: 0.6147 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 824/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0092 - acc: 0.6280 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 825/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0093 - acc: 0.6253 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 826/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0092 - acc: 0.6093 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 827/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0092 - acc: 0.6253 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 828/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 107us/step - loss: 0.0092 - acc: 0.6347 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 829/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0093 - acc: 0.6333 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 830/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0092 - acc: 0.6040 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 831/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0092 - acc: 0.6267 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 832/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0092 - acc: 0.6160 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 833/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0091 - acc: 0.6320 - val_loss: 0.0200 - val_acc: 0.4080\n",
      "Epoch 834/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0093 - acc: 0.6187 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 835/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0092 - acc: 0.6107 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 836/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0091 - acc: 0.6333 - val_loss: 0.0200 - val_acc: 0.4080\n",
      "Epoch 837/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0093 - acc: 0.6400 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 838/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0092 - acc: 0.6187 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 839/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0092 - acc: 0.6293 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 840/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0092 - acc: 0.6173 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 841/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0092 - acc: 0.6320 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 842/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0092 - acc: 0.6240 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 843/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0092 - acc: 0.6227 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 844/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0092 - acc: 0.6080 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 845/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0091 - acc: 0.6400 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 846/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0091 - acc: 0.6333 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 847/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0091 - acc: 0.6227 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 848/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0091 - acc: 0.6347 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 849/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0092 - acc: 0.6133 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 850/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0091 - acc: 0.6240 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 851/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0092 - acc: 0.6440 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 852/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0092 - acc: 0.6227 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 853/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0091 - acc: 0.6320 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 854/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0091 - acc: 0.6280 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 855/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0092 - acc: 0.6107 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 856/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0092 - acc: 0.6400 - val_loss: 0.0201 - val_acc: 0.3880\n",
      "Epoch 857/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0091 - acc: 0.6493 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 858/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0091 - acc: 0.6333 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 859/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0091 - acc: 0.6427 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 860/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0091 - acc: 0.6200 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 861/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0090 - acc: 0.6267 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 862/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0090 - acc: 0.6387 - val_loss: 0.0200 - val_acc: 0.4160\n",
      "Epoch 863/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0091 - acc: 0.6307 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 864/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0090 - acc: 0.6267 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 865/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0090 - acc: 0.6253 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 866/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0090 - acc: 0.6253 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 867/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0091 - acc: 0.6333 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 868/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0090 - acc: 0.6320 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 869/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0090 - acc: 0.6373 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 870/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0091 - acc: 0.6067 - val_loss: 0.0200 - val_acc: 0.4160\n",
      "Epoch 871/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0090 - acc: 0.6280 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 872/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0090 - acc: 0.6387 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 873/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0091 - acc: 0.6387 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 874/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0090 - acc: 0.6320 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 875/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0090 - acc: 0.6440 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 876/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0089 - acc: 0.6347 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 877/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0090 - acc: 0.6147 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 878/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0090 - acc: 0.6413 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 879/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0090 - acc: 0.6400 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 880/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0090 - acc: 0.6533 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 881/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0091 - acc: 0.6267 - val_loss: 0.0201 - val_acc: 0.4240\n",
      "Epoch 882/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0091 - acc: 0.6187 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 883/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0089 - acc: 0.6333 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 884/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0091 - acc: 0.6267 - val_loss: 0.0200 - val_acc: 0.4160\n",
      "Epoch 885/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0090 - acc: 0.6347 - val_loss: 0.0200 - val_acc: 0.4160\n",
      "Epoch 886/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0091 - acc: 0.6493 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 887/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 115us/step - loss: 0.0090 - acc: 0.6520 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 888/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0089 - acc: 0.6387 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 889/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0090 - acc: 0.6360 - val_loss: 0.0202 - val_acc: 0.3880\n",
      "Epoch 890/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0090 - acc: 0.6307 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 891/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0090 - acc: 0.6280 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 892/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0090 - acc: 0.6307 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 893/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0090 - acc: 0.6187 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 894/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0089 - acc: 0.6427 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 895/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0090 - acc: 0.6360 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 896/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0089 - acc: 0.6400 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 897/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0090 - acc: 0.6480 - val_loss: 0.0200 - val_acc: 0.4080\n",
      "Epoch 898/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0089 - acc: 0.6453 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 899/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0090 - acc: 0.6200 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 900/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0090 - acc: 0.6307 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 901/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0089 - acc: 0.6413 - val_loss: 0.0202 - val_acc: 0.3920\n",
      "Epoch 902/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0089 - acc: 0.6360 - val_loss: 0.0201 - val_acc: 0.3920\n",
      "Epoch 903/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0089 - acc: 0.6427 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 904/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0089 - acc: 0.6293 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 905/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0089 - acc: 0.6480 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 906/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0089 - acc: 0.6240 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 907/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0090 - acc: 0.6347 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 908/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0090 - acc: 0.6533 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 909/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0089 - acc: 0.6227 - val_loss: 0.0201 - val_acc: 0.3880\n",
      "Epoch 910/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0089 - acc: 0.6400 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 911/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0089 - acc: 0.6320 - val_loss: 0.0201 - val_acc: 0.3920\n",
      "Epoch 912/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0089 - acc: 0.6387 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 913/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0089 - acc: 0.6320 - val_loss: 0.0201 - val_acc: 0.3880\n",
      "Epoch 914/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0089 - acc: 0.6187 - val_loss: 0.0200 - val_acc: 0.3960\n",
      "Epoch 915/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0088 - acc: 0.6280 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 916/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0089 - acc: 0.6093 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 917/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0089 - acc: 0.6480 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 918/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0088 - acc: 0.6320 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 919/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0089 - acc: 0.6627 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 920/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0089 - acc: 0.6173 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 921/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0088 - acc: 0.6347 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 922/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0088 - acc: 0.6427 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 923/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0089 - acc: 0.6547 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 924/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0090 - acc: 0.6493 - val_loss: 0.0202 - val_acc: 0.3960\n",
      "Epoch 925/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0088 - acc: 0.6360 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 926/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0089 - acc: 0.6453 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 927/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0088 - acc: 0.6413 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 928/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0088 - acc: 0.6347 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 929/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0089 - acc: 0.6320 - val_loss: 0.0200 - val_acc: 0.4080\n",
      "Epoch 930/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0089 - acc: 0.6520 - val_loss: 0.0200 - val_acc: 0.4080\n",
      "Epoch 931/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0088 - acc: 0.6493 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 932/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0088 - acc: 0.6400 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 933/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0089 - acc: 0.6533 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 934/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0088 - acc: 0.6480 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 935/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0088 - acc: 0.6240 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 936/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0088 - acc: 0.6360 - val_loss: 0.0202 - val_acc: 0.3920\n",
      "Epoch 937/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0089 - acc: 0.6467 - val_loss: 0.0202 - val_acc: 0.3920\n",
      "Epoch 938/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0088 - acc: 0.6467 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 939/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0088 - acc: 0.6240 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 940/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0088 - acc: 0.6507 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 941/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0088 - acc: 0.6320 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 942/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0088 - acc: 0.6307 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 943/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0088 - acc: 0.6413 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 944/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0088 - acc: 0.6533 - val_loss: 0.0200 - val_acc: 0.3920\n",
      "Epoch 945/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0088 - acc: 0.6413 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 946/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 116us/step - loss: 0.0088 - acc: 0.6547 - val_loss: 0.0201 - val_acc: 0.3880\n",
      "Epoch 947/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0088 - acc: 0.6587 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 948/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0087 - acc: 0.6467 - val_loss: 0.0201 - val_acc: 0.3880\n",
      "Epoch 949/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0089 - acc: 0.6373 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 950/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0087 - acc: 0.6453 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 951/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0087 - acc: 0.6560 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 952/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0088 - acc: 0.6400 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 953/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0087 - acc: 0.6480 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 954/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0088 - acc: 0.6453 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 955/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0087 - acc: 0.6613 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 956/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0087 - acc: 0.6373 - val_loss: 0.0201 - val_acc: 0.3920\n",
      "Epoch 957/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0088 - acc: 0.6253 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 958/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0087 - acc: 0.6587 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 959/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0088 - acc: 0.6587 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 960/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0088 - acc: 0.6520 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 961/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0088 - acc: 0.6453 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 962/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0087 - acc: 0.6600 - val_loss: 0.0200 - val_acc: 0.4000\n",
      "Epoch 963/2000\n",
      "750/750 [==============================] - 0s 126us/step - loss: 0.0087 - acc: 0.6667 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 964/2000\n",
      "750/750 [==============================] - 0s 129us/step - loss: 0.0087 - acc: 0.6533 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 965/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0088 - acc: 0.6560 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 966/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0087 - acc: 0.6533 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 967/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0087 - acc: 0.6560 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 968/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0088 - acc: 0.6360 - val_loss: 0.0200 - val_acc: 0.4160\n",
      "Epoch 969/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0087 - acc: 0.6613 - val_loss: 0.0200 - val_acc: 0.4160\n",
      "Epoch 970/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0086 - acc: 0.6547 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 971/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0087 - acc: 0.6653 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 972/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0087 - acc: 0.6627 - val_loss: 0.0201 - val_acc: 0.3920\n",
      "Epoch 973/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0087 - acc: 0.6480 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 974/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0087 - acc: 0.6533 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 975/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0086 - acc: 0.6600 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 976/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0087 - acc: 0.6200 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 977/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0087 - acc: 0.6493 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 978/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0087 - acc: 0.6627 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 979/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0086 - acc: 0.6373 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 980/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0087 - acc: 0.6507 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 981/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0087 - acc: 0.6413 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 982/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0087 - acc: 0.6307 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 983/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0087 - acc: 0.6307 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 984/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0086 - acc: 0.6560 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 985/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0086 - acc: 0.6533 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 986/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0087 - acc: 0.6587 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 987/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0086 - acc: 0.6640 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 988/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0087 - acc: 0.6347 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 989/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0087 - acc: 0.6533 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 990/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0086 - acc: 0.6573 - val_loss: 0.0200 - val_acc: 0.4240\n",
      "Epoch 991/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0087 - acc: 0.6413 - val_loss: 0.0200 - val_acc: 0.4040\n",
      "Epoch 992/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0086 - acc: 0.6480 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 993/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0086 - acc: 0.6413 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 994/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0086 - acc: 0.6560 - val_loss: 0.0200 - val_acc: 0.4160\n",
      "Epoch 995/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0087 - acc: 0.6613 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 996/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0086 - acc: 0.6493 - val_loss: 0.0200 - val_acc: 0.4120\n",
      "Epoch 997/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0085 - acc: 0.6507 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 998/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0086 - acc: 0.6547 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 999/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0086 - acc: 0.6493 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 1000/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0086 - acc: 0.6573 - val_loss: 0.0201 - val_acc: 0.3880\n",
      "Epoch 1001/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0086 - acc: 0.6547 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 1002/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0086 - acc: 0.6627 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 1003/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0087 - acc: 0.6493 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 1004/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0085 - acc: 0.6653 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 1005/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 115us/step - loss: 0.0086 - acc: 0.6667 - val_loss: 0.0202 - val_acc: 0.3920\n",
      "Epoch 1006/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0086 - acc: 0.6680 - val_loss: 0.0202 - val_acc: 0.3880\n",
      "Epoch 1007/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0086 - acc: 0.6493 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 1008/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0086 - acc: 0.6627 - val_loss: 0.0201 - val_acc: 0.3840\n",
      "Epoch 1009/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0086 - acc: 0.6600 - val_loss: 0.0202 - val_acc: 0.3880\n",
      "Epoch 1010/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0086 - acc: 0.6560 - val_loss: 0.0201 - val_acc: 0.3760\n",
      "Epoch 1011/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0085 - acc: 0.6387 - val_loss: 0.0202 - val_acc: 0.3920\n",
      "Epoch 1012/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0086 - acc: 0.6440 - val_loss: 0.0201 - val_acc: 0.3840\n",
      "Epoch 1013/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0086 - acc: 0.6613 - val_loss: 0.0201 - val_acc: 0.3880\n",
      "Epoch 1014/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0086 - acc: 0.6533 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 1015/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0086 - acc: 0.6600 - val_loss: 0.0200 - val_acc: 0.3920\n",
      "Epoch 1016/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0085 - acc: 0.6480 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 1017/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0085 - acc: 0.6440 - val_loss: 0.0201 - val_acc: 0.3800\n",
      "Epoch 1018/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0085 - acc: 0.6613 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 1019/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0086 - acc: 0.6627 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 1020/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0085 - acc: 0.6573 - val_loss: 0.0202 - val_acc: 0.3960\n",
      "Epoch 1021/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0084 - acc: 0.6627 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 1022/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0085 - acc: 0.6720 - val_loss: 0.0201 - val_acc: 0.3880\n",
      "Epoch 1023/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0084 - acc: 0.6507 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1024/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0085 - acc: 0.6573 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 1025/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0086 - acc: 0.6440 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1026/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0086 - acc: 0.6547 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1027/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0085 - acc: 0.6560 - val_loss: 0.0201 - val_acc: 0.4200\n",
      "Epoch 1028/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0085 - acc: 0.6653 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 1029/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0085 - acc: 0.6667 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 1030/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0084 - acc: 0.6440 - val_loss: 0.0201 - val_acc: 0.4280\n",
      "Epoch 1031/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0086 - acc: 0.6787 - val_loss: 0.0201 - val_acc: 0.4200\n",
      "Epoch 1032/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0085 - acc: 0.6667 - val_loss: 0.0202 - val_acc: 0.4200\n",
      "Epoch 1033/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0085 - acc: 0.6693 - val_loss: 0.0202 - val_acc: 0.4240\n",
      "Epoch 1034/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0085 - acc: 0.6720 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 1035/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0085 - acc: 0.6573 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1036/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0085 - acc: 0.6587 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 1037/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0084 - acc: 0.6587 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 1038/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0086 - acc: 0.6840 - val_loss: 0.0202 - val_acc: 0.4200\n",
      "Epoch 1039/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0085 - acc: 0.6800 - val_loss: 0.0201 - val_acc: 0.4200\n",
      "Epoch 1040/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0085 - acc: 0.6773 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 1041/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0085 - acc: 0.6600 - val_loss: 0.0202 - val_acc: 0.4240\n",
      "Epoch 1042/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0085 - acc: 0.6520 - val_loss: 0.0201 - val_acc: 0.4320\n",
      "Epoch 1043/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0086 - acc: 0.6427 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1044/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0084 - acc: 0.6427 - val_loss: 0.0202 - val_acc: 0.4320\n",
      "Epoch 1045/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0086 - acc: 0.6653 - val_loss: 0.0202 - val_acc: 0.4240\n",
      "Epoch 1046/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0085 - acc: 0.6627 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 1047/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0085 - acc: 0.6760 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 1048/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0084 - acc: 0.6720 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 1049/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0084 - acc: 0.6533 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 1050/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0085 - acc: 0.6653 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 1051/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0085 - acc: 0.6520 - val_loss: 0.0201 - val_acc: 0.4240\n",
      "Epoch 1052/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0084 - acc: 0.6667 - val_loss: 0.0201 - val_acc: 0.4360\n",
      "Epoch 1053/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0085 - acc: 0.6747 - val_loss: 0.0201 - val_acc: 0.4240\n",
      "Epoch 1054/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0085 - acc: 0.6560 - val_loss: 0.0203 - val_acc: 0.4320\n",
      "Epoch 1055/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0084 - acc: 0.6653 - val_loss: 0.0201 - val_acc: 0.4280\n",
      "Epoch 1056/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0085 - acc: 0.6680 - val_loss: 0.0201 - val_acc: 0.4240\n",
      "Epoch 1057/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0085 - acc: 0.6653 - val_loss: 0.0201 - val_acc: 0.4240\n",
      "Epoch 1058/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0084 - acc: 0.6653 - val_loss: 0.0201 - val_acc: 0.4280\n",
      "Epoch 1059/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0084 - acc: 0.6707 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1060/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0085 - acc: 0.6547 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 1061/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0084 - acc: 0.6800 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 1062/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0084 - acc: 0.6813 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 1063/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0085 - acc: 0.6720 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1064/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 120us/step - loss: 0.0084 - acc: 0.6693 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 1065/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0084 - acc: 0.6747 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1066/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0084 - acc: 0.6733 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1067/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0084 - acc: 0.6707 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1068/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0084 - acc: 0.6707 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 1069/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0084 - acc: 0.6733 - val_loss: 0.0202 - val_acc: 0.4200\n",
      "Epoch 1070/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0084 - acc: 0.6667 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1071/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0084 - acc: 0.6587 - val_loss: 0.0201 - val_acc: 0.4240\n",
      "Epoch 1072/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0085 - acc: 0.6653 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1073/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0084 - acc: 0.6520 - val_loss: 0.0201 - val_acc: 0.4240\n",
      "Epoch 1074/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0084 - acc: 0.6680 - val_loss: 0.0201 - val_acc: 0.4280\n",
      "Epoch 1075/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0084 - acc: 0.6827 - val_loss: 0.0202 - val_acc: 0.4200\n",
      "Epoch 1076/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0084 - acc: 0.6560 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1077/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0084 - acc: 0.6627 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 1078/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0084 - acc: 0.6773 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1079/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0084 - acc: 0.6707 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1080/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0083 - acc: 0.6640 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 1081/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0083 - acc: 0.6787 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1082/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0083 - acc: 0.6893 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1083/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0084 - acc: 0.6680 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1084/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0082 - acc: 0.6760 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1085/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0083 - acc: 0.6587 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1086/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0084 - acc: 0.6640 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1087/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0084 - acc: 0.6907 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 1088/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0083 - acc: 0.6827 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1089/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0083 - acc: 0.6533 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 1090/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0083 - acc: 0.6533 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 1091/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0084 - acc: 0.6840 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1092/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0083 - acc: 0.6640 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1093/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0083 - acc: 0.6560 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1094/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0083 - acc: 0.6773 - val_loss: 0.0201 - val_acc: 0.3960\n",
      "Epoch 1095/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0084 - acc: 0.6707 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1096/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0083 - acc: 0.6707 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1097/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0084 - acc: 0.6600 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1098/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0083 - acc: 0.6560 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1099/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0083 - acc: 0.6333 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 1100/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0083 - acc: 0.6693 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 1101/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0083 - acc: 0.6613 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1102/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0083 - acc: 0.6773 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1103/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0083 - acc: 0.6800 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1104/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0083 - acc: 0.6707 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1105/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0083 - acc: 0.6600 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1106/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0082 - acc: 0.6693 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1107/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0083 - acc: 0.6680 - val_loss: 0.0203 - val_acc: 0.4000\n",
      "Epoch 1108/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0083 - acc: 0.6707 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1109/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0083 - acc: 0.6827 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 1110/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0083 - acc: 0.6707 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 1111/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0083 - acc: 0.6653 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 1112/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0083 - acc: 0.6773 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 1113/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0083 - acc: 0.6653 - val_loss: 0.0201 - val_acc: 0.4160\n",
      "Epoch 1114/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0083 - acc: 0.6973 - val_loss: 0.0202 - val_acc: 0.4200\n",
      "Epoch 1115/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0083 - acc: 0.6800 - val_loss: 0.0202 - val_acc: 0.3960\n",
      "Epoch 1116/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0083 - acc: 0.6827 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1117/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0082 - acc: 0.6680 - val_loss: 0.0201 - val_acc: 0.4080\n",
      "Epoch 1118/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0083 - acc: 0.6840 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1119/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0083 - acc: 0.6747 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1120/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0083 - acc: 0.6640 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1121/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0082 - acc: 0.6933 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 1122/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0083 - acc: 0.6773 - val_loss: 0.0202 - val_acc: 0.3960\n",
      "Epoch 1123/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 118us/step - loss: 0.0082 - acc: 0.6813 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 1124/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0082 - acc: 0.6680 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 1125/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0082 - acc: 0.6733 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1126/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0083 - acc: 0.6680 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 1127/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0082 - acc: 0.6893 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 1128/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0083 - acc: 0.6707 - val_loss: 0.0202 - val_acc: 0.3960\n",
      "Epoch 1129/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0083 - acc: 0.6800 - val_loss: 0.0201 - val_acc: 0.4000\n",
      "Epoch 1130/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0082 - acc: 0.6813 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 1131/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0082 - acc: 0.6840 - val_loss: 0.0202 - val_acc: 0.3960\n",
      "Epoch 1132/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0082 - acc: 0.6600 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 1133/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0082 - acc: 0.6733 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 1134/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0082 - acc: 0.6720 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1135/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0082 - acc: 0.6987 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 1136/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0082 - acc: 0.6707 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 1137/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0082 - acc: 0.6667 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1138/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0083 - acc: 0.6760 - val_loss: 0.0201 - val_acc: 0.4120\n",
      "Epoch 1139/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0082 - acc: 0.6720 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1140/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0082 - acc: 0.6560 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1141/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0082 - acc: 0.6787 - val_loss: 0.0202 - val_acc: 0.4000\n",
      "Epoch 1142/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0082 - acc: 0.6707 - val_loss: 0.0202 - val_acc: 0.3960\n",
      "Epoch 1143/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0083 - acc: 0.6800 - val_loss: 0.0202 - val_acc: 0.3960\n",
      "Epoch 1144/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0082 - acc: 0.6920 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1145/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0082 - acc: 0.6827 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1146/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0082 - acc: 0.6893 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1147/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0082 - acc: 0.6907 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1148/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0082 - acc: 0.6693 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1149/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0081 - acc: 0.6853 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1150/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0081 - acc: 0.6907 - val_loss: 0.0202 - val_acc: 0.3960\n",
      "Epoch 1151/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0081 - acc: 0.6893 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1152/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0082 - acc: 0.6960 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1153/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0082 - acc: 0.6733 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1154/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0083 - acc: 0.6800 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1155/2000\n",
      "750/750 [==============================] - 0s 125us/step - loss: 0.0082 - acc: 0.6733 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1156/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0082 - acc: 0.6880 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1157/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0082 - acc: 0.6720 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1158/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0082 - acc: 0.6800 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1159/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0081 - acc: 0.6733 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1160/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0081 - acc: 0.6973 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1161/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0082 - acc: 0.6680 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1162/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0081 - acc: 0.6813 - val_loss: 0.0202 - val_acc: 0.4200\n",
      "Epoch 1163/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0082 - acc: 0.6880 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1164/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0081 - acc: 0.6587 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1165/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0081 - acc: 0.6840 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1166/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0082 - acc: 0.6787 - val_loss: 0.0203 - val_acc: 0.3920\n",
      "Epoch 1167/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0082 - acc: 0.6853 - val_loss: 0.0202 - val_acc: 0.3960\n",
      "Epoch 1168/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0081 - acc: 0.6640 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1169/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0081 - acc: 0.6640 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1170/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0082 - acc: 0.6947 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1171/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0081 - acc: 0.6560 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1172/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0082 - acc: 0.6707 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1173/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0081 - acc: 0.6733 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1174/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0082 - acc: 0.6787 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1175/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0081 - acc: 0.6867 - val_loss: 0.0202 - val_acc: 0.4200\n",
      "Epoch 1176/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0081 - acc: 0.7013 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1177/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0081 - acc: 0.7000 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1178/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0081 - acc: 0.6707 - val_loss: 0.0203 - val_acc: 0.4280\n",
      "Epoch 1179/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0081 - acc: 0.6867 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1180/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0081 - acc: 0.6787 - val_loss: 0.0202 - val_acc: 0.4240\n",
      "Epoch 1181/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0082 - acc: 0.6867 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1182/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 108us/step - loss: 0.0082 - acc: 0.6760 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1183/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0081 - acc: 0.6707 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1184/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0081 - acc: 0.6933 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1185/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0081 - acc: 0.6813 - val_loss: 0.0202 - val_acc: 0.4200\n",
      "Epoch 1186/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0081 - acc: 0.6933 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1187/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0081 - acc: 0.6973 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1188/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0081 - acc: 0.6960 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1189/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0081 - acc: 0.6947 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1190/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0081 - acc: 0.6920 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1191/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0081 - acc: 0.6893 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1192/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0080 - acc: 0.6813 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1193/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0081 - acc: 0.6733 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1194/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0080 - acc: 0.6680 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1195/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0081 - acc: 0.6947 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1196/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6800 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1197/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0081 - acc: 0.6920 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1198/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0081 - acc: 0.6973 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1199/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0081 - acc: 0.6853 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1200/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0081 - acc: 0.6787 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1201/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0081 - acc: 0.6853 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1202/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0081 - acc: 0.6813 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1203/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0080 - acc: 0.7227 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1204/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0081 - acc: 0.6720 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1205/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0080 - acc: 0.6787 - val_loss: 0.0203 - val_acc: 0.4280\n",
      "Epoch 1206/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0081 - acc: 0.6960 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1207/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0081 - acc: 0.6893 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1208/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0080 - acc: 0.7107 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1209/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0081 - acc: 0.6787 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1210/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0081 - acc: 0.6840 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1211/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6733 - val_loss: 0.0202 - val_acc: 0.4200\n",
      "Epoch 1212/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0081 - acc: 0.6747 - val_loss: 0.0202 - val_acc: 0.4200\n",
      "Epoch 1213/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6893 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1214/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6720 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1215/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0080 - acc: 0.6827 - val_loss: 0.0202 - val_acc: 0.4200\n",
      "Epoch 1216/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0081 - acc: 0.6747 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1217/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0079 - acc: 0.6813 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1218/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0080 - acc: 0.6840 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1219/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0081 - acc: 0.6893 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1220/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0080 - acc: 0.6947 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1221/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6667 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1222/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6893 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1223/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6640 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1224/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.7027 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1225/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6600 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1226/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0079 - acc: 0.6760 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1227/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6960 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1228/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0080 - acc: 0.6813 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1229/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6893 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1230/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6760 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1231/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0079 - acc: 0.7053 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1232/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6800 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1233/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0081 - acc: 0.6853 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1234/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0080 - acc: 0.6853 - val_loss: 0.0202 - val_acc: 0.4320\n",
      "Epoch 1235/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0080 - acc: 0.6947 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1236/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0079 - acc: 0.6933 - val_loss: 0.0202 - val_acc: 0.4240\n",
      "Epoch 1237/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0079 - acc: 0.6947 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1238/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0079 - acc: 0.7000 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1239/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0079 - acc: 0.6893 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1240/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0079 - acc: 0.6987 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1241/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 108us/step - loss: 0.0080 - acc: 0.6853 - val_loss: 0.0202 - val_acc: 0.4080\n",
      "Epoch 1242/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0079 - acc: 0.6933 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1243/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0079 - acc: 0.6733 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1244/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.7080 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1245/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0080 - acc: 0.6907 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1246/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0079 - acc: 0.6880 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1247/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.7067 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1248/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0080 - acc: 0.6707 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1249/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0080 - acc: 0.7080 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1250/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0080 - acc: 0.6973 - val_loss: 0.0202 - val_acc: 0.4160\n",
      "Epoch 1251/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0079 - acc: 0.6813 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1252/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0080 - acc: 0.6800 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1253/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0079 - acc: 0.7080 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1254/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0079 - acc: 0.6680 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1255/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0079 - acc: 0.7040 - val_loss: 0.0202 - val_acc: 0.4040\n",
      "Epoch 1256/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0079 - acc: 0.6920 - val_loss: 0.0201 - val_acc: 0.4040\n",
      "Epoch 1257/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0079 - acc: 0.6973 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1258/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0079 - acc: 0.6827 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1259/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0079 - acc: 0.6800 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1260/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0080 - acc: 0.6840 - val_loss: 0.0203 - val_acc: 0.4280\n",
      "Epoch 1261/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0079 - acc: 0.7053 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1262/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0080 - acc: 0.6880 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1263/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0080 - acc: 0.6880 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1264/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0079 - acc: 0.6947 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1265/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0078 - acc: 0.6947 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1266/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0078 - acc: 0.6867 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1267/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0079 - acc: 0.6947 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1268/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0079 - acc: 0.6907 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1269/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0079 - acc: 0.6880 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1270/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0078 - acc: 0.6747 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1271/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0079 - acc: 0.7000 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1272/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0079 - acc: 0.6960 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1273/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0079 - acc: 0.7187 - val_loss: 0.0203 - val_acc: 0.4000\n",
      "Epoch 1274/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0079 - acc: 0.7093 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1275/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0079 - acc: 0.6893 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1276/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0079 - acc: 0.6880 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1277/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0079 - acc: 0.7013 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1278/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0079 - acc: 0.6960 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1279/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0079 - acc: 0.6880 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1280/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0078 - acc: 0.6667 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1281/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0078 - acc: 0.7013 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1282/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0079 - acc: 0.7187 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1283/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0079 - acc: 0.6947 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1284/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0079 - acc: 0.6893 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1285/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0079 - acc: 0.6813 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1286/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0078 - acc: 0.7080 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1287/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0078 - acc: 0.7053 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1288/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0079 - acc: 0.7013 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1289/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0079 - acc: 0.6960 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1290/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0078 - acc: 0.6920 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1291/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0078 - acc: 0.7133 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1292/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0079 - acc: 0.6973 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1293/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0079 - acc: 0.6867 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1294/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0079 - acc: 0.6867 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1295/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0079 - acc: 0.7000 - val_loss: 0.0202 - val_acc: 0.4120\n",
      "Epoch 1296/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0078 - acc: 0.6813 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1297/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0078 - acc: 0.7187 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1298/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0079 - acc: 0.6853 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1299/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0079 - acc: 0.6933 - val_loss: 0.0204 - val_acc: 0.3960\n",
      "Epoch 1300/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 111us/step - loss: 0.0079 - acc: 0.6960 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1301/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0078 - acc: 0.6933 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1302/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0079 - acc: 0.6947 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1303/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0078 - acc: 0.7213 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1304/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0078 - acc: 0.6987 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1305/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0079 - acc: 0.7093 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1306/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0079 - acc: 0.6827 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1307/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0078 - acc: 0.7040 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1308/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0078 - acc: 0.7013 - val_loss: 0.0203 - val_acc: 0.4280\n",
      "Epoch 1309/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0078 - acc: 0.7027 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1310/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0079 - acc: 0.7013 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1311/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0079 - acc: 0.7187 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1312/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0079 - acc: 0.7080 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1313/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0078 - acc: 0.7053 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1314/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0078 - acc: 0.6853 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1315/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0078 - acc: 0.7133 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1316/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0077 - acc: 0.7080 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1317/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0078 - acc: 0.6907 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1318/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0078 - acc: 0.7093 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1319/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0079 - acc: 0.7053 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1320/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0078 - acc: 0.7080 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1321/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0079 - acc: 0.6960 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1322/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0078 - acc: 0.7147 - val_loss: 0.0204 - val_acc: 0.4000\n",
      "Epoch 1323/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0077 - acc: 0.7200 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1324/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0079 - acc: 0.7013 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1325/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0078 - acc: 0.7080 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1326/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0078 - acc: 0.7040 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1327/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0078 - acc: 0.7000 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1328/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0077 - acc: 0.7013 - val_loss: 0.0204 - val_acc: 0.4040\n",
      "Epoch 1329/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0078 - acc: 0.6933 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1330/2000\n",
      "750/750 [==============================] - 0s 126us/step - loss: 0.0077 - acc: 0.6920 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1331/2000\n",
      "750/750 [==============================] - 0s 125us/step - loss: 0.0078 - acc: 0.7080 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1332/2000\n",
      "750/750 [==============================] - 0s 127us/step - loss: 0.0077 - acc: 0.6893 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1333/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0077 - acc: 0.7160 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1334/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0078 - acc: 0.7160 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1335/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0077 - acc: 0.6853 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1336/2000\n",
      "750/750 [==============================] - 0s 128us/step - loss: 0.0078 - acc: 0.6880 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1337/2000\n",
      "750/750 [==============================] - 0s 126us/step - loss: 0.0077 - acc: 0.7067 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1338/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0077 - acc: 0.7053 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1339/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0078 - acc: 0.6840 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1340/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0077 - acc: 0.7027 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1341/2000\n",
      "750/750 [==============================] - 0s 128us/step - loss: 0.0077 - acc: 0.7013 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1342/2000\n",
      "750/750 [==============================] - 0s 130us/step - loss: 0.0078 - acc: 0.7173 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1343/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0077 - acc: 0.6947 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1344/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0077 - acc: 0.7080 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1345/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0078 - acc: 0.7107 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1346/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0078 - acc: 0.7133 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1347/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0078 - acc: 0.7120 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1348/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0078 - acc: 0.7200 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1349/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0077 - acc: 0.6920 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1350/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0077 - acc: 0.6960 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1351/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0077 - acc: 0.7187 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1352/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0078 - acc: 0.6880 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1353/2000\n",
      "750/750 [==============================] - 0s 130us/step - loss: 0.0077 - acc: 0.6973 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1354/2000\n",
      "750/750 [==============================] - 0s 128us/step - loss: 0.0078 - acc: 0.6987 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1355/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0078 - acc: 0.7093 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1356/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0077 - acc: 0.6893 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1357/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0077 - acc: 0.7173 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1358/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0077 - acc: 0.7173 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1359/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 108us/step - loss: 0.0077 - acc: 0.7067 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1360/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0077 - acc: 0.7040 - val_loss: 0.0203 - val_acc: 0.4280\n",
      "Epoch 1361/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0077 - acc: 0.7160 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1362/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0077 - acc: 0.7187 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1363/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0077 - acc: 0.7000 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1364/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0077 - acc: 0.7200 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1365/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0077 - acc: 0.7187 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1366/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0076 - acc: 0.7227 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1367/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0077 - acc: 0.7040 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1368/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0076 - acc: 0.6880 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1369/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0077 - acc: 0.6920 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1370/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0077 - acc: 0.7120 - val_loss: 0.0203 - val_acc: 0.4280\n",
      "Epoch 1371/2000\n",
      "750/750 [==============================] - 0s 106us/step - loss: 0.0077 - acc: 0.7173 - val_loss: 0.0203 - val_acc: 0.4280\n",
      "Epoch 1372/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0077 - acc: 0.7027 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1373/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0077 - acc: 0.7173 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1374/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0077 - acc: 0.7027 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1375/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0076 - acc: 0.7160 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1376/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0076 - acc: 0.7067 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1377/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0076 - acc: 0.7093 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1378/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0077 - acc: 0.6880 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1379/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0077 - acc: 0.7280 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1380/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0078 - acc: 0.7013 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1381/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0077 - acc: 0.7067 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1382/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0076 - acc: 0.7173 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1383/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0077 - acc: 0.7120 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1384/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0077 - acc: 0.7053 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1385/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0076 - acc: 0.7200 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1386/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0077 - acc: 0.7160 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1387/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0077 - acc: 0.7053 - val_loss: 0.0204 - val_acc: 0.4000\n",
      "Epoch 1388/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0076 - acc: 0.7280 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1389/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0077 - acc: 0.7053 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1390/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0077 - acc: 0.7000 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1391/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0077 - acc: 0.7027 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1392/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0077 - acc: 0.7093 - val_loss: 0.0204 - val_acc: 0.4040\n",
      "Epoch 1393/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0076 - acc: 0.7107 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1394/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0077 - acc: 0.7253 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1395/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0077 - acc: 0.7133 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1396/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0076 - acc: 0.7187 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1397/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0077 - acc: 0.7160 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1398/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0076 - acc: 0.7293 - val_loss: 0.0203 - val_acc: 0.4080\n",
      "Epoch 1399/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0076 - acc: 0.6973 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1400/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0077 - acc: 0.6973 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1401/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0076 - acc: 0.7147 - val_loss: 0.0203 - val_acc: 0.4040\n",
      "Epoch 1402/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0077 - acc: 0.7067 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1403/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0077 - acc: 0.6973 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1404/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0076 - acc: 0.7253 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1405/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0076 - acc: 0.6960 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1406/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0076 - acc: 0.7227 - val_loss: 0.0203 - val_acc: 0.4120\n",
      "Epoch 1407/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0076 - acc: 0.7147 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1408/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0077 - acc: 0.6893 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1409/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0076 - acc: 0.7000 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1410/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0076 - acc: 0.7040 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1411/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0076 - acc: 0.7067 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1412/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0077 - acc: 0.6867 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1413/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0077 - acc: 0.6960 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1414/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0076 - acc: 0.7200 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1415/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0077 - acc: 0.7160 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1416/2000\n",
      "750/750 [==============================] - 0s 108us/step - loss: 0.0077 - acc: 0.7173 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1417/2000\n",
      "750/750 [==============================] - 0s 107us/step - loss: 0.0075 - acc: 0.7253 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1418/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 108us/step - loss: 0.0077 - acc: 0.7200 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1419/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0075 - acc: 0.7133 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1420/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0076 - acc: 0.7160 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1421/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0076 - acc: 0.7200 - val_loss: 0.0203 - val_acc: 0.4280\n",
      "Epoch 1422/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0076 - acc: 0.7240 - val_loss: 0.0203 - val_acc: 0.4280\n",
      "Epoch 1423/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0076 - acc: 0.7053 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1424/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0076 - acc: 0.7280 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1425/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0077 - acc: 0.7173 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1426/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0077 - acc: 0.7133 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1427/2000\n",
      "750/750 [==============================] - 0s 109us/step - loss: 0.0076 - acc: 0.7173 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1428/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0076 - acc: 0.6973 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1429/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0076 - acc: 0.6973 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1430/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0076 - acc: 0.7227 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1431/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0076 - acc: 0.6933 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1432/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0077 - acc: 0.7173 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1433/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0076 - acc: 0.7093 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1434/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0076 - acc: 0.7147 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1435/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0076 - acc: 0.7173 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1436/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0076 - acc: 0.7227 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1437/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0076 - acc: 0.7133 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1438/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0075 - acc: 0.7133 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1439/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0076 - acc: 0.7347 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1440/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0076 - acc: 0.7293 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1441/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0076 - acc: 0.6933 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1442/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0076 - acc: 0.7040 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1443/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0077 - acc: 0.7133 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1444/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0075 - acc: 0.7320 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1445/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0076 - acc: 0.7053 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1446/2000\n",
      "750/750 [==============================] - 0s 125us/step - loss: 0.0076 - acc: 0.6933 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1447/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0075 - acc: 0.7293 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1448/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0075 - acc: 0.7120 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1449/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0075 - acc: 0.7067 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1450/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0075 - acc: 0.6973 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1451/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0075 - acc: 0.7227 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1452/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0076 - acc: 0.7000 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1453/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0077 - acc: 0.7240 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1454/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7173 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1455/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0076 - acc: 0.7213 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1456/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0076 - acc: 0.7080 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1457/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0075 - acc: 0.7200 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1458/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0075 - acc: 0.7227 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1459/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7253 - val_loss: 0.0204 - val_acc: 0.4320\n",
      "Epoch 1460/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0075 - acc: 0.7333 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1461/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0075 - acc: 0.7093 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1462/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7107 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1463/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0075 - acc: 0.7067 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1464/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0075 - acc: 0.7320 - val_loss: 0.0204 - val_acc: 0.4320\n",
      "Epoch 1465/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0076 - acc: 0.7093 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1466/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0075 - acc: 0.7133 - val_loss: 0.0204 - val_acc: 0.4400\n",
      "Epoch 1467/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0076 - acc: 0.7147 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1468/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0075 - acc: 0.7213 - val_loss: 0.0205 - val_acc: 0.4280\n",
      "Epoch 1469/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0075 - acc: 0.7400 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1470/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0076 - acc: 0.7107 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1471/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0075 - acc: 0.7253 - val_loss: 0.0205 - val_acc: 0.4280\n",
      "Epoch 1472/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0075 - acc: 0.7307 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1473/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7240 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1474/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0077 - acc: 0.7160 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1475/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0075 - acc: 0.7253 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1476/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0076 - acc: 0.7173 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1477/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 121us/step - loss: 0.0074 - acc: 0.7200 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1478/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0075 - acc: 0.7227 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1479/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0075 - acc: 0.7187 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1480/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0075 - acc: 0.7280 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1481/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0076 - acc: 0.7147 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1482/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0075 - acc: 0.7227 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1483/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0076 - acc: 0.7120 - val_loss: 0.0203 - val_acc: 0.4280\n",
      "Epoch 1484/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7200 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1485/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0075 - acc: 0.7267 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1486/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0074 - acc: 0.7280 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1487/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0075 - acc: 0.7240 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1488/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0075 - acc: 0.7067 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1489/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7253 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1490/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7253 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1491/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0075 - acc: 0.7267 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1492/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0075 - acc: 0.7187 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1493/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0075 - acc: 0.7320 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1494/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0075 - acc: 0.7280 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1495/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0074 - acc: 0.7293 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1496/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7333 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1497/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0075 - acc: 0.7133 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1498/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7200 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1499/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0075 - acc: 0.7160 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1500/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0074 - acc: 0.7147 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1501/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0075 - acc: 0.7240 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1502/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0075 - acc: 0.7093 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1503/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0075 - acc: 0.7400 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1504/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0074 - acc: 0.7427 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1505/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7293 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1506/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7107 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1507/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7107 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1508/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0074 - acc: 0.7307 - val_loss: 0.0203 - val_acc: 0.4280\n",
      "Epoch 1509/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0074 - acc: 0.7400 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1510/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7267 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1511/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0075 - acc: 0.7400 - val_loss: 0.0204 - val_acc: 0.4320\n",
      "Epoch 1512/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0075 - acc: 0.7187 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1513/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0074 - acc: 0.7280 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1514/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0074 - acc: 0.7227 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1515/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0075 - acc: 0.7427 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1516/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0075 - acc: 0.7427 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1517/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7280 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1518/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0075 - acc: 0.7160 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1519/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0075 - acc: 0.7253 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1520/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7253 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1521/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0075 - acc: 0.7187 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1522/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0075 - acc: 0.7320 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1523/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7133 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1524/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7227 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1525/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0075 - acc: 0.7240 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1526/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0074 - acc: 0.7360 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1527/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0074 - acc: 0.7187 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1528/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0074 - acc: 0.7173 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1529/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0075 - acc: 0.7227 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1530/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7213 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1531/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0074 - acc: 0.7333 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1532/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0075 - acc: 0.7347 - val_loss: 0.0205 - val_acc: 0.4320\n",
      "Epoch 1533/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0075 - acc: 0.7213 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1534/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0075 - acc: 0.7280 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1535/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0075 - acc: 0.7360 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1536/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 115us/step - loss: 0.0074 - acc: 0.7120 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1537/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0075 - acc: 0.7213 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1538/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0074 - acc: 0.7400 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1539/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0075 - acc: 0.7347 - val_loss: 0.0205 - val_acc: 0.4280\n",
      "Epoch 1540/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7320 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1541/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0074 - acc: 0.7067 - val_loss: 0.0204 - val_acc: 0.4320\n",
      "Epoch 1542/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0075 - acc: 0.7267 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1543/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0074 - acc: 0.7307 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1544/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0075 - acc: 0.7240 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1545/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0074 - acc: 0.7307 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1546/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0075 - acc: 0.7120 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1547/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0075 - acc: 0.7320 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1548/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0074 - acc: 0.7160 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1549/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0074 - acc: 0.7400 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1550/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0074 - acc: 0.7213 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1551/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0075 - acc: 0.7267 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1552/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0074 - acc: 0.7360 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1553/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0074 - acc: 0.7360 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1554/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0074 - acc: 0.7227 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1555/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7267 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1556/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0073 - acc: 0.7267 - val_loss: 0.0204 - val_acc: 0.4000\n",
      "Epoch 1557/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0074 - acc: 0.7187 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1558/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0074 - acc: 0.7360 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1559/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0074 - acc: 0.7187 - val_loss: 0.0204 - val_acc: 0.4040\n",
      "Epoch 1560/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0074 - acc: 0.7387 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1561/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0074 - acc: 0.7013 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1562/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7360 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1563/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7400 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1564/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0074 - acc: 0.7160 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1565/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0074 - acc: 0.7293 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1566/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0073 - acc: 0.7040 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1567/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7240 - val_loss: 0.0203 - val_acc: 0.4160\n",
      "Epoch 1568/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0074 - acc: 0.7320 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1569/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0075 - acc: 0.7293 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1570/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0073 - acc: 0.7213 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1571/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7267 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1572/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0073 - acc: 0.7227 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1573/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0075 - acc: 0.7333 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1574/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0074 - acc: 0.7333 - val_loss: 0.0203 - val_acc: 0.4200\n",
      "Epoch 1575/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0074 - acc: 0.7467 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1576/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0074 - acc: 0.7427 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1577/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0074 - acc: 0.7093 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1578/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7213 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1579/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0074 - acc: 0.7240 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1580/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0073 - acc: 0.7533 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1581/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0074 - acc: 0.7160 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1582/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0074 - acc: 0.7360 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1583/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0073 - acc: 0.7520 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1584/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0073 - acc: 0.7267 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1585/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0073 - acc: 0.7200 - val_loss: 0.0205 - val_acc: 0.4280\n",
      "Epoch 1586/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0074 - acc: 0.7280 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1587/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0074 - acc: 0.7427 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1588/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0074 - acc: 0.7253 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1589/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0073 - acc: 0.7400 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1590/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0073 - acc: 0.7440 - val_loss: 0.0205 - val_acc: 0.4280\n",
      "Epoch 1591/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0074 - acc: 0.7280 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1592/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0073 - acc: 0.7333 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1593/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0074 - acc: 0.7373 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1594/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0074 - acc: 0.7413 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1595/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 121us/step - loss: 0.0074 - acc: 0.7320 - val_loss: 0.0205 - val_acc: 0.4280\n",
      "Epoch 1596/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0074 - acc: 0.7453 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1597/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0074 - acc: 0.7240 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1598/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0074 - acc: 0.7280 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1599/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0074 - acc: 0.7333 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1600/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0073 - acc: 0.7360 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1601/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0073 - acc: 0.7440 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1602/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0074 - acc: 0.7387 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1603/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0073 - acc: 0.7453 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1604/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7120 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1605/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0073 - acc: 0.7573 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1606/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0073 - acc: 0.7440 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1607/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0073 - acc: 0.7373 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1608/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0074 - acc: 0.7427 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1609/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0073 - acc: 0.7467 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1610/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0073 - acc: 0.7373 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1611/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0073 - acc: 0.7373 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1612/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0074 - acc: 0.7227 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1613/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0073 - acc: 0.7147 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1614/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0074 - acc: 0.7293 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1615/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0073 - acc: 0.7333 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1616/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0074 - acc: 0.7253 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1617/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0074 - acc: 0.7200 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1618/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0073 - acc: 0.7640 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1619/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0072 - acc: 0.7253 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1620/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0073 - acc: 0.7400 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1621/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0073 - acc: 0.7307 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1622/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0073 - acc: 0.7440 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1623/2000\n",
      "750/750 [==============================] - 0s 127us/step - loss: 0.0073 - acc: 0.7280 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1624/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0074 - acc: 0.7533 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1625/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0073 - acc: 0.7533 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1626/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0073 - acc: 0.7493 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1627/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0073 - acc: 0.7360 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1628/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0073 - acc: 0.7547 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1629/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0073 - acc: 0.7387 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1630/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0072 - acc: 0.7280 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1631/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0073 - acc: 0.7413 - val_loss: 0.0203 - val_acc: 0.4240\n",
      "Epoch 1632/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0073 - acc: 0.7293 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1633/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0073 - acc: 0.7333 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1634/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0073 - acc: 0.7547 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1635/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0073 - acc: 0.7253 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1636/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0073 - acc: 0.7507 - val_loss: 0.0205 - val_acc: 0.4280\n",
      "Epoch 1637/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0073 - acc: 0.7267 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1638/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0073 - acc: 0.7547 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1639/2000\n",
      "750/750 [==============================] - 0s 125us/step - loss: 0.0073 - acc: 0.7387 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1640/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0073 - acc: 0.7187 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1641/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0073 - acc: 0.7293 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1642/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0073 - acc: 0.7227 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1643/2000\n",
      "750/750 [==============================] - 0s 126us/step - loss: 0.0073 - acc: 0.7427 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1644/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0073 - acc: 0.7373 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1645/2000\n",
      "750/750 [==============================] - 0s 125us/step - loss: 0.0073 - acc: 0.7333 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1646/2000\n",
      "750/750 [==============================] - 0s 126us/step - loss: 0.0073 - acc: 0.7507 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1647/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0073 - acc: 0.7293 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1648/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0073 - acc: 0.7493 - val_loss: 0.0204 - val_acc: 0.4040\n",
      "Epoch 1649/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0073 - acc: 0.7493 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1650/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0073 - acc: 0.7427 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1651/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0073 - acc: 0.7587 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1652/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0073 - acc: 0.7493 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1653/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0072 - acc: 0.7333 - val_loss: 0.0204 - val_acc: 0.4040\n",
      "Epoch 1654/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7307 - val_loss: 0.0204 - val_acc: 0.4040\n",
      "Epoch 1655/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7547 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1656/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7360 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1657/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0073 - acc: 0.7427 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1658/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0073 - acc: 0.7280 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1659/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0073 - acc: 0.7453 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1660/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0073 - acc: 0.7280 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1661/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0073 - acc: 0.7520 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1662/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0073 - acc: 0.7507 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1663/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7520 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1664/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0073 - acc: 0.7240 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1665/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0073 - acc: 0.7507 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1666/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0072 - acc: 0.7240 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1667/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0073 - acc: 0.7160 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1668/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0073 - acc: 0.7173 - val_loss: 0.0204 - val_acc: 0.4280\n",
      "Epoch 1669/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7573 - val_loss: 0.0205 - val_acc: 0.4360\n",
      "Epoch 1670/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0073 - acc: 0.7427 - val_loss: 0.0205 - val_acc: 0.4280\n",
      "Epoch 1671/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7493 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1672/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7347 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1673/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0073 - acc: 0.7520 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1674/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0073 - acc: 0.7520 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1675/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0073 - acc: 0.7320 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1676/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0072 - acc: 0.7480 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1677/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0073 - acc: 0.7173 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1678/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7480 - val_loss: 0.0204 - val_acc: 0.4120\n",
      "Epoch 1679/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7600 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1680/2000\n",
      "750/750 [==============================] - 0s 110us/step - loss: 0.0073 - acc: 0.7480 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1681/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0073 - acc: 0.7493 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1682/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0073 - acc: 0.7413 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1683/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7400 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1684/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7253 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1685/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7560 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1686/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0073 - acc: 0.7560 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1687/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0072 - acc: 0.7533 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1688/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7467 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1689/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7587 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1690/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0072 - acc: 0.7493 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1691/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0073 - acc: 0.7187 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1692/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0072 - acc: 0.7360 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1693/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7520 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1694/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7427 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1695/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7387 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1696/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7440 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1697/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7533 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1698/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0073 - acc: 0.7427 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1699/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0073 - acc: 0.7413 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1700/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7640 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1701/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7467 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1702/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7333 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1703/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0072 - acc: 0.7520 - val_loss: 0.0204 - val_acc: 0.4200\n",
      "Epoch 1704/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7533 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1705/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7347 - val_loss: 0.0204 - val_acc: 0.4240\n",
      "Epoch 1706/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0072 - acc: 0.7493 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1707/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7587 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1708/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7413 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1709/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7440 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1710/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0072 - acc: 0.7493 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1711/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7507 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1712/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7413 - val_loss: 0.0205 - val_acc: 0.3960\n",
      "Epoch 1713/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7333 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1714/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0071 - acc: 0.7547 - val_loss: 0.0205 - val_acc: 0.4000\n",
      "Epoch 1715/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7413 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1716/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0072 - acc: 0.7493 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1717/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7453 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1718/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0073 - acc: 0.7507 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1719/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7453 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1720/2000\n",
      "750/750 [==============================] - 0s 112us/step - loss: 0.0073 - acc: 0.7453 - val_loss: 0.0205 - val_acc: 0.4000\n",
      "Epoch 1721/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7627 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1722/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7533 - val_loss: 0.0205 - val_acc: 0.4000\n",
      "Epoch 1723/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7547 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1724/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7453 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1725/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7400 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1726/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0072 - acc: 0.7373 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1727/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.7413 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1728/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0072 - acc: 0.7400 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1729/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0072 - acc: 0.7360 - val_loss: 0.0204 - val_acc: 0.4080\n",
      "Epoch 1730/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0072 - acc: 0.7307 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1731/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0072 - acc: 0.7333 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1732/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0072 - acc: 0.7440 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1733/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7533 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1734/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7333 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1735/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0072 - acc: 0.7533 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1736/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7267 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1737/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0072 - acc: 0.7507 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1738/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0072 - acc: 0.7400 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1739/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0072 - acc: 0.7547 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1740/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0072 - acc: 0.7453 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1741/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0072 - acc: 0.7453 - val_loss: 0.0204 - val_acc: 0.4040\n",
      "Epoch 1742/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0071 - acc: 0.7720 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1743/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0072 - acc: 0.7360 - val_loss: 0.0205 - val_acc: 0.4000\n",
      "Epoch 1744/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0072 - acc: 0.7280 - val_loss: 0.0206 - val_acc: 0.4040\n",
      "Epoch 1745/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7453 - val_loss: 0.0206 - val_acc: 0.4040\n",
      "Epoch 1746/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0072 - acc: 0.7493 - val_loss: 0.0206 - val_acc: 0.4000\n",
      "Epoch 1747/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0072 - acc: 0.7640 - val_loss: 0.0206 - val_acc: 0.4000\n",
      "Epoch 1748/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0072 - acc: 0.7493 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1749/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0072 - acc: 0.7493 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1750/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0072 - acc: 0.7293 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1751/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0072 - acc: 0.7427 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1752/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0072 - acc: 0.7533 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1753/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0072 - acc: 0.7520 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1754/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7440 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1755/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7467 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1756/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0072 - acc: 0.7720 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1757/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0072 - acc: 0.7453 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1758/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7493 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1759/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0072 - acc: 0.7627 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1760/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0072 - acc: 0.7467 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1761/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0072 - acc: 0.7080 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1762/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0071 - acc: 0.7440 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1763/2000\n",
      "750/750 [==============================] - 0s 127us/step - loss: 0.0072 - acc: 0.7587 - val_loss: 0.0204 - val_acc: 0.4160\n",
      "Epoch 1764/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0072 - acc: 0.7640 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1765/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0072 - acc: 0.7520 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1766/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0071 - acc: 0.7440 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1767/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7547 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1768/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7547 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1769/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0072 - acc: 0.7373 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1770/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7507 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1771/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7400 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1772/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 115us/step - loss: 0.0072 - acc: 0.7600 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1773/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0072 - acc: 0.7507 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1774/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0071 - acc: 0.7560 - val_loss: 0.0205 - val_acc: 0.3960\n",
      "Epoch 1775/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0071 - acc: 0.7387 - val_loss: 0.0204 - val_acc: 0.4040\n",
      "Epoch 1776/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7413 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1777/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7493 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1778/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0072 - acc: 0.7453 - val_loss: 0.0205 - val_acc: 0.4000\n",
      "Epoch 1779/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7467 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1780/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0072 - acc: 0.7533 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1781/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0071 - acc: 0.7293 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1782/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0072 - acc: 0.7480 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1783/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7467 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1784/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0072 - acc: 0.7400 - val_loss: 0.0206 - val_acc: 0.4000\n",
      "Epoch 1785/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7613 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1786/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0072 - acc: 0.7373 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1787/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7520 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1788/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7507 - val_loss: 0.0206 - val_acc: 0.4040\n",
      "Epoch 1789/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7773 - val_loss: 0.0206 - val_acc: 0.4040\n",
      "Epoch 1790/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7573 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1791/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0072 - acc: 0.7640 - val_loss: 0.0206 - val_acc: 0.4040\n",
      "Epoch 1792/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7680 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1793/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7613 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1794/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7253 - val_loss: 0.0207 - val_acc: 0.4080\n",
      "Epoch 1795/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7387 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1796/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7573 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1797/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0072 - acc: 0.7467 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1798/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0071 - acc: 0.7587 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1799/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0071 - acc: 0.7480 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1800/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7653 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1801/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7520 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1802/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7587 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1803/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0070 - acc: 0.7587 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1804/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7573 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1805/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7507 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1806/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7627 - val_loss: 0.0205 - val_acc: 0.4280\n",
      "Epoch 1807/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0071 - acc: 0.7493 - val_loss: 0.0206 - val_acc: 0.4280\n",
      "Epoch 1808/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0072 - acc: 0.7400 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1809/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7693 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1810/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7653 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1811/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7547 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1812/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7493 - val_loss: 0.0206 - val_acc: 0.4280\n",
      "Epoch 1813/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0071 - acc: 0.7547 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1814/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7600 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1815/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7707 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1816/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7480 - val_loss: 0.0206 - val_acc: 0.4280\n",
      "Epoch 1817/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7600 - val_loss: 0.0206 - val_acc: 0.4280\n",
      "Epoch 1818/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7733 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1819/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7427 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1820/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7720 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1821/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0071 - acc: 0.7520 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1822/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7547 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1823/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0072 - acc: 0.7573 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1824/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7587 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1825/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7467 - val_loss: 0.0206 - val_acc: 0.4280\n",
      "Epoch 1826/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7360 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1827/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7560 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1828/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0071 - acc: 0.7640 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1829/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0071 - acc: 0.7467 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1830/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7560 - val_loss: 0.0206 - val_acc: 0.4320\n",
      "Epoch 1831/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 118us/step - loss: 0.0071 - acc: 0.7600 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1832/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0206 - val_acc: 0.4040\n",
      "Epoch 1833/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7440 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1834/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0070 - acc: 0.7560 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1835/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7267 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1836/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0070 - acc: 0.7387 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1837/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7320 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1838/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7440 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1839/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7387 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1840/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7693 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1841/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0070 - acc: 0.7640 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1842/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0071 - acc: 0.7493 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1843/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0071 - acc: 0.7653 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1844/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7520 - val_loss: 0.0207 - val_acc: 0.4040\n",
      "Epoch 1845/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0070 - acc: 0.7587 - val_loss: 0.0207 - val_acc: 0.4200\n",
      "Epoch 1846/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7733 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1847/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7573 - val_loss: 0.0207 - val_acc: 0.4120\n",
      "Epoch 1848/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0071 - acc: 0.7627 - val_loss: 0.0205 - val_acc: 0.4120\n",
      "Epoch 1849/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7520 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1850/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0070 - acc: 0.7520 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1851/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7560 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1852/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0071 - acc: 0.7560 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1853/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7467 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1854/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7680 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1855/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7560 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1856/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0205 - val_acc: 0.4200\n",
      "Epoch 1857/2000\n",
      "750/750 [==============================] - 0s 111us/step - loss: 0.0071 - acc: 0.7547 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1858/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 0.7680 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1859/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7387 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1860/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1861/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7747 - val_loss: 0.0206 - val_acc: 0.4000\n",
      "Epoch 1862/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0071 - acc: 0.7600 - val_loss: 0.0207 - val_acc: 0.4080\n",
      "Epoch 1863/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0071 - acc: 0.7467 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1864/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0070 - acc: 0.7773 - val_loss: 0.0206 - val_acc: 0.4040\n",
      "Epoch 1865/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0070 - acc: 0.7493 - val_loss: 0.0207 - val_acc: 0.4080\n",
      "Epoch 1866/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7533 - val_loss: 0.0206 - val_acc: 0.4000\n",
      "Epoch 1867/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0070 - acc: 0.7573 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1868/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0206 - val_acc: 0.4040\n",
      "Epoch 1869/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7640 - val_loss: 0.0207 - val_acc: 0.4120\n",
      "Epoch 1870/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1871/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7653 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1872/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0070 - acc: 0.7520 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1873/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7800 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1874/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7573 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1875/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7640 - val_loss: 0.0205 - val_acc: 0.4040\n",
      "Epoch 1876/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7627 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1877/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1878/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 0.7520 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1879/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 0.7573 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1880/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7600 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1881/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7613 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1882/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7667 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1883/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7600 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1884/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7560 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1885/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0070 - acc: 0.7640 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1886/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7680 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1887/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7573 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1888/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0070 - acc: 0.7653 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1889/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0071 - acc: 0.7707 - val_loss: 0.0205 - val_acc: 0.4160\n",
      "Epoch 1890/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 119us/step - loss: 0.0070 - acc: 0.7560 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1891/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0070 - acc: 0.7587 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1892/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0070 - acc: 0.7667 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1893/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0071 - acc: 0.7493 - val_loss: 0.0206 - val_acc: 0.4040\n",
      "Epoch 1894/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 0.7480 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1895/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1896/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7480 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1897/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0070 - acc: 0.7693 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1898/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0071 - acc: 0.7493 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1899/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0071 - acc: 0.7560 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1900/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7680 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1901/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0071 - acc: 0.7627 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1902/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7493 - val_loss: 0.0206 - val_acc: 0.4000\n",
      "Epoch 1903/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7520 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1904/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7720 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1905/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0070 - acc: 0.7440 - val_loss: 0.0207 - val_acc: 0.4120\n",
      "Epoch 1906/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.7600 - val_loss: 0.0207 - val_acc: 0.4120\n",
      "Epoch 1907/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0070 - acc: 0.7560 - val_loss: 0.0207 - val_acc: 0.4080\n",
      "Epoch 1908/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0071 - acc: 0.7533 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1909/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7467 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1910/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0070 - acc: 0.7640 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1911/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0070 - acc: 0.7640 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1912/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7680 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1913/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7707 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1914/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 0.7653 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1915/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0070 - acc: 0.7533 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1916/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7653 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1917/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7653 - val_loss: 0.0205 - val_acc: 0.4240\n",
      "Epoch 1918/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0070 - acc: 0.7640 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1919/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0070 - acc: 0.7600 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1920/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1921/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 0.7427 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1922/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0069 - acc: 0.7533 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1923/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7787 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1924/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0070 - acc: 0.7720 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1925/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0070 - acc: 0.7587 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1926/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1927/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.7480 - val_loss: 0.0205 - val_acc: 0.4080\n",
      "Epoch 1928/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0070 - acc: 0.7733 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1929/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1930/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0070 - acc: 0.7573 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1931/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7587 - val_loss: 0.0207 - val_acc: 0.4080\n",
      "Epoch 1932/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7600 - val_loss: 0.0207 - val_acc: 0.4240\n",
      "Epoch 1933/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0069 - acc: 0.7680 - val_loss: 0.0206 - val_acc: 0.4080\n",
      "Epoch 1934/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7827 - val_loss: 0.0207 - val_acc: 0.4080\n",
      "Epoch 1935/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1936/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7600 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1937/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7747 - val_loss: 0.0207 - val_acc: 0.4240\n",
      "Epoch 1938/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 0.7573 - val_loss: 0.0207 - val_acc: 0.4200\n",
      "Epoch 1939/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7507 - val_loss: 0.0207 - val_acc: 0.4280\n",
      "Epoch 1940/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0069 - acc: 0.7720 - val_loss: 0.0207 - val_acc: 0.4200\n",
      "Epoch 1941/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0069 - acc: 0.7600 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1942/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 0.7800 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1943/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0069 - acc: 0.7773 - val_loss: 0.0207 - val_acc: 0.4080\n",
      "Epoch 1944/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0070 - acc: 0.7653 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1945/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0069 - acc: 0.7733 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1946/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7720 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1947/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0069 - acc: 0.7760 - val_loss: 0.0206 - val_acc: 0.4040\n",
      "Epoch 1948/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0069 - acc: 0.7653 - val_loss: 0.0207 - val_acc: 0.4120\n",
      "Epoch 1949/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 122us/step - loss: 0.0070 - acc: 0.7880 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1950/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0069 - acc: 0.7760 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1951/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0069 - acc: 0.7427 - val_loss: 0.0207 - val_acc: 0.4120\n",
      "Epoch 1952/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0069 - acc: 0.7587 - val_loss: 0.0207 - val_acc: 0.4120\n",
      "Epoch 1953/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7587 - val_loss: 0.0207 - val_acc: 0.4200\n",
      "Epoch 1954/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0069 - acc: 0.7787 - val_loss: 0.0207 - val_acc: 0.4200\n",
      "Epoch 1955/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7587 - val_loss: 0.0207 - val_acc: 0.4080\n",
      "Epoch 1956/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0070 - acc: 0.7707 - val_loss: 0.0207 - val_acc: 0.4080\n",
      "Epoch 1957/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0069 - acc: 0.7773 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1958/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0207 - val_acc: 0.4080\n",
      "Epoch 1959/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0070 - acc: 0.7827 - val_loss: 0.0207 - val_acc: 0.4080\n",
      "Epoch 1960/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0070 - acc: 0.7773 - val_loss: 0.0207 - val_acc: 0.4120\n",
      "Epoch 1961/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0069 - acc: 0.7787 - val_loss: 0.0207 - val_acc: 0.4200\n",
      "Epoch 1962/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0069 - acc: 0.7640 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1963/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0069 - acc: 0.7707 - val_loss: 0.0207 - val_acc: 0.4040\n",
      "Epoch 1964/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0069 - acc: 0.7693 - val_loss: 0.0207 - val_acc: 0.4080\n",
      "Epoch 1965/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7600 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1966/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0069 - acc: 0.7627 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1967/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0070 - acc: 0.7600 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1968/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0069 - acc: 0.7373 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1969/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0070 - acc: 0.7680 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1970/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 0.7627 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1971/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0069 - acc: 0.7693 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1972/2000\n",
      "750/750 [==============================] - 0s 118us/step - loss: 0.0070 - acc: 0.7600 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1973/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0070 - acc: 0.7827 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1974/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7667 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1975/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0069 - acc: 0.7800 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1976/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0070 - acc: 0.7533 - val_loss: 0.0206 - val_acc: 0.4120\n",
      "Epoch 1977/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0069 - acc: 0.7480 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1978/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0070 - acc: 0.7693 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1979/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0069 - acc: 0.7613 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1980/2000\n",
      "750/750 [==============================] - 0s 113us/step - loss: 0.0069 - acc: 0.7547 - val_loss: 0.0207 - val_acc: 0.4200\n",
      "Epoch 1981/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0069 - acc: 0.7613 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1982/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0070 - acc: 0.7587 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1983/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7387 - val_loss: 0.0206 - val_acc: 0.4240\n",
      "Epoch 1984/2000\n",
      "750/750 [==============================] - 0s 114us/step - loss: 0.0069 - acc: 0.7653 - val_loss: 0.0206 - val_acc: 0.4320\n",
      "Epoch 1985/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0069 - acc: 0.7693 - val_loss: 0.0205 - val_acc: 0.4280\n",
      "Epoch 1986/2000\n",
      "750/750 [==============================] - 0s 115us/step - loss: 0.0070 - acc: 0.7787 - val_loss: 0.0206 - val_acc: 0.4280\n",
      "Epoch 1987/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0069 - acc: 0.7693 - val_loss: 0.0206 - val_acc: 0.4280\n",
      "Epoch 1988/2000\n",
      "750/750 [==============================] - 0s 116us/step - loss: 0.0069 - acc: 0.7707 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 1989/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 0.7853 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1990/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0070 - acc: 0.7733 - val_loss: 0.0207 - val_acc: 0.4280\n",
      "Epoch 1991/2000\n",
      "750/750 [==============================] - 0s 117us/step - loss: 0.0069 - acc: 0.7680 - val_loss: 0.0207 - val_acc: 0.4200\n",
      "Epoch 1992/2000\n",
      "750/750 [==============================] - 0s 119us/step - loss: 0.0069 - acc: 0.7693 - val_loss: 0.0207 - val_acc: 0.4240\n",
      "Epoch 1993/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0069 - acc: 0.7840 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1994/2000\n",
      "750/750 [==============================] - 0s 124us/step - loss: 0.0069 - acc: 0.7787 - val_loss: 0.0207 - val_acc: 0.4240\n",
      "Epoch 1995/2000\n",
      "750/750 [==============================] - 0s 122us/step - loss: 0.0069 - acc: 0.7520 - val_loss: 0.0207 - val_acc: 0.4200\n",
      "Epoch 1996/2000\n",
      "750/750 [==============================] - 0s 125us/step - loss: 0.0069 - acc: 0.7640 - val_loss: 0.0207 - val_acc: 0.4120\n",
      "Epoch 1997/2000\n",
      "750/750 [==============================] - 0s 120us/step - loss: 0.0070 - acc: 0.7707 - val_loss: 0.0207 - val_acc: 0.4160\n",
      "Epoch 1998/2000\n",
      "750/750 [==============================] - 0s 123us/step - loss: 0.0069 - acc: 0.7533 - val_loss: 0.0206 - val_acc: 0.4160\n",
      "Epoch 1999/2000\n",
      "750/750 [==============================] - 0s 121us/step - loss: 0.0069 - acc: 0.7600 - val_loss: 0.0206 - val_acc: 0.4200\n",
      "Epoch 2000/2000\n",
      "750/750 [==============================] - 0s 126us/step - loss: 0.0069 - acc: 0.7707 - val_loss: 0.0206 - val_acc: 0.4120\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3X20XHV97/H3d/bMnOeTZwgkhISAvQRQiEfqU7VWRPC2Ulus0FoRsVl21auty7uKyy5RbC20tfUBepHWULRVRKm3tAsuUtvaWhUSMCoQMSEEOCSQ55yTnId5+t4/fr85Z3JyZuac5MzMSc7ntdasmdn7t/f+zp6Z/d2/3977t83dERERqSXV6gBERGT2U7IQEZG6lCxERKQuJQsREalLyUJEROpSshARkbqULESOg5mtNDM3s/QUyr7bzL57vPMRaQUlC5kzzGy7meXMbPGE4ZvihnplayITmf2ULGSueRq4uvzGzC4AOloXjsiJQclC5povA++qeH8N8KXKAmY2z8y+ZGa7zewZM/sjM0vFcYmZ/YWZ7TGzbcD/nGTaL5rZTjN73sz+2MyS6QZpZqeb2b1mts/MtprZ71SMu9jMNprZgJm9aGZ/GYe3m9nfm9leMztgZhvM7NTpLltkMkoWMtf8AOg1s3PjRvwdwN9PKPN5YB5wFvB6QnK5No77HeCXgYuAPuDKCdPeCRSAs2OZS4H3HkOcXwX6gdPjMj5lZm+M4z4LfNbde4HVwN1x+DUx7jOARcD7gOFjWLbIUZQsZC4q1y7eBPwUeL48oiKBfMTdB919O/Bp4Ldjkd8APuPuz7n7PuBPK6Y9Fbgc+H13P+zuu4C/Aq6aTnBmdgbwWuAP3X3E3TcBf1sRQx4428wWu/shd/9BxfBFwNnuXnT3R9x9YDrLFqlGyULmoi8Dvwm8mwlNUMBiIAs8UzHsGWBZfH068NyEcWVnAhlgZ2wGOgB8AThlmvGdDuxz98EqMVwHvAT4aWxq+uWKz/UAcJeZ7TCzPzOzzDSXLTIpJQuZc9z9GcKB7rcA/zhh9B7CHvqZFcNWMF772Elo5qkcV/YcMAosdvf58dHr7udNM8QdwEIz65ksBnff4u5XE5LQzcA3zKzL3fPu/gl3XwO8mtBc9i5EZoCShcxV1wG/5O6HKwe6e5FwDOBPzKzHzM4EPsT4cY27gQ+Y2XIzWwBcXzHtTuBbwKfNrNfMUma22sxeP53A3P054HvAn8aD1i+N8f4DgJm908yWuHsJOBAnK5rZG8zsgtiUNkBIesXpLFukGiULmZPc/Sl331hl9P8CDgPbgO8CXwHWx3F/Q2jq+RHwKEfXTN5FaMZ6AtgPfAM47RhCvBpYSahlfBO4wd0fjOMuAx43s0OEg91XufsIsDQubwDYDHyHow/eixwT082PRESkHtUsRESkLiULERGpS8lCRETqUrIQEZG6TprukBcvXuwrV65sdRgiIieURx55ZI+7L6lX7qRJFitXrmTjxmpnQoqIyGTM7Jn6pdQMJSIiU6BkISIidSlZiIhIXSfNMYvJ5PN5+vv7GRkZaXUoTdPe3s7y5cvJZNTZqIjMnJM6WfT399PT08PKlSsxs1aH03Duzt69e+nv72fVqlWtDkdETiIndTPUyMgIixYtmhOJAsDMWLRo0ZyqSYlIc5zUyQKYM4mibK59XhFpjpM+WdRTLDkvHBxhKFdodSgiIrPWnE8WJXd2DY4wlJv5e8Ts3buXCy+8kAsvvJClS5eybNmysfe5XG5K87j22mt58sknZzw2EZHpOKkPcE9FIxttFi1axKZNmwD4+Mc/Tnd3Nx/+8IePKOPuuDup1OR5+4477mhghCIiUzPnaxatsHXrVs4//3ze9773sXbtWnbu3Mm6devo6+vjvPPO48Ybbxwr+9rXvpZNmzZRKBSYP38+119/PS972ct41atexa5du1r4KURkLpkzNYtP/PPjPLFj4KjhDgyNFsimU2SS6eXONaf3csOvnHdM8TzxxBPccccd3HbbbQDcdNNNLFy4kEKhwBve8AauvPJK1qxZc8Q0Bw8e5PWvfz033XQTH/rQh1i/fj3XX3/9ZLMXEZlRqlm0yOrVq3nFK14x9v6rX/0qa9euZe3atWzevJknnnjiqGk6Ojq4/PLLAXj5y1/O9u3bmxWuiMxxc6ZmUa0GUCiWeGLnAKfP72Bxd1vT4unq6hp7vWXLFj772c/y8MMPM3/+fN75zndOeq1ENpsde50kCYWCzuASkeZQzaLMW7fogYEBenp66O3tZefOnTzwwAOtC0ZEZBJzpmZRTwtzBWvXrmXNmjWcf/75nHXWWbzmNa9pYTQiIkcz91ZuJmdOX1+fT7z50ebNmzn33HNrTlcolXhixwCnzetgSU/zmqEaaSqfW0QEwMwecfe+euXmfDOUOscQEalvzicLERGpT8lCRETqUrIYa4g6OY7diIg0gpKFiIjUpWQhIiJ1KVlEjWiEmokuygHWr1/PCy+80IAIRUSmZs5flNfqLsqnYv369axdu5alS5fOdIgiIlMy55NFq9x5553ceuut5HI5Xv3qV3PLLbdQKpW49tpr2bRpE+7OunXrOPXUU9m0aRPveMc76Ojo4OGHHz6ijygRkWaYO8ni/uvhhZ8cNdhwzhotkk2nYJpdlLP0Arj8pmmH8thjj/HNb36T733ve6TTadatW8ddd93F6tWr2bNnDz/5SYjzwIEDzJ8/n89//vPccsstXHjhhdNelojITJg7yWIW+dd//Vc2bNhAX1+4wn54eJgzzjiDN7/5zTz55JN88IMf5C1veQuXXnppiyMVEQnmTrKoUgNwd7Y9f5Clve2c0tvelFDcnfe85z188pOfPGrcj3/8Y+6//34+97nPcc8993D77bc3JSYRkVp0NlQLXHLJJdx9993s2bMHCGdNPfvss+zevRt35+1vfzuf+MQnePTRRwHo6elhcHCwlSGLyBw3d2oWs8gFF1zADTfcwCWXXEKpVCKTyXDbbbeRJAnXXXcd7o6ZcfPNNwNw7bXX8t73vlcHuEWkZRraRbmZXQZ8FkiAv3X3myaM/xDwXqAA7Abe4+7PxHHXAH8Ui/6xu99Za1nH2kV5yZ3Hnj/Iqb3tnNqkZqhGUxflIjJVLe+i3MwS4FbgcmANcLWZrZlQ7IdAn7u/FPgG8Gdx2oXADcDPAxcDN5jZgobE2YiZioicZBp5zOJiYKu7b3P3HHAXcEVlAXf/d3cfim9/ACyPr98MPOju+9x9P/AgcFkDYxURkRoamSyWAc9VvO+Pw6q5Drh/OtOa2Toz22hmG3fv3j3pTE+WOwFO1Vz7vCLSHI1MFpO18Ey6JTOzdwJ9wJ9PZ1p3v93d+9y9b8mSJUdN0N7ezt69e+fMBtTd2bt3L+3tJ8exFxGZPRp5NlQ/cEbF++XAjomFzOwS4KPA6919tGLaX5ww7X9MN4Dly5fT399PtVpH2Yv7hxnuSLOvPTPdRcw67e3tLF++vH5BEZFpaGSy2ACcY2argOeBq4DfrCxgZhcBXwAuc/ddFaMeAD5VcVD7UuAj0w0gk8mwatWqmmXcncs/ch8ffOM5/MGbXjLdRYiIzAkNSxbuXjCz9xM2/Amw3t0fN7MbgY3ufi+h2akb+LqZATzr7m91931m9klCwgG40d33NSLOuFzdJ09EpIaGXpTn7vcB900Y9rGK15fUmHY9sL5x0R21wKYtSkTkRKPuPkYG+KvMX7PiwEOtjkREZNZSsijmeFvyXRYMP9PqSEREZi0li/JZumqFEhGpSskicmULEZGqlCxMvUOJiNSjZFGms6FERKpSshijZCEiUo2ShZqhRETqUrIoUzOUiEhVSha6/ZGISF1KFmNUsxARqUbJonzMQs1QIiJVKVmoGUpEpC4lizGqWYiIVKNkUb6fhXKFiEhVShZjlC1ERKpRsojHLEzJQkSkKiULNUOJiNSlZDFG2UJEpBolC3SdhYhIPUoW6khQRKQuJYtIB7hFRKpTskAHuEVE6lGyGKNsISJSjZKF6ToLEZF6lCzKzVAtjkJEZDZTsijTQQsRkaqULHTqrIhIXUoWY1SzEBGpRslCNz8SEalLyWLstqqtDUNEZDZTshhTanUAIiKzlpLF2P0sRESkGiUL3c9CRKQuJYsyZQsRkaoamizM7DIze9LMtprZ9ZOMf52ZPWpmBTO7csK4opltio97Gxhkw2YtInKySDdqxmaWALcCbwL6gQ1mdq+7P1FR7Fng3cCHJ5nFsLtf2Kj4jqaahYhINQ1LFsDFwFZ33wZgZncBVwBjycLdt8dxs+BUJCULEZFqGtkMtQx4ruJ9fxw2Ve1mttHMfmBmvzpZATNbF8ts3L179zEHWtK5UCIiNTUyWUy2BZ7O7vsKd+8DfhP4jJmtPmpm7re7e5+79y1ZsuRY4yzP7PimFxE5iTUyWfQDZ1S8Xw7smOrE7r4jPm8D/gO4aCaDO2JZqlmIiNTUyGSxATjHzFaZWRa4CpjSWU1mtsDM2uLrxcBrqDjW0RiqWYiIVNOwZOHuBeD9wAPAZuBud3/czG40s7cCmNkrzKwfeDvwBTN7PE5+LrDRzH4E/Dtw04SzqGY21hBwo2YvInLCa+TZULj7fcB9E4Z9rOL1BkLz1MTpvgdc0MjYjqRmKBGRWnQF9xjVLEREqlGyIBzgNjVDiYhUpWRBqFMoVYiIVKdkEZnShYhIVUoWgFKFiEhtShYiIlKXkgXxCm6fBX0ZiojMUkoW6OC2iEg9ShaRLssTEalOyYJyM1SroxARmb2ULMbomIWISDVKFoAaoUREalOyQPezEBGpR8miTH1DiYhUpWRB+di2koWISDVTShZmtrriznW/aGYfMLP5jQ2tmdQMJSJSy1RrFvcARTM7G/gisAr4SsOiagU1Q4mIVDXVZFGKt0l9G/AZd/8D4LTGhdVcOsAtIlLbVJNF3syuBq4B/iUOyzQmpBYw0DELEZHqpposrgVeBfyJuz9tZquAv29cWM3l6KiFiEgt6akUcvcngA8AmNkCoMfdb2pkYM1lqGYhIlLdVM+G+g8z6zWzhcCPgDvM7C8bG1qT6QC3iEhVU22GmufuA8CvAXe4+8uBSxoXVnO57pQnIlLTVJNF2sxOA36D8QPcJxUdsxARqW6qyeJG4AHgKXffYGZnAVsaF1az6U55IiK1TPUA99eBr1e83wb8eqOCajY1QYmI1DbVA9zLzeybZrbLzF40s3vMbHmjgxMRkdlhqs1QdwD3AqcDy4B/jsNOCo7pELeISA1TTRZL3P0Ody/Ex98BSxoYV5MpVYiI1DLVZLHHzN5pZkl8vBPY28jAmk7XWYiIVDXVZPEewmmzLwA7gSsJXYCcFNx04qyISC1TShbu/qy7v9Xdl7j7Ke7+q4QL9E4aaogSEanueO6U96EZi2JWULIQEanmeJLFSdN2o/tZiIjUdjzJ4qTaFVczlIhIdTWv4DazQSZPCgZ0NCSiFnBMJ0OJiNRQs2bh7j3u3jvJo8fd63YVYmaXmdmTZrbVzK6fZPzrzOxRMyuY2ZUTxl1jZlvi45rpf7SpUyOUiEhtx9MMVZOZJcCtwOXAGuBqM1szodizwLuBr0yYdiFwA/DzwMXADfGmSw0RruBWR4IiItU0LFkQNvJb3X2bu+eAu4ArKgu4+3Z3/zEctaV+M/Cgu+9z9/3Ag8BljQpULVAiIrU1MlksA56reN8fh83YtGa2zsw2mtnG3bt3H3OggDKGiEgNjUwWkx0KmOomeUrTuvvt7t7n7n1LlhxPV1W6B7eISC2NTBb9wBkV75cDO5ow7bSpuw8RkdoamSw2AOeY2SozywJXEbo5n4oHgEvNbEE8sH1pHNYwpnNnRUSqaliycPcC8H7CRn4zcLe7P25mN5rZWwHM7BVm1g+8HfiCmT0ep90HfJKQcDYAN8ZhDaKahYhILVO6reqxcvf7gPsmDPtYxesNhCamyaZdD6xvZHwTlti8RYmInGAa2Qx1wlCaEBGpTckCUDOUiEhtShZlriu4RUSqUbJAXZSLiNSjZCEiInUpWQCY6X4WIiI1KFmgs6FEROpRshijlCEiUo2SBQCm7j5ERGpQskBnQ4mI1KNkISIidSlZALqfhYhIbUoWIiJSl5IF6DoLEZE6lCyIDVDKFSIiVSlZjFG2EBGpRskCUBflIiK1KVmMUc1CRKQaJQvCRXk6wC0iUp2SBYCZKhYiIjUoWYxRthARqUbJgnIzlIiIVKNkEaleISJSnZJFpAPcIiLVKVkAus5CRKQ2JQuIuUI1CxGRapQsiAe4dac8EZGqlCwANUOJiNSmZCEiInUpWQCqWYiI1KZkEenUWRGR6pQsANfZUCIiNSlZAGqGEhGpTcki0qmzIiLVKVkQrrNQM5SISHUNTRZmdpmZPWlmW83s+knGt5nZ1+L4h8xsZRy+0syGzWxTfNzWyDjVDCUiUlu6UTM2swS4FXgT0A9sMLN73f2JimLXAfvd/Wwzuwq4GXhHHPeUu1/YqPiOirdZCxIROQE1smZxMbDV3be5ew64C7hiQpkrgDvj628AbzSz5m+3zXAdsxARqaqRyWIZ8FzF+/44bNIy7l4ADgKL4rhVZvZDM/uOmf1CA+MES2GUGroIEZETWcOaoZi8ZWfi7nu1MjuBFe6+18xeDvxfMzvP3QeOmNhsHbAOYMWKFcceaSrBvHDs04uInOQaWbPoB86oeL8c2FGtjJmlgXnAPncfdfe9AO7+CPAU8JKJC3D32929z937lixZcsyBeipDyovHPL2IyMmukcliA3COma0ysyxwFXDvhDL3AtfE11cC/+bubmZL4gFyzOws4BxgW6MCdUtIq2YhIlJVw5qh3L1gZu8HHgASYL27P25mNwIb3f1e4IvAl81sK7CPkFAAXgfcaGYFoAi8z933NSzWVIYURUolJ5XSeVEiIhM18pgF7n4fcN+EYR+reD0CvH2S6e4B7mlkbEdIJWQokiuWaE8lTVusiMiJQldwA6QyJBTJF3VGlIjIZJQsAEvSpCmSL+paCxGRyShZAKQyZFSzEBGpSskCIElIrEiuoGQhIjIZJQvAkszYAW4RETmakgVg8QD3SF4X5omITEbJAujsaCdNkef3D7c6FBGRWamh11mcKHo72ylS4qndh1sdiojIrKSaBdDW1kbGivzw2f2tDkVEZFZSsoCxi/I2bN9HqaRrLUREJlKyAEilSeEcHBpl6+5DrY5GRGTWUbIAyLQD0MUIDz3dsP4KRUROWEoWAPPPBODC7oM8rGQhInIUJQuARasBuHTxXh7atlf34xYRmUDJAuCU86B3GZfwfXYNjvLfW/e2OiIRkVlFyQIglYLz3sbSXd9lVVeOTz/4JEWdFSUiMkbJouz8X8dKeT59wbP88NkD3PHfT7c6IhGRWUPJouz0i2DhWVy0737etOZUPnXfZm7/z6d0/EJEBCWLcWZw8Trs2e/zuQue5tI1S/nUfT/lmjs2sOOA+owSkbnNTpY9576+Pt+4cePxzaRYgC++CfZswS+/iS8O/Dx//uBWzOCqV6zgt191JquXdM9MwCLSOu5hB7HeMIBSETDwEqSSUKZUCsc6S0Uo5iGVhuIopDLhtcXypWJ4nvgwC2WLo6H8xHKlInicd7oNLIHCcBjesSAuLzceYyoJw4+BmT3i7n11yylZTDCwA+5+F/RvgK4lHD7tlXz/wHz+aec8BryLC848lVedfQoXrz6FTCYdvsRUOv6IkvB8xOs0WAryw5BkIN0evvDCCGS7wjJHDkKmA7Dw7MXxH09hJPxgzML48jNAYTRcUJjthtzhsLxDL0JbL+Ah+e3bBgtWhmVbCkYOxFjaQnkIyyjHlT8c5l8qhPIQ4vRSGFYqhukLI+GzdS2Jwwsx1lx4TrJhHRRHw5+wMBpiqPxTpBI4vCcso703LO/QrjBtui3Mx0shVo/3Gkky4bPu3Qq9y8L6Gh2ErsUh7tyhUDbdBvmRsC6t/KfOhXWJh8+Ah/ft88N6sVSINdMx/ice3h/WZzEX5gmhXDEfyuWH4nQxvlQaRg+FdZZKx89aDBsXL4b54+MbA/fweUv58fVe3lhkOuL6HI3zS8JyS8Xx9V1mFuZVjiM/HOaLh/mmkvHvKdsV5lleTn44rrNsmH/uEHSdAod3h89czIXPWMhBkoZsT1g/EL5jL8bP6rGsxc9UDN9NkhmPb3QwvC7/P8rrPJUOG99CbrxsKomfJ254i7nx3ywW4h0ZiO/j7738efH4+zXomD/+u8DCeiuMhO/VPXxGL4bfVaYzxFvIhWmSbChb3vin0uPD0u3h+58NlvXB73z7mCadarJQr7MT9Z4O1z0IP/0X2PzPdD3zPS4Z3MklmUIYvzM+/quVQcoxy3SN//HTbWHj6A5t3WEjnz8cNggdC+IGqjC+sSvmxhNXKh329DJdYQOcZGJSHBlPpEnmyI0ixI1TTKTlYaXCeDIa2zNNhQ1Rkg0b6MJo2PgmmVgmFTZW5Q1jeT6WCtNkOo783KW4QbckbLDLyygchnnLxjeAqXRcJ8WwI5BKwga0vDc8GrvDSWfj5ymFeZYK43vLMJ5gyok2FI47MlTsEHn4COU99HKCK+/ElhNuOdnB+PKKuZD4yjta5T36Yi6u3/g9jwxAtjMMw8N681LYERjbAUgqEmoxDM90hnllOuPOXff4DlF5B6GtZzzGJBvGlYoxIabGE6OljnxU1hq8FIfHcqlUxXuLO4Lpip3LgbBzkZRjt/BdNZiSxWTM4NxfCQ8If9S9T0HuEKXcEI/17+eRp3fzXz97kYQSKUqc0pXmgtO7OGdJJ2fMy7KoM8HKe5XFQvhhdi2GoX3hh5vEvbjy3n7n4lg2N/5HtiT8KZPs+B7pWE3Qw54zca+9vTdutNrGq9KpDAztCfOG8R9l1+KwnPxw+LHmDoc/ULotLHtoL3QsjDWBfNgrttR4rSndEfa60m1h7zPTOT4+3TG+oSoVwnzLf47yxspsfK/RUvHPOBri6FwYaxWjsXZi8c8X/5zFfFh/5ap/KgnlhveHMum2sA7yh8Ofu/xHLhXG51dLef3WKycyx6gZ6jjkCiW27Brk0Wf2892te/jOz3Yzkg/NAIu721ixsIO+lQtZu2I+p/a2c+5pvbRnkjpzFRFpHh2zaIHhXJFHn93PlhcHeejpfWzYvp89h0bHxpvBioWdnNrbzjmndHP+snmsWtzF6fM6OGNhB6a9WRFpMiWLWWIkX2TTcwd4es9hdhwYZtNzB3jh4Ahbdh3ZFXo6ZRRKzitWLmBBZ5aXLp9HNp2itz3DRSsWsHxBB53ZRAlFRGaUDnDPEu2ZhFeetYhXnrXoiOHFkvP8/mGe2nOIbbsPs3XXITZs38fAcIGNz+znW0+8eNS8etrSLOzOMr8zy77Do7zp3KUs6WmjM5uwfEEH8zuztKVTnLGgk1QKetozzfqYInKSU7JokSRlrFjUyYpFnbzh544c5+4M5YrsPDjCT18YYNfAKKOFEi8cHOb5AyMcGs3z3L5h1tfpkmRxdxu9HWkGhgucv6yXlBkrFnZiBqf0tNORSeHA/1jaS29HmkySYl5HhnkdGR1bEZEjKFnMQmZGV1uas0/p5uxTql8E6O4M54scGMqz8+AIuwdHeHbfEPmis+9wjoPDeZ7fP0xio2zfc5jte6d3Tnhve3qsttLdnqanPUNPe5qDQ3mWzmvn9Hnt9LRnGM4X6cwmnLGwE3dY3J0lnaQoudOVTdPVljC/M0tXNqFQctIpU3OayAlGyeIEZmZ0ZtN0ZtOcPr+j/gSE5q8DQznSSYrdg6Ns3jlAT3ua4VyRXYOjbNk1SDqVihepOgeH84zkSxwaLXBwOE///iG27T4cl19xJu8UpAxKPn58Jp0yli3ooCOTcDhXIDFj5eIu2tMJbZkUbekU2XSKbJLQnkmRTlJ0ZBI6swnuTmc2TTox2tIJC7uyFEvOSL7Igq4MKTO629K0pRN6O9KYGdkkzDNfKpFNUkpYItOgZDHHJCljUXe4mGdeR6ZmzaWa8kkR7jA4UmBwNE++6BweLTCcL3J4tEAplhnOlRgYyfPCwREKpRIlh8GRPI/vGGBJdxvpxBgcKdCdS7NrcJRn9w2FC5HdGS2UGC2UyBVKDOeLM9ptfDpl9LSn2T+UZ15Hhmw6RU9bGjPG3u85FC4mO31+B23pcAFdJjEM48kXB7l41UJ62tKMFkoxSYVaWKnkdLal6cjEpNYW/mbZJMWh0QI97WnmdYTjSSV3zIxi0UlSRmc2oSOb0N2WJmUWrunCxi77MIMFnVmSlFEsOR2ZhFyxRFtayU8aS8lCpq28UTKDeZ0Z5nU2/kB6oRiuXzk8WiRfKjE0WiRXLJGkjFyhxO7BUYZyBQolZ2A4T75YoqstzeBIqBGV3CmVnMHRUINJEuPA4Txbdg1y5qIuCiWn5KHWdXA4T7HktKVT7BocpTObcChOV3RnaLTICwMj7D00ylCuyGghxFauOTVTeZkpg5QZHZmEojuZmJiKJeeUnjay6RSZJEU6ZaSTFJnExpoD+/cP0ZYONbYlPW2kzBjOFenIJnRkEkYLodY5WiixanFXTKpGJjEySZhvJh2SfmKG44zkS3S3pckkxlCuOJYc29IJSQpyRceARd1ZDgzl2T+UY/WSboqlEHs2ncKIFzPHZFlOnikzjPA7LL9PxZ5wLI47omxMuKk4vrJsakL5sbKpyZczsWw2nSIxo7s9TTZJsX8oT3sm7FjkC046MZJUWE54DvMrlZxUynD30LNJavYneiULOSGkk/AHnNcZu8iYUCH6uaU9TY5onLtTKDkps1B7KkGuWKJQLDGUKzI4UhjbuOw7lKM9m4xtLAx4cWCUlIVaWnd7GncYzhdiDSt05uHuOOFC0H2Hc4zki2PJMJMY+aLjOAeH8iRxw1NOFuUNVb5YolB0CqUS+YrndCpsnLvj/AqlEokZLw6OkKSM9nTCrsFR9hwapX//EF3ZNO2ZZGz6fKHEaPy8Xdk0mXSKfKwNphMbu1BVxoWkNN4sC4x9b9l0ChySmNCHckWy6RRDo0U62xIOjRSY35kdaypOJ8YFy+bzt9fUPfv1uChZiByn8l42QBI7uuubIfFHAAAIoklEQVQgPC+qOtXcUSiWxvb4CyUfa1I0oOghmQ3lChSKTnd7mnyxRL4Qkp97aKorJ8xSTKAlHx8H4bnk42XgyLKlmHVLDs542YnzGkvMsezRw8afiyVnx8HQmWNbOsVovsjASIHObEI6SeHudLelKcZabaE0/pwrlGjPJDjhdSZJkS+WSJmNNWuWdyaKpdAkawaFYjjW1xabOJOUUSg6yxdM7Zjl8VCyEJGGKtcKAbIpC3vOEyzsyjYzJDkGuvmRiIjU1dBkYWaXmdmTZrbVzK6fZHybmX0tjn/IzFZWjPtIHP6kmb25kXGKiEhtDUsWZpYAtwKXA2uAq81szYRi1wH73f1s4K+Am+O0a4CrgPOAy4C/jvMTEZEWaGTN4mJgq7tvc/cccBdwxYQyVwB3xtffAN5o4bzMK4C73H3U3Z8Gtsb5iYhICzQyWSwDnqt43x+HTVrG3QvAQcIJJFOZFjNbZ2YbzWzj7t27ZzB0ERGp1MhkMdlVJhMvWapWZirT4u63u3ufu/ctWdL42wqKiMxVjUwW/cAZFe+XAzuqlTGzNDAP2DfFaUVEpEkamSw2AOeY2SozyxIOWN87ocy9wDXx9ZXAv3noeOhe4Kp4ttQq4Bzg4QbGKiIiNTTsojx3L5jZ+4EHgARY7+6Pm9mNwEZ3vxf4IvBlM9tKqFFcFad93MzuBp4ACsDvuXux1vIeeeSRPWb2zHGEvBjYcxzTN4rimh7FNT2Ka3pOxrjOnEqhk+a2qsfLzDZO5daCzaa4pkdxTY/imp65HJeu4BYRkbqULEREpC4li3G3tzqAKhTX9Ciu6VFc0zNn49IxCxERqUs1CxERqUvJQkRE6przyaJeN+oNXvYZZvbvZrbZzB43sw/G4R83s+fNbFN8vKVimqZ03W5m283sJ3H5G+OwhWb2oJltic8L4nAzs8/FuH5sZmsbFNPPVayTTWY2YGa/34r1ZWbrzWyXmT1WMWza68fMronlt5jZNZMtawbi+nMz+2lc9jfNbH4cvtLMhivW220V07w8fv9bY+zHfZPoKrFN+7ub6f9slbi+VhHTdjPbFIc3ZZ3V2Da07jcWbhc4Nx+EiwWfAs4CssCPgDVNXP5pwNr4ugf4GaE7948DH56k/JoYYxuwKsaeNCi27cDiCcP+DLg+vr4euDm+fgtwP6FPr1cCDzXpu3uBcEFR09cX8DpgLfDYsa4fYCGwLT4viK8XNCCuS4F0fH1zRVwrK8tNmM/DwKtizPcDlzdonU3ru2vEf3ayuCaM/zTwsWausxrbhpb9xuZ6zWIq3ag3jLvvdPdH4+tBYDOT9K5bodVdt1d2KX8n8KsVw7/kwQ+A+WZ2WoNjeSPwlLvXumq/YevL3f+T0OvAxOVNZ/28GXjQ3fe5+37gQcL9W2Y0Lnf/lodenQF+QOhrraoYW6+7f9/DFudLFZ9lRmOrodp3N+P/2VpxxdrBbwBfrTWPmV5nNbYNLfuNzfVkMaWu0JvBwl0CLwIeioPeH6uT68tVTZobrwPfMrNHzGxdHHaqu++E8GMGTmlBXGVXceQfuNXrC6a/flqx3t5D2AMtW2VmPzSz75jZL8Rhy2IszYprOt9ds9fZLwAvuvuWimFNXWcTtg0t+43N9WQxpa7QGx6EWTdwD/D77j4A/B9gNXAhsJNQDYbmxvsad19LuNPh75nZ62qUbep6tNAx5VuBr8dBs2F91XJcXfHPWBBmHyX0tfYPcdBOYIW7XwR8CPiKmfU2Oa7pfnfN/k6v5sidkqaus0m2DVWLVln+jMU115NFy7tCN7MM4cfwD+7+jwDu/qK7F929BPwN400nTYvX3XfE513AN2MML5abl+LzrmbHFV0OPOruL8YYW76+oumun6bFFw9s/jLwW7GZhNjEsze+foRwLOAlMa7KpqpG/s6m+901c52lgV8DvlYRb9PW2WTbBlr4G5vryWIq3ag3TGwP/SKw2d3/smJ4ZXv/24DyWRpN6brdzLrMrKf8mnCA9DGO7FL+GuCfKuJ6Vzwj45XAwXJVuUGO2Ntr9fqqMN318wBwqZktiM0vl8ZhM8rMLgP+EHiruw9VDF9i8d72ZnYWYf1si7ENmtkr42/0XRWfZaZjm+5318z/7CXAT919rHmpWeus2raBVv7GjvVo/cnyIJxF8DPCHsJHm7zs1xKqhD8GNsXHW4AvAz+Jw+8FTquY5qMx1ieZgTNUqsR1FuEskx8Bj5fXC+GWt98GtsTnhXG4AbfGuH4C9DVwnXUCe4F5FcOavr4IyWonkCfsvV13LOuHcAxha3xc26C4thLarcu/sdti2V+P3++PgEeBX6mYTx9hw/0UcAuxt4cGxDbt726m/7OTxRWH/x3wvgllm7LOqL5taNlvTN19iIhIXXO9GUpERKZAyUJEROpSshARkbqULEREpC4lCxERqUvJQmQazKxoR/Z8O2M9FVvo0fSx+iVFmi/d6gBETjDD7n5hq4MQaTbVLERmgIV7HtxsZg/Hx9lx+Jlm9u3YUd63zWxFHH6qhXtL/Cg+Xh1nlZjZ31i4h8G3zKyjZR9KpIKShcj0dExohnpHxbgBd7+YcPXuZ+KwWwhdR7+U0IHf5+LwzwHfcfeXEe6l8Hgcfg5wq7ufBxwgXDEs0nK6gltkGszskLt3TzJ8O/BL7r4tdgD3grsvMrM9hC4s8nH4TndfbGa7geXuPloxj5WEew+cE9//IZBx9z9u/CcTqU01C5GZ41VeVyszmdGK10V0XFFmCSULkZnzjorn78fX3yP0jArwW8B34+tvA78LYGZJvCeCyKylvRaR6ekws00V7/+fu5dPn20zs4cIO2FXx2EfANab2f8GdgPXxuEfBG43s+sINYjfJfR8KjIr6ZiFyAyIxyz63H1Pq2MRaQQ1Q4mISF2qWYiISF2qWYiISF1KFiIiUpeShYiI1KVkISIidSlZiIhIXf8f4dUS3eTiptsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10650674 0.08775062 0.14509289 ... 0.11015762 0.19488764 0.        ]\n",
      " [0.         0.         0.12152971 ... 0.         0.18381919 0.        ]\n",
      " [0.         1.2280072  0.         ... 1.4078118  0.28208175 0.        ]\n",
      " ...\n",
      " [0.         0.05688608 0.19966392 ... 0.         0.02119619 0.        ]\n",
      " [0.06381162 0.50971955 0.         ... 0.284954   0.         0.        ]\n",
      " [0.18007988 0.5737731  0.17992344 ... 0.37065166 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "\n",
    "rmsprop = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=rmsprop,\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy']  # , mean_pred]\n",
    ")\n",
    "print('Train-------------------------')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.25, epochs=2000, shuffle = True, batch_size=75, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[1].output])\n",
    "layer_output1 = get_3rd_layer_output([X_train])[0]\n",
    "\n",
    "print(layer_output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_mask = y_train.reshape(1000,1024)\n",
    "plt.imshow(abs(y_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of the model [[0.         0.         0.         ... 1.         0.         0.        ]\n",
      " [0.         0.         0.         ... 1.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.38489527 0.         0.        ]\n",
      " [1.         0.70320594 0.         ... 0.         0.         1.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "prediction size 1024000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_pred = model.predict(X_train[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1024)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Predicted_Training_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_mask = y_test.reshape(1000,1024)\n",
    "plt.imshow(abs(y_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Lable_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of the model [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [1.         1.         0.         ... 0.25256693 0.         1.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.32646942 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.4896231  0.         0.        ]\n",
      " [0.         0.         0.         ... 1.         0.         0.        ]]\n",
      "prediction size 1024000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_pred = model.predict(X_test[0:1000])\n",
    "print('prediction of the model', x_pred)\n",
    "print('prediction size', x_pred.size)\n",
    "\n",
    "x_mask = x_pred.reshape(1000,1024)\n",
    "plt.imshow(abs(x_mask[:, : int(512 / 2 + 1)].T), aspect = \"auto\", cmap=plt.cm.afmhot, origin = \"lower\")\n",
    "plt.title(\"Test_Predicted_Mask\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
