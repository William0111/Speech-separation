{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN test by data-10*512\n",
    "# 20000 steps with lr = 0.001\n",
    "# cell_size = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are better than\n",
    "best run: \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/william/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(batch_input_shape=(None, 10,..., unroll=True, units=400)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next_Train----------: step =  0\n",
      "train_cost:  1662.1689453125 train_accuracy:  0.0\n",
      "test cost:  1986.37890625 test accuracy:  0.0\n",
      "Next_Train----------: step =  500\n",
      "train_cost:  1459.9954833984375 train_accuracy:  0.1120000034570694\n",
      "test cost:  1784.5760498046875 test accuracy:  0.14800000190734863\n",
      "Next_Train----------: step =  1000\n",
      "train_cost:  1395.83056640625 train_accuracy:  0.11800000071525574\n",
      "test cost:  1778.428955078125 test accuracy:  0.14300000667572021\n",
      "Next_Train----------: step =  1500\n",
      "train_cost:  1373.466796875 train_accuracy:  0.13600000739097595\n",
      "test cost:  1786.575439453125 test accuracy:  0.11599999666213989\n",
      "Next_Train----------: step =  2000\n",
      "train_cost:  1356.0416259765625 train_accuracy:  0.12200000137090683\n",
      "test cost:  1821.64208984375 test accuracy:  0.10499999672174454\n",
      "Next_Train----------: step =  2500\n",
      "train_cost:  1350.1600341796875 train_accuracy:  0.10499999672174454\n",
      "test cost:  1810.3499755859375 test accuracy:  0.0689999982714653\n",
      "Next_Train----------: step =  3000\n",
      "train_cost:  1322.2198486328125 train_accuracy:  0.0820000022649765\n",
      "test cost:  1869.74755859375 test accuracy:  0.08299999684095383\n",
      "Next_Train----------: step =  3500\n",
      "train_cost:  1296.18017578125 train_accuracy:  0.12999999523162842\n",
      "test cost:  1925.2703857421875 test accuracy:  0.07000000029802322\n",
      "Next_Train----------: step =  4000\n",
      "train_cost:  1287.745849609375 train_accuracy:  0.11900000274181366\n",
      "test cost:  1943.2813720703125 test accuracy:  0.07000000029802322\n",
      "Next_Train----------: step =  4500\n",
      "train_cost:  1328.8084716796875 train_accuracy:  0.08500000089406967\n",
      "test cost:  1848.3050537109375 test accuracy:  0.0729999989271164\n",
      "Next_Train----------: step =  5000\n",
      "train_cost:  1258.1534423828125 train_accuracy:  0.0989999994635582\n",
      "test cost:  2050.406494140625 test accuracy:  0.0689999982714653\n",
      "Next_Train----------: step =  5500\n",
      "train_cost:  1249.337158203125 train_accuracy:  0.11999999731779099\n",
      "test cost:  2050.149658203125 test accuracy:  0.06599999964237213\n",
      "Next_Train----------: step =  6000\n",
      "train_cost:  1249.26220703125 train_accuracy:  0.09700000286102295\n",
      "test cost:  2081.146484375 test accuracy:  0.054999999701976776\n",
      "Next_Train----------: step =  6500\n",
      "train_cost:  1309.4365234375 train_accuracy:  0.18000000715255737\n",
      "test cost:  1918.2777099609375 test accuracy:  0.12099999934434891\n",
      "Next_Train----------: step =  7000\n",
      "train_cost:  1219.97314453125 train_accuracy:  0.08900000154972076\n",
      "test cost:  2152.7119140625 test accuracy:  0.06199999898672104\n",
      "Next_Train----------: step =  7500\n",
      "train_cost:  1242.666015625 train_accuracy:  0.1589999943971634\n",
      "test cost:  2062.96435546875 test accuracy:  0.07400000095367432\n",
      "Next_Train----------: step =  8000\n",
      "train_cost:  1227.0096435546875 train_accuracy:  0.16200000047683716\n",
      "test cost:  2122.460205078125 test accuracy:  0.09300000220537186\n",
      "Next_Train----------: step =  8500\n",
      "train_cost:  1197.0616455078125 train_accuracy:  0.0860000029206276\n",
      "test cost:  2237.200927734375 test accuracy:  0.05400000140070915\n",
      "Next_Train----------: step =  9000\n",
      "train_cost:  1318.760498046875 train_accuracy:  0.1860000044107437\n",
      "test cost:  1872.4561767578125 test accuracy:  0.10000000149011612\n",
      "Next_Train----------: step =  9500\n",
      "train_cost:  1273.51123046875 train_accuracy:  0.18400000035762787\n",
      "test cost:  1960.59228515625 test accuracy:  0.1940000057220459\n",
      "Next_Train----------: step =  10000\n",
      "train_cost:  1304.46923828125 train_accuracy:  0.14800000190734863\n",
      "test cost:  1928.5472412109375 test accuracy:  0.11299999803304672\n",
      "Next_Train----------: step =  10500\n",
      "train_cost:  1248.5634765625 train_accuracy:  0.20100000500679016\n",
      "test cost:  2034.2998046875 test accuracy:  0.12800000607967377\n",
      "Next_Train----------: step =  11000\n",
      "train_cost:  1231.0426025390625 train_accuracy:  0.21199999749660492\n",
      "test cost:  2110.267822265625 test accuracy:  0.1509999930858612\n",
      "Next_Train----------: step =  11500\n",
      "train_cost:  1230.7513427734375 train_accuracy:  0.16699999570846558\n",
      "test cost:  2071.287109375 test accuracy:  0.09300000220537186\n",
      "Next_Train----------: step =  12000\n",
      "train_cost:  1196.8538818359375 train_accuracy:  0.10300000011920929\n",
      "test cost:  2235.508056640625 test accuracy:  0.06400000303983688\n",
      "Next_Train----------: step =  12500\n",
      "train_cost:  1283.8857421875 train_accuracy:  0.22100000083446503\n",
      "test cost:  1938.978759765625 test accuracy:  0.13099999725818634\n",
      "Next_Train----------: step =  13000\n",
      "train_cost:  1234.41357421875 train_accuracy:  0.15199999511241913\n",
      "test cost:  2079.509521484375 test accuracy:  0.1550000011920929\n",
      "Next_Train----------: step =  13500\n",
      "train_cost:  1198.2760009765625 train_accuracy:  0.14300000667572021\n",
      "test cost:  2206.140380859375 test accuracy:  0.1120000034570694\n",
      "Next_Train----------: step =  14000\n",
      "train_cost:  1183.858642578125 train_accuracy:  0.10300000011920929\n",
      "test cost:  2263.580322265625 test accuracy:  0.07999999821186066\n",
      "Next_Train----------: step =  14500\n",
      "train_cost:  1216.640380859375 train_accuracy:  0.1589999943971634\n",
      "test cost:  2127.583740234375 test accuracy:  0.11500000208616257\n",
      "Next_Train----------: step =  15000\n",
      "train_cost:  1183.783447265625 train_accuracy:  0.08500000089406967\n",
      "test cost:  2269.984130859375 test accuracy:  0.041999999433755875\n",
      "Next_Train----------: step =  15500\n",
      "train_cost:  1263.6856689453125 train_accuracy:  0.18799999356269836\n",
      "test cost:  1985.1942138671875 test accuracy:  0.12600000202655792\n",
      "Next_Train----------: step =  16000\n",
      "train_cost:  1188.8372802734375 train_accuracy:  0.12300000339746475\n",
      "test cost:  2242.8349609375 test accuracy:  0.061000000685453415\n",
      "Next_Train----------: step =  16500\n",
      "train_cost:  1176.2076416015625 train_accuracy:  0.08799999952316284\n",
      "test cost:  2307.103271484375 test accuracy:  0.039000000804662704\n",
      "Next_Train----------: step =  17000\n",
      "train_cost:  1205.6019287109375 train_accuracy:  0.19200000166893005\n",
      "test cost:  2184.592529296875 test accuracy:  0.1379999965429306\n",
      "Next_Train----------: step =  17500\n",
      "train_cost:  1194.2354736328125 train_accuracy:  0.13600000739097595\n",
      "test cost:  2201.08154296875 test accuracy:  0.07900000363588333\n",
      "Next_Train----------: step =  18000\n",
      "train_cost:  1163.9896240234375 train_accuracy:  0.061000000685453415\n",
      "test cost:  2365.79638671875 test accuracy:  0.052000001072883606\n",
      "Next_Train----------: step =  18500\n",
      "train_cost:  1254.1383056640625 train_accuracy:  0.23499999940395355\n",
      "test cost:  2039.9725341796875 test accuracy:  0.14300000667572021\n",
      "Next_Train----------: step =  19000\n",
      "train_cost:  1201.778076171875 train_accuracy:  0.1550000011920929\n",
      "test cost:  2188.635498046875 test accuracy:  0.09700000286102295\n",
      "Next_Train----------: step =  19500\n",
      "train_cost:  1270.6434326171875 train_accuracy:  0.2879999876022339\n",
      "test cost:  1981.5 test accuracy:  0.18700000643730164\n",
      "Next_Train----------: step =  20000\n",
      "train_cost:  1183.170166015625 train_accuracy:  0.13899999856948853\n",
      "test cost:  2255.4287109375 test accuracy:  0.07100000232458115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "TIME_STEPS = 10\n",
    "INPUT_SIZE = 512\n",
    "BATCH_SIZE = 50\n",
    "BATCH_INDEX = 0\n",
    "OUTPUT_SIZE = 5120\n",
    "CELL_SIZE = 400\n",
    "LR = 0.001\n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "# loading data\n",
    "X_train = np.loadtxt(\"0131_spec_train_1000*5120.txt\")\n",
    "y_train = np.loadtxt(\"0131_mask_train_1000*5120.txt\")\n",
    "\n",
    "X_test = np.loadtxt(\"0131_spec_test_1000*5120.txt\")\n",
    "y_test = np.loadtxt(\"0131_mask_test_1000*5120.txt\")\n",
    "\n",
    "# batch_size=y_test.shape[0]\n",
    "\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 10, 512)\n",
    "#y_train = y_train.reshape(-1, 3, 512)\n",
    "X_test = X_test.reshape(-1, 10, 512)\n",
    "#y_test = y_test.reshape(-1, 3, 512)\n",
    "\n",
    "#  build RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# RNN cell\n",
    "\n",
    "model.add(SimpleRNN(\n",
    "    batch_input_shape=(None, TIME_STEPS, INPUT_SIZE),\n",
    "    # input_dim=INPUT_SIZE,\n",
    "    # input_length=TIME_STEPS,\n",
    "    output_dim=CELL_SIZE,\n",
    "    unroll=True\n",
    "))\n",
    "\n",
    "# output layer\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(OUTPUT_SIZE))\n",
    "model.add(Activation('hard_sigmoid'))\n",
    "\n",
    "# # optimizer\n",
    "#\n",
    "adam = Adam(LR)\n",
    "\n",
    "#optimizer\n",
    "#rmsprop = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # training\n",
    "#\n",
    "\n",
    "for step in range(20001):\n",
    "    # data shape = (batch_num, steps, inputs/outputs)\n",
    "    X_batch = X_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :, :]\n",
    "    Y_batch = y_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :]\n",
    "    cost = model.train_on_batch(X_batch, Y_batch)\n",
    "    BATCH_INDEX += BATCH_SIZE\n",
    "    BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print('Next_Train----------: step = ', step)\n",
    "        train_cost, train_accuracy = model.evaluate(X_train, y_train, batch_size=y_train.shape[0], verbose=False)\n",
    "        print('train_cost: ', train_cost, 'train_accuracy: ', train_accuracy)\n",
    "        cost, accuracy = model.evaluate(X_test, y_test, batch_size=y_test.shape[0], verbose=False)\n",
    "        print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "        \n",
    "       \n",
    "\n",
    "# print('Train-------------------------')\n",
    "#\n",
    "# history = model.fit(X_train, y_train, validation_split=0.25, epochs=3100, shuffle=True, batch_size=75, verbose=1)\n",
    "#\n",
    "# # Plot training & validation accuracy values\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()\n",
    "#\n",
    "# # Plot training & validation loss values\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()\n",
    "#\n",
    "# get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "#                                   [model.layers[1].output])\n",
    "# layer_output1 = get_3rd_layer_output([X_train])[0]\n",
    "#\n",
    "# print(layer_output1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
