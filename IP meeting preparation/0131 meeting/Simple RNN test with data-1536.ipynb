{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN test by data-3*512\n",
    "# 20000steps with lr = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results shown that the lr is too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/william/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(batch_input_shape=(None, 3, ..., unroll=True, units=1200)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next_Train----------: step =  0\n",
      "train_cost:  417.9826354980469 train_accuracy:  0.0\n",
      "test cost:  506.51263427734375 test accuracy:  0.0010000000474974513\n",
      "Next_Train----------: step =  500\n",
      "train_cost:  336.29443359375 train_accuracy:  0.13099999725818634\n",
      "test cost:  432.98828125 test accuracy:  0.08699999749660492\n",
      "Next_Train----------: step =  1000\n",
      "train_cost:  324.0320129394531 train_accuracy:  0.014999999664723873\n",
      "test cost:  440.6346130371094 test accuracy:  0.014999999664723873\n",
      "Next_Train----------: step =  1500\n",
      "train_cost:  314.4673156738281 train_accuracy:  0.039000000804662704\n",
      "test cost:  446.051025390625 test accuracy:  0.020999999716877937\n",
      "Next_Train----------: step =  2000\n",
      "train_cost:  305.2302551269531 train_accuracy:  0.041999999433755875\n",
      "test cost:  458.97589111328125 test accuracy:  0.01899999938905239\n",
      "Next_Train----------: step =  2500\n",
      "train_cost:  297.18231201171875 train_accuracy:  0.017000000923871994\n",
      "test cost:  485.4804382324219 test accuracy:  0.009999999776482582\n",
      "Next_Train----------: step =  3000\n",
      "train_cost:  296.03338623046875 train_accuracy:  0.0010000000474974513\n",
      "test cost:  475.8249206542969 test accuracy:  0.0\n",
      "Next_Train----------: step =  3500\n",
      "train_cost:  292.0138854980469 train_accuracy:  0.0010000000474974513\n",
      "test cost:  489.00762939453125 test accuracy:  0.0\n",
      "Next_Train----------: step =  4000\n",
      "train_cost:  291.71551513671875 train_accuracy:  0.0010000000474974513\n",
      "test cost:  509.7441711425781 test accuracy:  0.0\n",
      "Next_Train----------: step =  4500\n",
      "train_cost:  287.7360534667969 train_accuracy:  0.0010000000474974513\n",
      "test cost:  511.73663330078125 test accuracy:  0.0\n",
      "Next_Train----------: step =  5000\n",
      "train_cost:  285.58087158203125 train_accuracy:  0.0010000000474974513\n",
      "test cost:  502.9718017578125 test accuracy:  0.0\n",
      "Next_Train----------: step =  5500\n",
      "train_cost:  291.15460205078125 train_accuracy:  0.0020000000949949026\n",
      "test cost:  492.0361022949219 test accuracy:  0.0\n",
      "Next_Train----------: step =  6000\n",
      "train_cost:  286.0414733886719 train_accuracy:  0.004000000189989805\n",
      "test cost:  508.41180419921875 test accuracy:  0.0\n",
      "Next_Train----------: step =  6500\n",
      "train_cost:  283.22247314453125 train_accuracy:  0.009999999776482582\n",
      "test cost:  516.8599243164062 test accuracy:  0.00800000037997961\n",
      "Next_Train----------: step =  7000\n",
      "train_cost:  281.7067565917969 train_accuracy:  0.023000000044703484\n",
      "test cost:  546.1777954101562 test accuracy:  0.017000000923871994\n",
      "Next_Train----------: step =  7500\n",
      "train_cost:  282.3033752441406 train_accuracy:  0.03200000151991844\n",
      "test cost:  573.3843994140625 test accuracy:  0.02199999988079071\n",
      "Next_Train----------: step =  8000\n",
      "train_cost:  279.5552978515625 train_accuracy:  0.02500000037252903\n",
      "test cost:  539.0658569335938 test accuracy:  0.027000000700354576\n",
      "Next_Train----------: step =  8500\n",
      "train_cost:  277.2292785644531 train_accuracy:  0.03400000184774399\n",
      "test cost:  561.1757202148438 test accuracy:  0.02800000086426735\n",
      "Next_Train----------: step =  9000\n",
      "train_cost:  277.2045593261719 train_accuracy:  0.035999998450279236\n",
      "test cost:  587.9088134765625 test accuracy:  0.03400000184774399\n",
      "Next_Train----------: step =  9500\n",
      "train_cost:  275.1882019042969 train_accuracy:  0.05299999937415123\n",
      "test cost:  579.0493774414062 test accuracy:  0.039000000804662704\n",
      "Next_Train----------: step =  10000\n",
      "train_cost:  278.2464904785156 train_accuracy:  0.03400000184774399\n",
      "test cost:  566.6183471679688 test accuracy:  0.024000000208616257\n",
      "Next_Train----------: step =  10500\n",
      "train_cost:  280.28680419921875 train_accuracy:  0.004999999888241291\n",
      "test cost:  544.231689453125 test accuracy:  0.004000000189989805\n",
      "Next_Train----------: step =  11000\n",
      "train_cost:  275.4786376953125 train_accuracy:  0.03099999949336052\n",
      "test cost:  579.1599731445312 test accuracy:  0.02199999988079071\n",
      "Next_Train----------: step =  11500\n",
      "train_cost:  279.87176513671875 train_accuracy:  0.012000000104308128\n",
      "test cost:  581.172607421875 test accuracy:  0.014000000432133675\n",
      "Next_Train----------: step =  12000\n",
      "train_cost:  274.0667419433594 train_accuracy:  0.039000000804662704\n",
      "test cost:  572.0267333984375 test accuracy:  0.041999999433755875\n",
      "Next_Train----------: step =  12500\n",
      "train_cost:  273.5220031738281 train_accuracy:  0.0430000014603138\n",
      "test cost:  589.7264404296875 test accuracy:  0.039000000804662704\n",
      "Next_Train----------: step =  13000\n",
      "train_cost:  272.8061828613281 train_accuracy:  0.0430000014603138\n",
      "test cost:  598.4308471679688 test accuracy:  0.04600000008940697\n",
      "Next_Train----------: step =  13500\n",
      "train_cost:  272.77239990234375 train_accuracy:  0.05400000140070915\n",
      "test cost:  618.563232421875 test accuracy:  0.050999999046325684\n",
      "Next_Train----------: step =  14000\n",
      "train_cost:  273.4851989746094 train_accuracy:  0.017000000923871994\n",
      "test cost:  601.7257080078125 test accuracy:  0.00800000037997961\n",
      "Next_Train----------: step =  14500\n",
      "train_cost:  272.12738037109375 train_accuracy:  0.050999999046325684\n",
      "test cost:  610.2273559570312 test accuracy:  0.050999999046325684\n",
      "Next_Train----------: step =  15000\n",
      "train_cost:  280.1496887207031 train_accuracy:  0.028999999165534973\n",
      "test cost:  551.1513671875 test accuracy:  0.026000000536441803\n",
      "Next_Train----------: step =  15500\n",
      "train_cost:  277.80438232421875 train_accuracy:  0.004999999888241291\n",
      "test cost:  564.2650146484375 test accuracy:  0.004000000189989805\n",
      "Next_Train----------: step =  16000\n",
      "train_cost:  274.7159118652344 train_accuracy:  0.028999999165534973\n",
      "test cost:  575.6368408203125 test accuracy:  0.027000000700354576\n",
      "Next_Train----------: step =  16500\n",
      "train_cost:  273.38214111328125 train_accuracy:  0.03500000014901161\n",
      "test cost:  583.803466796875 test accuracy:  0.035999998450279236\n",
      "Next_Train----------: step =  17000\n",
      "train_cost:  275.898193359375 train_accuracy:  0.028999999165534973\n",
      "test cost:  568.239501953125 test accuracy:  0.029999999329447746\n",
      "Next_Train----------: step =  17500\n",
      "train_cost:  273.0318298339844 train_accuracy:  0.04899999871850014\n",
      "test cost:  583.560791015625 test accuracy:  0.04500000178813934\n",
      "Next_Train----------: step =  18000\n",
      "train_cost:  272.1277160644531 train_accuracy:  0.04899999871850014\n",
      "test cost:  591.4368286132812 test accuracy:  0.03999999910593033\n",
      "Next_Train----------: step =  18500\n",
      "train_cost:  274.3109436035156 train_accuracy:  0.003000000026077032\n",
      "test cost:  575.1871948242188 test accuracy:  0.003000000026077032\n",
      "Next_Train----------: step =  19000\n",
      "train_cost:  272.078125 train_accuracy:  0.01600000075995922\n",
      "test cost:  586.4422607421875 test accuracy:  0.012000000104308128\n",
      "Next_Train----------: step =  19500\n",
      "train_cost:  271.29168701171875 train_accuracy:  0.02199999988079071\n",
      "test cost:  590.2989501953125 test accuracy:  0.006000000052154064\n",
      "Next_Train----------: step =  20000\n",
      "train_cost:  270.7508850097656 train_accuracy:  0.04100000113248825\n",
      "test cost:  597.1170654296875 test accuracy:  0.017999999225139618\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "TIME_STEPS = 3\n",
    "INPUT_SIZE = 512\n",
    "BATCH_SIZE = 50\n",
    "BATCH_INDEX = 0\n",
    "OUTPUT_SIZE = 1536\n",
    "CELL_SIZE = 1200\n",
    "LR = 0.0001\n",
    "\n",
    "\n",
    "           \n",
    "           \n",
    "# loading data\n",
    "X_train = np.loadtxt(\"0126_spec_train_1000.txt\")\n",
    "y_train = np.loadtxt(\"0126_mask_train_1000.txt\")\n",
    "\n",
    "X_test = np.loadtxt(\"0126_spec_test_1000.txt\")\n",
    "y_test = np.loadtxt(\"0126_mask_test_1000.txt\")\n",
    "\n",
    "# batch_size=y_test.shape[0]\n",
    "\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 3, 512)\n",
    "#y_train = y_train.reshape(-1, 3, 512)\n",
    "X_test = X_test.reshape(-1, 3, 512)\n",
    "#y_test = y_test.reshape(-1, 3, 512)\n",
    "\n",
    "#  build RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# RNN cell\n",
    "\n",
    "model.add(SimpleRNN(\n",
    "    batch_input_shape=(None, TIME_STEPS, INPUT_SIZE),\n",
    "    # input_dim=INPUT_SIZE,\n",
    "    # input_length=TIME_STEPS,\n",
    "    output_dim=CELL_SIZE,\n",
    "    unroll=True\n",
    "))\n",
    "\n",
    "# output layer\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(OUTPUT_SIZE))\n",
    "model.add(Activation('hard_sigmoid'))\n",
    "\n",
    "# # optimizer\n",
    "#\n",
    "adam = Adam(LR)\n",
    "\n",
    "#optimizer\n",
    "#rmsprop = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # training\n",
    "#\n",
    "\n",
    "for step in range(20001):\n",
    "    # data shape = (batch_num, steps, inputs/outputs)\n",
    "    X_batch = X_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :, :]\n",
    "    Y_batch = y_train[BATCH_INDEX: BATCH_INDEX + BATCH_SIZE, :]\n",
    "    cost = model.train_on_batch(X_batch, Y_batch)\n",
    "    BATCH_INDEX += BATCH_SIZE\n",
    "    BATCH_INDEX = 0 if BATCH_INDEX >= X_train.shape[0] else BATCH_INDEX\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print('Next_Train----------: step = ', step)\n",
    "        train_cost, train_accuracy = model.evaluate(X_train, y_train, batch_size=y_train.shape[0], verbose=False)\n",
    "        print('train_cost: ', train_cost, 'train_accuracy: ', train_accuracy)\n",
    "        cost, accuracy = model.evaluate(X_test, y_test, batch_size=y_test.shape[0], verbose=False)\n",
    "        print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "        \n",
    "       \n",
    "\n",
    "# print('Train-------------------------')\n",
    "#\n",
    "# history = model.fit(X_train, y_train, validation_split=0.25, epochs=3100, shuffle=True, batch_size=75, verbose=1)\n",
    "#\n",
    "# # Plot training & validation accuracy values\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()\n",
    "#\n",
    "# # Plot training & validation loss values\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()\n",
    "#\n",
    "# get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "#                                   [model.layers[1].output])\n",
    "# layer_output1 = get_3rd_layer_output([X_train])[0]\n",
    "#\n",
    "# print(layer_output1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
